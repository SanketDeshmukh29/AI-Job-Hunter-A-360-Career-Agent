[
  {
    "title": "AI/ML Engineer Level 2 Jobs",
    "company": "CACI",
    "location": "Suitland-Silver Hill",
    "salary": "",
    "description": "AI/ML Engineer Level 2\n\nJob Category: Science\n\nTime Type: Full time\n\nMinimum Clearance Required to Start: TS/SCI\n\nEmployee Type: Regular\n\nPercentage of Travel Required: Up to 10%\n\nType of Travel: Local\n\u2022 * *\n\nThe Opportunity:\n\nCACI is seeking a skilled and experienced mid-level AI/ML Engineer to join our dynamic team to support a DoD client in Suitland, MD. The ideal candidate will have a strong background in machine learning, deep learning, and AI system development, with a proven track record of designing, developing, and deploying machine learning models. This role requires a deep understanding of MLOps, containerization, and CI/CD pipelines, as well as advanced knowledge in data preprocessing and cloud environments.\n\nResponsibilities:\n\u2022 Design, develop, and deploy machine learning models and manage pipelines using tools such as Azure ML, Kubeflow, or MLflow.\n\u2022 Implement and manage MLOps practices, including containerization (e.g., Docker, Kubernetes) and CI/CD pipelines.\n\u2022 Handle large datasets in cloud environments, performing advanced data preprocessing.\n\u2022 Develop custom AI APIs and integrate them into enterprise applications.\n\u2022 Ensure adherence to Responsible AI (RAI) policies and develop metrics, measurements, and evaluation methods for emerging and existing AI areas.\n\u2022 Collaborate with cross-functional teams to identify opportunities for AI/ML integration and improvement.\n\nQualifications:\n\n\u2022 TS/SCI Clearance\n\u2022 Bachelor's degree in Computer Science, Data Science, Mathematics, Statistics, Engineering, or a related field.\n\u2022 3-5 years of experience in machine learning, deep learning, or AI system development.\n\u2022 Experience in MLOps, containerization (e.g., Docker, Kubernetes), and CI/CD pipelines.\n\u2022 Proficiency in designing, developing, and deploying machine learning models.\n\u2022 Advanced knowledge in data preprocessing, including handling large datasets in cloud environments.\n\u2022 Experience in developing custom AI APIs and integrating them into enterprise applications.\n\u2022 Strong knowledge of programming languages for Machine Learning (Python, R, or similar).\n\u2022 Good understanding of AI cloud tools and capabilities.\n\u2022 Familiarity with Responsible AI (RAI) policies and development of metrics, measurements, and evaluation methods for AI.\n\nCertifications:\n\u2022 AI Engineer Associate (AI-102)\n\u2022 Microsoft Certified: Data Scientist Associate\n\u2022 Or similar relevant certifications\n\nPreferred Skills:\n\u2022 Experience with cloud platforms (Azure, AWS, GCP)\n\u2022 Knowledge of distributed computing frameworks (e.g., Apache Spark)\n\u2022 Familiarity with version control systems (e.g., Git)\n\nThis position is contingent on funding and may not be filled immediately. However, this position is representative of positions within CACI that are consistently available. Individuals who apply may also be considered for other positions at CACI.\n________________________________________________________________________________________\n\nWhat You Can Expect:\n\nA culture of integrity.\n\nAt CACI, we place character and innovation at the center of everything we do. As a valued team member, you'll be part of a high-performing group dedicated to our customer's missions and driven by a higher purpose - to ensure the safety of our nation.\n\nAn environment of trust.\n\nCACI values the unique contributions that every employee brings to our company and our customers - every day. You'll have the autonomy to take the time you need through a unique flexible time off benefit and have access to robust learning resources to make your ambitions a reality.\n\nA focus on continuous growth.\n\nTogether, we will advance our nation's most critical missions, build on our lengthy track record of business success, and find opportunities to break new ground - in your career and in our legacy.\n\nYour potential is limitless. So is ours.\n\nLearn more about CACI here.\n\n________________________________________________________________________________________\n\nPay Range: There are a host of factors that can influence final salary including, but not limited to, geographic location, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, education, and certifications. Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our broad and competitive mix of benefits options is designed to support and protect employees and their families. At CACI, you will receive comprehensive benefits such as; healthcare, wellness, financial, retirement, family support, continuing education, and time off benefits. Learn more here .\n\nThe proposed salary range for this position is:\n$79,400 - $162,700\n\nCACI is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, age, national origin, disability, status as a protected veteran, or any other protected characteristic.",
    "url": "https://www.clearancejobs.com/jobs/8614774/aiml-engineer-level-2?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "AI/ML Engineer Level 2",
    "company": "CACI",
    "location": "Suitland-Silver Hill",
    "salary": "",
    "description": "AI/ML Engineer Level 2\n\nJob Category: Science\n\nTime Type: Full time\n\nMinimum Clearance Required to Start: TS/SCI\n\nEmployee Type: Regular\n\nPercentage of Travel Required: Up to 10%\n\nType of Travel: Local\n\u2022 * *\n\nThe Opportunity:\n\nCACI is seeking a skilled and experienced mid-level AI/ML Engineer to join our dynamic team to support a DoD client in Suitland, MD. The ideal candidate will have a strong background in machine learning, deep learning, and AI system development, with a proven track record of designing, developing, and deploying machine learning models. This role requires a deep understanding of MLOps, containerization, and CI/CD pipelines, as well as advanced knowledge in data preprocessing and cloud environments.\n\nResponsibilities:\n\u2022 Design, develop, and deploy machine learning models and manage pipelines using tools such as Azure ML, Kubeflow, or MLflow.\n\u2022 Implement and manage MLOps practices, including containerization (e.g., Docker, Kubernetes) and CI/CD pipelines.\n\u2022 Handle large datasets in cloud environments, performing advanced data preprocessing.\n\u2022 Develop custom AI APIs and integrate them into enterprise applications.\n\u2022 Ensure adherence to Responsible AI (RAI) policies and develop metrics, measurements, and evaluation methods for emerging and existing AI areas.\n\u2022 Collaborate with cross-functional teams to identify opportunities for AI/ML integration and improvement.\n\nQualifications:\n\n\u2022 TS/SCI Clearance\n\u2022 Bachelor\u2019s degree in Computer Science, Data Science, Mathematics, Statistics, Engineering, or a related field.\n\u2022 3\u20135 years of experience in machine learning, deep learning, or AI system development.\n\u2022 Experience in MLOps, containerization (e.g., Docker, Kubernetes), and CI/CD pipelines.\n\u2022 Proficiency in designing, developing, and deploying machine learning models.\n\u2022 Advanced knowledge in data preprocessing, including handling large datasets in cloud environments.\n\u2022 Experience in developing custom AI APIs and integrating them into enterprise applications.\n\u2022 Strong knowledge of programming languages for Machine Learning (Python, R, or similar).\n\u2022 Good understanding of AI cloud tools and capabilities.\n\u2022 Familiarity with Responsible AI (RAI) policies and development of metrics, measurements, and evaluation methods for AI.\n\nCertifications:\n\u2022 AI Engineer Associate (AI-102)\n\u2022 Microsoft Certified: Data Scientist Associate\n\u2022 Or similar relevant certifications\n\nPreferred Skills:\n\u2022 Experience with cloud platforms (Azure, AWS, GCP)\n\u2022 Knowledge of distributed computing frameworks (e.g., Apache Spark)\n\u2022 Familiarity with version control systems (e.g., Git)\n\nThis position is contingent on funding and may not be filled immediately. However, this position is representative of positions within CACI that are consistently available. Individuals who apply may also be considered for other positions at CACI.\n\n________________________________________________________________________________________\n\nWhat You Can Expect:\n\nA culture of integrity.\n\nAt CACI, we place character and innovation at the center of everything we do. As a valued team member, you\u2019ll be part of a high-performing group dedicated to our customer\u2019s missions and driven by a higher purpose \u2013 to ensure the safety of our nation.\n\nAn environment of trust.\n\nCACI values the unique contributions that every employee brings to our company and our customers - every day. You\u2019ll have the autonomy to take the time you need through a unique flexible time off benefit and have access to robust learning resources to make your ambitions a reality.\n\nA focus on continuous growth.\n\nTogether, we will advance our nation's most critical missions, build on our lengthy track record of business success, and find opportunities to break new ground \u2014 in your career and in our legacy.\n\nYour potential is limitless. So is ours.\n\nLearn more about CACI here.\n\n________________________________________________________________________________________\n\nPay Range: There are a host of factors that can influence final salary including, but not limited to, geographic location, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, education, and certifications. Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our broad and competitive mix of benefits options is designed to support and protect employees and their families. At CACI, you will receive comprehensive benefits such as; healthcare, wellness, financial, retirement, family support, continuing education, and time off benefits. Learn more here.\n\nThe proposed salary range for this position is:\n$79,400 - $162,700\n\nCACI is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, age, national origin, disability, status as a protected veteran, or any other protected characteristic.",
    "url": "https://careers.caci.com/global/en/job/CACIGLOBAL319062EXTERNALENGLOBAL/AI-ML-Engineer-Level-2?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "ML Ops Engineer",
    "company": "Sev1Tech LLC",
    "location": "Arlington",
    "salary": "",
    "description": "Job Summary\n\nWe are seeking a skilled MLOps Engineer to join our team and ensure the seamless deployment, monitoring, and optimization of AI models in production.\n\nThe MLOps Engineer will design, implement, and maintain end-to-end machine learning pipelines, focusing on automating model deployment, monitoring model health, detecting data drift, and managing AI-related logging. This role will involve building scalable infrastructure and dashboards for real-time and historical insights, ensuring models are secure, performant, and aligned with business needs.\n\nKey Responsibilities\n\u2022 Model Deployment: Deploy and manage machine learning models in production using tools like MLflow, Kubeflow, or AWS SageMaker, ensuring scalability and low latency.\n\u2022 Monitoring and Observability: Build and maintain dashboards using Grafana, Prometheus, or Kibana to track real-time model health (e.g., accuracy, latency) and historical trends.\n\u2022 Data Drift Detection: Implement drift detection pipelines using tools like Evidently AI or Alibi Detect to identify shifts in data distributions and trigger alerts or retraining.\n\u2022 Logging and Tracing: Set up centralized logging with ELK Stack or Open Telemetry to capture AI inference events, errors, and audit trails for debugging and compliance.\n\u2022 Pipeline Automation: Develop CI/CD pipelines with GitHub Actions or Jenkins to automate model updates, testing, and deployment.\n\u2022 Security and Compliance: Apply secure-by-design principles to protect data pipelines and models, using encryption, access controls, and compliance with regulations like GDPR or NIST AI RMF.\n\u2022 Collaboration: Work with data scientists, AI Integration Engineers, and DevOps teams to align model performance with business requirements and infrastructure capabilities.\n\u2022 Optimization: Optimize models for production (e.g., via quantization or pruning) and ensure efficient resource usage on cloud platforms like AWS, Azure, or Google Cloud.\n\u2022 Documentation: Maintain clear documentation of pipelines, dashboards, and monitoring processes for cross-team transparency.\n\nQualifications\n\u2022 Education: Bachelor\u2019s or Master\u2019s degree in computer science, Data Science, Engineering, or a related field.\n\u2022 Experience:\n\u2022 5+ years in MLOps, DevOps, or software engineering with a focus on AI/ML systems.\n\u2022 Proven experience deploying models in production using MLflow, Kubeflow, or cloud platforms (AWS SageMaker, Azure ML).\n\u2022 Hands-on experience with observability tools like Prometheus, Grafana, or Datadog for real-time monitoring.\n\u2022 Technical Skills:\n\u2022 Proficiency in Python and SQL; familiarity with JavaScript or Go is a plus.\n\u2022 Expertise in containerization (Docker, Kubernetes) and CI/CD tools (GitHub Actions, Jenkins).\n\u2022 Knowledge of time-series databases (e.g., InfluxDB, TimescaleDB) and logging frameworks (e.g., ELK Stack, Open Telemetry).\n\u2022 Experience with drift detection tools (e.g., Evidently AI, Alibi Detect) and visualization libraries (e.g., Plotly, Seaborn).\n\u2022 AI-Specific Skills:\n\u2022 Understanding of model performance metrics (e.g., precision, recall, AUC) and drift detection methods (e.g., KS test, PSI).\n\u2022 Familiarity with AI vulnerabilities (e.g., data poisoning, adversarial attacks) and mitigation tools like Adversarial Robustness Toolbox (ART).\n\u2022 Soft Skills:\n\u2022 Strong problem-solving and debugging skills for resolving pipeline and monitoring issues.\n\u2022 Excellent collaboration and communication skills to work with cross-functional teams.\n\u2022 Attention to detail for ensuring accurate and secure dashboard reporting.\n\u2022 Must be eligible to obtain a Department of Homeland Security EOD clearance ( Requirements 1. US Citizenship, 2. Favorable Background Investigation)\n\nPreferred Qualifications\n\u2022 Experience with LLM monitoring tools like LangSmith or Helicone for generative AI applications.\n\u2022 Knowledge of compliance frameworks (e.g., GDPR, HIPAA) for secure data handling.\n\u2022 Contributions to open-source MLOps projects or familiarity with X platform discussions on #MLOps or #AIOps.\n\nAbout US\n\nWelcome to Sev1Tech! Founded in 2010, we are proud to be a leading provider of IT modernization, engineering, and program management solutions. Our commitment is to deliver exceptional program and IT support services that empower critical missions for both Federal and Commercial clients.\n\nAt Sev1Tech, our mission is clear: Build better companies. Enable better government. Protect our nation. Build better humans across the country. We believe that through innovation and dedication, we can make a significant impact on the communities we serve\n\n.\nJoin the Sev1Tech family, where your potential for greatness is limitless! Here, you will not only achieve remarkable accomplishments but also enjoy a fulfilling and rewarding career progression. We invite you to explore opportunities with us and become part of a team that values your contributions and growt\n\nh.\nReady to take the next step? Apply directly through our website: Sev1Tech Careers and use the hashtag #joinSev1Tech to connect with us on social med\n\nia!\nFor any additional questions or to submit referrals, feel free to reach out to recruiting@sev1tech.\n\ncom.",
    "url": "https://www.linkedin.com/jobs/view/ml-ops-engineer-at-sev1tech-llc-4318935073?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "AI Engineer (Python & Backend Frameworks)",
    "company": "VeeRteq Solutions LLC",
    "location": "Washington",
    "salary": "",
    "description": "Role - AI Engineer (Python & Backend Frameworks)\n\nLocation: Remote (US/Canada)\n\nDuration: Long Term\n\nAs an AI Engineer, you will be an integral member of a collaborative multi-asset trading team. You'll work on high-impact machine learning (ML) and artificial intelligence (AI) initiatives that are central to our business strategy. In this role, you will build critical infrastructure and tooling that leverages AI and ML technology to enhance productivity, efficiency, and discover innovative paths to challenging business and technology problems. Surrounded by cutting-edge technology and experienced trading teams, you will have the opportunity to tackle fascinating new projects while becoming a subject-matter expert in a critical and innovative role.\n\nKey Responsibilities\n\u2022 Drive end-to-end development of AI infrastructure and AI driven applications: from initial proof-of-concept to production deployment and ongoing maintenance.\n\u2022 Collaborate with technologists, traders, quantitative researchers, and data scientists to identify high-impact opportunities for integrating AI and machine learning into technology and business use cases.\n\u2022 Implement automated systems for continuous training, validation, and monitoring of models, minimizing downtime and ensuring reliability.\n\u2022 Provide technical leadership in selecting, integrating, and optimizing AI and ML frameworks, libraries, and tools across diverse hardware and software environments.\n\u2022 Create and maintain feature pipelines, feature stores, and model stores.\n\u2022 Develop frameworks to enable scalable, reproducible research.\n\u2022 Proactively troubleshoot performance bottlenecks, conduct root-cause analyses, and implement solutions to optimize GPU or CPU resource usage.\n\nQualifications\n\u2022 Bachelor's or advanced degree in Computer Science, Machine Learning, Artificial Intelligence, or a related field.\n\u2022 3+ years of experience working with machine learning and artificial intelligence technology.\n\u2022 Strong understanding of core machine learning and artificial intelligence concepts.\n\u2022 Excellent programming skills in Python.\n\u2022 Demonstrated experience in building, validating, deploying, monitoring, and updating production ML and AI models.\n\u2022 Hands-on experience with MLOps and AIOps infrastructure and tooling.\n\u2022 Proficient in problem-solving and analytical reasoning.\n\u2022 Exceptional communication and collaboration skills.\n\u2022 Experience with ML frameworks such as TensorFlow, PyTorch, TensorRT, or ONNX.\n\u2022 Experience with Large Language Models, including RAG and fine-tuning techniques.\n\u2022 Familiarity with compute infrastructure necessary to support operating AI and ML technology.\n\nKey Responsibilities\n\u2022 Develop and enhance AI agents and backend systems for Mastercard's AI platform\n\u2022 Evaluate LLMs and emerging technologies to identify innovation opportunities\n\u2022 Design and optimize prompts for LLMs\n\u2022 Implement safeguards to ensure secure, ethical AI responses\n\u2022 Build APIs, microservices, and data integrations for AI features\n\u2022 Write clean, maintainable code following industry best practices\n\u2022 Stay current with advancements in AI and software engineering\n\nAll About You\n\u2022 Strong hands-on experience and understanding of AI/ML concepts and enthusiasm for generative AI\n\u2022 Experience with Python and backend frameworks (e.g., FastAPI, Flask, Node.js)\n\u2022 Knowledge of REST APIs and cloud platforms (AWS, Azure, GCP)\n\u2022 Strong analytical skills and curiosity for exploring new AI capabilities\n\u2022 Collaborative mindset and openness to feedback and mentorship\n\u2022 Interest in prompt engineering, AI safety, and scalable deployment",
    "url": "https://www.linkedin.com/jobs/view/ai-engineer-python-backend-frameworks-at-veerteq-solutions-llc-4332761727?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "AI and ML Engineer Jobs",
    "company": "Booz Allen Hamilton",
    "location": "Alexandria",
    "salary": "",
    "description": "Job Number: R0227633\n\nAI and ML Engineer\n\nThe Opportunity:\n\nAs an experienced engineer, you know that machine learning is critical to understanding and processing massive datasets. Your ability to conduct statistical analyses on workflow processes using ML techniques makes you an integral part of delivering a customer-focused solution. We need your technical knowledge and desire to problem-solve to support research and development for a key national defense client. As an Artificial Intelligence (AI) and Machine Learning (ML) Engineer on our intelligence team, you'll train, test, deploy, and maintain models that learn from data.\n\nIn this role, you'll own and define the direction of mission-critical solutions by applying best-fit ML algorithms and technologies. You'll be part of a large community of ML engineers across the company and collaborate with software developers and engineers as well as end users to deliver world-class solutions to develop and drive solutions to remote sensing issues for operations clients. You will be testing and driving AI and ML concepts and solutions for a data-intensive system. As data feeds continue to be brought online, the relatively fixed number of operators needs your help driving solutions. Your advanced skills and extensive technical expertise will guide clients as they navigate the landscape of ML algorithms, tools, and frameworks.\n\nWork with us to solve real-world challenges and define ML strategy.\n\nJoin us. The world can't wait.\n\nYou Have:\n\u2022 4+ years of experience delivering AI and ML based solutions for object identification and classification\n\u2022 4+ years of experience with Python coding, including for AI and ML solutions\n\u2022 Experience with remote sensing image processing, data exploitation, and algorithm development\n\u2022 Experience with software configuration management using Git\n\u2022 Ability to execute machine learning models in a Linux environment\n\u2022 Active TS/SCI clearance; willingness to take a polygraph exam\n\u2022 Bachelor's degree\n\nNice If You Have:\n\u2022 Experience with AWS\n\u2022 Knowledge of sensor capabilities\n\u2022 Ability to work with limited guidance and clear direction\n\u2022 Possession of excellent verbal and written communication skills, including with peers and clients\n\nClearance:\n\nApplicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance is required.\n\nCompensation\n\nAt Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen's benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.\n\nSalary at Booz Allen is determined by various factors, including but not limited to location, the individual's particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $99,000.00 to $225,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen's total compensation package for employees. This posting will close within 90 days from the Posting Date.\n\nIdentity Statement\n\nAs part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.\n\nWork Model\n\nOur people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.\n\u2022 If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility.\n\u2022 If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role.\n\nCommitment to Non-Discrimination\n\nAll qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law.",
    "url": "https://www.clearancejobs.com/jobs/8577608/ai-and-ml-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-27T00:00:00.000Z"
  },
  {
    "title": "Sr. Lead Machine Learning Engineer, Shopping (Remote-Eligible)",
    "company": "Capital One",
    "location": "McLean",
    "salary": "",
    "description": "Sr. Lead Machine Learning Engineer, Shopping (Remote-Eligible)\n\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One Shopping, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs.\n\nAs a Capital One Machine Learning Engineer (MLE), you'll be part of an Agile team dedicated to productionizing machine learning applications and systems at scale. You\u2019ll participate in the detailed technical design, development, and implementation of machine learning applications using existing and emerging technology platforms. You\u2019ll focus on machine learning architectural design, develop and review model and application code, and ensure high availability and performance of our machine learning applications. You'll have the opportunity to continuously learn and apply the latest innovations and best practices in machine learning engineering.\n\nWhat you\u2019ll do in the role:\n\u2022 The MLE role overlaps with many disciplines, such as Ops, Modeling, and Data Engineering. In this role, you'll be expected to perform many ML engineering activities, including one or more of the following:\n\u2022 Design, build, and/or deliver ML models and components that solve real-world business problems, while working in collaboration with the Product and Data Science teams.\n\u2022 Inform your ML infrastructure decisions using your understanding of ML modeling techniques and issues, including choice of model, data, and feature selection, model training, hyperparameter tuning, dimensionality, bias/variance, and validation).\n\u2022 Solve complex problems by writing and testing application code, developing and validating ML models, and automating tests and deployment.\n\u2022 Collaborate as part of a cross-functional Agile team to create and enhance software that enables state-of-the-art big data and ML applications.\n\u2022 Retrain, maintain, and monitor models in production.\n\u2022 Leverage or build cloud-based architectures, technologies, and/or platforms to deliver optimized ML models at scale.\n\u2022 Construct optimized data pipelines to feed ML models.\n\u2022 Leverage continuous integration and continuous deployment best practices, including test automation and monitoring, to ensure successful deployment of ML models and application code.\n\u2022 Ensure all code is well-managed to reduce vulnerabilities, models are well-governed from a risk perspective, and the ML follows best practices in Responsible and Explainable AI.\n\u2022 Use programming languages like Python, Scala, or Java.\n\nBasic Qualifications:\n\u2022 Bachelor\u2019s degree\n\u2022 At least 8 years of experience designing and building data-intensive solutions using distributed computing (Internship experience does not apply)\n\u2022 At least 4 years of experience programming with Python, Scala, or Java\n\u2022 At least 3 years of experience building, scaling, and optimizing ML systems\n\u2022 At least 2 years of experience leading teams developing ML solutions\n\nPreferred Qualifications:\n\u2022 Master's or doctoral degree in computer science, electrical engineering, mathematics, or a similar field\n\u2022 Experience developing and deploying ML solutions in a public cloud such as AWS, Azure, or Google Cloud Platform\n\u2022 4+ years of on-the-job experience with an industry recognized ML framework such as scikit-learn, PyTorch, Dask, Spark, or TensorFlow\n\u2022 3+ years of experience developing performant, resilient, and maintainable code\n\u2022 3+ years of experience with data gathering and preparation for ML models\n\u2022 3+ years of people management experience\n\u2022 ML industry impact through conference presentations, papers, blog posts, open source contributions, or patents\n\u2022 3+ years of experience building production-ready data pipelines that feed ML models\n\u2022 Ability to communicate complex technical concepts clearly to a variety of audiences\n\nCapital One will consider sponsoring a new qualified applicant for employment authorization for this position.\n\nThe minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.\n\nRemote (Regardless of Location): $204,900 - $233,800 for Sr. Lead Machine Learning Engineer\n\nMcLean, VA: $225,400 - $257,200 for Sr. Lead Machine Learning Engineer\n\nCandidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter.\n\nThis role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\n\nThis role is expected to accept applications for a minimum of 5 business days.\n\nNo agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\n\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\n\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\n\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",
    "url": "https://www.capitalonecareers.com/job/mclean/sr-lead-machine-learning-engineer-shopping-remote-eligible/1732/87800123136?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "AI/ML Engineer with Security Clearance",
    "company": "ClearanceJobs",
    "location": "Burke",
    "salary": "",
    "description": "Job Title: AI/ML Engineer Location: Springfield, VA Eligibility: Candidate must possess an active TS/SCI clearance Job Description: In this role, you\u2019ll help shape the strategic direction of high-impact\n\nsolutions by applying advanced machine learning methods to complex\n\noperational challenges. As part of a broad network of ML engineers,\n\nyou\u2019ll work closely with software teams and mission users to design and\n\ndeploy innovative capabilities that address critical remote sensing\n\nneeds. You\u2019ll play a key role in testing and implementing AI and ML\n\nconcepts within a demanding, data-rich environment, supporting operators\n\nwho rely on intelligent systems to scale mission effectiveness. Your\n\ntechnical depth and expertise will help guide stakeholders in selecting\n\nand applying the most effective algorithms, tools, and frameworks to\n\nsolve real-world problems. This project is focused on accelerating the fusion of multi-sensor\n\ndetections into persistent, time-critical object tracks. Your work will\n\nhelp enable rapid, reliable decision-making in operational environments\n\nby integrating AI/ML with GEOINT and sensor fusion frameworks. Must-Have Requirements: - 4+ years of experience delivering AI/ML based solutions for object\n\nidentification and classification - 4+ years of experience with Python coding, and Python coding for\n\nAI/ML solutions - Experience applying AI/ML to tracking, sensor fusion, or GEOINT data\n\nworkflows - Familiarity with real-time or near-real-time data processing for\n\nmulti-sensor systems - Experience with remote sensing image processing, data exploitation,\n\nand algorithm development - Experience with software configuration management using Git - Ability to execute machine learning models in a Linux environment - Active TS/SCI clearance; willingness to take a polygraph exam - Bachelor's degree & 4 years of experience (for mid level) or\n\nBacehlors degree &10 years of experience (for senior level) Nice If You Have: - Experience with AWS - Knowledge sensor capabilities - Background in multi-sensor data association, track correlation, or\n\npersistent surveillance analytics - Ability to work with limited guidance and clear direction - Possession of excellent verbal and written communication skills,\n\nwith peers and clients",
    "url": "https://www.linkedin.com/jobs/view/ai-ml-engineer-with-security-clearance-at-clearancejobs-4319479793?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Principal AI/ML Engineer - Remote",
    "company": "UnitedHealth Group",
    "location": "Arlington",
    "salary": "",
    "description": "Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start Caring. Connecting. Growing together.\n\nOptum AI is UnitedHealth Group's enterprise AI team. We are AI/ML scientists and engineers with deep expertise in AI/ML engineering for health care. We develop AI/ML solutions for the highest impact opportunities across UnitedHealth Group businesses including UnitedHealthcare, Optum Financial, Optum Health, Optum Insight, and Optum Rx. In addition to transforming the health care journey through responsible AI/ML innovation, our charter also includes developing and supporting an enterprise AI/ML development platform.\n\nOptum AI team members:\n\u2022 Have impact at scale: We have the data and resources to make an impact at scale. When our solutions are deployed, they have the potential to make health care system work better for everyone\n\u2022 Do ground-breaking work: Many of our current projects involve cutting edge ML, NLP and LLM techniques. Generative AI methods for working with structured and unstructured health care data are continuously being developed and improved. We are working in one of the most important frontiers of AI/ML research and development\n\u2022 Partner with world-class experts on innovative solutions: Our team members are developing novel AI/ML solutions to business challenges. In some cases, this includes the opportunity to file patents and publish papers about the methods we develop. We also collaborate with AI/ML researchers at some of the world's top universities\n\nYou'll enjoy the flexibility to work remotely* from anywhere within the U.S. as you take on some tough challenges. For all hires in the Minneapolis or Washington, D.C. area, you will be required to work in the office a minimum of four days per week.\n\nPrimary Responsibilities:\n\u2022 Drive end-to-end Machine Learning projects that have a high degree of ambiguity, scale and complexity\n\u2022 Build Machine Learning models, perform proof-of-concept, experiment, optimize, and deploy your models into production; work closely with software engineers to assist in productionizing the ML models\n\u2022 Perform hands-on analysis and modeling of healthcare data sets to develop insights that increase business value\n\u2022 Run A/B experiments, gather data, and perform statistical analysis\n\u2022 Establish scalable, efficient, automated processes for large-scale data analysis, machine-learning model development, model validation and serving\n\u2022 Research and implement innovative machine learning approaches\n\u2022 Mentor and help recruit AI/ML scientists and machine learning engineers to the team\n\u2022 Present findings and insights to senior leadership and at internal venues\n\u2022 Be the thought leader in cutting-edge AI research and proactively pursue IP submissions\n\nYou'll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.\n\nRequired Qualifications:\n\u2022 PhD in AI, computer science, data science, applied math or related technical fields\n\u2022 10+ years of industry/academic experience in machine learning or a related field\n\u2022 5+ years of building models for business application experience\n\u2022 5+ years leading technical teams\n\u2022 Advanced understanding of Deep Learning with applications in NLP and multimodal modeling\n\u2022 Proven solid Python programming skills and experience with deep learning frameworks such as PyTorch or TensorFlow\n\u2022 Experienced mathematical background, especially in optimization theory, stochastic algorithms, and/or numerical methods\n\u2022 Experience with state-of-the-art algorithms and topologies including, but not limited to: GNNs, GANs, Transformers, deep and wide, SSMs, LLMs among others\n\u2022 Proven in-depth knowledge in Generative AI technology and Large Language Models (LLM) with focus in LLM optimization\n\nPreferred Qualifications:\n\u2022 Experience in AI/ML in the healthcare and or Fintech sector\n\u2022 Experience working with cross-functional and distributed teams in a global and diverse environment\n\u2022 Experience in establishing AI/ML best practices, standards, and ethics\n\u2022 All employees working remotely will be required to adhere to UnitedHealth Group\u2019s Telecommuter Policy.\n\nCalifornia, Colorado, Connecticut, Hawaii, Nevada, New Jersey, New York, Maryland, Rhode Island, Washington, Washington, D.C. Residents Only: The salary range for this role is $122,100 to $234,700 annually. Pay is based on several factors including but not limited to local labor markets, education, work experience, certifications, etc. UnitedHealth Group complies with all minimum wage laws as applicable. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you\u2019ll find a far-reaching choice of benefits and incentives.\n\nApplication Deadline: This will be posted for a minimum of 2 business days or until a sufficient candidate pool has been collected. Job posting may come down early due to volume of applicants.\n\nAt UnitedHealth Group, our mission is to help people live healthier lives and make the health system work better for everyone. We believe everyone\u2013of every race, gender, sexuality, age, location and income\u2013deserves the opportunity to live their healthiest life. Today, however, there are still far too many barriers to good health which are disproportionately experienced by people of color, historically marginalized groups and those with lower incomes. We are committed to mitigating our impact on the environment and enabling and delivering equitable care that addresses health disparities and improves health outcomes \u2014 an enterprise priority reflected in our mission.\n\nUnitedHealth Group is an Equal Employment Opportunity employer under applicable law and qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status, or any other characteristic protected by local, state, or federal laws, rules, or regulations.\n\nUnitedHealth Group is a drug - free workplace. Candidates are required to pass a drug test before beginning employment.\n\n#OptumTechPJ",
    "url": "https://usnlx.com/arlington-va/principal-aiml-engineer-remote/2CFF1B20BB7E4072BFB2C0D19F587866/job/?vs=28&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "AI/ML Engineer/Digital Mapping (Jr.)",
    "company": "Quadrant, Inc.",
    "location": "Vienna",
    "salary": "",
    "description": "AI/ML Engineer/Digital Mapping (Jr)\nVienna, VA\nPay From: $28.00 per hour\n\nMUST:\nEntry level AI/ML Engineer (digital mapping)\nProgramming in Python and familiarity with ML libraries.\nUnderstanding of image processing and an interest in remote sensing/ GIS tools.\nStrong attention to detail in data preparation and annotation.\nInterest in generative AI and how it can be applied to infrastructure/ spatial analytics.\nProactive and resourceful with a strong willingness to learn.\nExcellent communication skills for documenting work and collaborating across teams.\nDetail-oriented mindset with the ability to manage multiple tasks effectively.\nBachelor s degree (completed or in progress) in Computer Science, Data Science, AI/ML, Geospatial Science, or related field.\n\nDUTIES:\nAssist with training, testing and fine-tuning AI/ML models for remote sending data (imagery, 3D scans, point clouds).\nSupport development of GenAI tools for reporting, insights, and automation.\nWork on GeoAI pipelines that process georeferenced datasets for mapping, temporal change detection, and digital twins.\nAnnotate, clean, and validate data to support model accuracy and reliability.\nRun experiments and contribute to performance evaluation of computer vision and geospatial models.\nDocument workflows, maintain datasets, and assist in deployment preparation.\nParticipate in weekend coverage schedules to ensure data and models run smoothly.\n\nQuadrant is an affirmative action/equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, status as a protected veteran, or status as an individual with a disability. Healthcare benefits are offered to all eligible employees according to compliance mandated by the Affordable Care Act .",
    "url": "https://www.indeed.com/viewjob?jk=10d6326e5a787734&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Sr. Lead Machine Learning Engineer, Shopping (Remote-Eligible)",
    "company": "Capital One",
    "location": "McLean",
    "salary": "",
    "description": "Sr. Lead Machine Learning Engineer, Shopping (Remote-Eligible)\n\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One Shopping, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs.\n\nAs a Capital One Machine Learning Engineer (MLE), you'll be part of an Agile team dedicated to productionizing machine learning applications and systems at scale. You'll participate in the detailed technical design, development, and implementation of machine learning applications using existing and emerging technology platforms. You'll focus on machine learning architectural design, develop and review model and application code, and ensure high availability and performance of our machine learning applications. You'll have the opportunity to continuously learn and apply the latest innovations and best practices in machine learning engineering.\n\nWhat you'll do in the role:\n\u2022 The MLE role overlaps with many disciplines, such as Ops, Modeling, and Data Engineering. In this role, you'll be expected to perform many ML engineering activities, including one or more of the following:\n\u2022 Design, build, and/or deliver ML models and components that solve real-world business problems, while working in collaboration with the Product and Data Science teams.\n\u2022 Inform your ML infrastructure decisions using your understanding of ML modeling techniques and issues, including choice of model, data, and feature selection, model training, hyperparameter tuning, dimensionality, bias/variance, and validation).\n\u2022 Solve complex problems by writing and testing application code, developing and validating ML models, and automating tests and deployment.\n\u2022 Collaborate as part of a cross-functional Agile team to create and enhance software that enables state-of-the-art big data and ML applications.\n\u2022 Retrain, maintain, and monitor models in production.\n\u2022 Leverage or build cloud-based architectures, technologies, and/or platforms to deliver optimized ML models at scale.\n\u2022 Construct optimized data pipelines to feed ML models.\n\u2022 Leverage continuous integration and continuous deployment best practices, including test automation and monitoring, to ensure successful deployment of ML models and application code.\n\u2022 Ensure all code is well-managed to reduce vulnerabilities, models are well-governed from a risk perspective, and the ML follows best practices in Responsible and Explainable AI.\n\u2022 Use programming languages like Python, Scala, or Java.\n\nBasic Qualifications:\n\u2022 Bachelor's degree\n\u2022 At least 8 years of experience designing and building data-intensive solutions using distributed computing (Internship experience does not apply)\n\u2022 At least 4 years of experience programming with Python, Scala, or Java\n\u2022 At least 3 years of experience building, scaling, and optimizing ML systems\n\u2022 At least 2 years of experience leading teams developing ML solutions\n\nPreferred Qualifications:\n\u2022 Master's or doctoral degree in computer science, electrical engineering, mathematics, or a similar field\n\u2022 Experience developing and deploying ML solutions in a public cloud such as AWS, Azure, or Google Cloud Platform\n\u2022 4+ years of on-the-job experience with an industry recognized ML framework such as scikit-learn, PyTorch, Dask, Spark, or TensorFlow\n\u2022 3+ years of experience developing performant, resilient, and maintainable code\n\u2022 3+ years of experience with data gathering and preparation for ML models\n\u2022 3+ years of people management experience\n\u2022 ML industry impact through conference presentations, papers, blog posts, open source contributions, or patents\n\u2022 3+ years of experience building production-ready data pipelines that feed ML models\n\u2022 Ability to communicate complex technical concepts clearly to a variety of audiences\n\nCapital One will consider sponsoring a new qualified applicant for employment authorization for this position.\n\nThe minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.\n\nRemote (Regardless of Location): $204,900 - $233,800 for Sr. Lead Machine Learning Engineer\n\nMcLean, VA: $225,400 - $257,200 for Sr. Lead Machine Learning Engineer\n\nCandidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate's offer letter.\n\nThis role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\n\nThis role is expected to accept applications for a minimum of 5 business days.\n\nNo agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City's Fair Chance Act; Philadelphia's Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\n\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\n\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\n\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",
    "url": "https://www.ziprecruiter.com/c/Capitalone/Job/Sr.-Lead-Machine-Learning-Engineer,-Shopping-(Remote-Eligible)/-in-Mclean,VA?jid=41a67ef17e1338d4&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "AI/ML Engineer Level 2 Jobs",
    "company": "CACI",
    "location": "Suitland-Silver Hill",
    "salary": "",
    "description": "AI/ML Engineer Level 2\n\nJob Category: Science\n\nTime Type: Full time\n\nMinimum Clearance Required to Start: TS/SCI\n\nEmployee Type: Regular\n\nPercentage of Travel Required: Up to 10%\n\nType of Travel: Local\n\u2022 * *\n\nThe Opportunity:\n\nCACI is seeking a skilled and experienced mid-level AI/ML Engineer to join our dynamic team to support a DoD client in Suitland, MD. The ideal candidate will have a strong background in machine learning, deep learning, and AI system development, with a proven track record of designing, developing, and deploying machine learning models. This role requires a deep understanding of MLOps, containerization, and CI/CD pipelines, as well as advanced knowledge in data preprocessing and cloud environments.\n\nResponsibilities:\n\u2022 Design, develop, and deploy machine learning models and manage pipelines using tools such as Azure ML, Kubeflow, or MLflow.\n\u2022 Implement and manage MLOps practices, including containerization (e.g., Docker, Kubernetes) and CI/CD pipelines.\n\u2022 Handle large datasets in cloud environments, performing advanced data preprocessing.\n\u2022 Develop custom AI APIs and integrate them into enterprise applications.\n\u2022 Ensure adherence to Responsible AI (RAI) policies and develop metrics, measurements, and evaluation methods for emerging and existing AI areas.\n\u2022 Collaborate with cross-functional teams to identify opportunities for AI/ML integration and improvement.\n\nQualifications:\n\n\u2022 TS/SCI Clearance\n\u2022 Bachelor's degree in Computer Science, Data Science, Mathematics, Statistics, Engineering, or a related field.\n\u2022 3-5 years of experience in machine learning, deep learning, or AI system development.\n\u2022 Experience in MLOps, containerization (e.g., Docker, Kubernetes), and CI/CD pipelines.\n\u2022 Proficiency in designing, developing, and deploying machine learning models.\n\u2022 Advanced knowledge in data preprocessing, including handling large datasets in cloud environments.\n\u2022 Experience in developing custom AI APIs and integrating them into enterprise applications.\n\u2022 Strong knowledge of programming languages for Machine Learning (Python, R, or similar).\n\u2022 Good understanding of AI cloud tools and capabilities.\n\u2022 Familiarity with Responsible AI (RAI) policies and development of metrics, measurements, and evaluation methods for AI.\n\nCertifications:\n\u2022 AI Engineer Associate (AI-102)\n\u2022 Microsoft Certified: Data Scientist Associate\n\u2022 Or similar relevant certifications\n\nPreferred Skills:\n\u2022 Experience with cloud platforms (Azure, AWS, GCP)\n\u2022 Knowledge of distributed computing frameworks (e.g., Apache Spark)\n\u2022 Familiarity with version control systems (e.g., Git)\n\nThis position is contingent on funding and may not be filled immediately. However, this position is representative of positions within CACI that are consistently available. Individuals who apply may also be considered for other positions at CACI.\n________________________________________________________________________________________\n\nWhat You Can Expect:\n\nA culture of integrity.\n\nAt CACI, we place character and innovation at the center of everything we do. As a valued team member, you'll be part of a high-performing group dedicated to our customer's missions and driven by a higher purpose - to ensure the safety of our nation.\n\nAn environment of trust.\n\nCACI values the unique contributions that every employee brings to our company and our customers - every day. You'll have the autonomy to take the time you need through a unique flexible time off benefit and have access to robust learning resources to make your ambitions a reality.\n\nA focus on continuous growth.\n\nTogether, we will advance our nation's most critical missions, build on our lengthy track record of business success, and find opportunities to break new ground - in your career and in our legacy.\n\nYour potential is limitless. So is ours.\n\nLearn more about CACI here.\n\n________________________________________________________________________________________\n\nPay Range: There are a host of factors that can influence final salary including, but not limited to, geographic location, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, education, and certifications. Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our broad and competitive mix of benefits options is designed to support and protect employees and their families. At CACI, you will receive comprehensive benefits such as; healthcare, wellness, financial, retirement, family support, continuing education, and time off benefits. Learn more here .\n\nThe proposed salary range for this position is:\n$79,400 - $162,700\n\nCACI is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, age, national origin, disability, status as a protected veteran, or any other protected characteristic.",
    "url": "https://www.clearancejobs.com/jobs/8614774/aiml-engineer-level-2?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "AI/ML Engineer Level 2",
    "company": "CACI",
    "location": "Suitland-Silver Hill",
    "salary": "",
    "description": "AI/ML Engineer Level 2\n\nJob Category: Science\n\nTime Type: Full time\n\nMinimum Clearance Required to Start: TS/SCI\n\nEmployee Type: Regular\n\nPercentage of Travel Required: Up to 10%\n\nType of Travel: Local\n\u2022 * *\n\nThe Opportunity:\n\nCACI is seeking a skilled and experienced mid-level AI/ML Engineer to join our dynamic team to support a DoD client in Suitland, MD. The ideal candidate will have a strong background in machine learning, deep learning, and AI system development, with a proven track record of designing, developing, and deploying machine learning models. This role requires a deep understanding of MLOps, containerization, and CI/CD pipelines, as well as advanced knowledge in data preprocessing and cloud environments.\n\nResponsibilities:\n\u2022 Design, develop, and deploy machine learning models and manage pipelines using tools such as Azure ML, Kubeflow, or MLflow.\n\u2022 Implement and manage MLOps practices, including containerization (e.g., Docker, Kubernetes) and CI/CD pipelines.\n\u2022 Handle large datasets in cloud environments, performing advanced data preprocessing.\n\u2022 Develop custom AI APIs and integrate them into enterprise applications.\n\u2022 Ensure adherence to Responsible AI (RAI) policies and develop metrics, measurements, and evaluation methods for emerging and existing AI areas.\n\u2022 Collaborate with cross-functional teams to identify opportunities for AI/ML integration and improvement.\n\nQualifications:\n\n\u2022 TS/SCI Clearance\n\u2022 Bachelor\u2019s degree in Computer Science, Data Science, Mathematics, Statistics, Engineering, or a related field.\n\u2022 3\u20135 years of experience in machine learning, deep learning, or AI system development.\n\u2022 Experience in MLOps, containerization (e.g., Docker, Kubernetes), and CI/CD pipelines.\n\u2022 Proficiency in designing, developing, and deploying machine learning models.\n\u2022 Advanced knowledge in data preprocessing, including handling large datasets in cloud environments.\n\u2022 Experience in developing custom AI APIs and integrating them into enterprise applications.\n\u2022 Strong knowledge of programming languages for Machine Learning (Python, R, or similar).\n\u2022 Good understanding of AI cloud tools and capabilities.\n\u2022 Familiarity with Responsible AI (RAI) policies and development of metrics, measurements, and evaluation methods for AI.\n\nCertifications:\n\u2022 AI Engineer Associate (AI-102)\n\u2022 Microsoft Certified: Data Scientist Associate\n\u2022 Or similar relevant certifications\n\nPreferred Skills:\n\u2022 Experience with cloud platforms (Azure, AWS, GCP)\n\u2022 Knowledge of distributed computing frameworks (e.g., Apache Spark)\n\u2022 Familiarity with version control systems (e.g., Git)\n\nThis position is contingent on funding and may not be filled immediately. However, this position is representative of positions within CACI that are consistently available. Individuals who apply may also be considered for other positions at CACI.\n\n________________________________________________________________________________________\n\nWhat You Can Expect:\n\nA culture of integrity.\n\nAt CACI, we place character and innovation at the center of everything we do. As a valued team member, you\u2019ll be part of a high-performing group dedicated to our customer\u2019s missions and driven by a higher purpose \u2013 to ensure the safety of our nation.\n\nAn environment of trust.\n\nCACI values the unique contributions that every employee brings to our company and our customers - every day. You\u2019ll have the autonomy to take the time you need through a unique flexible time off benefit and have access to robust learning resources to make your ambitions a reality.\n\nA focus on continuous growth.\n\nTogether, we will advance our nation's most critical missions, build on our lengthy track record of business success, and find opportunities to break new ground \u2014 in your career and in our legacy.\n\nYour potential is limitless. So is ours.\n\nLearn more about CACI here.\n\n________________________________________________________________________________________\n\nPay Range: There are a host of factors that can influence final salary including, but not limited to, geographic location, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, education, and certifications. Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our broad and competitive mix of benefits options is designed to support and protect employees and their families. At CACI, you will receive comprehensive benefits such as; healthcare, wellness, financial, retirement, family support, continuing education, and time off benefits. Learn more here.\n\nThe proposed salary range for this position is:\n$79,400 - $162,700\n\nCACI is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, age, national origin, disability, status as a protected veteran, or any other protected characteristic.",
    "url": "https://careers.caci.com/global/en/job/CACIGLOBAL319062EXTERNALENGLOBAL/AI-ML-Engineer-Level-2?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "ML Ops Engineer",
    "company": "Sev1Tech LLC",
    "location": "Arlington",
    "salary": "",
    "description": "Job Summary\n\nWe are seeking a skilled MLOps Engineer to join our team and ensure the seamless deployment, monitoring, and optimization of AI models in production.\n\nThe MLOps Engineer will design, implement, and maintain end-to-end machine learning pipelines, focusing on automating model deployment, monitoring model health, detecting data drift, and managing AI-related logging. This role will involve building scalable infrastructure and dashboards for real-time and historical insights, ensuring models are secure, performant, and aligned with business needs.\n\nKey Responsibilities\n\u2022 Model Deployment: Deploy and manage machine learning models in production using tools like MLflow, Kubeflow, or AWS SageMaker, ensuring scalability and low latency.\n\u2022 Monitoring and Observability: Build and maintain dashboards using Grafana, Prometheus, or Kibana to track real-time model health (e.g., accuracy, latency) and historical trends.\n\u2022 Data Drift Detection: Implement drift detection pipelines using tools like Evidently AI or Alibi Detect to identify shifts in data distributions and trigger alerts or retraining.\n\u2022 Logging and Tracing: Set up centralized logging with ELK Stack or Open Telemetry to capture AI inference events, errors, and audit trails for debugging and compliance.\n\u2022 Pipeline Automation: Develop CI/CD pipelines with GitHub Actions or Jenkins to automate model updates, testing, and deployment.\n\u2022 Security and Compliance: Apply secure-by-design principles to protect data pipelines and models, using encryption, access controls, and compliance with regulations like GDPR or NIST AI RMF.\n\u2022 Collaboration: Work with data scientists, AI Integration Engineers, and DevOps teams to align model performance with business requirements and infrastructure capabilities.\n\u2022 Optimization: Optimize models for production (e.g., via quantization or pruning) and ensure efficient resource usage on cloud platforms like AWS, Azure, or Google Cloud.\n\u2022 Documentation: Maintain clear documentation of pipelines, dashboards, and monitoring processes for cross-team transparency.\n\nQualifications\n\u2022 Education: Bachelor\u2019s or Master\u2019s degree in computer science, Data Science, Engineering, or a related field.\n\u2022 Experience:\n\u2022 5+ years in MLOps, DevOps, or software engineering with a focus on AI/ML systems.\n\u2022 Proven experience deploying models in production using MLflow, Kubeflow, or cloud platforms (AWS SageMaker, Azure ML).\n\u2022 Hands-on experience with observability tools like Prometheus, Grafana, or Datadog for real-time monitoring.\n\u2022 Technical Skills:\n\u2022 Proficiency in Python and SQL; familiarity with JavaScript or Go is a plus.\n\u2022 Expertise in containerization (Docker, Kubernetes) and CI/CD tools (GitHub Actions, Jenkins).\n\u2022 Knowledge of time-series databases (e.g., InfluxDB, TimescaleDB) and logging frameworks (e.g., ELK Stack, Open Telemetry).\n\u2022 Experience with drift detection tools (e.g., Evidently AI, Alibi Detect) and visualization libraries (e.g., Plotly, Seaborn).\n\u2022 AI-Specific Skills:\n\u2022 Understanding of model performance metrics (e.g., precision, recall, AUC) and drift detection methods (e.g., KS test, PSI).\n\u2022 Familiarity with AI vulnerabilities (e.g., data poisoning, adversarial attacks) and mitigation tools like Adversarial Robustness Toolbox (ART).\n\u2022 Soft Skills:\n\u2022 Strong problem-solving and debugging skills for resolving pipeline and monitoring issues.\n\u2022 Excellent collaboration and communication skills to work with cross-functional teams.\n\u2022 Attention to detail for ensuring accurate and secure dashboard reporting.\n\u2022 Must be eligible to obtain a Department of Homeland Security EOD clearance ( Requirements 1. US Citizenship, 2. Favorable Background Investigation)\n\nPreferred Qualifications\n\u2022 Experience with LLM monitoring tools like LangSmith or Helicone for generative AI applications.\n\u2022 Knowledge of compliance frameworks (e.g., GDPR, HIPAA) for secure data handling.\n\u2022 Contributions to open-source MLOps projects or familiarity with X platform discussions on #MLOps or #AIOps.\n\nAbout US\n\nWelcome to Sev1Tech! Founded in 2010, we are proud to be a leading provider of IT modernization, engineering, and program management solutions. Our commitment is to deliver exceptional program and IT support services that empower critical missions for both Federal and Commercial clients.\n\nAt Sev1Tech, our mission is clear: Build better companies. Enable better government. Protect our nation. Build better humans across the country. We believe that through innovation and dedication, we can make a significant impact on the communities we serve\n\n.\nJoin the Sev1Tech family, where your potential for greatness is limitless! Here, you will not only achieve remarkable accomplishments but also enjoy a fulfilling and rewarding career progression. We invite you to explore opportunities with us and become part of a team that values your contributions and growt\n\nh.\nReady to take the next step? Apply directly through our website: Sev1Tech Careers and use the hashtag #joinSev1Tech to connect with us on social med\n\nia!\nFor any additional questions or to submit referrals, feel free to reach out to recruiting@sev1tech.\n\ncom.",
    "url": "https://www.linkedin.com/jobs/view/ml-ops-engineer-at-sev1tech-llc-4318935073?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "AI Engineer (Python & Backend Frameworks)",
    "company": "VeeRteq Solutions LLC",
    "location": "Washington",
    "salary": "",
    "description": "Role - AI Engineer (Python & Backend Frameworks)\n\nLocation: Remote (US/Canada)\n\nDuration: Long Term\n\nAs an AI Engineer, you will be an integral member of a collaborative multi-asset trading team. You'll work on high-impact machine learning (ML) and artificial intelligence (AI) initiatives that are central to our business strategy. In this role, you will build critical infrastructure and tooling that leverages AI and ML technology to enhance productivity, efficiency, and discover innovative paths to challenging business and technology problems. Surrounded by cutting-edge technology and experienced trading teams, you will have the opportunity to tackle fascinating new projects while becoming a subject-matter expert in a critical and innovative role.\n\nKey Responsibilities\n\u2022 Drive end-to-end development of AI infrastructure and AI driven applications: from initial proof-of-concept to production deployment and ongoing maintenance.\n\u2022 Collaborate with technologists, traders, quantitative researchers, and data scientists to identify high-impact opportunities for integrating AI and machine learning into technology and business use cases.\n\u2022 Implement automated systems for continuous training, validation, and monitoring of models, minimizing downtime and ensuring reliability.\n\u2022 Provide technical leadership in selecting, integrating, and optimizing AI and ML frameworks, libraries, and tools across diverse hardware and software environments.\n\u2022 Create and maintain feature pipelines, feature stores, and model stores.\n\u2022 Develop frameworks to enable scalable, reproducible research.\n\u2022 Proactively troubleshoot performance bottlenecks, conduct root-cause analyses, and implement solutions to optimize GPU or CPU resource usage.\n\nQualifications\n\u2022 Bachelor's or advanced degree in Computer Science, Machine Learning, Artificial Intelligence, or a related field.\n\u2022 3+ years of experience working with machine learning and artificial intelligence technology.\n\u2022 Strong understanding of core machine learning and artificial intelligence concepts.\n\u2022 Excellent programming skills in Python.\n\u2022 Demonstrated experience in building, validating, deploying, monitoring, and updating production ML and AI models.\n\u2022 Hands-on experience with MLOps and AIOps infrastructure and tooling.\n\u2022 Proficient in problem-solving and analytical reasoning.\n\u2022 Exceptional communication and collaboration skills.\n\u2022 Experience with ML frameworks such as TensorFlow, PyTorch, TensorRT, or ONNX.\n\u2022 Experience with Large Language Models, including RAG and fine-tuning techniques.\n\u2022 Familiarity with compute infrastructure necessary to support operating AI and ML technology.\n\nKey Responsibilities\n\u2022 Develop and enhance AI agents and backend systems for Mastercard's AI platform\n\u2022 Evaluate LLMs and emerging technologies to identify innovation opportunities\n\u2022 Design and optimize prompts for LLMs\n\u2022 Implement safeguards to ensure secure, ethical AI responses\n\u2022 Build APIs, microservices, and data integrations for AI features\n\u2022 Write clean, maintainable code following industry best practices\n\u2022 Stay current with advancements in AI and software engineering\n\nAll About You\n\u2022 Strong hands-on experience and understanding of AI/ML concepts and enthusiasm for generative AI\n\u2022 Experience with Python and backend frameworks (e.g., FastAPI, Flask, Node.js)\n\u2022 Knowledge of REST APIs and cloud platforms (AWS, Azure, GCP)\n\u2022 Strong analytical skills and curiosity for exploring new AI capabilities\n\u2022 Collaborative mindset and openness to feedback and mentorship\n\u2022 Interest in prompt engineering, AI safety, and scalable deployment",
    "url": "https://www.linkedin.com/jobs/view/ai-engineer-python-backend-frameworks-at-veerteq-solutions-llc-4332761727?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "AI and ML Engineer Jobs",
    "company": "Booz Allen Hamilton",
    "location": "Alexandria",
    "salary": "",
    "description": "Job Number: R0227633\n\nAI and ML Engineer\n\nThe Opportunity:\n\nAs an experienced engineer, you know that machine learning is critical to understanding and processing massive datasets. Your ability to conduct statistical analyses on workflow processes using ML techniques makes you an integral part of delivering a customer-focused solution. We need your technical knowledge and desire to problem-solve to support research and development for a key national defense client. As an Artificial Intelligence (AI) and Machine Learning (ML) Engineer on our intelligence team, you'll train, test, deploy, and maintain models that learn from data.\n\nIn this role, you'll own and define the direction of mission-critical solutions by applying best-fit ML algorithms and technologies. You'll be part of a large community of ML engineers across the company and collaborate with software developers and engineers as well as end users to deliver world-class solutions to develop and drive solutions to remote sensing issues for operations clients. You will be testing and driving AI and ML concepts and solutions for a data-intensive system. As data feeds continue to be brought online, the relatively fixed number of operators needs your help driving solutions. Your advanced skills and extensive technical expertise will guide clients as they navigate the landscape of ML algorithms, tools, and frameworks.\n\nWork with us to solve real-world challenges and define ML strategy.\n\nJoin us. The world can't wait.\n\nYou Have:\n\u2022 4+ years of experience delivering AI and ML based solutions for object identification and classification\n\u2022 4+ years of experience with Python coding, including for AI and ML solutions\n\u2022 Experience with remote sensing image processing, data exploitation, and algorithm development\n\u2022 Experience with software configuration management using Git\n\u2022 Ability to execute machine learning models in a Linux environment\n\u2022 Active TS/SCI clearance; willingness to take a polygraph exam\n\u2022 Bachelor's degree\n\nNice If You Have:\n\u2022 Experience with AWS\n\u2022 Knowledge of sensor capabilities\n\u2022 Ability to work with limited guidance and clear direction\n\u2022 Possession of excellent verbal and written communication skills, including with peers and clients\n\nClearance:\n\nApplicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance is required.\n\nCompensation\n\nAt Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen's benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.\n\nSalary at Booz Allen is determined by various factors, including but not limited to location, the individual's particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $99,000.00 to $225,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen's total compensation package for employees. This posting will close within 90 days from the Posting Date.\n\nIdentity Statement\n\nAs part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.\n\nWork Model\n\nOur people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.\n\u2022 If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility.\n\u2022 If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role.\n\nCommitment to Non-Discrimination\n\nAll qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law.",
    "url": "https://www.clearancejobs.com/jobs/8577608/ai-and-ml-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-27T00:00:00.000Z"
  },
  {
    "title": "Sr. Lead Machine Learning Engineer, Shopping (Remote-Eligible)",
    "company": "Capital One",
    "location": "McLean",
    "salary": "",
    "description": "Sr. Lead Machine Learning Engineer, Shopping (Remote-Eligible)\n\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One Shopping, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs.\n\nAs a Capital One Machine Learning Engineer (MLE), you'll be part of an Agile team dedicated to productionizing machine learning applications and systems at scale. You\u2019ll participate in the detailed technical design, development, and implementation of machine learning applications using existing and emerging technology platforms. You\u2019ll focus on machine learning architectural design, develop and review model and application code, and ensure high availability and performance of our machine learning applications. You'll have the opportunity to continuously learn and apply the latest innovations and best practices in machine learning engineering.\n\nWhat you\u2019ll do in the role:\n\u2022 The MLE role overlaps with many disciplines, such as Ops, Modeling, and Data Engineering. In this role, you'll be expected to perform many ML engineering activities, including one or more of the following:\n\u2022 Design, build, and/or deliver ML models and components that solve real-world business problems, while working in collaboration with the Product and Data Science teams.\n\u2022 Inform your ML infrastructure decisions using your understanding of ML modeling techniques and issues, including choice of model, data, and feature selection, model training, hyperparameter tuning, dimensionality, bias/variance, and validation).\n\u2022 Solve complex problems by writing and testing application code, developing and validating ML models, and automating tests and deployment.\n\u2022 Collaborate as part of a cross-functional Agile team to create and enhance software that enables state-of-the-art big data and ML applications.\n\u2022 Retrain, maintain, and monitor models in production.\n\u2022 Leverage or build cloud-based architectures, technologies, and/or platforms to deliver optimized ML models at scale.\n\u2022 Construct optimized data pipelines to feed ML models.\n\u2022 Leverage continuous integration and continuous deployment best practices, including test automation and monitoring, to ensure successful deployment of ML models and application code.\n\u2022 Ensure all code is well-managed to reduce vulnerabilities, models are well-governed from a risk perspective, and the ML follows best practices in Responsible and Explainable AI.\n\u2022 Use programming languages like Python, Scala, or Java.\n\nBasic Qualifications:\n\u2022 Bachelor\u2019s degree\n\u2022 At least 8 years of experience designing and building data-intensive solutions using distributed computing (Internship experience does not apply)\n\u2022 At least 4 years of experience programming with Python, Scala, or Java\n\u2022 At least 3 years of experience building, scaling, and optimizing ML systems\n\u2022 At least 2 years of experience leading teams developing ML solutions\n\nPreferred Qualifications:\n\u2022 Master's or doctoral degree in computer science, electrical engineering, mathematics, or a similar field\n\u2022 Experience developing and deploying ML solutions in a public cloud such as AWS, Azure, or Google Cloud Platform\n\u2022 4+ years of on-the-job experience with an industry recognized ML framework such as scikit-learn, PyTorch, Dask, Spark, or TensorFlow\n\u2022 3+ years of experience developing performant, resilient, and maintainable code\n\u2022 3+ years of experience with data gathering and preparation for ML models\n\u2022 3+ years of people management experience\n\u2022 ML industry impact through conference presentations, papers, blog posts, open source contributions, or patents\n\u2022 3+ years of experience building production-ready data pipelines that feed ML models\n\u2022 Ability to communicate complex technical concepts clearly to a variety of audiences\n\nCapital One will consider sponsoring a new qualified applicant for employment authorization for this position.\n\nThe minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.\n\nRemote (Regardless of Location): $204,900 - $233,800 for Sr. Lead Machine Learning Engineer\n\nMcLean, VA: $225,400 - $257,200 for Sr. Lead Machine Learning Engineer\n\nCandidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter.\n\nThis role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\n\nThis role is expected to accept applications for a minimum of 5 business days.\n\nNo agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\n\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\n\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\n\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",
    "url": "https://www.capitalonecareers.com/job/mclean/sr-lead-machine-learning-engineer-shopping-remote-eligible/1732/87800123136?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "AI/ML Engineer with Security Clearance",
    "company": "ClearanceJobs",
    "location": "Burke",
    "salary": "",
    "description": "Job Title: AI/ML Engineer Location: Springfield, VA Eligibility: Candidate must possess an active TS/SCI clearance Job Description: In this role, you\u2019ll help shape the strategic direction of high-impact\n\nsolutions by applying advanced machine learning methods to complex\n\noperational challenges. As part of a broad network of ML engineers,\n\nyou\u2019ll work closely with software teams and mission users to design and\n\ndeploy innovative capabilities that address critical remote sensing\n\nneeds. You\u2019ll play a key role in testing and implementing AI and ML\n\nconcepts within a demanding, data-rich environment, supporting operators\n\nwho rely on intelligent systems to scale mission effectiveness. Your\n\ntechnical depth and expertise will help guide stakeholders in selecting\n\nand applying the most effective algorithms, tools, and frameworks to\n\nsolve real-world problems. This project is focused on accelerating the fusion of multi-sensor\n\ndetections into persistent, time-critical object tracks. Your work will\n\nhelp enable rapid, reliable decision-making in operational environments\n\nby integrating AI/ML with GEOINT and sensor fusion frameworks. Must-Have Requirements: - 4+ years of experience delivering AI/ML based solutions for object\n\nidentification and classification - 4+ years of experience with Python coding, and Python coding for\n\nAI/ML solutions - Experience applying AI/ML to tracking, sensor fusion, or GEOINT data\n\nworkflows - Familiarity with real-time or near-real-time data processing for\n\nmulti-sensor systems - Experience with remote sensing image processing, data exploitation,\n\nand algorithm development - Experience with software configuration management using Git - Ability to execute machine learning models in a Linux environment - Active TS/SCI clearance; willingness to take a polygraph exam - Bachelor's degree & 4 years of experience (for mid level) or\n\nBacehlors degree &10 years of experience (for senior level) Nice If You Have: - Experience with AWS - Knowledge sensor capabilities - Background in multi-sensor data association, track correlation, or\n\npersistent surveillance analytics - Ability to work with limited guidance and clear direction - Possession of excellent verbal and written communication skills,\n\nwith peers and clients",
    "url": "https://www.linkedin.com/jobs/view/ai-ml-engineer-with-security-clearance-at-clearancejobs-4319479793?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Principal AI/ML Engineer - Remote",
    "company": "UnitedHealth Group",
    "location": "Arlington",
    "salary": "",
    "description": "Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start Caring. Connecting. Growing together.\n\nOptum AI is UnitedHealth Group's enterprise AI team. We are AI/ML scientists and engineers with deep expertise in AI/ML engineering for health care. We develop AI/ML solutions for the highest impact opportunities across UnitedHealth Group businesses including UnitedHealthcare, Optum Financial, Optum Health, Optum Insight, and Optum Rx. In addition to transforming the health care journey through responsible AI/ML innovation, our charter also includes developing and supporting an enterprise AI/ML development platform.\n\nOptum AI team members:\n\u2022 Have impact at scale: We have the data and resources to make an impact at scale. When our solutions are deployed, they have the potential to make health care system work better for everyone\n\u2022 Do ground-breaking work: Many of our current projects involve cutting edge ML, NLP and LLM techniques. Generative AI methods for working with structured and unstructured health care data are continuously being developed and improved. We are working in one of the most important frontiers of AI/ML research and development\n\u2022 Partner with world-class experts on innovative solutions: Our team members are developing novel AI/ML solutions to business challenges. In some cases, this includes the opportunity to file patents and publish papers about the methods we develop. We also collaborate with AI/ML researchers at some of the world's top universities\n\nYou'll enjoy the flexibility to work remotely* from anywhere within the U.S. as you take on some tough challenges. For all hires in the Minneapolis or Washington, D.C. area, you will be required to work in the office a minimum of four days per week.\n\nPrimary Responsibilities:\n\u2022 Drive end-to-end Machine Learning projects that have a high degree of ambiguity, scale and complexity\n\u2022 Build Machine Learning models, perform proof-of-concept, experiment, optimize, and deploy your models into production; work closely with software engineers to assist in productionizing the ML models\n\u2022 Perform hands-on analysis and modeling of healthcare data sets to develop insights that increase business value\n\u2022 Run A/B experiments, gather data, and perform statistical analysis\n\u2022 Establish scalable, efficient, automated processes for large-scale data analysis, machine-learning model development, model validation and serving\n\u2022 Research and implement innovative machine learning approaches\n\u2022 Mentor and help recruit AI/ML scientists and machine learning engineers to the team\n\u2022 Present findings and insights to senior leadership and at internal venues\n\u2022 Be the thought leader in cutting-edge AI research and proactively pursue IP submissions\n\nYou'll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.\n\nRequired Qualifications:\n\u2022 PhD in AI, computer science, data science, applied math or related technical fields\n\u2022 10+ years of industry/academic experience in machine learning or a related field\n\u2022 5+ years of building models for business application experience\n\u2022 5+ years leading technical teams\n\u2022 Advanced understanding of Deep Learning with applications in NLP and multimodal modeling\n\u2022 Proven solid Python programming skills and experience with deep learning frameworks such as PyTorch or TensorFlow\n\u2022 Experienced mathematical background, especially in optimization theory, stochastic algorithms, and/or numerical methods\n\u2022 Experience with state-of-the-art algorithms and topologies including, but not limited to: GNNs, GANs, Transformers, deep and wide, SSMs, LLMs among others\n\u2022 Proven in-depth knowledge in Generative AI technology and Large Language Models (LLM) with focus in LLM optimization\n\nPreferred Qualifications:\n\u2022 Experience in AI/ML in the healthcare and or Fintech sector\n\u2022 Experience working with cross-functional and distributed teams in a global and diverse environment\n\u2022 Experience in establishing AI/ML best practices, standards, and ethics\n\u2022 All employees working remotely will be required to adhere to UnitedHealth Group\u2019s Telecommuter Policy.\n\nCalifornia, Colorado, Connecticut, Hawaii, Nevada, New Jersey, New York, Maryland, Rhode Island, Washington, Washington, D.C. Residents Only: The salary range for this role is $122,100 to $234,700 annually. Pay is based on several factors including but not limited to local labor markets, education, work experience, certifications, etc. UnitedHealth Group complies with all minimum wage laws as applicable. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you\u2019ll find a far-reaching choice of benefits and incentives.\n\nApplication Deadline: This will be posted for a minimum of 2 business days or until a sufficient candidate pool has been collected. Job posting may come down early due to volume of applicants.\n\nAt UnitedHealth Group, our mission is to help people live healthier lives and make the health system work better for everyone. We believe everyone\u2013of every race, gender, sexuality, age, location and income\u2013deserves the opportunity to live their healthiest life. Today, however, there are still far too many barriers to good health which are disproportionately experienced by people of color, historically marginalized groups and those with lower incomes. We are committed to mitigating our impact on the environment and enabling and delivering equitable care that addresses health disparities and improves health outcomes \u2014 an enterprise priority reflected in our mission.\n\nUnitedHealth Group is an Equal Employment Opportunity employer under applicable law and qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status, or any other characteristic protected by local, state, or federal laws, rules, or regulations.\n\nUnitedHealth Group is a drug - free workplace. Candidates are required to pass a drug test before beginning employment.\n\n#OptumTechPJ",
    "url": "https://usnlx.com/arlington-va/principal-aiml-engineer-remote/2CFF1B20BB7E4072BFB2C0D19F587866/job/?vs=28&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "AI/ML Engineer/Digital Mapping (Jr.)",
    "company": "Quadrant, Inc.",
    "location": "Vienna",
    "salary": "",
    "description": "AI/ML Engineer/Digital Mapping (Jr)\nVienna, VA\nPay From: $28.00 per hour\n\nMUST:\nEntry level AI/ML Engineer (digital mapping)\nProgramming in Python and familiarity with ML libraries.\nUnderstanding of image processing and an interest in remote sensing/ GIS tools.\nStrong attention to detail in data preparation and annotation.\nInterest in generative AI and how it can be applied to infrastructure/ spatial analytics.\nProactive and resourceful with a strong willingness to learn.\nExcellent communication skills for documenting work and collaborating across teams.\nDetail-oriented mindset with the ability to manage multiple tasks effectively.\nBachelor s degree (completed or in progress) in Computer Science, Data Science, AI/ML, Geospatial Science, or related field.\n\nDUTIES:\nAssist with training, testing and fine-tuning AI/ML models for remote sending data (imagery, 3D scans, point clouds).\nSupport development of GenAI tools for reporting, insights, and automation.\nWork on GeoAI pipelines that process georeferenced datasets for mapping, temporal change detection, and digital twins.\nAnnotate, clean, and validate data to support model accuracy and reliability.\nRun experiments and contribute to performance evaluation of computer vision and geospatial models.\nDocument workflows, maintain datasets, and assist in deployment preparation.\nParticipate in weekend coverage schedules to ensure data and models run smoothly.\n\nQuadrant is an affirmative action/equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, status as a protected veteran, or status as an individual with a disability. Healthcare benefits are offered to all eligible employees according to compliance mandated by the Affordable Care Act .",
    "url": "https://www.indeed.com/viewjob?jk=10d6326e5a787734&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Sr. Lead Machine Learning Engineer, Shopping (Remote-Eligible)",
    "company": "Capital One",
    "location": "McLean",
    "salary": "",
    "description": "Sr. Lead Machine Learning Engineer, Shopping (Remote-Eligible)\n\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One Shopping, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs.\n\nAs a Capital One Machine Learning Engineer (MLE), you'll be part of an Agile team dedicated to productionizing machine learning applications and systems at scale. You'll participate in the detailed technical design, development, and implementation of machine learning applications using existing and emerging technology platforms. You'll focus on machine learning architectural design, develop and review model and application code, and ensure high availability and performance of our machine learning applications. You'll have the opportunity to continuously learn and apply the latest innovations and best practices in machine learning engineering.\n\nWhat you'll do in the role:\n\u2022 The MLE role overlaps with many disciplines, such as Ops, Modeling, and Data Engineering. In this role, you'll be expected to perform many ML engineering activities, including one or more of the following:\n\u2022 Design, build, and/or deliver ML models and components that solve real-world business problems, while working in collaboration with the Product and Data Science teams.\n\u2022 Inform your ML infrastructure decisions using your understanding of ML modeling techniques and issues, including choice of model, data, and feature selection, model training, hyperparameter tuning, dimensionality, bias/variance, and validation).\n\u2022 Solve complex problems by writing and testing application code, developing and validating ML models, and automating tests and deployment.\n\u2022 Collaborate as part of a cross-functional Agile team to create and enhance software that enables state-of-the-art big data and ML applications.\n\u2022 Retrain, maintain, and monitor models in production.\n\u2022 Leverage or build cloud-based architectures, technologies, and/or platforms to deliver optimized ML models at scale.\n\u2022 Construct optimized data pipelines to feed ML models.\n\u2022 Leverage continuous integration and continuous deployment best practices, including test automation and monitoring, to ensure successful deployment of ML models and application code.\n\u2022 Ensure all code is well-managed to reduce vulnerabilities, models are well-governed from a risk perspective, and the ML follows best practices in Responsible and Explainable AI.\n\u2022 Use programming languages like Python, Scala, or Java.\n\nBasic Qualifications:\n\u2022 Bachelor's degree\n\u2022 At least 8 years of experience designing and building data-intensive solutions using distributed computing (Internship experience does not apply)\n\u2022 At least 4 years of experience programming with Python, Scala, or Java\n\u2022 At least 3 years of experience building, scaling, and optimizing ML systems\n\u2022 At least 2 years of experience leading teams developing ML solutions\n\nPreferred Qualifications:\n\u2022 Master's or doctoral degree in computer science, electrical engineering, mathematics, or a similar field\n\u2022 Experience developing and deploying ML solutions in a public cloud such as AWS, Azure, or Google Cloud Platform\n\u2022 4+ years of on-the-job experience with an industry recognized ML framework such as scikit-learn, PyTorch, Dask, Spark, or TensorFlow\n\u2022 3+ years of experience developing performant, resilient, and maintainable code\n\u2022 3+ years of experience with data gathering and preparation for ML models\n\u2022 3+ years of people management experience\n\u2022 ML industry impact through conference presentations, papers, blog posts, open source contributions, or patents\n\u2022 3+ years of experience building production-ready data pipelines that feed ML models\n\u2022 Ability to communicate complex technical concepts clearly to a variety of audiences\n\nCapital One will consider sponsoring a new qualified applicant for employment authorization for this position.\n\nThe minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.\n\nRemote (Regardless of Location): $204,900 - $233,800 for Sr. Lead Machine Learning Engineer\n\nMcLean, VA: $225,400 - $257,200 for Sr. Lead Machine Learning Engineer\n\nCandidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate's offer letter.\n\nThis role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\n\nThis role is expected to accept applications for a minimum of 5 business days.\n\nNo agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City's Fair Chance Act; Philadelphia's Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\n\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\n\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\n\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",
    "url": "https://www.ziprecruiter.com/c/Capitalone/Job/Sr.-Lead-Machine-Learning-Engineer,-Shopping-(Remote-Eligible)/-in-Mclean,VA?jid=41a67ef17e1338d4&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "AI/ML Engineer Level 2 Jobs",
    "company": "CACI",
    "location": "Suitland-Silver Hill",
    "salary": "",
    "description": "AI/ML Engineer Level 2\n\nJob Category: Science\n\nTime Type: Full time\n\nMinimum Clearance Required to Start: TS/SCI\n\nEmployee Type: Regular\n\nPercentage of Travel Required: Up to 10%\n\nType of Travel: Local\n\u2022 * *\n\nThe Opportunity:\n\nCACI is seeking a skilled and experienced mid-level AI/ML Engineer to join our dynamic team to support a DoD client in Suitland, MD. The ideal candidate will have a strong background in machine learning, deep learning, and AI system development, with a proven track record of designing, developing, and deploying machine learning models. This role requires a deep understanding of MLOps, containerization, and CI/CD pipelines, as well as advanced knowledge in data preprocessing and cloud environments.\n\nResponsibilities:\n\u2022 Design, develop, and deploy machine learning models and manage pipelines using tools such as Azure ML, Kubeflow, or MLflow.\n\u2022 Implement and manage MLOps practices, including containerization (e.g., Docker, Kubernetes) and CI/CD pipelines.\n\u2022 Handle large datasets in cloud environments, performing advanced data preprocessing.\n\u2022 Develop custom AI APIs and integrate them into enterprise applications.\n\u2022 Ensure adherence to Responsible AI (RAI) policies and develop metrics, measurements, and evaluation methods for emerging and existing AI areas.\n\u2022 Collaborate with cross-functional teams to identify opportunities for AI/ML integration and improvement.\n\nQualifications:\n\n\u2022 TS/SCI Clearance\n\u2022 Bachelor's degree in Computer Science, Data Science, Mathematics, Statistics, Engineering, or a related field.\n\u2022 3-5 years of experience in machine learning, deep learning, or AI system development.\n\u2022 Experience in MLOps, containerization (e.g., Docker, Kubernetes), and CI/CD pipelines.\n\u2022 Proficiency in designing, developing, and deploying machine learning models.\n\u2022 Advanced knowledge in data preprocessing, including handling large datasets in cloud environments.\n\u2022 Experience in developing custom AI APIs and integrating them into enterprise applications.\n\u2022 Strong knowledge of programming languages for Machine Learning (Python, R, or similar).\n\u2022 Good understanding of AI cloud tools and capabilities.\n\u2022 Familiarity with Responsible AI (RAI) policies and development of metrics, measurements, and evaluation methods for AI.\n\nCertifications:\n\u2022 AI Engineer Associate (AI-102)\n\u2022 Microsoft Certified: Data Scientist Associate\n\u2022 Or similar relevant certifications\n\nPreferred Skills:\n\u2022 Experience with cloud platforms (Azure, AWS, GCP)\n\u2022 Knowledge of distributed computing frameworks (e.g., Apache Spark)\n\u2022 Familiarity with version control systems (e.g., Git)\n\nThis position is contingent on funding and may not be filled immediately. However, this position is representative of positions within CACI that are consistently available. Individuals who apply may also be considered for other positions at CACI.\n________________________________________________________________________________________\n\nWhat You Can Expect:\n\nA culture of integrity.\n\nAt CACI, we place character and innovation at the center of everything we do. As a valued team member, you'll be part of a high-performing group dedicated to our customer's missions and driven by a higher purpose - to ensure the safety of our nation.\n\nAn environment of trust.\n\nCACI values the unique contributions that every employee brings to our company and our customers - every day. You'll have the autonomy to take the time you need through a unique flexible time off benefit and have access to robust learning resources to make your ambitions a reality.\n\nA focus on continuous growth.\n\nTogether, we will advance our nation's most critical missions, build on our lengthy track record of business success, and find opportunities to break new ground - in your career and in our legacy.\n\nYour potential is limitless. So is ours.\n\nLearn more about CACI here.\n\n________________________________________________________________________________________\n\nPay Range: There are a host of factors that can influence final salary including, but not limited to, geographic location, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, education, and certifications. Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our broad and competitive mix of benefits options is designed to support and protect employees and their families. At CACI, you will receive comprehensive benefits such as; healthcare, wellness, financial, retirement, family support, continuing education, and time off benefits. Learn more here .\n\nThe proposed salary range for this position is:\n$79,400 - $162,700\n\nCACI is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, age, national origin, disability, status as a protected veteran, or any other protected characteristic.",
    "url": "https://www.clearancejobs.com/jobs/8614774/aiml-engineer-level-2?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "AI/ML Engineer Level 2",
    "company": "CACI",
    "location": "Suitland-Silver Hill",
    "salary": "",
    "description": "AI/ML Engineer Level 2\n\nJob Category: Science\n\nTime Type: Full time\n\nMinimum Clearance Required to Start: TS/SCI\n\nEmployee Type: Regular\n\nPercentage of Travel Required: Up to 10%\n\nType of Travel: Local\n\u2022 * *\n\nThe Opportunity:\n\nCACI is seeking a skilled and experienced mid-level AI/ML Engineer to join our dynamic team to support a DoD client in Suitland, MD. The ideal candidate will have a strong background in machine learning, deep learning, and AI system development, with a proven track record of designing, developing, and deploying machine learning models. This role requires a deep understanding of MLOps, containerization, and CI/CD pipelines, as well as advanced knowledge in data preprocessing and cloud environments.\n\nResponsibilities:\n\u2022 Design, develop, and deploy machine learning models and manage pipelines using tools such as Azure ML, Kubeflow, or MLflow.\n\u2022 Implement and manage MLOps practices, including containerization (e.g., Docker, Kubernetes) and CI/CD pipelines.\n\u2022 Handle large datasets in cloud environments, performing advanced data preprocessing.\n\u2022 Develop custom AI APIs and integrate them into enterprise applications.\n\u2022 Ensure adherence to Responsible AI (RAI) policies and develop metrics, measurements, and evaluation methods for emerging and existing AI areas.\n\u2022 Collaborate with cross-functional teams to identify opportunities for AI/ML integration and improvement.\n\nQualifications:\n\n\u2022 TS/SCI Clearance\n\u2022 Bachelor\u2019s degree in Computer Science, Data Science, Mathematics, Statistics, Engineering, or a related field.\n\u2022 3\u20135 years of experience in machine learning, deep learning, or AI system development.\n\u2022 Experience in MLOps, containerization (e.g., Docker, Kubernetes), and CI/CD pipelines.\n\u2022 Proficiency in designing, developing, and deploying machine learning models.\n\u2022 Advanced knowledge in data preprocessing, including handling large datasets in cloud environments.\n\u2022 Experience in developing custom AI APIs and integrating them into enterprise applications.\n\u2022 Strong knowledge of programming languages for Machine Learning (Python, R, or similar).\n\u2022 Good understanding of AI cloud tools and capabilities.\n\u2022 Familiarity with Responsible AI (RAI) policies and development of metrics, measurements, and evaluation methods for AI.\n\nCertifications:\n\u2022 AI Engineer Associate (AI-102)\n\u2022 Microsoft Certified: Data Scientist Associate\n\u2022 Or similar relevant certifications\n\nPreferred Skills:\n\u2022 Experience with cloud platforms (Azure, AWS, GCP)\n\u2022 Knowledge of distributed computing frameworks (e.g., Apache Spark)\n\u2022 Familiarity with version control systems (e.g., Git)\n\nThis position is contingent on funding and may not be filled immediately. However, this position is representative of positions within CACI that are consistently available. Individuals who apply may also be considered for other positions at CACI.\n\n________________________________________________________________________________________\n\nWhat You Can Expect:\n\nA culture of integrity.\n\nAt CACI, we place character and innovation at the center of everything we do. As a valued team member, you\u2019ll be part of a high-performing group dedicated to our customer\u2019s missions and driven by a higher purpose \u2013 to ensure the safety of our nation.\n\nAn environment of trust.\n\nCACI values the unique contributions that every employee brings to our company and our customers - every day. You\u2019ll have the autonomy to take the time you need through a unique flexible time off benefit and have access to robust learning resources to make your ambitions a reality.\n\nA focus on continuous growth.\n\nTogether, we will advance our nation's most critical missions, build on our lengthy track record of business success, and find opportunities to break new ground \u2014 in your career and in our legacy.\n\nYour potential is limitless. So is ours.\n\nLearn more about CACI here.\n\n________________________________________________________________________________________\n\nPay Range: There are a host of factors that can influence final salary including, but not limited to, geographic location, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, education, and certifications. Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our broad and competitive mix of benefits options is designed to support and protect employees and their families. At CACI, you will receive comprehensive benefits such as; healthcare, wellness, financial, retirement, family support, continuing education, and time off benefits. Learn more here.\n\nThe proposed salary range for this position is:\n$79,400 - $162,700\n\nCACI is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, age, national origin, disability, status as a protected veteran, or any other protected characteristic.",
    "url": "https://careers.caci.com/global/en/job/CACIGLOBAL319062EXTERNALENGLOBAL/AI-ML-Engineer-Level-2?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "ML Ops Engineer",
    "company": "Sev1Tech LLC",
    "location": "Arlington",
    "salary": "",
    "description": "Job Summary\n\nWe are seeking a skilled MLOps Engineer to join our team and ensure the seamless deployment, monitoring, and optimization of AI models in production.\n\nThe MLOps Engineer will design, implement, and maintain end-to-end machine learning pipelines, focusing on automating model deployment, monitoring model health, detecting data drift, and managing AI-related logging. This role will involve building scalable infrastructure and dashboards for real-time and historical insights, ensuring models are secure, performant, and aligned with business needs.\n\nKey Responsibilities\n\u2022 Model Deployment: Deploy and manage machine learning models in production using tools like MLflow, Kubeflow, or AWS SageMaker, ensuring scalability and low latency.\n\u2022 Monitoring and Observability: Build and maintain dashboards using Grafana, Prometheus, or Kibana to track real-time model health (e.g., accuracy, latency) and historical trends.\n\u2022 Data Drift Detection: Implement drift detection pipelines using tools like Evidently AI or Alibi Detect to identify shifts in data distributions and trigger alerts or retraining.\n\u2022 Logging and Tracing: Set up centralized logging with ELK Stack or Open Telemetry to capture AI inference events, errors, and audit trails for debugging and compliance.\n\u2022 Pipeline Automation: Develop CI/CD pipelines with GitHub Actions or Jenkins to automate model updates, testing, and deployment.\n\u2022 Security and Compliance: Apply secure-by-design principles to protect data pipelines and models, using encryption, access controls, and compliance with regulations like GDPR or NIST AI RMF.\n\u2022 Collaboration: Work with data scientists, AI Integration Engineers, and DevOps teams to align model performance with business requirements and infrastructure capabilities.\n\u2022 Optimization: Optimize models for production (e.g., via quantization or pruning) and ensure efficient resource usage on cloud platforms like AWS, Azure, or Google Cloud.\n\u2022 Documentation: Maintain clear documentation of pipelines, dashboards, and monitoring processes for cross-team transparency.\n\nQualifications\n\u2022 Education: Bachelor\u2019s or Master\u2019s degree in computer science, Data Science, Engineering, or a related field.\n\u2022 Experience:\n\u2022 5+ years in MLOps, DevOps, or software engineering with a focus on AI/ML systems.\n\u2022 Proven experience deploying models in production using MLflow, Kubeflow, or cloud platforms (AWS SageMaker, Azure ML).\n\u2022 Hands-on experience with observability tools like Prometheus, Grafana, or Datadog for real-time monitoring.\n\u2022 Technical Skills:\n\u2022 Proficiency in Python and SQL; familiarity with JavaScript or Go is a plus.\n\u2022 Expertise in containerization (Docker, Kubernetes) and CI/CD tools (GitHub Actions, Jenkins).\n\u2022 Knowledge of time-series databases (e.g., InfluxDB, TimescaleDB) and logging frameworks (e.g., ELK Stack, Open Telemetry).\n\u2022 Experience with drift detection tools (e.g., Evidently AI, Alibi Detect) and visualization libraries (e.g., Plotly, Seaborn).\n\u2022 AI-Specific Skills:\n\u2022 Understanding of model performance metrics (e.g., precision, recall, AUC) and drift detection methods (e.g., KS test, PSI).\n\u2022 Familiarity with AI vulnerabilities (e.g., data poisoning, adversarial attacks) and mitigation tools like Adversarial Robustness Toolbox (ART).\n\u2022 Soft Skills:\n\u2022 Strong problem-solving and debugging skills for resolving pipeline and monitoring issues.\n\u2022 Excellent collaboration and communication skills to work with cross-functional teams.\n\u2022 Attention to detail for ensuring accurate and secure dashboard reporting.\n\u2022 Must be eligible to obtain a Department of Homeland Security EOD clearance ( Requirements 1. US Citizenship, 2. Favorable Background Investigation)\n\nPreferred Qualifications\n\u2022 Experience with LLM monitoring tools like LangSmith or Helicone for generative AI applications.\n\u2022 Knowledge of compliance frameworks (e.g., GDPR, HIPAA) for secure data handling.\n\u2022 Contributions to open-source MLOps projects or familiarity with X platform discussions on #MLOps or #AIOps.\n\nAbout US\n\nWelcome to Sev1Tech! Founded in 2010, we are proud to be a leading provider of IT modernization, engineering, and program management solutions. Our commitment is to deliver exceptional program and IT support services that empower critical missions for both Federal and Commercial clients.\n\nAt Sev1Tech, our mission is clear: Build better companies. Enable better government. Protect our nation. Build better humans across the country. We believe that through innovation and dedication, we can make a significant impact on the communities we serve\n\n.\nJoin the Sev1Tech family, where your potential for greatness is limitless! Here, you will not only achieve remarkable accomplishments but also enjoy a fulfilling and rewarding career progression. We invite you to explore opportunities with us and become part of a team that values your contributions and growt\n\nh.\nReady to take the next step? Apply directly through our website: Sev1Tech Careers and use the hashtag #joinSev1Tech to connect with us on social med\n\nia!\nFor any additional questions or to submit referrals, feel free to reach out to recruiting@sev1tech.\n\ncom.",
    "url": "https://www.linkedin.com/jobs/view/ml-ops-engineer-at-sev1tech-llc-4318935073?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "AI Engineer (Python & Backend Frameworks)",
    "company": "VeeRteq Solutions LLC",
    "location": "Washington",
    "salary": "",
    "description": "Role - AI Engineer (Python & Backend Frameworks)\n\nLocation: Remote (US/Canada)\n\nDuration: Long Term\n\nAs an AI Engineer, you will be an integral member of a collaborative multi-asset trading team. You'll work on high-impact machine learning (ML) and artificial intelligence (AI) initiatives that are central to our business strategy. In this role, you will build critical infrastructure and tooling that leverages AI and ML technology to enhance productivity, efficiency, and discover innovative paths to challenging business and technology problems. Surrounded by cutting-edge technology and experienced trading teams, you will have the opportunity to tackle fascinating new projects while becoming a subject-matter expert in a critical and innovative role.\n\nKey Responsibilities\n\u2022 Drive end-to-end development of AI infrastructure and AI driven applications: from initial proof-of-concept to production deployment and ongoing maintenance.\n\u2022 Collaborate with technologists, traders, quantitative researchers, and data scientists to identify high-impact opportunities for integrating AI and machine learning into technology and business use cases.\n\u2022 Implement automated systems for continuous training, validation, and monitoring of models, minimizing downtime and ensuring reliability.\n\u2022 Provide technical leadership in selecting, integrating, and optimizing AI and ML frameworks, libraries, and tools across diverse hardware and software environments.\n\u2022 Create and maintain feature pipelines, feature stores, and model stores.\n\u2022 Develop frameworks to enable scalable, reproducible research.\n\u2022 Proactively troubleshoot performance bottlenecks, conduct root-cause analyses, and implement solutions to optimize GPU or CPU resource usage.\n\nQualifications\n\u2022 Bachelor's or advanced degree in Computer Science, Machine Learning, Artificial Intelligence, or a related field.\n\u2022 3+ years of experience working with machine learning and artificial intelligence technology.\n\u2022 Strong understanding of core machine learning and artificial intelligence concepts.\n\u2022 Excellent programming skills in Python.\n\u2022 Demonstrated experience in building, validating, deploying, monitoring, and updating production ML and AI models.\n\u2022 Hands-on experience with MLOps and AIOps infrastructure and tooling.\n\u2022 Proficient in problem-solving and analytical reasoning.\n\u2022 Exceptional communication and collaboration skills.\n\u2022 Experience with ML frameworks such as TensorFlow, PyTorch, TensorRT, or ONNX.\n\u2022 Experience with Large Language Models, including RAG and fine-tuning techniques.\n\u2022 Familiarity with compute infrastructure necessary to support operating AI and ML technology.\n\nKey Responsibilities\n\u2022 Develop and enhance AI agents and backend systems for Mastercard's AI platform\n\u2022 Evaluate LLMs and emerging technologies to identify innovation opportunities\n\u2022 Design and optimize prompts for LLMs\n\u2022 Implement safeguards to ensure secure, ethical AI responses\n\u2022 Build APIs, microservices, and data integrations for AI features\n\u2022 Write clean, maintainable code following industry best practices\n\u2022 Stay current with advancements in AI and software engineering\n\nAll About You\n\u2022 Strong hands-on experience and understanding of AI/ML concepts and enthusiasm for generative AI\n\u2022 Experience with Python and backend frameworks (e.g., FastAPI, Flask, Node.js)\n\u2022 Knowledge of REST APIs and cloud platforms (AWS, Azure, GCP)\n\u2022 Strong analytical skills and curiosity for exploring new AI capabilities\n\u2022 Collaborative mindset and openness to feedback and mentorship\n\u2022 Interest in prompt engineering, AI safety, and scalable deployment",
    "url": "https://www.linkedin.com/jobs/view/ai-engineer-python-backend-frameworks-at-veerteq-solutions-llc-4332761727?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "AI and ML Engineer Jobs",
    "company": "Booz Allen Hamilton",
    "location": "Alexandria",
    "salary": "",
    "description": "Job Number: R0227633\n\nAI and ML Engineer\n\nThe Opportunity:\n\nAs an experienced engineer, you know that machine learning is critical to understanding and processing massive datasets. Your ability to conduct statistical analyses on workflow processes using ML techniques makes you an integral part of delivering a customer-focused solution. We need your technical knowledge and desire to problem-solve to support research and development for a key national defense client. As an Artificial Intelligence (AI) and Machine Learning (ML) Engineer on our intelligence team, you'll train, test, deploy, and maintain models that learn from data.\n\nIn this role, you'll own and define the direction of mission-critical solutions by applying best-fit ML algorithms and technologies. You'll be part of a large community of ML engineers across the company and collaborate with software developers and engineers as well as end users to deliver world-class solutions to develop and drive solutions to remote sensing issues for operations clients. You will be testing and driving AI and ML concepts and solutions for a data-intensive system. As data feeds continue to be brought online, the relatively fixed number of operators needs your help driving solutions. Your advanced skills and extensive technical expertise will guide clients as they navigate the landscape of ML algorithms, tools, and frameworks.\n\nWork with us to solve real-world challenges and define ML strategy.\n\nJoin us. The world can't wait.\n\nYou Have:\n\u2022 4+ years of experience delivering AI and ML based solutions for object identification and classification\n\u2022 4+ years of experience with Python coding, including for AI and ML solutions\n\u2022 Experience with remote sensing image processing, data exploitation, and algorithm development\n\u2022 Experience with software configuration management using Git\n\u2022 Ability to execute machine learning models in a Linux environment\n\u2022 Active TS/SCI clearance; willingness to take a polygraph exam\n\u2022 Bachelor's degree\n\nNice If You Have:\n\u2022 Experience with AWS\n\u2022 Knowledge of sensor capabilities\n\u2022 Ability to work with limited guidance and clear direction\n\u2022 Possession of excellent verbal and written communication skills, including with peers and clients\n\nClearance:\n\nApplicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance is required.\n\nCompensation\n\nAt Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen's benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.\n\nSalary at Booz Allen is determined by various factors, including but not limited to location, the individual's particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $99,000.00 to $225,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen's total compensation package for employees. This posting will close within 90 days from the Posting Date.\n\nIdentity Statement\n\nAs part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.\n\nWork Model\n\nOur people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.\n\u2022 If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility.\n\u2022 If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role.\n\nCommitment to Non-Discrimination\n\nAll qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law.",
    "url": "https://www.clearancejobs.com/jobs/8577608/ai-and-ml-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-27T00:00:00.000Z"
  },
  {
    "title": "Sr. Lead Machine Learning Engineer, Shopping (Remote-Eligible)",
    "company": "Capital One",
    "location": "McLean",
    "salary": "",
    "description": "Sr. Lead Machine Learning Engineer, Shopping (Remote-Eligible)\n\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One Shopping, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs.\n\nAs a Capital One Machine Learning Engineer (MLE), you'll be part of an Agile team dedicated to productionizing machine learning applications and systems at scale. You\u2019ll participate in the detailed technical design, development, and implementation of machine learning applications using existing and emerging technology platforms. You\u2019ll focus on machine learning architectural design, develop and review model and application code, and ensure high availability and performance of our machine learning applications. You'll have the opportunity to continuously learn and apply the latest innovations and best practices in machine learning engineering.\n\nWhat you\u2019ll do in the role:\n\u2022 The MLE role overlaps with many disciplines, such as Ops, Modeling, and Data Engineering. In this role, you'll be expected to perform many ML engineering activities, including one or more of the following:\n\u2022 Design, build, and/or deliver ML models and components that solve real-world business problems, while working in collaboration with the Product and Data Science teams.\n\u2022 Inform your ML infrastructure decisions using your understanding of ML modeling techniques and issues, including choice of model, data, and feature selection, model training, hyperparameter tuning, dimensionality, bias/variance, and validation).\n\u2022 Solve complex problems by writing and testing application code, developing and validating ML models, and automating tests and deployment.\n\u2022 Collaborate as part of a cross-functional Agile team to create and enhance software that enables state-of-the-art big data and ML applications.\n\u2022 Retrain, maintain, and monitor models in production.\n\u2022 Leverage or build cloud-based architectures, technologies, and/or platforms to deliver optimized ML models at scale.\n\u2022 Construct optimized data pipelines to feed ML models.\n\u2022 Leverage continuous integration and continuous deployment best practices, including test automation and monitoring, to ensure successful deployment of ML models and application code.\n\u2022 Ensure all code is well-managed to reduce vulnerabilities, models are well-governed from a risk perspective, and the ML follows best practices in Responsible and Explainable AI.\n\u2022 Use programming languages like Python, Scala, or Java.\n\nBasic Qualifications:\n\u2022 Bachelor\u2019s degree\n\u2022 At least 8 years of experience designing and building data-intensive solutions using distributed computing (Internship experience does not apply)\n\u2022 At least 4 years of experience programming with Python, Scala, or Java\n\u2022 At least 3 years of experience building, scaling, and optimizing ML systems\n\u2022 At least 2 years of experience leading teams developing ML solutions\n\nPreferred Qualifications:\n\u2022 Master's or doctoral degree in computer science, electrical engineering, mathematics, or a similar field\n\u2022 Experience developing and deploying ML solutions in a public cloud such as AWS, Azure, or Google Cloud Platform\n\u2022 4+ years of on-the-job experience with an industry recognized ML framework such as scikit-learn, PyTorch, Dask, Spark, or TensorFlow\n\u2022 3+ years of experience developing performant, resilient, and maintainable code\n\u2022 3+ years of experience with data gathering and preparation for ML models\n\u2022 3+ years of people management experience\n\u2022 ML industry impact through conference presentations, papers, blog posts, open source contributions, or patents\n\u2022 3+ years of experience building production-ready data pipelines that feed ML models\n\u2022 Ability to communicate complex technical concepts clearly to a variety of audiences\n\nCapital One will consider sponsoring a new qualified applicant for employment authorization for this position.\n\nThe minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.\n\nRemote (Regardless of Location): $204,900 - $233,800 for Sr. Lead Machine Learning Engineer\n\nMcLean, VA: $225,400 - $257,200 for Sr. Lead Machine Learning Engineer\n\nCandidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter.\n\nThis role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\n\nThis role is expected to accept applications for a minimum of 5 business days.\n\nNo agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\n\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\n\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\n\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",
    "url": "https://www.capitalonecareers.com/job/mclean/sr-lead-machine-learning-engineer-shopping-remote-eligible/1732/87800123136?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "AI/ML Engineer with Security Clearance",
    "company": "ClearanceJobs",
    "location": "Burke",
    "salary": "",
    "description": "Job Title: AI/ML Engineer Location: Springfield, VA Eligibility: Candidate must possess an active TS/SCI clearance Job Description: In this role, you\u2019ll help shape the strategic direction of high-impact\n\nsolutions by applying advanced machine learning methods to complex\n\noperational challenges. As part of a broad network of ML engineers,\n\nyou\u2019ll work closely with software teams and mission users to design and\n\ndeploy innovative capabilities that address critical remote sensing\n\nneeds. You\u2019ll play a key role in testing and implementing AI and ML\n\nconcepts within a demanding, data-rich environment, supporting operators\n\nwho rely on intelligent systems to scale mission effectiveness. Your\n\ntechnical depth and expertise will help guide stakeholders in selecting\n\nand applying the most effective algorithms, tools, and frameworks to\n\nsolve real-world problems. This project is focused on accelerating the fusion of multi-sensor\n\ndetections into persistent, time-critical object tracks. Your work will\n\nhelp enable rapid, reliable decision-making in operational environments\n\nby integrating AI/ML with GEOINT and sensor fusion frameworks. Must-Have Requirements: - 4+ years of experience delivering AI/ML based solutions for object\n\nidentification and classification - 4+ years of experience with Python coding, and Python coding for\n\nAI/ML solutions - Experience applying AI/ML to tracking, sensor fusion, or GEOINT data\n\nworkflows - Familiarity with real-time or near-real-time data processing for\n\nmulti-sensor systems - Experience with remote sensing image processing, data exploitation,\n\nand algorithm development - Experience with software configuration management using Git - Ability to execute machine learning models in a Linux environment - Active TS/SCI clearance; willingness to take a polygraph exam - Bachelor's degree & 4 years of experience (for mid level) or\n\nBacehlors degree &10 years of experience (for senior level) Nice If You Have: - Experience with AWS - Knowledge sensor capabilities - Background in multi-sensor data association, track correlation, or\n\npersistent surveillance analytics - Ability to work with limited guidance and clear direction - Possession of excellent verbal and written communication skills,\n\nwith peers and clients",
    "url": "https://www.linkedin.com/jobs/view/ai-ml-engineer-with-security-clearance-at-clearancejobs-4319479793?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Principal AI/ML Engineer - Remote",
    "company": "UnitedHealth Group",
    "location": "Arlington",
    "salary": "",
    "description": "Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start Caring. Connecting. Growing together.\n\nOptum AI is UnitedHealth Group's enterprise AI team. We are AI/ML scientists and engineers with deep expertise in AI/ML engineering for health care. We develop AI/ML solutions for the highest impact opportunities across UnitedHealth Group businesses including UnitedHealthcare, Optum Financial, Optum Health, Optum Insight, and Optum Rx. In addition to transforming the health care journey through responsible AI/ML innovation, our charter also includes developing and supporting an enterprise AI/ML development platform.\n\nOptum AI team members:\n\u2022 Have impact at scale: We have the data and resources to make an impact at scale. When our solutions are deployed, they have the potential to make health care system work better for everyone\n\u2022 Do ground-breaking work: Many of our current projects involve cutting edge ML, NLP and LLM techniques. Generative AI methods for working with structured and unstructured health care data are continuously being developed and improved. We are working in one of the most important frontiers of AI/ML research and development\n\u2022 Partner with world-class experts on innovative solutions: Our team members are developing novel AI/ML solutions to business challenges. In some cases, this includes the opportunity to file patents and publish papers about the methods we develop. We also collaborate with AI/ML researchers at some of the world's top universities\n\nYou'll enjoy the flexibility to work remotely* from anywhere within the U.S. as you take on some tough challenges. For all hires in the Minneapolis or Washington, D.C. area, you will be required to work in the office a minimum of four days per week.\n\nPrimary Responsibilities:\n\u2022 Drive end-to-end Machine Learning projects that have a high degree of ambiguity, scale and complexity\n\u2022 Build Machine Learning models, perform proof-of-concept, experiment, optimize, and deploy your models into production; work closely with software engineers to assist in productionizing the ML models\n\u2022 Perform hands-on analysis and modeling of healthcare data sets to develop insights that increase business value\n\u2022 Run A/B experiments, gather data, and perform statistical analysis\n\u2022 Establish scalable, efficient, automated processes for large-scale data analysis, machine-learning model development, model validation and serving\n\u2022 Research and implement innovative machine learning approaches\n\u2022 Mentor and help recruit AI/ML scientists and machine learning engineers to the team\n\u2022 Present findings and insights to senior leadership and at internal venues\n\u2022 Be the thought leader in cutting-edge AI research and proactively pursue IP submissions\n\nYou'll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.\n\nRequired Qualifications:\n\u2022 PhD in AI, computer science, data science, applied math or related technical fields\n\u2022 10+ years of industry/academic experience in machine learning or a related field\n\u2022 5+ years of building models for business application experience\n\u2022 5+ years leading technical teams\n\u2022 Advanced understanding of Deep Learning with applications in NLP and multimodal modeling\n\u2022 Proven solid Python programming skills and experience with deep learning frameworks such as PyTorch or TensorFlow\n\u2022 Experienced mathematical background, especially in optimization theory, stochastic algorithms, and/or numerical methods\n\u2022 Experience with state-of-the-art algorithms and topologies including, but not limited to: GNNs, GANs, Transformers, deep and wide, SSMs, LLMs among others\n\u2022 Proven in-depth knowledge in Generative AI technology and Large Language Models (LLM) with focus in LLM optimization\n\nPreferred Qualifications:\n\u2022 Experience in AI/ML in the healthcare and or Fintech sector\n\u2022 Experience working with cross-functional and distributed teams in a global and diverse environment\n\u2022 Experience in establishing AI/ML best practices, standards, and ethics\n\u2022 All employees working remotely will be required to adhere to UnitedHealth Group\u2019s Telecommuter Policy.\n\nCalifornia, Colorado, Connecticut, Hawaii, Nevada, New Jersey, New York, Maryland, Rhode Island, Washington, Washington, D.C. Residents Only: The salary range for this role is $122,100 to $234,700 annually. Pay is based on several factors including but not limited to local labor markets, education, work experience, certifications, etc. UnitedHealth Group complies with all minimum wage laws as applicable. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you\u2019ll find a far-reaching choice of benefits and incentives.\n\nApplication Deadline: This will be posted for a minimum of 2 business days or until a sufficient candidate pool has been collected. Job posting may come down early due to volume of applicants.\n\nAt UnitedHealth Group, our mission is to help people live healthier lives and make the health system work better for everyone. We believe everyone\u2013of every race, gender, sexuality, age, location and income\u2013deserves the opportunity to live their healthiest life. Today, however, there are still far too many barriers to good health which are disproportionately experienced by people of color, historically marginalized groups and those with lower incomes. We are committed to mitigating our impact on the environment and enabling and delivering equitable care that addresses health disparities and improves health outcomes \u2014 an enterprise priority reflected in our mission.\n\nUnitedHealth Group is an Equal Employment Opportunity employer under applicable law and qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status, or any other characteristic protected by local, state, or federal laws, rules, or regulations.\n\nUnitedHealth Group is a drug - free workplace. Candidates are required to pass a drug test before beginning employment.\n\n#OptumTechPJ",
    "url": "https://usnlx.com/arlington-va/principal-aiml-engineer-remote/2CFF1B20BB7E4072BFB2C0D19F587866/job/?vs=28&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "AI/ML Engineer/Digital Mapping (Jr.)",
    "company": "Quadrant, Inc.",
    "location": "Vienna",
    "salary": "",
    "description": "AI/ML Engineer/Digital Mapping (Jr)\nVienna, VA\nPay From: $28.00 per hour\n\nMUST:\nEntry level AI/ML Engineer (digital mapping)\nProgramming in Python and familiarity with ML libraries.\nUnderstanding of image processing and an interest in remote sensing/ GIS tools.\nStrong attention to detail in data preparation and annotation.\nInterest in generative AI and how it can be applied to infrastructure/ spatial analytics.\nProactive and resourceful with a strong willingness to learn.\nExcellent communication skills for documenting work and collaborating across teams.\nDetail-oriented mindset with the ability to manage multiple tasks effectively.\nBachelor s degree (completed or in progress) in Computer Science, Data Science, AI/ML, Geospatial Science, or related field.\n\nDUTIES:\nAssist with training, testing and fine-tuning AI/ML models for remote sending data (imagery, 3D scans, point clouds).\nSupport development of GenAI tools for reporting, insights, and automation.\nWork on GeoAI pipelines that process georeferenced datasets for mapping, temporal change detection, and digital twins.\nAnnotate, clean, and validate data to support model accuracy and reliability.\nRun experiments and contribute to performance evaluation of computer vision and geospatial models.\nDocument workflows, maintain datasets, and assist in deployment preparation.\nParticipate in weekend coverage schedules to ensure data and models run smoothly.\n\nQuadrant is an affirmative action/equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, status as a protected veteran, or status as an individual with a disability. Healthcare benefits are offered to all eligible employees according to compliance mandated by the Affordable Care Act .",
    "url": "https://www.indeed.com/viewjob?jk=10d6326e5a787734&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Sr. Lead Machine Learning Engineer, Shopping (Remote-Eligible)",
    "company": "Capital One",
    "location": "McLean",
    "salary": "",
    "description": "Sr. Lead Machine Learning Engineer, Shopping (Remote-Eligible)\n\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One Shopping, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs.\n\nAs a Capital One Machine Learning Engineer (MLE), you'll be part of an Agile team dedicated to productionizing machine learning applications and systems at scale. You'll participate in the detailed technical design, development, and implementation of machine learning applications using existing and emerging technology platforms. You'll focus on machine learning architectural design, develop and review model and application code, and ensure high availability and performance of our machine learning applications. You'll have the opportunity to continuously learn and apply the latest innovations and best practices in machine learning engineering.\n\nWhat you'll do in the role:\n\u2022 The MLE role overlaps with many disciplines, such as Ops, Modeling, and Data Engineering. In this role, you'll be expected to perform many ML engineering activities, including one or more of the following:\n\u2022 Design, build, and/or deliver ML models and components that solve real-world business problems, while working in collaboration with the Product and Data Science teams.\n\u2022 Inform your ML infrastructure decisions using your understanding of ML modeling techniques and issues, including choice of model, data, and feature selection, model training, hyperparameter tuning, dimensionality, bias/variance, and validation).\n\u2022 Solve complex problems by writing and testing application code, developing and validating ML models, and automating tests and deployment.\n\u2022 Collaborate as part of a cross-functional Agile team to create and enhance software that enables state-of-the-art big data and ML applications.\n\u2022 Retrain, maintain, and monitor models in production.\n\u2022 Leverage or build cloud-based architectures, technologies, and/or platforms to deliver optimized ML models at scale.\n\u2022 Construct optimized data pipelines to feed ML models.\n\u2022 Leverage continuous integration and continuous deployment best practices, including test automation and monitoring, to ensure successful deployment of ML models and application code.\n\u2022 Ensure all code is well-managed to reduce vulnerabilities, models are well-governed from a risk perspective, and the ML follows best practices in Responsible and Explainable AI.\n\u2022 Use programming languages like Python, Scala, or Java.\n\nBasic Qualifications:\n\u2022 Bachelor's degree\n\u2022 At least 8 years of experience designing and building data-intensive solutions using distributed computing (Internship experience does not apply)\n\u2022 At least 4 years of experience programming with Python, Scala, or Java\n\u2022 At least 3 years of experience building, scaling, and optimizing ML systems\n\u2022 At least 2 years of experience leading teams developing ML solutions\n\nPreferred Qualifications:\n\u2022 Master's or doctoral degree in computer science, electrical engineering, mathematics, or a similar field\n\u2022 Experience developing and deploying ML solutions in a public cloud such as AWS, Azure, or Google Cloud Platform\n\u2022 4+ years of on-the-job experience with an industry recognized ML framework such as scikit-learn, PyTorch, Dask, Spark, or TensorFlow\n\u2022 3+ years of experience developing performant, resilient, and maintainable code\n\u2022 3+ years of experience with data gathering and preparation for ML models\n\u2022 3+ years of people management experience\n\u2022 ML industry impact through conference presentations, papers, blog posts, open source contributions, or patents\n\u2022 3+ years of experience building production-ready data pipelines that feed ML models\n\u2022 Ability to communicate complex technical concepts clearly to a variety of audiences\n\nCapital One will consider sponsoring a new qualified applicant for employment authorization for this position.\n\nThe minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.\n\nRemote (Regardless of Location): $204,900 - $233,800 for Sr. Lead Machine Learning Engineer\n\nMcLean, VA: $225,400 - $257,200 for Sr. Lead Machine Learning Engineer\n\nCandidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate's offer letter.\n\nThis role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\n\nThis role is expected to accept applications for a minimum of 5 business days.\n\nNo agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City's Fair Chance Act; Philadelphia's Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\n\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\n\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\n\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",
    "url": "https://www.ziprecruiter.com/c/Capitalone/Job/Sr.-Lead-Machine-Learning-Engineer,-Shopping-(Remote-Eligible)/-in-Mclean,VA?jid=41a67ef17e1338d4&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Data Scientist",
    "company": "Willow Informative Services LLC",
    "location": "Suitland-Silver Hill",
    "salary": "",
    "description": "Company Description\n\nWillow Informative Services is a veteran-owned consulting firm that provides strategic advisory, program management, and operational support to government and commercial clients. With expertise in defense, intelligence, and mission-driven environments, we deliver tailored, data-informed solutions to drive clarity, impact, and long-term success. We work closely with clients to solve complex challenges through collaboration, agility, and integrity.\n\nRole Description\n\nThis is a full-time, on-site role for a Data Scientist located in Suitland, MD. The Data Scientist will be responsible for analyzing and interpreting complex data sets to support decision-making processes. Daily tasks include statistical analysis, data analytics, data visualization, and designing data models. The Data Scientist will work closely with cross-functional teams to ensure insights are effectively implemented and aligned with organizational goals.\n\nQualifications\n\u2022 Top Secret Clearance\n\u2022 Experience in Data Science and Data Analysis\n\u2022 Proficiency in Statistics and Data Analytics\n\u2022 Skills in Data Visualization\n\u2022 Strong problem-solving and analytical thinking abilities\n\u2022 Excellent written and verbal communication skills\n\u2022 Ability to work independently and collaboratively in a team environment\n\u2022 Experience with tools and languages such as Python, R, SQL is a plus\n\u2022 Bachelor's or Master's degree in Data Science, Statistics, Computer Science, or a related field",
    "url": "https://www.linkedin.com/jobs/view/data-scientist-at-willow-informative-services-llc-4332431781?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (Python / Data Analytics)",
    "company": "Innovative Object Solutions Inc",
    "location": "Washington",
    "salary": "",
    "description": "Benefits:\n\u2022 401(k)\n\u2022 Bonus based on performance\n\u2022 Competitive salary\n\u2022 Paid time off\n\nJoin a mission-driven team improving one of the nation\u2019s most visible online systems. We build analytics and data-driven tools that help millions of users have faster, easier digital experiences. You\u2019ll work with senior engineers and data scientists on large-scale behavioral datasets, modern cloud tech, and real-world challenges that truly matter.\n\nWhat You\u2019ll Do\n\u2022 Develop and maintain Python code for data ingestion, transformation, and analytics pipelines.\n\u2022 Build and optimize ETL workflows, APIs, and database integrations.\n\u2022 Support dashboards and visualization tools that inform UX and product decisions.\n\u2022 Collaborate on data quality, performance tuning, and automated testing.\n\u2022 Contribute to CI/CD pipelines and reproducible analytic environments.\n\nWhat We\u2019re Looking For\n\u2022 1\u20134 years of software development experience (internships or full-time).\n\u2022 Strong skills in Python and SQL; familiarity with Spark, Databricks, or Snowflake is a plus.\n\u2022 Understanding of REST APIs, data pipelines, and version control (Git).\n\u2022 Interest in data analytics, UX improvement, and modern cloud environments (AWS/Azure).\nClear communicator who thrives in collaborative, agile teams.\n\u2022 Why Join Us\n\u2022 Work on a high-profile federal digital system used by millions.\n\u2022 Learn from senior mentors while building your technical portfolio.\n\u2022 Flexible hybrid work, competitive salary, and strong benefits.\n\u2022 Opportunity to make measurable impact through technology that serves the public.\n\nFlexible work from home options available.",
    "url": "https://www.glassdoor.com/job-listing/data-scientist-python-data-analytics-innovative-object-solutions-inc-JV_IC1138213_KO0,36_KE37,68.htm?jl=1009922882242&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Advanced Data Scientist and Researcher",
    "company": "Booz Allen Hamilton",
    "location": "Arlington",
    "salary": 113000,
    "description": "Job Number: R0228930\n\nAdvanced Data Scientist and Researcher\n\nThe Opportunity:\n\nAs an analytics professional, you\u2019re excited at the prospect of unlocking the secrets held by a data set, and you\u2019re fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. If you care about leading a mission forward as much as advancing the field of data science, this is the opportunity for you. Your deep analytics, data science, and consulting expertise, coupled with an original approach to your work, will guide clients and stakeholders as they make sense of their data and encourage actionable results. We\u2019re looking for someone like you to lead complex data exploration and analytics projects through your experience with data solutions, operationalizing models, containerization, data architecture, and cloud computing on data analytics platforms used by the Department of Defense.\n\nAs an advanced data scientist and researcher on our National Security team, you\u2019ll introduce innovative data analytics and AI methodologies to make a real-world impact on resiliency projects, change the world, and protect our Service members. You\u2019ll share your skills in data science and AI and shape the future of analytics through a variety of means, such as peer-reviewed papers and major conference presentations.\n\nYou will apply expert understanding of social science disciplines, research methodology, and statistics to investigate, analyze, and evaluate warfighter readiness and resiliency policies, programs, and procedures. In addition, you will apply specific functional knowledge, including working and general industry knowledge, leading solutions, and working independently on a variety of Department of Defense problems of complex scope in a dynamic and fast-paced environment. You will be responsible for reviewing or guiding the activities of more junior employees.\n\nJoin us. The world can\u2019t wait.\n\nYou Have:\u202f\n\u2022 10+ years of experience conducting social science, public health, and readiness research supporting the DoD initiatives\n\u2022 10+ years of experience creating verbal and written communication products for non-technical clients, including research reports, briefing decks, and information papers\n\u2022 10+ years of experience interpreting statistical findings and presenting data and research results to non-technical audiences\n\u2022 Knowledge of research methodology, including qualitative methods, quantitative methods, and statistics\n\u2022 Knowledge of workplace climate indicators that contribute to warfighter readiness\n\u2022 Secret clearance\n\u2022 Doctorate degree in Social Science\n\nNice If You Have:\u202f\n\u2022 Experience applying public health and social science research in a military setting\n\u2022 Knowledge of multivariate statistical methods, including logistic regression, multivariate regression, or multilevel modeling\n\u2022 Ability to leverage quantitative methodology to shape research questions and data models\n\u2022 Ability to operationalize key research concepts\n\u2022 Ability to prioritize tasks and work in a fast-paced environment\n\nClearance:\n\nApplicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required.\n\nCompensation\n\nAt Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.\n\nSalary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $112,800.00 to $257,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees. This posting will close within 90 days from the Posting Date.\n\nIdentity Statement\n\nAs part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.\n\nWork Model\n\nOur people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.\n\u2022 If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility.\n\u2022 If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role.\n\nCommitment to Non-Discrimination\n\nAll qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law.",
    "url": "https://www.linkedin.com/jobs/view/advanced-data-scientist-and-researcher-at-booz-allen-hamilton-4333103320?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Scientist - All Experience Levels",
    "company": "Actifai",
    "location": "Washington",
    "salary": "",
    "description": "Actifai is seeking experienced data scientists.\n\nThe Data Scientist will participate as a key team member in envisioning, designing, coding, testing, and improving the algorithms that are central to our mission as a company. They will work in continual collaboration with software engineers and partner company stakeholders.\n\nThe Company\n\nActifai is an artificial intelligence company. We help clients - primarily those in the cable and telecom industry - optimize their high value, high leverage decisions. Typically this includes things like customer acquisition, customer retention, and customer development (upsells/cross-sells).\n\nActifai is part of Foundry.ai, a technology fund/studio that creates AI software companies in partnership with large global enterprises. Foundry's operating companies focus on practical applications of AI that drive immediate, measurable, and recurring improvements to financial performance. Foundry is backed by approximately $100MM in capital from leading private equity and venture capital partners.\n\nThe Position\n\nThe Data Scientist will participate as a key team member in envisioning, designing, coding, testing and improving the algorithms that are central to our mission as a company. They will work in continual collaboration with software engineers and partner company stakeholders.\n\nSome key challenges will include: identifying external datasets and developing API or other methods for accessing them; fluidly self-educating on existing methods for modeling end-user behavior in a variety of contexts, or developing new methods for doing this when necessary; designing experiments to answer targeted questions; teaming with developers to embed algorithms in applications; understanding business economics, user motivation and other contextual information in order to guide analytical trade-offs, with a focus on \"minimum viable algorithm\" followed by intensive, iterative improvement; writing code that builds new companies and products.\n\nEntry level candidates will likely have many of the following characteristics:\n\u2022 Comfortable using scripting languages, and relational or NoSQL databases.\n\u2022 Familiar with general-purpose machine learning methods, such as regression, decision trees, neural networks, Bayesian networks, and so on. Capable of self-teaching new algorithmic methods easily.\n\u2022 Passionate about using data to drive strategy and business recommendation.\n\u2022 Well-rounded top performer who is able to \"crunch the numbers\" one minute, and critically think through strategic issues the next.\n\u2022 Excited to move fast and know how to prioritize and make critical decisions.\n\u2022 A self-starter: you have started something on your own before -- an open-source project, a new project within a company or university, a start-up, or something else.\n\u2022 Able to communicate as effectively when delivering complex data-driven findings to businesspeople, as when discussing machine-learning specifications with engineers.\n\nSenior candidates will often differentiate themselves with some of the following:\n\u2022 Proven capability in applying machine learning methods to novel problems and driving quantifiable gains in outcome.\n\u2022 Experience planning and executing work modules that span several months.\n\u2022 Broad skillset that blurs the lines between data science and software engineering.\nExceptional computational background (e.g., developed new algorithms and/or has a relevant PhD).\n\u2022 Exceptional business background (e.g., managing client relationships on technical projects, experience at a top-tier consultancy and/or MBA from a leading program).\n\nAcademic Qualifications\n\nCandidates should hold a very strong CS, math, science or similar degree from a leading program. PhD applicants are actively considered. Successful candidates will be comfortable in a fluid, entrepreneurial environment, but one that is focused on developing reusable software applications, not bespoke analytical solutions.\n\nThe programming languages and tools used most frequently at Actifai are: Python, SQL, Javascript, Github, AWS, Google Cloud, Docker, Kubernetes, and shell scripts. We do not expect candidates to be experts in all of these, although a strong proficiency in Python and the ability to learn new languages as needed are common.\n\nBenefits and Culture\n\nActifai offers an extremely competitive compensation package, including equity, employer-covered health/vision/dental insurance (with an optional FSA), and 401k matching. Employees receive a generous PTO allowance, and can work both remotely and from our office in downtown Washington, D.C. Successful candidates will join a small team of ambitious, supportive co-workers with ample opportunities to take on responsibilities beyond their assigned role.\n\nFor additional information on benefits & what it's like to work at Actifai, please visit actif.ai/careers.\n\nFinally, we highlight that excellence has no single mold, particularly in a field as rapidly evolving as AI. We're looking for excellent candidates of all backgrounds with strong business intuition and coding skills, and welcome applicants regardless of ethnic/national origin, gender, race, religious beliefs, disability, sexual orientation or age.\n\nA Note on the Interview Process\n\nActifai interviews share some common features with other technical hiring processes and have some important differences. These reflect the unique roles our employees play, which often involve early-stage development of products and environments where idea generation, product-market fit, and partner interaction may be significant aspects of their jobs.\n\nAll our roles have technical interviews that test core engineering competencies, ability to discuss technical work, formalize generic problems into a quantitative system, problem-solve, and act as part of a team.\n\nWe also ask case-study interview questions, which are less common for technical roles. Case studies are open-ended business problems that do not have set correct answers. They require the interviewee to consider the provided information, decide what is most important, and then build a structure to answer the key questions in discussion with the interviewer. We've incorporated these into our process because Actifai is, similarly, working on dynamic problems with many possible solutions. These challenges require business acumen, problem-solving skills, and the ability to think on your feet and prioritize information and actions.\n\nOur staff will often describe this unique mindset as not only wanting to write the code to solve a problem but also being able to define the problem that we are solving - and our interview process is designed to help employees showcase their skills in this area.",
    "url": "https://www.ziprecruiter.com/c/Actifai/Job/Data-Scientist-All-Experience-Levels/-in-Washington,DC?jid=e360b407c2480d29&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Data Scientist 2",
    "company": "HII",
    "location": "Arlington",
    "salary": 91464,
    "description": "Date: Oct 29, 2025\n\nLocation: Arlington, VA, Virginia, United States\n\nCompany: HII's Mission Technologies division\n\nRequisition Number: 25962\n\nRequired Travel: 0 - 10%\n\nEmployment Type: Full Time/Salaried/Exempt\n\nAnticipated Salary Range: $91,464.00 - $139,000.00\n\nSecurity Clearance: Secret\n\nLevel of Experience: Mid\n\nThis opportunity resides with Warfare Systems (WS), a business group within HII\u2019s Mission Technologies division. Warfare Systems comprises cyber and mission IT; electronic warfare; and C5ISR systems.\n\nHII works within our nation\u2019s intelligence and cyber operations communities to defend our interests in cyberspace and anticipate emerging threats. Our capabilities in cybersecurity, network architecture, reverse engineering, software and hardware development uniquely enable us to support sensitive missions for the U.S. military and federal agency partners.\n\nMeet HII\u2019s Mission Technologies Division\nOur team of more than 7,000 professionals worldwide delivers all-domain expertise and advanced technologies in service of mission partners across the globe. Mission Technologies is leading the next evolution of national defense \u2013 the data evolution - by accelerating a breadth of national security solutions for government and commercial customers. Our capabilities range from C5ISR, AI and Big Data, cyber operations and synthetic training environments to fleet sustainment, environmental remediation and the largest family of unmanned underwater vehicles in every class. Find the role that\u2019s right for you. Apply today. We look forward to meeting you.\n\nTo learn more about Mission Technologies, click here for a short video: https://vimeo.com/732533072\n\nJob Description\n\nCome join our growing team today, supporting our C5ISR Business Group! HII-Mission Technologies is currently seeking a skilled Data Scientist, who will support refining a centralized data environment (CDE) with impact across DoD! Key functionality for this position contributes toward auditable financial transaction data and building a common operating picture for leadership.\n\nA successful candidate will be well-versed in Python, knowledgeable about relational database (SQL), has strong written/oral communications, and can work as part of a team providing productive input toward solving challenging problems. Team members must be able to internalize and appreciate strategic requirements, to best align the most meaningful data to decision makers- getting the right data to the right people!\n\nEssential Job Responsibilities\n\u2022 Designs, models, documents, and guides the logical and conceptual relationship of data and database changes for complex applications.\n\u2022 Analyzes needs and requirements of existing and proposed systems, and develops technical, structural, and organizational specifications.\n\u2022 May create standards and/or do modeling to monitor and enhance capacity and performance.\n\u2022 Creates scripts for data ingest pipelines (Python).\n\u2022 Familiar with Relational Databases (SQL).\n\u2022 Utilizes Agile development processes.\n\u2022 Guides development aligned to established business needs and/or policies.\n\u2022 Additional duties as assigned or required.\n\nMinimum Qualifications\n\u2022 3 years relevant experience with Bachelors in related field; 1 year relevant experience with Masters in related field; or High School Diploma or equivalent and 7 years relevant experience.\n\u2022 Python experience.\n\u2022 Can operate independently and within a team.\n\u2022 Self-starter who takes initiative.\n\u2022 Clearance: Must possess and maintain a Secret clearance.\n\nPhysical Requirements\n\nMay require working in an office, industrial, shipboard, or laboratory environment. Capable of climbing ladders and tolerating confined spaces and extreme temperature variances.\n\nHII is more than a job - it\u2019s an opportunity to build a new future. We offer competitive benefits such as best-in-class medical, dental and vision plan choices; wellness resources; employee assistance programs; Savings Plan Options (401(k)); financial planning tools, life insurance; employee discounts; paid holidays and paid time off; tuition reimbursement; as well as early childhood and post-secondary education scholarships. Bonus/other non-recurrent compensation is occasionally offered for qualified positions, and if applicable to this role will be addressed by the recruiter at the screening phase of application.\n\nWhy HII\nWe build the world\u2019s most powerful, survivable naval ships and defense technology solutions that safeguard our seas, sky, land, space and cyber. Our workforce includes skilled tradespeople; artificial intelligence, machine learning (AI/ML) experts; engineers; technologists; scientists; logistics experts; and business administration professionals.\n\nRecognized as one of America\u2019s top large company employers, we are a values and ethics driven organization that puts people\u2019s safety and well-being first. Regardless of your role or where you serve, at HII, you\u2019ll find a supportive and welcoming environment, competitive benefits, and valuable educational and training programs for continual career growth at every stage of your career.\n\nTogether we are working to ensure a future where everyone can be free and thrive.\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, physical or mental disability, age, or veteran status or any other basis protected by federal, state, or local law.\n\nDo You Need Assistance?\nIf you need a reasonable accommodation for any part of the employment process, please send an e-mail to buildyourcareer@hii-co.com and let us know the nature of your request and your contact information. Reasonable accommodations are considered on a case-by-case basis. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address. Additionally, you may also call 1-844-849-8463 for assistance. Press #3 for HII Mission Technologies.",
    "url": "https://www.indeed.com/viewjob?jk=cc15ae23a2e3b751&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Scientist SME",
    "company": "Iron EagleX",
    "location": "Arlington",
    "salary": "",
    "description": "Overview\n\nIron EagleX (IEX), a wholly owned subsidiary of General Dynamics Information Technology, delivers agile IT and Intelligence solutions. Combining small-team flexibility with global scale, IEX leverages emerging technologies to provide innovative, user-focused solutions that empower organizations and end users to operate smarter, faster, and more securely in dynamic environments.\n\nResponsibilities\n\nJob Description:\n\nIron EagleX is seeking a Data Scientist SME to join our dynamic team in Crystal City, VA. This role creates and delivers innovative analytics through production software as a member of a fast-paced, multi-discipline team. This position is onsite and requires travel for 60-90 days to CONUS sites each year.\n\nJob Duties Include (but not limited to):\n\u2022 Build and ship Python-based analytic services (APIs, batch, streaming) with CI/CD, testing, and containerization.\n\u2022 Build and update web-based GUIs (Streamlit, etc.) for the lightweight visualization of complex analytics.\n\u2022 Design and harden automated methods for linking disparate sources across very large datasets.\n\u2022 Own the lifecycle: ingest/ETL, modeling, deployment, and monitoring (performance, drift, data quality).\n\u2022 Work with analysts, developers, and other data scientists to turn workflows into robust, automated pipelines.\n\u2022 Apply supervised/unsupervised learning, graph methods, and statistical modeling.\n\u2022 Enforce engineering rigor: unit and integration testing, typing, code review, and documentation.\n\u2022 Identify data gaps/anomalies and improve TTPs and methodologies in classified environments.\n\nQualifications\n\nRequired Skills & Experience:\n\u2022 Production Python expertise (packages, APIs/services, packaging, dependency management).\n\u2022 SQL proficiency; experience with large-scale systems (Trino, PostgreSQL, Hive; OpenSearch, ElasticSearch; distributed compute a plus).\n\u2022 Proven model productionization (FastAPI, batch jobs, or streaming), CI/CD, Docker, and Linux.Strong with NumPy, SciPy, pandas, scikit-learn, Matplotlib; comfortable moving from exploration to maintainable code.\n\u2022 Practical experience in entity resolution, graph/relational reasoning, and applied statistics.\n\u2022 Experience integrating structured, unstructured text, and semi-structured data.\n\u2022 Due to US Government Contract Requirements, only US Citizens are eligible for this role.\n\nDesired Skills:\n\u2022 Orchestration & Data Quality: Airflow\n\u2022 Distributed & Streaming: Spark, Kafka\n\u2022 Development and CI/CD: Kubernetes, pytest\n\u2022 Observability & Reliability: Data & model drift monitoring\n\nEducation & Certifications:\n\u2022 Bachelor's degree in Computer Science, Statistics, Engineering, or a related field (or equivalent experience). Advanced degrees are a plus.\n\nSecurity Clearance:\n\u2022 An active TS/SCI security clearance is REQUIRED and candidates must have or be willing to obtain a CI Poly. Candidates without this clearance will not be considered.\n\nEqual Opportunity Employer / Individuals with Disabilities / Protected Veterans",
    "url": "https://careers-ironeaglex.icims.com/jobs/2788/data-scientist-sme/job?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T04:00:00.000Z"
  },
  {
    "title": "Advanced Data Scientist and Researcher with Security Clearance",
    "company": "ClearanceJobs",
    "location": "Arlington",
    "salary": 113000,
    "description": "Job Number: R0228930 Advanced Data Scientist and Researcher The Opportunity: As an analytics professional, you're excited at the prospect of unlocking the secrets held by a data set, and you're fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. If you care about leading a mission forward as much as advancing the field of data science, this is the opportunity for you. Your deep analytics, data science, and consulting expertise, coupled with an original approach to your work, will guide clients and stakeholders as they make sense of their data and encourage actionable results. We're looking for someone like you to lead complex data exploration and analytics projects through your experience with data solutions, operationalizing models, containerization, data architecture, and cloud computing on data analytics platforms used by the Department of Defense. As an advanced data scientist and researcher on our National Security team, you'll introduce innovative data analytics and AI methodologies to make a real-world impact on resiliency projects, change the world, and protect our Service members. You'll share your skills in data science and AI and shape the future of analytics through a variety of means, such as peer-reviewed papers and major conference presentations. You will apply expert understanding of social science disciplines, research methodology, and statistics to investigate, analyze, and evaluate warfighter readiness and resiliency policies, programs, and procedures. In addition, you will apply specific functional knowledge, including working and general industry knowledge, leading solutions, and working independently on a variety of Department of Defense problems of complex scope in a dynamic and fast-paced environment. You will be responsible for reviewing or guiding the activities of more junior employees. Join us. The world can't wait. You Have: * 10+ years of experience conducting social science, public health, and readiness research supporting the DoD initiatives\n\u2022 10+ years of experience creating verbal and written communication products for non-technical clients, including research reports, briefing decks, and information papers\n\u2022 10+ years of experience interpreting statistical findings and presenting data and research results to non-technical audiences\n\u2022 Knowledge of research methodology, including qualitative methods, quantitative methods, and statistics\n\u2022 Knowledge of workplace climate indicators that contribute to warfighter readiness\n\u2022 Secret clearance\n\u2022 Doctorate degree in Social Science Nice If You Have: * Experience applying public health and social science research in a military setting\n\u2022 Knowledge of multivariate statistical methods, including logistic regression, multivariate regression, or multilevel modeling\n\u2022 Ability to leverage quantitative methodology to shape research questions and data models\n\u2022 Ability to operationalize key research concepts\n\u2022 Ability to prioritize tasks and work in a fast-paced environment Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen's benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual's particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $112,800.00 to $257,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen's total compensation package for employees. This posting will close within 90 days from the Posting Date. Identity Statement As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. * If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility.\n\u2022 If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role. Commitment to Non-Discrimination All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law.",
    "url": "https://www.linkedin.com/jobs/view/advanced-data-scientist-and-researcher-with-security-clearance-at-clearancejobs-4331407726?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T08:00:00.000Z"
  },
  {
    "title": "Data Scientist 2 - 25962",
    "company": "HII's Mission Technologies division",
    "location": "Arlington",
    "salary": "",
    "description": "Requisition Number: 25962\n\nRequired Travel: 0 - 10%\n\nEmployment Type: Full Time/Salaried/Exempt\n\nAnticipated Salary Range: $91,464.00 - $139,000.00\n\nSecurity Clearance: Secret\n\nLevel of Experience: Mid\n\nThis opportunity resides with Warfare Systems (WS), a business group within HII\u2019s Mission Technologies division. Warfare Systems comprises cyber and mission IT; electronic warfare; and C5ISR systems.\n\nHII works within our nation\u2019s intelligence and cyber operations communities to defend our interests in cyberspace and anticipate emerging threats. Our capabilities in cybersecurity, network architecture, reverse engineering, software and hardware development uniquely enable us to support sensitive missions for the U.S. military and federal agency partners.\n\nMeet HII\u2019s Mission Technologies Division\nOur team of more than 7,000 professionals worldwide delivers all-domain expertise and advanced technologies in service of mission partners across the globe. Mission Technologies is leading the next evolution of national defense \u2013 the data evolution - by accelerating a breadth of national security solutions for government and commercial customers. Our capabilities range from C5ISR, AI and Big Data, cyber operations and synthetic training environments to fleet sustainment, environmental remediation and the largest family of unmanned underwater vehicles in every class. Find the role that\u2019s right for you. Apply today. We look forward to meeting you.\n\nTo learn more about Mission Technologies, click here for a short video: https://vimeo.com/732533072\nJob Description\n\nCome join our growing team today, supporting our C5ISR Business Group! HII-Mission Technologies is currently seeking a skilled Data Scientist, who will support refining a centralized data environment (CDE) with impact across DoD! Key functionality for this position contributes toward auditable financial transaction data and building a common operating picture for leadership.\n\nA successful candidate will be well-versed in Python, knowledgeable about relational database (SQL), has strong written/oral communications, and can work as part of a team providing productive input toward solving challenging problems. Team members must be able to internalize and appreciate strategic requirements, to best align the most meaningful data to decision makers- getting the right data to the right people!\n\nEssential Job Responsibilities\n\u2022 Designs, models, documents, and guides the logical and conceptual relationship of data and database changes for complex applications.\n\u2022 Analyzes needs and requirements of existing and proposed systems, and develops technical, structural, and organizational specifications.\n\u2022 May create standards and/or do modeling to monitor and enhance capacity and performance.\n\u2022 Creates scripts for data ingest pipelines (Python).\n\u2022 Familiar with Relational Databases (SQL).\n\u2022 Utilizes Agile development processes.\n\u2022 Guides development aligned to established business needs and/or policies.\n\u2022 Additional duties as assigned or required.\n\nMinimum Qualifications\n\u2022 3 years relevant experience with Bachelors in related field; 1 year relevant experience with Masters in related field; or High School Diploma or equivalent and 7 years relevant experience.\n\u2022 Python experience.\n\u2022 Can operate independently and within a team.\n\u2022 Self-starter who takes initiative.\n\u2022 Clearance: Must possess and maintain a Secret clearance.\n\nPhysical Requirements\n\nMay require working in an office, industrial, shipboard, or laboratory environment. Capable of climbing ladders and tolerating confined spaces and extreme temperature variances.\n\nHII is more than a job - it\u2019s an opportunity to build a new future. We offer competitive benefits such as best-in-class medical, dental and vision plan choices; wellness resources; employee assistance programs; Savings Plan Options (401(k)); financial planning tools, life insurance; employee discounts; paid holidays and paid time off; tuition reimbursement; as well as early childhood and post-secondary education scholarships. Bonus/other non-recurrent compensation is occasionally offered for qualified positions, and if applicable to this role will be addressed by the recruiter at the screening phase of application.\n\nWhy HII\nWe build the world\u2019s most powerful, survivable naval ships and defense technology solutions that safeguard our seas, sky, land, space and cyber. Our workforce includes skilled tradespeople; artificial intelligence, machine learning (AI/ML) experts; engineers; technologists; scientists; logistics experts; and business administration professionals.\n\nRecognized as one of America\u2019s top large company employers, we are a values and ethics driven organization that puts people\u2019s safety and well-being first. Regardless of your role or where you serve, at HII, you\u2019ll find a supportive and welcoming environment, competitive benefits, and valuable educational and training programs for continual career growth at every stage of your career.\n\nTogether we are working to ensure a future where everyone can be free and thrive.\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, physical or mental disability, age, or veteran status or any other basis protected by federal, state, or local law.\n\nDo You Need Assistance?\nIf you need a reasonable accommodation for any part of the employment process, please send an e-mail to buildyourcareer@hii-co.com and let us know the nature of your request and your contact information. Reasonable accommodations are considered on a case-by-case basis. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address. Additionally, you may also call 1-844-849-8463 for assistance. Press #3 for HII Mission Technologies.",
    "url": "https://jobs.hii-tsd.com/job/Arlington%2C-VA-Data-Scientist-2-25962-Virg/1338747600/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Data Scientist - AI/ML Jobs",
    "company": "Altamira",
    "location": "Suitland-Silver Hill",
    "salary": "",
    "description": "Altamira Technologies has a long and successful history providing innovative solutions throughout the U.S. National Security community. Headquartered in McLean, Virginia, Altamira serves the defense, intelligence, and homeland security communities worldwide by focusing on creating innovative solutions leveraging common standards in architecture, data, and security. Altamira believes that our people and the culture of our company differentiate us from other companies.\n\nPOSITION: Data Scientist - AI/ML\n\nResponsibilities:\n\u2022 Analyze, interpret, and apply data science methodologies to inform DoD policy development and implementation.\n\u2022 Plan and execute the deployment of trained AI/ML models to production environments.\n\u2022 Translate complex technical findings into actionable policy recommendations for senior leadership.\n\u2022 Develop frameworks and guidelines for the ethical, secure, and effective use of data within defense operations.\n\u2022 Collaborate with cross-functional teams, including military leadership, policymakers, and technical experts, to align data initiatives with mission objectives.\n\u2022 Monitor and evaluate the impact of data-driven policies, ensuring compliance with federal regulations, cybersecurity standards, and DoD directives.\n\u2022 Provide subject matter expertise on emerging technologies, artificial intelligence, and machine learning as they relate to defense policy.\n\u2022 Ensure data governance, privacy, and security considerations are embedded in all policy recommendations.\n\nRequired Qualifications:\n\u2022 U.S. citizenship with the ability to obtain and maintain a Top Secret/SCI security clearance.\n\u2022 Bachelor degree or higher in Data Science, Computer Science, Statistics, Public Policy, or a related field.\n\u2022 Minimum of 3 years of experience in data science, analytics, or quantitative research, with demonstrated expertise in AI/ML deployments to a production environment.\n\u2022 Strong understanding of DoD operations, defense policy frameworks, and national security priorities.\n\u2022 Proficiency in statistical modeling, machine learning, and data visualization tools (e.g., Python, R, SQL, Tableau).\n\u2022 Demonstrated ability to synthesize technical findings into clear, concise policy recommendations.\n\u2022 Knowledge of federal data governance standards, cybersecurity requirements, and ethical considerations in AI/ML.\n\u2022 Excellent written and verbal communication skills, with experience briefing senior leaders and policymakers.\n\nDesired Qualifications:\n\u2022 Prior experience working within the Department of Defense or other federal agencies.Familiarity with classified data environments and secure data handling practices.\n\u2022 Strong leadership skills with the ability to manage cross-disciplinary teams\n\nCompetencies:\n\u2022 Strategic Thinking: Ability to align data science initiatives with defense policy objectives.\n\u2022 Technical Expertise: Deep knowledge of data science methods and deployments\n\u2022 Communication: Skilled at translating technical insights into policy-relevant language for diverse audiences.\n\u2022 Adaptability: Ability to pivot quickly in response to evolving mission requirements and emerging technologies.\n\nClearance Requirement:\n\u2022 Must possess or be eligible to obtain a Top Secret/SCI clearance.\n\nTHIS POSITITION REQUIRES A TS/SCI CLEARANCE. A TS/SCI clearance would require US Citizenship and any candidate that applies should possess this level of clearance before applying.\n\nAltamira is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, national origin, disability, or protected veteran status.",
    "url": "https://www.clearancejobs.com/jobs/8570503/data-scientist-policy-specialist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-26T00:00:00.000Z"
  },
  {
    "title": "Data Scientist Sr",
    "company": "BAE Systems",
    "location": "Washington",
    "salary": "",
    "description": "Job Description\n\nBAE Systems is seeking a Data Scientist to join the Machine-assisted Analytic Rapid-repository System (MARS) Advanced Development Operations (DevOps) and Sustainment Support (ADOS) program and provide support to facilitate operations of critical MARS infrastructure and services. This effort focuses on providing a comprehensive set of System/ Software Engineering and IT Services to maintain, sustain, enhance, and improve/ modernize MARS. The ideal candidate will be located in the National Capital Region.\n\nPlease note that this is contingent upon contract award, with an anticipated decision expected by Winter/ Spring 2026.\n\nThe Data Scientist responsibilities include, but are not limited to:\n\u2022 Collects, processes, and performs sophisticated statistical analyses on large datasets to support intelligence decision-making within the MARS framework\n\u2022 Develops dashboards and visualizations to present actionable insights to intelligence analysts and decision-makers\n\u2022 Collaborates with multiple stakeholders to understand data needs and provide tailored analytical solutions\n\u2022 Ensures data integrity and accuracy, adhering to security and confidentiality protocols\n\u2022 Utilizes advanced analytical tools and techniques to identify trends, patterns, and anomalies in intelligence data\n\u2022 Continuously refines data analysis processes to enhance the quality and effectiveness of intelligence operations\nRequired Education, Experience, & Skills\n\u2022 Bachelor\u2019s Degree in IT, Cybersecurity, Computer Science, Information Systems, Data Science, or Software Engineering and 10 years or more of related experience; Masters and 8 years or more experience (an additional 4 years of experience will be considered in lieu of degree)\n\u2022 Active Certification: CCISO, CISM, CISSP, GSLC, GSEC, or SSCP\n\u2022 Proficiency in analyzing datasets, generating insights, and creating reports to support decision-making processes\n\u2022 Experience in data cleaning, performing statistical analysis, and visualizing data using tools like Tableau or Power BI\n\u2022 Strong understanding of database management and data warehousing concepts\n\nPay Information\nFull-Time Salary Range: $115779 - $196825\n\nPlease note: This range is based on our market pay structures. However, individual salaries are determined by a variety of factors including, but not limited to: business considerations, local market conditions, and internal equity, as well as candidate qualifications, such as skills, education, and experience.\n\nEmployee Benefits: At BAE Systems, we support our employees in all aspects of their life, including their health and financial well-being. Regular employees scheduled to work 20+ hours per week are offered: health, dental, and vision insurance; health savings accounts; a 401(k) savings plan; disability coverage; and life and accident insurance. We also have an employee assistance program, a legal plan, and other perks including discounts on things like home, auto, and pet insurance. Our leave programs include paid time off, paid holidays, as well as other types of leave, including paid parental, military, bereavement, and any applicable federal and state sick leave. Employees may participate in the company recognition program to receive monetary or non-monetary recognition awards. Other incentives may be available based on position level and/or job specifics.\nAbout BAE Systems Intelligence & Security BAE Systems, Inc. is the U.S. subsidiary of BAE Systems plc, an international defense, aerospace and security company which delivers a full range of products and services for air, land and naval forces, as well as advanced electronics, security, information technology solutions and customer support services. Improving the future and protecting lives is an ambitious mission, but it\u2019s what we do at BAE Systems. Working here means using your passion and ingenuity where it counts \u2013 defending national security with breakthrough technology, superior products, and intelligence solutions. As you develop the latest technology and defend national security, you will continually hone your skills on a team\u2014making a big impact on a global scale. At BAE Systems, you\u2019ll find a rewarding career that truly makes a difference.\n\nIntelligence & Security (I&S), based in McLean, Virginia, designs and delivers advanced defense, intelligence, and security solutions that support the important missions of our customers. Our pride and dedication shows in everything we do\u2014from intelligence analysis, cyber operations and IT expertise to systems development, systems integration, and operations and maintenance services. Knowing that our work enables the U.S. military and government to recognize, manage and defeat threats inspires us to push ourselves and our technologies to new levels.\n\nThis position will be posted for at least 5 calendar days. The posting will remain active until the position is filled, or a qualified pool of candidates is identified.",
    "url": "https://jobs.baesystems.com/global/en/job/117748BR/Data-Scientist-Sr?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Sr Data Scientist Pune (India)",
    "company": "Stackle",
    "location": "Pune",
    "salary": "",
    "description": "Title: Data Scientist \u2013 LLM & GIS Systems\n\nLocation: Roseville, CA (Hybrid or Remote)\n\nType: Contract-to-Hire or Full time\n\nAbout LowPropTax\n\nLowPropTax helps homeowners reduce property taxes using data-driven insights and automated appeals. We combine property data, geospatial analytics, and AI to identify over-assessed parcels and build automation pipelines for large-scale appeal filings.\n\nRole Overview\n\nYou will design and build LowPropTax\u2019s custom LLM and GIS intelligence stack from the ground up. This includes developing a proprietary language model for property data insights, creating geospatial overlays to visualize property inequities, and automating data workflows across counties.\n\nKey Responsibilities\nArchitect and train a custom LLM model using internal tax, assessor, and property datasets.\nBuild and fine-tune inference pipelines for automated valuation, appeal reasoning, and evidence generation.\nDevelop GIS-based mapping overlays integrating assessor parcels, zoning, and demographic data.\nAutomate data ingestion pipelines from public APIs, CSVs, and assessor databases.\nCollaborate with engineering to integrate model outputs into production systems.\nPerform EDA and feature engineering on large, messy, cross-county property datasets.\nEvaluate LLM models for accuracy, explainability, and auditability in compliance contexts.\n\nRequirements\n3+ years in data science, AI, or applied ML.\nDeep understanding of LLMs, embeddings, and transformer architectures (not wrappers like GPT APIs).\nExperience with PyTorch, Hugging Face, LangChain (core only), and vector databases.\nProficiency in Python, SQL, and geospatial tools (GeoPandas, Shapely, PostGIS, Mapbox).\nExperience with data pipelines and MLOps (Airflow, Prefect, MLflow).\nComfort working with county property, parcel, or tax datasets is a plus.\nSolid problem-solving and autonomy.\n\nNice to Have\nPrior experience with public records, real estate analytics, or valuation models.\nExperience in cloud environments (AWS, GCP) with scalable model training setups.\nFamiliarity with OCR pipelines for document parsing.\n\nWhy Join\n\nYou\u2019ll help shape the intelligence core of a quick-growing proptech startup rooted in real impact \u2014 saving thousands of homeowners real money through automation and AI precision.",
    "url": "https://in.jobrapido.com/jobpreview/7480401983036194816?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-26T00:00:00.000Z"
  },
  {
    "title": "Data Science Mentor",
    "company": "Greamio Technologies Pvt. Ltd",
    "location": "Pune",
    "salary": "",
    "description": "Call: 9225586827 (Mon to Sat / 11 am - 6 pm)\n\nCompany Name: Greamio Technologies Private Limited\n\nJob Title: Data Science Trainer\n\nLocation: Pune\n\nSalary: \u20b920,000 - \u20b930,000\n\nEmployment Type: Full-Time\n\nJob Description:\n\nWe are looking for a highly motivated and skilled Data Science Trainer to join our team. The ideal candidate will have a passion for teaching and a deep understanding of data science concepts, tools, and methodologies. The trainer will be responsible for delivering high-quality training to students, helping them build a solid foundation in data science, and guiding them through practical projects.\n\nKey Responsibilities:\n\u2022 Deliver engaging and interactive training sessions on various data science topics, including statistics, machine learning, data visualization, and programming (Python).\n\u2022 Design and develop course materials, assignments, quizzes, and hands-on projects.\n\u2022 Mentor and guide students through practical exercises and real-world applications.\n\u2022 Provide timely feedback and support to students on their progress and performance.\n\u2022 Stay up-to-date with the latest trends and advancements in data science and incorporate them into the curriculum.\n\u2022 Conduct assessments and evaluations to measure the effectiveness of the training program.\n\u2022 Adapt teaching methods and materials to meet the diverse needs of learners in both online and classroom settings.\n\nRequirements:\n\u2022 Bachelor's or Master's degree in Computer Science, Statistics, or a related field.\n\u2022 Proven experience as a Data Science Trainer or similar role.\n\u2022 Proficiency in programming languages such as Python, C, and SQL.\n\u2022 Strong knowledge of data science tools and platforms (e.g., Jupyter, TensorFlow, Pandas, NumPy, Scikit-learn).\n\u2022 Excellent communication and presentation skills.\n\u2022 Ability to explain complex concepts in a simple and clear manner.\n\u2022 Experience in mentoring or teaching is preferred.\n\u2022 Certifications in data science or related fields are a plus.\n\nPreferred Skills:\n\u2022 \u00b7 Hands-on experience with data analytics, machine learning models, and big data tools.\n\u2022 \u00b7 Familiarity with cloud platforms (AWS, Google Cloud, Azure) for data science projects.\n\u2022 \u00b7 Ability to design project-based learning experiences for students.\n\nJob Types: Full-time, Part-time, Permanent, Freelance\n\nPay: \u20b920,000.00 - \u20b935,000.00 per month\n\nAbility to commute/relocate:\n\u2022 Pune, Maharashtra: Reliably commute or planning to relocate before starting work (Required)\n\nExperience:\n\u2022 Python: 1 year (Required)\n\u2022 Teaching: 1 year (Required)\n\u2022 total work: 1 year (Required)\n\u2022 Data science: 1 year (Required)\n\u2022 Machine learning: 1 year (Required)\n\nLanguage:\n\u2022 English (Preferred)\n\nWork Location: In person",
    "url": "https://www.glassdoor.co.in/job-listing/data-science-mentor-greamio-technologies-pvt-ltd-JV_IC2856202_KO0,19_KE20,48.htm?jl=1009922443069&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Manager, Data Science (Media / Market Research) [3 Days Left]",
    "company": "NielsenIQ",
    "location": "Pune",
    "salary": "",
    "description": "As a Data Science Manager you will have following key accountabilities :\n\nTeam Leadership : Build and lead a high-performing team of 6-8 Data Scientists and Machine Learning Engineers in our Pune hub. Foster a collaborative and inclusive team culture that encourages innovation and continuous learning.\n\nTechnical Communication : Explain Data Science principles, concepts, algorithms, and approaches in simple terms to diverse audiences, including non-technical stakeholders.\n\nBusiness Understanding : Utilize your solid business understanding to align with stakeholders, discuss requirements and feasibility, and manage expectations effectively. Ensure clear communication and understanding of project goals and outcomes.\n\nEducational Background :\n\nPhD or Master\u2019s degree in Computer Science, Engineering, Statistics, Mathematics, or a related field, with min 8+ years of experience as a Data Scientist.\n\nLeadership Experience :\n\nProven experience as a people manager and / or mentor, with a track record of developing and leading high-performing teams.\n\nLeadership Experience :\n\nProven experience as a people manager and / or mentor, with a track record of developing and leading high-performing teams\n\nCommunication Skills :\n\u2022 Ability to effectively communicate complex methodologies and technologies to both technical and non-technical audiences.\n\u2022 Strong problem-solving skills and an independent working style.\n\nTechnical Expertise :\n\u2022 Strong statistical and machine learning modeling skills, including statistical tests, classification, predictive modeling, handling of missing data, and sampling / weighting techniques.\n\u2022 Solid in analytical programming languages such as Python or R, along with their respective ecosystems.\n\u2022 Hands-on experience implementing these models in production systems.\n\u2022 Proficient in software development skills, including unit testing, CI / CD, and version control with Git, along with familiarity with computer science and engineering fundamentals such as data structures, software design principles, and testing strategies.\n\nPreferred qualifications\n\u2022 Experience in the Media industry\n\u2022 Experience working with cloud-based data services (AWS, Azure, or GCP)\n\u2022 Experience with Optimization techniques such as : linear programming, integer programming, genetic algorithms, constrained optimization is a plus",
    "url": "https://in.talent.com/view?id=4fe045bcdd58&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Data Scientist + Junior Instructor",
    "company": "Uplers",
    "location": "Pune",
    "salary": "",
    "description": "Experience: 3.00 + years\n\nSalary: Confidential (based on experience)\n\nShift: (GMT+05:30) Asia/Kolkata (IST)\n\nOpportunity Type: Office (Pune)\n\nPlacement Type: Full time Permanent Position\n\n(*Note: This is a requirement for one of Uplers' client - Newton School)\n\nWhat do you need for this opportunity?\n\nMust have skills required:\n\nAI/ML, Deep Learning, LLMs, NLP, Transformers, Statistical Modelling, Agentic AI\n\nNewton School is Looking for:\n\nAbout:\n\nNewton School is on a mission to redefine tech education in India. Backed by global investors (RTP Global, Nexus, Kunal Shah, and more), we are building a Tech Institute to solve the employability gap for millions of graduates. In collaboration with Rishihood University (Sonipat), Ajeenkya DY Patil University (Pune), and S-VYASA University (Bangalore), were creating the next generation of industry-ready tech leaders.\n\nKey Responsibilities\n\u2022 Teach Applied AI/ML: Design and deliver practical, project-based courses in AI/ML (Python for ML, Statistics, ML Algorithms, Deep Learning, NLP, CV, ML Ops, GenAI).\n\u2022 Develop Industry-Relevant Curriculum: Help design and update the AI/ML curriculum to reflect current industry tools, techniques, and best practices, incorporating your professional experience and case studies.\n\u2022 Mentor Student Projects: Guide students through hands-on AI/ML projects, providing technical direction, code reviews, and feedback based on industry standards.\n\u2022 Guide & Mentor Students: Advise students on developing practical skills, understanding career paths in AI/ML, and preparing for internships and job placements.\n\u2022 Stay Current: Bring the latest AI/ML research, tools, and industry trends into the classroom.\n\u2022 Collaborate: Work closely with other expert faculty and staff to create a unified and effective learning experience.\n\u2022 Assess Practical Skills: Design and evaluate assignments, projects, and assessments focused on real-world applications.\n\nRequired Qualifications & Experience\n\u2022 Bachelors or Masters degree in Computer Science, Engineering, Data Science, AI/ML, or related field. (PhD is valued but not mandatory.)\n\u2022 3-6 years of direct, hands-on professional experience in the tech industry as an AI/ML Engineer, Data Scientist, Research Scientist, or similar role involving AI/ML development and deployment.\n\u2022 Proven Industry Track Record: Demonstrated experience in building, training, and deploying machine learning models (including deep learning) for real-world problems.\n\u2022 Deep AI/ML Understanding: Strong grasp of core ML algorithms (classical & deep learning CNNs, RNNs, Transformers), model evaluation, statistics, and awareness of current research/industry trends.\n\u2022 Passion for Teaching/Mentoring: Ability to explain complex concepts clearly and guide others. Prior mentoring, corporate training, technical workshops, or project supervision experience is highly relevant. (Formal academic teaching experience is not mandatory.)\n\nRequired Skills\n\u2022 Technical: Expert-level Python programming.\n\u2022 Proficiency with data science libraries (Pandas, NumPy, Scikit-learn).\n\u2022 Hands-on experience with ML/DL frameworks (TensorFlow, PyTorch).\n\u2022 Strong SQL and data handling skills.\n\u2022 Understanding of ML Ops practices and tools (Git, Docker, AWS/GCP/Azure).\n\u2022 Knowledge of key AI areas (NLP, Computer Vision, Generative AI/LLMs).\n\nSoft Skills: Strong communication, mentoring ability, collaboration, and a genuine passion for education.\n\nGood-to-Have\n\u2022 Prior teaching experience at the undergraduate or graduate level.\n\u2022 Familiarity with modern teaching methodologies and academic tools.\n\nHow to apply for this opportunity?\n\u2022 Step 1: Click On Apply! And Register or Login on our portal.\n\u2022 Step 2: Complete the Screening Form & Upload updated Resume\n\u2022 Step 3: Increase your chances to get shortlisted & meet the client for the Interview!\n\nAbout Uplers:\n\nOur goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement.\n\n(Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well).\n\nSo, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you!",
    "url": "https://in.linkedin.com/jobs/view/data-scientist-%2B-junior-instructor-at-uplers-4332460060?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Life Sciences Data Science Lead",
    "company": "beBeeDataScience",
    "location": "Pune",
    "salary": "",
    "description": "Are you a seasoned expert in data science and artificial intelligence seeking a challenging role that aligns with your skills?\n\nWe are currently looking for a lead data scientist to join our team.\n\nThe ideal candidate will have extensive experience in AI, ML, and GenAI, as well as a strong background in analytical formulation and problem-solving.\n\nAs a lead data scientist, you will be responsible for managing end-to-end data science project lifecycles, from problem comprehension to final delivery. You will also serve as the primary point of contact for client interactions, presentations, and requirement elicitation.\n\u2022 Lead data science efforts for multiple client engagements in the Life Sciences domain.\n\u2022 Manage teams on advanced data science techniques to ensure alignment with business objectives.\n\u2022 Collaborate cross-functionally with domain experts, business stakeholders, and technical teams to deliver robust analytical solutions.\n\u2022 Expert knowledge of data science algorithms, methodologies, and end-to-end lifecycle (AI/ML/GenAI), MLOps, and post-deployment service of AI models is required.\n\u2022 Exceptional articulation skills to communicate technical concepts clearly to both technical and business stakeholders.\nKey Responsibilities:\n\u2022 Develop and implement advanced data science solutions for clients in the Life Sciences domain.\n\u2022 Lead high-performing teams to achieve project goals and objectives.\n\u2022 Communicate complex technical concepts to both technical and non-technical stakeholders.\n\u2022 Stay up-to-date with industry trends and advancements in AI, ML, and GenAI.\nRequirements:\n\u2022 6+ years of experience in data science, AI, and/or ML.\n\u2022 Strong understanding of complex Life Sciences problems.\n\u2022 Exceptional analytical and problem-solving skills.\n\u2022 Excellent communication and interpersonal skills.",
    "url": "https://in.bebee.com/job/513dc10d79ddcebc308d4dd3571f1290?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Business Sales Head- Data Science",
    "company": "Cinecraft",
    "location": "Pune",
    "salary": "",
    "description": "Position: Business Head \u2013 Data Science\n\nLocation: Pune, Maharashtra\nInstitute: Cinecraft Digital Academy\n\nAbout the Role:\nWe are seeking a dynamic and experienced Business Head \u2013 Data Science to lead our Data Science, AI, and Analytics division. The ideal candidate will drive business growth, oversee academic excellence, and build strong industry partnerships to strengthen our position as a leading digital education brand.\n\nKey Responsibilities:\n\nAchieve admission and revenue targets for Data Science & AI programs.\nLead academic planning, curriculum upgrades, and faculty management.\nCollaborate with marketing for lead generation and brand building.\nDevelop industry tie-ups for placements, projects, and internships.\nManage team performance and ensure smooth operations.\nStay updated with market trends and identify new course opportunities.\n\nRequirements:\n\nGraduate/Postgraduate in Data Science, Computer Science, or Business/ MBA.\n3+ years of experience in education management, EdTech, or training industry working towards admissions.\nStrong knowledge of Data Science, AI, and analytics ecosystem.\n\nExcellent leadership, communication, and business development skills.\n\nWhat We Offer:\nCompetitive salary with performance incentives.\nGrowth-driven, creative work environment.\nOpportunity to lead an expanding digital education brand.\n\nMore about this Business Sales Head- Data Science job\n\nCinecraft is aggressively hiring for the job profile of Business Sales Head- Data Science at Pune in Pawar Quarter (Hotel Raviraj) locality. Kindly go through the FAQs below to get all answers related to the given job.\n\n1. How much salary can I expect as a Business Sales Head- Data Science in Cinecraft in Pune?\n\nAns. You can expect a minimum salary of 40,000 INR and can go up to 60,000 INR. The salary offered will depend on your skills, experience and performance in the interview.\n\n2. What is the eligibility criteria to apply for Business Sales Head- Data Science in Cinecraft in Pune?\n\nAns. The candidate should have completed Graduate degree and people who have 3 to 31 years are eligible to apply for this job. You can apply for more jobs in Pune to get hired quickly.\n\n3. Is there any specific skill required for this job?\n\nAns. The candidate should have Good (Intermediate / Advanced) English skills and sound communication skills for this job.\n\n4. Who can apply for this job?\n\nAns. Only Male candidates can apply for this job.\n\n5. Is it a work from home job?\n\nAns. No, it\u2019s not a work from home job and can\u2019t be done online. You can explore and apply for other work from home jobs in Pune at apna.\n\n6. Are there any charges or deposits required while applying for the role or while joining?\n\nAns. No work-related deposit needs to be made during your employment with the company.\n\n7. How can I apply for this job?\n\nAns. Go to the apna app and apply for this job. Click on the apply button and call HR directly to schedule your interview.\n\n8. What is the last date to apply?\n\nAns. The last date to apply for this job is 12-Nov-2025.\n\nFor more details, download apna app and find Full Time jobs in Pune. Through apna, you can find jobs in 74 cities across India. Join NOW!",
    "url": "https://apna.co/job/pune/business-sales-head-data-science-879117150?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Data-Driven Statistical Modeler",
    "company": "beBeeStatistical",
    "location": "Pune",
    "salary": "",
    "description": "Analytics Insights Developer\n\nA strategic position is available for an Analytics Insights Developer in the Statistics Industry in Pune. The role involves leveraging statistical models using SAS and/or R to drive business decisions, exploring data through various techniques like multi-level forecasting, time-series analysis, optimization, default scorecards, predictive failure modeling, generalized linear models, logistic/linear regression, and logit/probit modeling.\n\nKey Responsibilities:\n\u2022 Communicate complex analytics insights to business stakeholders\n\u2022 Collaborate effectively with cross-functional teams\n\u2022 Develop strong data understanding, hypothesis formulation, data preparation, and model building skills\n\u2022 Apply creative problem-solving approaches and analytical thinking\n\u2022 Design and implement statistical models using SAS and/or R\n\u2022 Gain expertise in analytics applications across Retail, Technology, Finance, and Life Sciences\n\u2022 Preferred experience in machine learning and pattern recognition techniques\n\nFunctional Area:\n\nStatistical modeling, data analysis, analytics, collaboration, data management, SAS, machine learning, statistics jobs in Pune, analytics jobs in India, statistical analysis jobs in Maharashtra\n\nView Opportunities",
    "url": "https://in.bebee.com/job/e8923e7eb87d2b044e3cd00cec9b1c9d?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T08:00:00.000Z"
  },
  {
    "title": "Ishan Technologies - Data Scientist - ETL / Python",
    "company": "Ishan Technologies",
    "location": "Pune",
    "salary": "",
    "description": "Description : Job Summary :\n\nWe are seeking a highly skilled and analytical Data Scientist with hands-on experience in designing, developing, and deploying data-driven solutions.\n\nThe ideal candidate will have strong expertise in data analysis, machine learning, and cloud-based model deployment preferably on Google Cloud Platform (GCP).\n\nThis role involves working closely with cross-functional teams to translate data into actionable insights that enhance business decisions, optimize user experiences, and drive measurable outcomes across web and mobile applications, including React-based environments.\n\nKey Responsibilities :\n\nData Analysis and Modelling :\n\u2022 Analyse large-scale datasets from web and mobile applications (including React-based systems) to identify trends, patterns, and actionable insights.\n\u2022 Design and develop machine learning, predictive, and statistical models to solve complex business challenges such as churn prediction and customer segmentation.\n\u2022 Validate and refine model performance using suitable evaluation metrics to ensure accuracy, reliability, and business relevance.\n\nData Collection and Integration :\n\u2022 Collect and preprocess data from multiple sources, including Firebase services (Firestore, Firebase Analytics), ensuring data quality and consistency.\n\u2022 Integrate disparate data sources into unified datasets compatible with APIs and application backends on cloud platforms.\n\u2022 Perform data cleaning, transformation, and feature engineering for modelling and visualization readiness.\n\nInsight Generation and Reporting :\n\u2022 Derive actionable insights to support business and product strategies, such as enhancing user experience in React-based applications.\n\u2022 Develop and maintain data visualizations and interactive dashboards using cloud-compatible tools.\n\u2022 Present findings and recommendations through clear reports to both technical and non-technical stakeholders.\n\nCollaboration and Communication :\n\u2022 Collaborate with developers, product managers, and UX teams to align data science initiatives with business goals.\n\u2022 Communicate project progress, analysis outcomes, and model performance through regular stakeholder updates.\n\u2022 Work with engineering teams to deploy models seamlessly into production environments (e.g., Firebase-hosted systems).\n\nModel Deployment and Monitoring :\n\u2022 Deploy and operationalize machine learning models in production using Google Cloud Platform (GCP) or other public clouds.\n\u2022 Continuously monitor model performance, addressing issues like data drift and optimizing scalability and efficiency.\n\u2022 Implement and maintain model tracking, logging, and monitoring frameworks in cloud environments.\n\nRequired Skills :\n\u2022 4+ years of professional experience as a Data Scientist or in a similar analytical role.\n\u2022 Proven hands-on experience with at least one public cloud platform (strong preference for Google Cloud Platform).\n\u2022 Strong proficiency in Python and its data science libraries (Pandas, NumPy, Scikit-learn, TensorFlow, PyTorch, etc.\n\u2022 Experience with Firebase, BigQuery, and Vertex AI is highly desirable.\n\u2022 Expertise in data visualization tools (e.g., Looker Studio, Tableau, or Power BI).\n\u2022 Strong understanding of data modelling, ETL processes, and API integrations in cloud-based systems.\n\u2022 Excellent communication skills and ability to collaborate with cross-functional teams.\n\nQualification :\n\u2022 Strong analytical and problem-solving skills.\n\u2022 Desire and ability to rapidly learn a wide variety of new technical skills.\n\u2022 Self-motivated, takes initiative, assumes ownership.\n\u2022 Enthusiastic, professional, with a focus on customer success.\n\u2022 Passion for solving client challenges and commitment to client delight.\n\n(ref : hirist.tech)",
    "url": "https://in.talent.com/view?id=bf6193e7db6c&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Data scientist / ML Engineer -- US Client (Analytics) (Pune)",
    "company": "Aspyra HR Services",
    "location": "Pune",
    "salary": "",
    "description": "Salary : 30 to 45 LPA\n\nExp: 7 to 12 years\n\nLocation :Mumbai Only\n\nNotice: Immediate to 30 days..!!\n\nRoles & responsibilities:\n\n7+ years exp on Python, ML and Banking model development\n\n- Interact with the client to understand their requirements and communicate / brainstorm solutions, model Development: Design, build, and implement credit risk model.\n- Contribute to how analytical approach is structured for specification of analysis\n- Contribute insights from conclusions of analysis that integrate with initial hypothesis and business objective. Independently address complex problems\n- 3+ years exp on ML/Python (predictive modelling).\n- Design, implement, test, deploy and maintain cutting-edge data and machine learning solutions to accelerate our business.\n- Create experiments and prototype implementations of new learning algorithms and prediction techniques\n- Collaborate with product managers, and stockholders to design and implement software solutions for science problems\n- Use machine learning best practices to ensure a high standard of quality for all of the team deliverables\n- Has experience working on unstructured data ( text ): Text cleaning, TFIDF, text vectorization\n- Hands-on experience with IFRS 9 models and regulations.\n- Data Analysis: Analyze large datasets to identify trends and risk factors, ensuring data quality and integrity.\n- Statistical Analysis: Utilize advanced statistical methods to build robust models, leveraging expertise in R programming.\n- Collaboration: Work closely with data scientists, business analysts, and other stakeholders to align models with business needs.\n- Continuous Improvement: Stay updated with the latest methodologies and tools in credit risk modeling and R programming.",
    "url": "https://in.jobrapido.com/jobpreview/2184121542248497152?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-25T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (Machine learning and AI)",
    "company": "YASH Technologies",
    "location": "Pune",
    "salary": "",
    "description": "We are seeking a highly experienced and visionary Senior Principal Data Scientist to join our dynamic team. This role is pivotal in driving our organization's advanced analytics initiatives and shaping our data-driven strategy. As a thought leader, you will lead complex data science projects, mentor junior scientists, and collaborate with cross-functional teams to deliver impactful solutions that address critical business challenges. You will leverage your deep expertise in machine learning, statistical modeling, and data engineering to extract actionable insights and drive innovation.\nResponsibilities:\n\nSet vision for Gen AI adoption and innovation roadmap.\nDrive R&D, capability building, and solution frameworks.\nInfluence customer strategy and support large digital transformation initiatives.\nMentor senior talent, define best practices, IP creation.\n\nRequired Skills:\n\nThought leader in ML/AI/Gen AI, deep expertise in LLMs and vector architecture.\nTrack record of designing scalable AI solutions in BFSI, healthcare, retail, etc.\nExperience in AI governance, ethical AI, and responsible AI practices.\nStrong publishing, client consulting, and leadership capabilities.",
    "url": "https://in.jooble.org/rjdp/-4651442101855054254?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-25T00:00:00.000Z"
  },
  {
    "title": "Data Scientist",
    "company": "Snowflake",
    "location": "Pune",
    "salary": "",
    "description": "Snowflake is about empowering enterprises to achieve their full potential \u2014 and people too. With a culture that\u2019s all in on impact, innovation, and collaboration, Snowflake is the sweet spot for building big, moving fast, and taking technology \u2014 and careers \u2014 to the next level.\n\nSnowflake is seeking a Data Scientist to join our expanding Enterprise AI & ML team. This role involves working on diverse AI/ML and data science initiatives, utilizing Snowflake's Data Cloud and Cortex AI. The successful candidate will design and develop scalable data science and machine learning solutions, build interactive AI applications, and collaborate on operationalizing intelligent systems to enhance data-driven decision-making throughout the company. This position focuses on applying data science, AI & ML skill sets to various domain specific business data problems across Snowflake.\n\nON THE ENTERPRISE AI & ML TEAM AT SNOWFLAKE, YOU WILL:\n\u2022 Design, prototype, and deploy data science and AI solutions.\n\u2022 Conduct end to end experimentation, including data exploration, feature engineering, model development, and validation.\n\u2022 Build and maintain Streamlit applications to visualize models, showcase insights, and enable business stakeholders to interact with AI driven solutions.\n\u2022 Develop and optimize LLM based applications, workflows, and operations; with a focus on retrieval, generation, semantic understanding and fine-tuning.\n\u2022 Partner cross functionally with data engineers, analysts, and product teams to translate ambiguous business problems into measurable outcomes.\n\nOUR IDEAL CANDIDATE WILL HAVE:\n\u2022 2 to 4 years of experience applying data science, machine learning, or AI techniques in real world business settings.\n\u2022 Strong programming skills in Python, proficiency in SQL for large scale data manipulation.\n\u2022 Familiarity with frameworks such as scikit-learn, XGBoost etc.\n\u2022 Understanding of LLM architectures, embeddings, vector search, and RAG pipelines.\n\u2022 Experience working on cloud platforms.\n\u2022 Strong analytical, storytelling, and communication skills to translate technical insights into actionable recommendations.\n\u2022 A mindset of curiosity, ownership, and collaboration, with an eagerness to work on open-ended problems.\n\u2022 Experience operationalizing AI & ML models in a production setting.\n\nSnowflake is growing fast, and we\u2019re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.\n\nHow do you want to make your impact?\n\nFor jobs located in the United States, please visit the job posting on the Snowflake Careers Site for salary and benefits information: careers.snowflake.com",
    "url": "https://careers.snowflake.com/us/en/job/SNCOUSE5563EEBE22F4F83ABADA6BD2B014860EXTERNALENUSF7C857F3DD284045B0C758E492307EC3/Data-Scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (Python/ GenAI/ AgenticAI)",
    "company": "Wolters Kluwer",
    "location": "Pune",
    "salary": "",
    "description": "Key Responsibilities\n\nActive Learner with Enthusiasm for Problem-Solving\n\nContinuously learn and apply new AI/ML techniques, including Generative AI, Agentic AI deep learning, and other emerging technologies. Demonstrate a passion for solving complex business challenges and experimenting with novel approaches to improve model performance.\n\nQuick Prototyping & Experimentation\n\nDevelop rapid prototypes to test new AI/GenAI/ML approaches and solutions for business problems. Implement proof-of-concept models quickly, enabling fast experimentation and iteration to assess feasibility before scaling to full development.\n\nSupport AI Product Development & Iteration\n\nCollaborate with lead/ senior data scientists and cross-functional teams to support the design, development, and deployment of AI-driven products. Contribute to the creation of prototypes and refine models based on business needs and feedback.\n\nModel Development and Optimization\n\nDesign, develop, and test machine learning, deep learning, and generative AI models, focusing on performance, scalability, and business relevance. Continuously refine and optimize models based on real-world results and metrics.\n\nData Preparation & Collaboration\n\nAssist in defining data requirements and support data engineers in building data pipelines. Clean and preprocess datasets, ensuring data quality and preparing it for use in machine learning applications. Collaborate closely with engineers to integrate models into production systems.\n\nResearch Support and Knowledge Sharing\n\nStay informed about the latest trends and research in AI/GenAI/ML and generative models, applying this knowledge to current projects. Actively participate in team discussions, contribute to the evaluation of new techniques, and share insights with peers to foster a collaborative learning environment.\n\nEssential Skills\n\u2022 Good knowledge of Python programming language, data engineering and data science ecosystem in Python.\n\u2022 Hands on experience in Generative AI, Agentic AI, LLM and Advance RAG techniques.\n\u2022 Hands on experience in developing and supporting Machine Learning solutions.\n\u2022 Hands on experience in developing Natural Language Processing (NLP) solutions\n\u2022 Hands on experience on SQL ecosystem\n\u2022 Hands on experience on Solr framework with Python\n\u2022 Experience of working on Linux and shell scripting\n\u2022 Basic statistical modelling knowledge\n\u2022 Strong Computer Science fundamentals are must. (Data structures, Algorithms, OS, Databases).\n\u2022 Good communication and organizational skills with significant attention to detail\n\u2022 Experience partnering with cross-functional teams of domain experts, engineers, data scientists, and production support teams.\n\u2022 Strong attention to detail with excellent problem-solving skills.\n\u2022 Desire and ability to thrive in a distributed technical environment while working on multiple projects simultaneously.\n\u2022 Passionate about latest technology trends with a strong desire for innovation.\n\u2022 Self-motivated, self-managing and able to work independently.\n\nEducation And Experience\n\u2022 Bachelor's degree (B.E/ B Tech. computer science, engineering, statistics/mathematics or a related field) from a four-year college or university, or equivalent, master\u2019s a plus.\n\u2022 Total at least 1 years of experience working on enterprise AI products\n\u2022 Experience in supporting software products or applications in the AI ML domain.\n\u2022 The above statements are intended to describe the general nature and level of work being performed by most people assigned to this job. They are not intended to be an exhaustive list of all duties and responsibilities and requirements.\n\nApplicants may be required to appear onsite at a Wolters Kluwer office as part of the recruitment process.",
    "url": "https://in.linkedin.com/jobs/view/data-scientist-python-genai-agenticai-at-wolters-kluwer-4319872554?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T14:00:00.000Z"
  },
  {
    "title": "\u25b7 Urgent : Senior Data Scientist",
    "company": "Tata Communications Transformation Services (TCTS)",
    "location": "Pune",
    "salary": "",
    "description": "Senior Data Scientist\n\nLocation : Pune\n\nJob Description :\n\u2022 We are seeking a visionary and execution oriented Senior Manager to lead customer centric projects focused on AI powered and Autonomous Network Solutions, spanning wireless (4G / 5G), wireline (fiber, broadband), and Fixed Wireless Access (FWA) domains.\n\u2022 This role connects business strategy, technical innovation, and operational delivery, ensuring customer success through intelligent network transformation.\n\u2022 Key Responsibilities AI and Autonomous Network Solutions Lead e2e engagement for AI enabled, closed loop autonomous network solutions across wireless, wireline, and FWA technologies.\n\u2022 Translate customer requirements into delivery roadmaps featuring AI / ML models, LLM prompting, network self-healing, and predictive analytics.\n\u2022 Oversee deployment of automation use cases like alarm correlation, anomaly detection, traffic prediction, and zero touch optimization.\n\u2022 Sales Enablement and Solution Engineering Partner with sales, product, and pre sales engineering teams to design scalable, AI driven solutions for both wireless (4G / 5G NSA / SA) and wireline networks (FTTx, xDSL, GPON, DOCSIS).\n\u2022 Create and present business cases and proof of concepts (PoCs) tailored to hybrid network environments, including FWA deployment strategies. Develop proposals that address customer pain points using AI driven KPI insights, RF / wireline performance analytics, and capacity modelling.\n\u2022 Project Leadership and Delivery Execution Manage cross functional delivery of multi technology engagements, from FWA rollout automation to AI driven fiber network analytics. Track timelines, budgets, risk mitigation plans, and outcomes using Agile or hybrid methodologies, ensuring high impact delivery aligned with customer goals.\n\u2022 Drive adoption of autonomous workflows and AI based decisioning across planning, optimization, provisioning, and fault management. Customer Relationship and Stakeholder Management Act as the primary interface with customers for sales aligned project delivery, status updates, and solution expansion discussions.\n\u2022 Conduct technical deep dives, workshops, and strategy sessions with telecom operators and enterprise clients.\n\u2022 Foster long term client relationships by consistently demonstrating value through network intelligence, automation, and performance improvement. Innovation and Ecosystem Leadership Champion the use of generative AI, prompting, and large language models (LLMs)for automation and proactive network management.\n\u2022 Collaborate with internal RandD, product management, and operations teams to evolve the service portfolio across wireless, wireline, and converged network domains. Influence the design and adoption of self-optimizing networks (SON), FWA performance platforms, and fiber diagnostics using AI.\n\u2022 Qualifications Bachelor / Master degree in Telecommunications, Computer Science, Data Science,or related fields.\n\u2022 12 plus years of experience in telecom network services with 5 plus years in AI / automation leadership roles. Strong understanding of 4G / 5G, FWA, and wireline network technologies (e.g. fiber broadband, GPON, DOCSIS, xDSL).\n\u2022 Expertise in AI / ML (supervised / unsupervised learning), prompt engineering, automation scripting (Python, SQL), and analytics tools (Tableau, Power BI). PMP, Agile, or relevant delivery certifications preferred. Key Skills AI / ML in Network Optimization Prompt Engineering and LLM Integration Autonomous Wireless / Wireline Network Architectures Fixed Wireless Access (FWA) Deployment and Analytics RF and Fiber Network Planning and Performance Customer Engagement and Technical Presales Automation Frameworks and Closed Loop Operations Program Management and Cross Functional Leadership",
    "url": "https://in.talent.com/view?id=67b159f7ca73&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T23:00:00.000Z"
  },
  {
    "title": "Data Scientist with Manufacturing Domain Expertise for our Esteemed Client",
    "company": "KHOOBI CONSULTING",
    "location": "Pune",
    "salary": "",
    "description": "Responsibility:\n\u2022 Help customers identify opportunities of monetizing their data assets to drive growth and profitability.\n\u2022 Understand customer's engineering, supply chain and production planning requirements and design digital solutions for customers that have AI and AI-Agents embedded in them.\n\u2022 Act as a bridge between customer business stakeholders and development teams comprising of Data Scientists and Solution Architects.\n\u2022 Publish Whitepapers on topics covering application of AI to solve domain specific issues and drive growth in the industry.\n\nEssential Skills:\n\u2022 Ability to manage senior customer stakeholders.\n\u2022 Ability to help customers understand how Industry 4.0 practices can be applied in their environment.\n\u2022 Ability to lead requirement gathering and solutioning workshops with customers.\n\u2022 Ability to understand the latest development in AI research and relate them to areas where they can be applied.\n\nExperience:\n\nOverall 15 - 20 years\n\nDomain: Minimum 10 years in Manufacturing (Production Planning, Maintenance, Automation, Control Systems, Supply Chain)\n\nPreferred Experience in Actual Automation and Control Systems experience preferred\n\nTechnical: Minimum 5 years in Control Systems data, Digital Applications implementation\n\nKnowledge:\n\nStrong in applying Statistics knowledge\n\nMachine Learning / Deep Learning / LLM / Agents\n\nQualifications\n\u2022 Masters or Bachelor's degree in Computer Science, Engineering or related field.\n\nWorking Arrangments\n\u2022 100% work from office",
    "url": "https://in.linkedin.com/jobs/view/data-scientist-with-manufacturing-domain-expertise-for-our-esteemed-client-at-khoobi-consulting-4331425353?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T07:00:00.000Z"
  },
  {
    "title": "\u25b7 Urgent! Data Scientist",
    "company": "Tata Consultancy Services",
    "location": "Pune",
    "salary": "",
    "description": "Dear Candidate,\n\nGreetings from TATA Consultancy Services!!\n\nPosition- Data Scientist-Python\n\nExperience-4 to 8 years\n\nLocation- Chennai, Pune, Mumbai\n\nNotice Period- 0 to 60 days / Serving Notice Period\n\nKey Responsibilities :\n\u2022 Understand business process / business problems and device Machine Learning solutions to optimize business processes wherever possible.\n\u2022 Experience using statistical computer languages (Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\n\u2022 Formulating machine learning solutions to business metrics, designing features from the data available from many large data sources, training, evaluating, and deploying models in production\n\u2022 Developing high-performance algorithms for precision targeting, testing and implementing these algorithms in scalable, production-ready code; Interacting with other teams to define interfaces and understanding and resolving dependencies.\n\u2022 Developing coding in high-level languages such as R, Python, Java\n\u2022 Experience working with and creating data architectures.\n\u2022 Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages / drawbacks.\n\u2022 Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.\n\nNote : Note-Candidates who have previously worked at TCS not eligible to apply.\n\nOnly relevant experience candidates can apply.",
    "url": "https://in.talent.com/view?id=820a7d06df0c&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "\u25b7 [Only 24h Left] Senior Data Scientist",
    "company": "Tata Communications Transformation Services (TCTS)",
    "location": "Pune",
    "salary": "",
    "description": "Senior Data Scientist\n\nLocation : Pune\n\nJob Description :\n\u2022 We are seeking a visionary and execution oriented Senior Manager to lead customer centric projects focused on AI powered and Autonomous Network Solutions, spanning wireless (4G / 5G), wireline (fiber, broadband), and Fixed Wireless Access (FWA) domains.\n\u2022 This role connects business strategy, technical innovation, and operational delivery, ensuring customer success through intelligent network transformation.\n\u2022 Key Responsibilities AI and Autonomous Network Solutions Lead e2e engagement for AI enabled, closed loop autonomous network solutions across wireless, wireline, and FWA technologies.\n\u2022 Translate customer requirements into delivery roadmaps featuring AI / ML models, LLM prompting, network self-healing, and predictive analytics.\n\u2022 Oversee deployment of automation use cases like alarm correlation, anomaly detection, traffic prediction, and zero touch optimization.\n\u2022 Sales Enablement and Solution Engineering Partner with sales, product, and pre sales engineering teams to design scalable, AI driven solutions for both wireless (4G / 5G NSA / SA) and wireline networks (FTTx, xDSL, GPON, DOCSIS).\n\u2022 Create and present business cases and proof of concepts (PoCs) tailored to hybrid network environments, including FWA deployment strategies. Develop proposals that address customer pain points using AI driven KPI insights, RF / wireline performance analytics, and capacity modelling.\n\u2022 Project Leadership and Delivery Execution Manage cross functional delivery of multi technology engagements, from FWA rollout automation to AI driven fiber network analytics. Track timelines, budgets, risk mitigation plans, and outcomes using Agile or hybrid methodologies, ensuring high impact delivery aligned with customer goals.\n\u2022 Drive adoption of autonomous workflows and AI based decisioning across planning, optimization, provisioning, and fault management. Customer Relationship and Stakeholder Management Act as the primary interface with customers for sales aligned project delivery, status updates, and solution expansion discussions.\n\u2022 Conduct technical deep dives, workshops, and strategy sessions with telecom operators and enterprise clients.\n\u2022 Foster long term client relationships by consistently demonstrating value through network intelligence, automation, and performance improvement. Innovation and Ecosystem Leadership Champion the use of generative AI, prompting, and large language models (LLMs)for automation and proactive network management.\n\u2022 Collaborate with internal RandD, product management, and operations teams to evolve the service portfolio across wireless, wireline, and converged network domains. Influence the design and adoption of self-optimizing networks (SON), FWA performance platforms, and fiber diagnostics using AI.\n\u2022 Qualifications Bachelor / Master degree in Telecommunications, Computer Science, Data Science,or related fields.\n\u2022 12 plus years of experience in telecom network services with 5 plus years in AI / automation leadership roles. Strong understanding of 4G / 5G, FWA, and wireline network technologies (e.g. fiber broadband, GPON, DOCSIS, xDSL).\n\u2022 Expertise in AI / ML (supervised / unsupervised learning), prompt engineering, automation scripting (Python, SQL), and analytics tools (Tableau, Power BI). PMP, Agile, or relevant delivery certifications preferred. Key Skills AI / ML in Network Optimization Prompt Engineering and LLM Integration Autonomous Wireless / Wireline Network Architectures Fixed Wireless Access (FWA) Deployment and Analytics RF and Fiber Network Planning and Performance Customer Engagement and Technical Presales Automation Frameworks and Closed Loop Operations Program Management and Cross Functional Leadership",
    "url": "https://in.talent.com/view?id=1d458450a270&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Scientist People Data Analytics & Insights",
    "company": "Syngenta Group",
    "location": "Pune",
    "salary": "",
    "description": "Company Description\n\nAt the Syngenta Group, our 56,000 people across more than 90 countries strive every day to transform agriculture through tailor-made solutions for the benefit of farmers, society and our planet \u2013 making us the world's most local agricultural technology and innovation partner.\n\nWebsite address - https://www.syngentagroup.com/\n\nLI page - https://www.linkedin.com/company/syngentagroup/posts/?feedView=all\n\nJob Description\n\nWe are seeking a highly analytical and business-focused Data Scientist to join our People Analytics & Insights team. In this role, you will leverage advanced analytics, machine learning, and statistical modeling to uncover insights from workforce data, supporting strategic talent decisions across the organization. You will partner closely with HR, Talent Management, and business leaders to deliver data-driven solutions that enhance employee experience, improve workforce planning, and inform diversity, equity, and inclusion (DEI) strategies.\n\nKey Responsibilities:\n\u2022 Analyze large and complex HR datasets (e.g., engagement, attrition, performance, compensation, hiring) to uncover trends, patterns, and opportunities for business impact.\n\u2022 Build predictive and prescriptive models (e.g., attrition risk, career pathing, workforce segmentation) to support data-informed people strategies.\n\u2022 Translate business problems into analytical questions and communicate findings in clear, actionable terms to non-technical audiences.\n\u2022 Develop visualizations, dashboards, and storytelling tools to enhance insight delivery (e.g., in Tableau, Power BI, Workday Discovery Boards).\n\u2022 Partner with HR stakeholders to identify KPIs, define success metrics, and improve people-related decision-making through data.\n\u2022 Design and implement surveys, experiments (A/B testing), and causal inference models to evaluate the impact of HR programs and initiatives.\n\u2022 Ensure ethical data use and compliance with privacy and governance standards.\n\u2022 Stay current on industry best practices in people analytics, data science, and AI/ML in HR.\n\nQualifications\n\u2022 Bachelor\u2019s or Master\u2019s degree in Data Science, Statistics, Computer Science, Industrial/Organizational Psychology, Economics, or a related field.\n\u2022 3\u20135+ years of experience in data science, analytics, or a similar role, ideally within HR or workforce analytics.\n\u2022 Proficiency in Python or R for statistical analysis and modeling.\n\u2022 Strong SQL skills for data extraction and manipulation.\n\u2022 Experience with data visualization tools (e.g., Tableau, Power BI, Workday Discovery Boards).\n\u2022 Solid understanding of machine learning algorithms, statistical modeling, and hypothesis testing.\n\u2022 Excellent communication skills, with the ability to explain complex analytical concepts to HR and business audiences.\n\u2022 Familiarity with Workday, SAP SuccessFactors, or other HRIS platforms is a plus.\n\nPreferred Skills:\n\u2022 Experience with natural language processing (NLP) on employee feedback or engagement data.\n\u2022 Knowledge of DEI analytics and workforce diversity measurement.\n\u2022 Exposure to cloud-based data platforms (e.g., AWS, GCP, Azure).\n\u2022 Understanding of HR functional areas like talent acquisition, performance management, and learning & development.\n\nKey Competencies:\n\u2022 Analytical Thinking & Problem Solving\n\u2022 Business Acumen & Strategic Mindset\n\u2022 Data Storytelling & Visualization\n\u2022 Collaboration & Stakeholder Management\n\u2022 Data Ethics & Privacy Awareness\n\nAdditional Information\n\nWL: 4A\n\nNote: Syngenta is an Equal Opportunity Employer and does not discriminate in recruitment, hiring, training, promotion or any other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, gender identity, marital or veteran status, disability, or any other legally protected status\n\nFollow us on: Twitter & LinkedIn\n\nhttps://twitter.com/SyngentaAPAC\n\nhttps://www.linkedin.com/company/syngenta/",
    "url": "https://jobs.smartrecruiters.com/SyngentaGroup/744000090828842-data-scientist-people-data-analytics-insights?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T12:00:00.000Z"
  },
  {
    "title": "(29 / 10 / 2025) Data Scientist",
    "company": "Tata Consultancy Services",
    "location": "Pune",
    "salary": "",
    "description": "Dear Candidate,\n\nGreetings from TATA Consultancy Services!!\n\nPosition- Data Scientist-Python\n\nExperience-4 to 8 years\n\nLocation- Chennai, Pune, Mumbai\n\nNotice Period- 0 to 60 days / Serving Notice Period\n\nKey Responsibilities :\n\u2022 Understand business process / business problems and device Machine Learning solutions to optimize business processes wherever possible.\n\u2022 Experience using statistical computer languages (Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\n\u2022 Formulating machine learning solutions to business metrics, designing features from the data available from many large data sources, training, evaluating, and deploying models in production\n\u2022 Developing high-performance algorithms for precision targeting, testing and implementing these algorithms in scalable, production-ready code; Interacting with other teams to define interfaces and understanding and resolving dependencies.\n\u2022 Developing coding in high-level languages such as R, Python, Java\n\u2022 Experience working with and creating data architectures.\n\u2022 Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages / drawbacks.\n\u2022 Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.\n\nNote : Note-Candidates who have previously worked at TCS not eligible to apply.\n\nOnly relevant experience candidates can apply.",
    "url": "https://in.talent.com/view?id=d99f903fffd8&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Data Science Data Science Senior Data Scientist (Python) (Remote)",
    "company": "Elevarae",
    "location": "Pune",
    "salary": "",
    "description": "Remote: Hybrid\n\nWe\u2019re Hiring \u2013 Data Science Offshore Leads (Life Sciences | PI \u2013 Oil & Energy)Elevarae is hiring two experienced Data Science Offshore Leads for our client, a global technology leader driving innovation across industries. These are immediate requirements for hybrid roles based in Pune \u2014 ideal for professionals ready to join immediately or within a short notice period. Location: Pune (Hybrid)Experience: 8\u201312 years Bachelor\u2019s and Master\u2019s in Engineering/Technology Join: Immediate to Early Joiners 1\ufe0f\u20e3 Data Science Offshore Lead \u2013 Life Sciences Domain 2\ufe0f\u20e3 Data Science Offshore Lead \u2013 PI, Oil & Energy Domain Lead and execute multiple Tier-1 client projects involving advanced Data Science techniques (AI, ML, GenAI). Manage the complete Data Science lifecycle \u2014 from problem comprehension and analytical solution development to deployment and post-delivery support. Deep expertise in AI/ML/GenAI algorithms, methodologies, and end-to-end lifecycle including MLOps and post-deployment model support. Robust comprehension of complex business problems in Life Sciences or Oil & Energy domains. Exposure to cloud platforms (AWS / Azure / GCP), DevOps, and deployment frameworks. Experience leading agile teams and using agile methodology. Familiarity with data visualization tools (Tableau, Power BI). Understanding of data engineering principles and big data ecosystems. If you\u2019re an experienced Data Science professional looking to make an impact in complex, high-visibility projects \u2014 we\u2019d love to hear from you. #Hiring #DataScience #AI #ML #GenAI #LifeSciences #OilAndEnergy #Elevarae #DataScienceJobs #HybridWork #ImmediateJoiners #PuneJobs",
    "url": "https://in.jobrapido.com/jobpreview/3118123186479169536?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Senior Data Scientist (Artificial Intelligence Machine Learning)",
    "company": "FIS Global",
    "location": "Pune",
    "salary": "",
    "description": "Position Type :\nFull time\n\nType Of Hire :\nExperienced (relevant combo of work and education)\n\nEducation Desired :\nBachelor of Engineering\n\nTravel Percentage :\n1 - 5%\n\nSenior Data Scientist (Artificial Intelligence Machine Learning)\n\nAre you curious, motivated, and forward-thinking? At FIS you\u2019ll have the opportunity to work on some of the most challenging and relevant issues in financial services and technology. Our talented people empower us, and we believe in being part of a team that is open, collaborative, entrepreneurial, passionate and above all fun.\n\nAbout the role:\n\u2022 We are looking for a talented and passionate Data Scientist willing to challenge themself and produce best in class AI enabled solution\n\u2022 You will be required to use the concepts of AIML, GenAI, LLMs, Sentiment analysis, etc.\n\u2022 The role requires creating correlation between different data points and do predictive, preventive analysis.\n\nAbout the Team :\n\nTeam provide solutions and services that help our clients grow, compete, and optimize their business. Our AIOPS team is creating AIML solution targeted to reduce the Enterprise MTTR through our world class product\n\nWhat you will be doing:\n\u2022 Employ machine learning and statistical modeling to create and enhance data driven products.\n\u2022 Analyze and extract insights from internal and external data.\n\u2022 Work with Big Data and transform complex datasets into more usable formats.\n\u2022 Work with a variety of data science tools and programming languages such as SAS, Python, R, Scala, SQL. Work independently and collaborate with other groups to solve complex problems.\n\u2022 Create and present analyses to internal and external partners and clients.\n\u2022 Will be working in 2 Pm to 11 Pm IST Shifts\n\nWhat you bring:\n\u2022 4 to 6 Years of machine learning, artificial intelligence, statistical modeling, data visualization, and data analysis\n\u2022 Proficient in data science tools and programming languages such as SAS, Python, R, Scala, SQL\n\u2022 Relevant degree in Artificial Intelligence Machine Learning\n\u2022 Experience or knowledge of cloud-based technology\n\u2022 Knowledge of financial services industry\n\nWhat we offer you:\n\u2022 A range of benefits designed to help support your lifestyle and wellbeing.\n\u2022 A multi-faceted job with a broad spectrum of responsibilities\n\u2022 A modern international work environment and a dedicated and innovative team\n\u2022 A broad range of professional education and personal development possibilities \u2013 FIS is your final career step.\n\nPrivacy Statement\n\nFIS is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how FIS protects personal information online, please see the Online Privacy Notice.\n\nSourcing Model\n\nRecruitment at FIS works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. FIS does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company.\n\n#pridepass",
    "url": "https://careers.fisglobal.com/us/en/job/FIGLUSJR0296204EXTERNAL/Senior-Data-Scientist-Artificial-Intelligence-Machine-Learning?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Data Science Mentor",
    "company": "Greamio Technologies Pvt. Ltd",
    "location": "Pune",
    "salary": "",
    "description": "Call: 9225586827 (Mon to Sat / 11 am - 6 pm)\n\nCompany Name: Greamio Technologies Private Limited\n\nJob Title: Data Science Trainer\n\nLocation: Pune\n\nSalary: \u20b920,000 - \u20b930,000\n\nEmployment Type: Full-Time\n\nJob Description:\n\nWe are looking for a highly motivated and skilled Data Science Trainer to join our team. The ideal candidate will have a passion for teaching and a deep understanding of data science concepts, tools, and methodologies. The trainer will be responsible for delivering high-quality training to students, helping them build a solid foundation in data science, and guiding them through practical projects.\n\nKey Responsibilities:\n\u2022 Deliver engaging and interactive training sessions on various data science topics, including statistics, machine learning, data visualization, and programming (Python).\n\u2022 Design and develop course materials, assignments, quizzes, and hands-on projects.\n\u2022 Mentor and guide students through practical exercises and real-world applications.\n\u2022 Provide timely feedback and support to students on their progress and performance.\n\u2022 Stay up-to-date with the latest trends and advancements in data science and incorporate them into the curriculum.\n\u2022 Conduct assessments and evaluations to measure the effectiveness of the training program.\n\u2022 Adapt teaching methods and materials to meet the diverse needs of learners in both online and classroom settings.\n\nRequirements:\n\u2022 Bachelor's or Master's degree in Computer Science, Statistics, or a related field.\n\u2022 Proven experience as a Data Science Trainer or similar role.\n\u2022 Proficiency in programming languages such as Python, C, and SQL.\n\u2022 Strong knowledge of data science tools and platforms (e.g., Jupyter, TensorFlow, Pandas, NumPy, Scikit-learn).\n\u2022 Excellent communication and presentation skills.\n\u2022 Ability to explain complex concepts in a simple and clear manner.\n\u2022 Experience in mentoring or teaching is preferred.\n\u2022 Certifications in data science or related fields are a plus.\n\nPreferred Skills:\n\u2022 \u00b7 Hands-on experience with data analytics, machine learning models, and big data tools.\n\u2022 \u00b7 Familiarity with cloud platforms (AWS, Google Cloud, Azure) for data science projects.\n\u2022 \u00b7 Ability to design project-based learning experiences for students.\n\nJob Types: Full-time, Part-time, Permanent, Freelance\n\nPay: \u20b920,000.00 - \u20b935,000.00 per month\n\nAbility to commute/relocate:\n\u2022 Pune, Maharashtra: Reliably commute or planning to relocate before starting work (Required)\n\nExperience:\n\u2022 Python: 1 year (Required)\n\u2022 Teaching: 1 year (Required)\n\u2022 total work: 1 year (Required)\n\u2022 Data science: 1 year (Required)\n\u2022 Machine learning: 1 year (Required)\n\nLanguage:\n\u2022 English (Preferred)\n\nWork Location: In person",
    "url": "https://www.glassdoor.co.in/job-listing/data-science-mentor-greamio-technologies-pvt-ltd-JV_IC2856202_KO0,19_KE20,48.htm?jl=1009922443069&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Manager, Data Science (Media / Market Research) [3 Days Left]",
    "company": "NielsenIQ",
    "location": "Pune",
    "salary": "",
    "description": "As a Data Science Manager you will have following key accountabilities :\n\nTeam Leadership : Build and lead a high-performing team of 6-8 Data Scientists and Machine Learning Engineers in our Pune hub. Foster a collaborative and inclusive team culture that encourages innovation and continuous learning.\n\nTechnical Communication : Explain Data Science principles, concepts, algorithms, and approaches in simple terms to diverse audiences, including non-technical stakeholders.\n\nBusiness Understanding : Utilize your solid business understanding to align with stakeholders, discuss requirements and feasibility, and manage expectations effectively. Ensure clear communication and understanding of project goals and outcomes.\n\nEducational Background :\n\nPhD or Master\u2019s degree in Computer Science, Engineering, Statistics, Mathematics, or a related field, with min 8+ years of experience as a Data Scientist.\n\nLeadership Experience :\n\nProven experience as a people manager and / or mentor, with a track record of developing and leading high-performing teams.\n\nLeadership Experience :\n\nProven experience as a people manager and / or mentor, with a track record of developing and leading high-performing teams\n\nCommunication Skills :\n\u2022 Ability to effectively communicate complex methodologies and technologies to both technical and non-technical audiences.\n\u2022 Strong problem-solving skills and an independent working style.\n\nTechnical Expertise :\n\u2022 Strong statistical and machine learning modeling skills, including statistical tests, classification, predictive modeling, handling of missing data, and sampling / weighting techniques.\n\u2022 Solid in analytical programming languages such as Python or R, along with their respective ecosystems.\n\u2022 Hands-on experience implementing these models in production systems.\n\u2022 Proficient in software development skills, including unit testing, CI / CD, and version control with Git, along with familiarity with computer science and engineering fundamentals such as data structures, software design principles, and testing strategies.\n\nPreferred qualifications\n\u2022 Experience in the Media industry\n\u2022 Experience working with cloud-based data services (AWS, Azure, or GCP)\n\u2022 Experience with Optimization techniques such as : linear programming, integer programming, genetic algorithms, constrained optimization is a plus",
    "url": "https://in.talent.com/view?id=4fe045bcdd58&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Data Scientist + Junior Instructor",
    "company": "Uplers",
    "location": "Pune",
    "salary": "",
    "description": "Experience: 3.00 + years\n\nSalary: Confidential (based on experience)\n\nShift: (GMT+05:30) Asia/Kolkata (IST)\n\nOpportunity Type: Office (Pune)\n\nPlacement Type: Full time Permanent Position\n\n(*Note: This is a requirement for one of Uplers' client - Newton School)\n\nWhat do you need for this opportunity?\n\nMust have skills required:\n\nAI/ML, Deep Learning, LLMs, NLP, Transformers, Statistical Modelling, Agentic AI\n\nNewton School is Looking for:\n\nAbout:\n\nNewton School is on a mission to redefine tech education in India. Backed by global investors (RTP Global, Nexus, Kunal Shah, and more), we are building a Tech Institute to solve the employability gap for millions of graduates. In collaboration with Rishihood University (Sonipat), Ajeenkya DY Patil University (Pune), and S-VYASA University (Bangalore), were creating the next generation of industry-ready tech leaders.\n\nKey Responsibilities\n\u2022 Teach Applied AI/ML: Design and deliver practical, project-based courses in AI/ML (Python for ML, Statistics, ML Algorithms, Deep Learning, NLP, CV, ML Ops, GenAI).\n\u2022 Develop Industry-Relevant Curriculum: Help design and update the AI/ML curriculum to reflect current industry tools, techniques, and best practices, incorporating your professional experience and case studies.\n\u2022 Mentor Student Projects: Guide students through hands-on AI/ML projects, providing technical direction, code reviews, and feedback based on industry standards.\n\u2022 Guide & Mentor Students: Advise students on developing practical skills, understanding career paths in AI/ML, and preparing for internships and job placements.\n\u2022 Stay Current: Bring the latest AI/ML research, tools, and industry trends into the classroom.\n\u2022 Collaborate: Work closely with other expert faculty and staff to create a unified and effective learning experience.\n\u2022 Assess Practical Skills: Design and evaluate assignments, projects, and assessments focused on real-world applications.\n\nRequired Qualifications & Experience\n\u2022 Bachelors or Masters degree in Computer Science, Engineering, Data Science, AI/ML, or related field. (PhD is valued but not mandatory.)\n\u2022 3-6 years of direct, hands-on professional experience in the tech industry as an AI/ML Engineer, Data Scientist, Research Scientist, or similar role involving AI/ML development and deployment.\n\u2022 Proven Industry Track Record: Demonstrated experience in building, training, and deploying machine learning models (including deep learning) for real-world problems.\n\u2022 Deep AI/ML Understanding: Strong grasp of core ML algorithms (classical & deep learning CNNs, RNNs, Transformers), model evaluation, statistics, and awareness of current research/industry trends.\n\u2022 Passion for Teaching/Mentoring: Ability to explain complex concepts clearly and guide others. Prior mentoring, corporate training, technical workshops, or project supervision experience is highly relevant. (Formal academic teaching experience is not mandatory.)\n\nRequired Skills\n\u2022 Technical: Expert-level Python programming.\n\u2022 Proficiency with data science libraries (Pandas, NumPy, Scikit-learn).\n\u2022 Hands-on experience with ML/DL frameworks (TensorFlow, PyTorch).\n\u2022 Strong SQL and data handling skills.\n\u2022 Understanding of ML Ops practices and tools (Git, Docker, AWS/GCP/Azure).\n\u2022 Knowledge of key AI areas (NLP, Computer Vision, Generative AI/LLMs).\n\nSoft Skills: Strong communication, mentoring ability, collaboration, and a genuine passion for education.\n\nGood-to-Have\n\u2022 Prior teaching experience at the undergraduate or graduate level.\n\u2022 Familiarity with modern teaching methodologies and academic tools.\n\nHow to apply for this opportunity?\n\u2022 Step 1: Click On Apply! And Register or Login on our portal.\n\u2022 Step 2: Complete the Screening Form & Upload updated Resume\n\u2022 Step 3: Increase your chances to get shortlisted & meet the client for the Interview!\n\nAbout Uplers:\n\nOur goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement.\n\n(Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well).\n\nSo, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you!",
    "url": "https://in.linkedin.com/jobs/view/data-scientist-%2B-junior-instructor-at-uplers-4332460060?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Life Sciences Data Science Lead",
    "company": "beBeeDataScience",
    "location": "Pune",
    "salary": "",
    "description": "Are you a seasoned expert in data science and artificial intelligence seeking a challenging role that aligns with your skills?\n\nWe are currently looking for a lead data scientist to join our team.\n\nThe ideal candidate will have extensive experience in AI, ML, and GenAI, as well as a strong background in analytical formulation and problem-solving.\n\nAs a lead data scientist, you will be responsible for managing end-to-end data science project lifecycles, from problem comprehension to final delivery. You will also serve as the primary point of contact for client interactions, presentations, and requirement elicitation.\n\u2022 Lead data science efforts for multiple client engagements in the Life Sciences domain.\n\u2022 Manage teams on advanced data science techniques to ensure alignment with business objectives.\n\u2022 Collaborate cross-functionally with domain experts, business stakeholders, and technical teams to deliver robust analytical solutions.\n\u2022 Expert knowledge of data science algorithms, methodologies, and end-to-end lifecycle (AI/ML/GenAI), MLOps, and post-deployment service of AI models is required.\n\u2022 Exceptional articulation skills to communicate technical concepts clearly to both technical and business stakeholders.\nKey Responsibilities:\n\u2022 Develop and implement advanced data science solutions for clients in the Life Sciences domain.\n\u2022 Lead high-performing teams to achieve project goals and objectives.\n\u2022 Communicate complex technical concepts to both technical and non-technical stakeholders.\n\u2022 Stay up-to-date with industry trends and advancements in AI, ML, and GenAI.\nRequirements:\n\u2022 6+ years of experience in data science, AI, and/or ML.\n\u2022 Strong understanding of complex Life Sciences problems.\n\u2022 Exceptional analytical and problem-solving skills.\n\u2022 Excellent communication and interpersonal skills.",
    "url": "https://in.bebee.com/job/513dc10d79ddcebc308d4dd3571f1290?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Business Sales Head- Data Science",
    "company": "Cinecraft",
    "location": "Pune",
    "salary": "",
    "description": "Position: Business Head \u2013 Data Science\n\nLocation: Pune, Maharashtra\nInstitute: Cinecraft Digital Academy\n\nAbout the Role:\nWe are seeking a dynamic and experienced Business Head \u2013 Data Science to lead our Data Science, AI, and Analytics division. The ideal candidate will drive business growth, oversee academic excellence, and build strong industry partnerships to strengthen our position as a leading digital education brand.\n\nKey Responsibilities:\n\nAchieve admission and revenue targets for Data Science & AI programs.\nLead academic planning, curriculum upgrades, and faculty management.\nCollaborate with marketing for lead generation and brand building.\nDevelop industry tie-ups for placements, projects, and internships.\nManage team performance and ensure smooth operations.\nStay updated with market trends and identify new course opportunities.\n\nRequirements:\n\nGraduate/Postgraduate in Data Science, Computer Science, or Business/ MBA.\n3+ years of experience in education management, EdTech, or training industry working towards admissions.\nStrong knowledge of Data Science, AI, and analytics ecosystem.\n\nExcellent leadership, communication, and business development skills.\n\nWhat We Offer:\nCompetitive salary with performance incentives.\nGrowth-driven, creative work environment.\nOpportunity to lead an expanding digital education brand.\n\nMore about this Business Sales Head- Data Science job\n\nCinecraft is aggressively hiring for the job profile of Business Sales Head- Data Science at Pune in Pawar Quarter (Hotel Raviraj) locality. Kindly go through the FAQs below to get all answers related to the given job.\n\n1. How much salary can I expect as a Business Sales Head- Data Science in Cinecraft in Pune?\n\nAns. You can expect a minimum salary of 40,000 INR and can go up to 60,000 INR. The salary offered will depend on your skills, experience and performance in the interview.\n\n2. What is the eligibility criteria to apply for Business Sales Head- Data Science in Cinecraft in Pune?\n\nAns. The candidate should have completed Graduate degree and people who have 3 to 31 years are eligible to apply for this job. You can apply for more jobs in Pune to get hired quickly.\n\n3. Is there any specific skill required for this job?\n\nAns. The candidate should have Good (Intermediate / Advanced) English skills and sound communication skills for this job.\n\n4. Who can apply for this job?\n\nAns. Only Male candidates can apply for this job.\n\n5. Is it a work from home job?\n\nAns. No, it\u2019s not a work from home job and can\u2019t be done online. You can explore and apply for other work from home jobs in Pune at apna.\n\n6. Are there any charges or deposits required while applying for the role or while joining?\n\nAns. No work-related deposit needs to be made during your employment with the company.\n\n7. How can I apply for this job?\n\nAns. Go to the apna app and apply for this job. Click on the apply button and call HR directly to schedule your interview.\n\n8. What is the last date to apply?\n\nAns. The last date to apply for this job is 12-Nov-2025.\n\nFor more details, download apna app and find Full Time jobs in Pune. Through apna, you can find jobs in 74 cities across India. Join NOW!",
    "url": "https://apna.co/job/pune/business-sales-head-data-science-879117150?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Data-Driven Statistical Modeler",
    "company": "beBeeStatistical",
    "location": "Pune",
    "salary": "",
    "description": "Analytics Insights Developer\n\nA strategic position is available for an Analytics Insights Developer in the Statistics Industry in Pune. The role involves leveraging statistical models using SAS and/or R to drive business decisions, exploring data through various techniques like multi-level forecasting, time-series analysis, optimization, default scorecards, predictive failure modeling, generalized linear models, logistic/linear regression, and logit/probit modeling.\n\nKey Responsibilities:\n\u2022 Communicate complex analytics insights to business stakeholders\n\u2022 Collaborate effectively with cross-functional teams\n\u2022 Develop strong data understanding, hypothesis formulation, data preparation, and model building skills\n\u2022 Apply creative problem-solving approaches and analytical thinking\n\u2022 Design and implement statistical models using SAS and/or R\n\u2022 Gain expertise in analytics applications across Retail, Technology, Finance, and Life Sciences\n\u2022 Preferred experience in machine learning and pattern recognition techniques\n\nFunctional Area:\n\nStatistical modeling, data analysis, analytics, collaboration, data management, SAS, machine learning, statistics jobs in Pune, analytics jobs in India, statistical analysis jobs in Maharashtra\n\nView Opportunities",
    "url": "https://in.bebee.com/job/e8923e7eb87d2b044e3cd00cec9b1c9d?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T08:00:00.000Z"
  },
  {
    "title": "Ishan Technologies - Data Scientist - ETL / Python",
    "company": "Ishan Technologies",
    "location": "Pune",
    "salary": "",
    "description": "Description : Job Summary :\n\nWe are seeking a highly skilled and analytical Data Scientist with hands-on experience in designing, developing, and deploying data-driven solutions.\n\nThe ideal candidate will have strong expertise in data analysis, machine learning, and cloud-based model deployment preferably on Google Cloud Platform (GCP).\n\nThis role involves working closely with cross-functional teams to translate data into actionable insights that enhance business decisions, optimize user experiences, and drive measurable outcomes across web and mobile applications, including React-based environments.\n\nKey Responsibilities :\n\nData Analysis and Modelling :\n\u2022 Analyse large-scale datasets from web and mobile applications (including React-based systems) to identify trends, patterns, and actionable insights.\n\u2022 Design and develop machine learning, predictive, and statistical models to solve complex business challenges such as churn prediction and customer segmentation.\n\u2022 Validate and refine model performance using suitable evaluation metrics to ensure accuracy, reliability, and business relevance.\n\nData Collection and Integration :\n\u2022 Collect and preprocess data from multiple sources, including Firebase services (Firestore, Firebase Analytics), ensuring data quality and consistency.\n\u2022 Integrate disparate data sources into unified datasets compatible with APIs and application backends on cloud platforms.\n\u2022 Perform data cleaning, transformation, and feature engineering for modelling and visualization readiness.\n\nInsight Generation and Reporting :\n\u2022 Derive actionable insights to support business and product strategies, such as enhancing user experience in React-based applications.\n\u2022 Develop and maintain data visualizations and interactive dashboards using cloud-compatible tools.\n\u2022 Present findings and recommendations through clear reports to both technical and non-technical stakeholders.\n\nCollaboration and Communication :\n\u2022 Collaborate with developers, product managers, and UX teams to align data science initiatives with business goals.\n\u2022 Communicate project progress, analysis outcomes, and model performance through regular stakeholder updates.\n\u2022 Work with engineering teams to deploy models seamlessly into production environments (e.g., Firebase-hosted systems).\n\nModel Deployment and Monitoring :\n\u2022 Deploy and operationalize machine learning models in production using Google Cloud Platform (GCP) or other public clouds.\n\u2022 Continuously monitor model performance, addressing issues like data drift and optimizing scalability and efficiency.\n\u2022 Implement and maintain model tracking, logging, and monitoring frameworks in cloud environments.\n\nRequired Skills :\n\u2022 4+ years of professional experience as a Data Scientist or in a similar analytical role.\n\u2022 Proven hands-on experience with at least one public cloud platform (strong preference for Google Cloud Platform).\n\u2022 Strong proficiency in Python and its data science libraries (Pandas, NumPy, Scikit-learn, TensorFlow, PyTorch, etc.\n\u2022 Experience with Firebase, BigQuery, and Vertex AI is highly desirable.\n\u2022 Expertise in data visualization tools (e.g., Looker Studio, Tableau, or Power BI).\n\u2022 Strong understanding of data modelling, ETL processes, and API integrations in cloud-based systems.\n\u2022 Excellent communication skills and ability to collaborate with cross-functional teams.\n\nQualification :\n\u2022 Strong analytical and problem-solving skills.\n\u2022 Desire and ability to rapidly learn a wide variety of new technical skills.\n\u2022 Self-motivated, takes initiative, assumes ownership.\n\u2022 Enthusiastic, professional, with a focus on customer success.\n\u2022 Passion for solving client challenges and commitment to client delight.\n\n(ref : hirist.tech)",
    "url": "https://in.talent.com/view?id=bf6193e7db6c&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Data scientist / ML Engineer -- US Client (Analytics) (Pune)",
    "company": "Aspyra HR Services",
    "location": "Pune",
    "salary": "",
    "description": "Salary : 30 to 45 LPA\n\nExp: 7 to 12 years\n\nLocation :Mumbai Only\n\nNotice: Immediate to 30 days..!!\n\nRoles & responsibilities:\n\n7+ years exp on Python, ML and Banking model development\n\n- Interact with the client to understand their requirements and communicate / brainstorm solutions, model Development: Design, build, and implement credit risk model.\n- Contribute to how analytical approach is structured for specification of analysis\n- Contribute insights from conclusions of analysis that integrate with initial hypothesis and business objective. Independently address complex problems\n- 3+ years exp on ML/Python (predictive modelling).\n- Design, implement, test, deploy and maintain cutting-edge data and machine learning solutions to accelerate our business.\n- Create experiments and prototype implementations of new learning algorithms and prediction techniques\n- Collaborate with product managers, and stockholders to design and implement software solutions for science problems\n- Use machine learning best practices to ensure a high standard of quality for all of the team deliverables\n- Has experience working on unstructured data ( text ): Text cleaning, TFIDF, text vectorization\n- Hands-on experience with IFRS 9 models and regulations.\n- Data Analysis: Analyze large datasets to identify trends and risk factors, ensuring data quality and integrity.\n- Statistical Analysis: Utilize advanced statistical methods to build robust models, leveraging expertise in R programming.\n- Collaboration: Work closely with data scientists, business analysts, and other stakeholders to align models with business needs.\n- Continuous Improvement: Stay updated with the latest methodologies and tools in credit risk modeling and R programming.",
    "url": "https://in.jobrapido.com/jobpreview/2184121542248497152?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-25T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (Machine learning and AI)",
    "company": "YASH Technologies",
    "location": "Pune",
    "salary": "",
    "description": "We are seeking a highly experienced and visionary Senior Principal Data Scientist to join our dynamic team. This role is pivotal in driving our organization's advanced analytics initiatives and shaping our data-driven strategy. As a thought leader, you will lead complex data science projects, mentor junior scientists, and collaborate with cross-functional teams to deliver impactful solutions that address critical business challenges. You will leverage your deep expertise in machine learning, statistical modeling, and data engineering to extract actionable insights and drive innovation.\nResponsibilities:\n\nSet vision for Gen AI adoption and innovation roadmap.\nDrive R&D, capability building, and solution frameworks.\nInfluence customer strategy and support large digital transformation initiatives.\nMentor senior talent, define best practices, IP creation.\n\nRequired Skills:\n\nThought leader in ML/AI/Gen AI, deep expertise in LLMs and vector architecture.\nTrack record of designing scalable AI solutions in BFSI, healthcare, retail, etc.\nExperience in AI governance, ethical AI, and responsible AI practices.\nStrong publishing, client consulting, and leadership capabilities.",
    "url": "https://in.jooble.org/rjdp/-4651442101855054254?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-25T00:00:00.000Z"
  },
  {
    "title": "Fresher - Python AI/ML",
    "company": "Futops Technologies India Pvt. Ltd",
    "location": "Pune",
    "salary": "",
    "description": "Job Title: AI/ML Engineer \u2013 Fresher (Walk-in Drive)\n\nLocation: Kharadi, Pune\n\nExperience: Fresher / 0\u20131 Years\n\nEmployment Type: Full-Time (Internship-to-Hire)\n\nInternship Duration: 3- 6 Months (Stipend - 10k)\n\nCTC Post Confirmation : 3-4 LPA\n\nNote : The shortlisted candidate will receive an invitation mail for the virtual drive\n\nAbout the Role:\n\nWe are looking for a passionate and motivated AI/ML Fresher to join our growing team. As an entry-level AI/ML Engineer, you will be working on real-world machine learning and data-driven projects under the guidance of senior team members. This is an excellent opportunity to build your career in artificial intelligence, machine learning, and data science.\n\nKey Responsibilities:\n\u2022 Assist in building and deploying machine learning models.\n\u2022 Collect, clean, and preprocess data from various sources.\n\u2022 Work with Python and ML frameworks like TensorFlow, PyTorch, or Scikit-learn.\n\u2022 Support the team in research, experimentation, and model evaluation.\n\u2022 Contribute to documentation and presentations of ML solutions.\n\u2022 Collaborate with software engineers and data teams to integrate models into applications.\n\nRequired Skills:-\n\u2022 Good understanding of machine learning concepts and algorithms.\n\u2022 Proficiency in Python and relevant libraries (NumPy, Pandas, Scikit-learn,LLM, OpenCV, Computer Vision, and Gstreamer etc.).\n\u2022 Basic knowledge of deep learning frameworks (TensorFlow, Keras, PyTorch).\n\u2022 Familiarity with data structures and algorithm fundamentals.\n\u2022 Strong analytical and problem-solving skills.\n\u2022 Excellent communication and willingness to learn.\n\nGood to Have:\n\u2022 Academic or personal projects in AI/ML.\n\u2022 Exposure to cloud platforms (AWS, GCP, Azure).\n\u2022 Knowledge of version control systems like Git.\n\nEducational Qualification:\n\u2022 Bachelor\u2019s or Master\u2019s (BE/Btech/MCA/MSC) degree in Computer Science, Data Science, Artificial Intelligence, or a related field.\n\nWhy Join Us:\n\u2022 Work on cutting-edge AI projects.\n\u2022 Mentorship and career development opportunities.\n\u2022 A collaborative and innovative work culture.",
    "url": "https://www.glassdoor.co.in/job-listing/fresher-python-ai-ml-futops-technologies-india-pvt-ltd-JV_IC2856202_KO0,20_KE21,54.htm?jl=1009827220643&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Senior AI Engineer (Remote)",
    "company": "Codvo.ai",
    "location": "Pune",
    "salary": "",
    "description": "Job Description: Senior AI Engineer\n\nCompany Overview:\n\nAt Codvo, software and people transformations go hand-in-hand. We are a global empathy-led technology services company where product innovation and mature software engineering are embedded in our core DNA. Our core values of Respect, Fairness, Growth, Agility, and Inclusiveness guide everything we do. We continually expand our expertise in digital strategy, design, architecture, and product management to offer measurable results and outside-the-box thinking.\n\nAbout the Role:\n\nWe are seeking a highly skilled and experienced Senior AI Engineer to lead the design, development, and implementation of robust and scalable pipelines and backend systems for our Generative AI applications. In this role, you will be responsible for orchestrating the flow of data, integrating AI services, developing RAG pipelines, working with LLMs, and ensuring the smooth operation of the backend infrastructure that powers our Generative AI solutions.\n\nResponsibilities:\n\u2022 Generative AI Pipeline Development:\n\u2022 Design and implement efficient and scalable pipelines for data ingestion, processing, and transformation, tailored for Generative AI workloads.\n\u2022 Orchestrate the flow of data between various AI services, databases, and backend systems within the Generative AI context.\n\u2022 Build and maintain CI/CD pipelines for deploying and updating Generative AI services and pipelines.\n\u2022 Data and Document Ingestion:\n\u2022 Develop and manage systems for ingesting diverse data sources (text, images, code, etc.) used in Generative AI applications.\n\u2022 Implement OCR and other preprocessing techniques to prepare data for use in Generative AI pipelines.\n\u2022 Ensure data quality, consistency, and security throughout the ingestion process.\n\u2022 AI Service Integration:\n\u2022 Integrate and manage external AI services (e.g., cloud-based APIs for image generation, text generation, LLMs) into our Generative AI applications.\n\u2022 Develop and maintain APIs for seamless communication between AI services and backend systems.\n\u2022 Monitor and optimize the performance of integrated AI services within the Generative AI pipeline.\n\u2022 Retrieval Augmented Generation (RAG) Pipelines:\n\u2022 Design and implement RAG pipelines to enhance Generative AI capabilities with external knowledge sources.\n\u2022 Develop and optimize data retrieval and indexing strategies for RAG systems used in conjunction with Generative AI.\n\u2022 Evaluate and improve the accuracy and relevance of RAG-generated responses in the context of Generative AI applications.\n\u2022 Large Language Model (LLM) Integration:\n\u2022 Develop and manage interactions with LLMs through APIs and SDKs within Generative AI pipelines.\n\u2022 Implement prompt engineering strategies to optimize LLM performance for specific Generative AI tasks.\n\u2022 Analyze and debug LLM outputs to ensure quality and consistency in Generative AI applications.\n\u2022 Backend Services Ownership:\n\u2022 Design, develop, and maintain backend services that support Generative AI applications.\n\u2022 Ensure the scalability, reliability, and security of backend infrastructure for Generative AI workloads.\n\u2022 Implement monitoring and logging systems for backend services and pipelines supporting Generative AI.\n\u2022 Troubleshoot and resolve backend-related issues impacting Generative AI applications.\n\nRequired Skills and Qualifications:\n\u2022 Education: Bachelor's or Master's degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field.\n\u2022 Experience:\n\u2022 5+ years of experience in AI/ML development with a focus on building and deploying AI pipelines and backend systems.\n\u2022 Proven experience in designing and implementing data ingestion and processing pipelines.\n\u2022 Strong experience with cloud platforms (e.g., AWS, Azure, GCP) and their AI/ML services.\n\u2022 Technical Skills:\n\u2022 Expertise in Python and relevant AI/ML libraries.\n\u2022 Strong understanding of AI infrastructure and deployment strategies.\n\u2022 Experience with data engineering and data processing techniques.\n\u2022 Proficiency in software development principles and best practices.\n\u2022 Experience with containerization and orchestration tools (e.g., Docker, Kubernetes).\n\u2022 Experience with version control (Git).\n\u2022 Experience with RESTful APIs and API development.\n\u2022 Experience with vector databases and their application in AI/ML, particularly for similarity search and retrieval.\n\u2022 Generative AI Specific Skills:\n\u2022 Familiarity with Generative AI concepts and techniques (e.g., GANs, Diffusion Models, VAEs, LLMs).\n\u2022 Experience with integrating and managing Generative AI services.\n\u2022 Understanding of RAG pipelines and their application in Generative AI.\n\u2022 Experience with prompt engineering for LLMs in Generative AI contexts.\n\u2022 Soft Skills:\n\u2022 Strong problem-solving and analytical skills.\n\u2022 Excellent communication and collaboration skills.\n\u2022 Ability to work in a fast-paced environment.\n\nPreferred Qualifications:\n\u2022 Experience with OCR and document processing technologies.\n\u2022 Experience with MLOps practices for Generative AI.\n\u2022 Contributions to open-source AI projects.\n\u2022 Strong experience with vector databases and their optimization for Generative AI applications.\n\nExperience - 5+ years\n\nShift Time - 2:30PM to 11:30PM",
    "url": "https://in.linkedin.com/jobs/view/senior-ai-engineer-remote-at-codvo-ai-4318619234?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-25T00:00:00.000Z"
  },
  {
    "title": "AI/ML: Engineers",
    "company": "Gravity Infosolutions, Inc.",
    "location": "Pune",
    "salary": "",
    "description": "Job Description\n\nWe are seeking an experienced AI/ML Engineer to design, develop, and deploy scalable machine learning and AI solutions across our digital ecosystem.\n\u2022 Design, develop, train, and deploy machine learning (ML) and deep learning (DL) models for life sciences and manufacturing use cases.\n\u2022 Collaborate with cross-functional teams to identify opportunities for AI/ML-driven automation and optimization.\n\u2022 Implement end-to-end ML pipelines \u2013 from data ingestion and feature engineering to model training, validation, and deployment.\n\u2022 Work with big data platforms to manage and process large-scale datasets.\n\u2022 Develop NLP, computer vision, or predictive analytics models for applications in research, digital labs, and customer analytics.\n\u2022 Cross-functionality",
    "url": "https://in.bebee.com/job/558b4d02d53930eb7d951af0b8e26b7d?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-26T00:00:00.000Z"
  },
  {
    "title": "\u25b7 3 Days Left! Artificial Intelligence Engineer",
    "company": "Pixeldust Technologies",
    "location": "Pune",
    "salary": "",
    "description": "Role Overview:\n\nWe are seeking an experienced AI Engineer with a strong background in Natural Language Processing (NLP), Machine Learning (ML) and Large Language Models (LLMs). The ideal candidate will have hands-on expertise with modern AI frameworks, vector databases and cloud based ML platforms with a focus on building and deploying scalable high performing solutions.\n\nKey Responsibilities:\n\n- Design, develop and deploy NLP and ML models for real world applications.\n- Work extensively with LLM frameworks, Hugging Face Transformers, LangChain Lama Index, OpenAI API, Vertex AI.\n- Fine tune large language models embeddings and optimize vector search using FAISS, Pinecone, Weaviate, Milvus or Vertex AI Matching Engine.\n- Perform data preprocessing statistical analysis and experiment design to validate models.\n- Collaborate with cross functional teams engineering product business to deliver AI driven solutions.\n- Leverage cloud ML platforms GCP preferred to build and scale production grade ML pipelines.\n- Continuously research and adopt state of the art techniques in NLP ML and LLMs.\n\nRequired Skills and Qualification:\n\n- Proven experience as a Data Scientist having 6-9 years of experience with a strong focus on NLP and ML.\n- Hands-on experience with LLM frameworks and libraries - Hugging Face Transformers, LangChain, LamaIndex, OpenAI API and Vertex AI.\n- Strong programming skills in Python with ML AI libraries - PyTorch, TensorFlow and Scikit learn.\n- Experience in fine tuning LLMs embeddings and vector databases - FAISS Pinecone, Weaviate, Milvus, Vertex AI Matching Engine.\n- Proficiency in data analysis statistics and experiment design.\n- Strong understanding of cloud ML platforms - GCP preferred.\n- Excellent problem solving analytical and communication skills.\n- Strong debugging, troubleshooting, and problem-solving skills.\n- Excellent collaboration abilities.\n\nGood to Have Skills:\n\n- Exposure to MLOps practices - CI CD for ML monitoring deployment.\n- Experience with other cloud platforms - AWS and Azure.\n- Knowledge of reinforcement learning and generative AI applications.\n\nWhat We Offer:\n\n- Competitive salary and benefits package.\n- Opportunity to work on cutting-edge security challenges.\n- A collaborative and growth-oriented work environment with opportunities for career development.",
    "url": "https://in.jobrapido.com/jobpreview/216629098766663680?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Senior AI Platform Engineer",
    "company": "AGCO",
    "location": "Pune",
    "salary": "",
    "description": "Do you want to help solve the world's most pressing challenges? Feeding the world's growing population and slowing climate change are two of the world's greatest challenges. AGCO is a part of the solution! Join us to make your contribution.\n\nIn this role, you\u2019ll lead the design and development of reusable, secure, and scalable platform services that enable AI innovation across the enterprise. You\u2019ll apply your systems thinking and deep software engineering expertise to accelerate the development and deployment of machine learning and AI capabilities at scale, from smart farming systems to enterprise automation\n\nYour Impact\n\u2022 Design and build platform services for containerized training, distributed compute, artifact tracking, and model deployment.\n\u2022 Develop infrastructure that supports scalable, reproducible, and secure AI workflows across cloud and hybrid environments.\n\u2022 Implement CI/CD pipelines, observability standards, and developer tooling for platform services used across multiple AI teams.\n\u2022 Collaborate with data scientists, ML engineers, architects, and software developers to define and deliver core platform capabilities. Drive automation and best practices for performance, security, and operational reliability.\n\u2022 Mentor engineers and contribute to architectural decisions that influence platform direction. Stay current with emerging tools and trends in cloud infrastructure, AI/ML tooling, and platform engineering.\n\nYour Experience and Qualifications\n\u2022 7+ years of experience in software or platform engineering, including 3+ years building infrastructure for data/AI systems.\n\u2022 Proven track record developing infrastructure using GCP or AWS. Preference for GCP experience.\n\u2022 Strong skills in Python, Go, or JavaScript, with deep experience building scalable, secure services. Experience designing secure, observable, and resilient distributed systems.\n\u2022 Deep knowledge of container orchestration, Serverless and Infrastructure-as-Code (Terraform or similar).\n\u2022 Hands-on experience with data processing (Spark, Airflow etc.) and ML pipeline orchestration. Deep understanding of CI/CD workflows, version control systems (e.g., Git), and monitoring/logging stacks\n\nYour Benefits\n\u2022 \u200b\u200bGLOBAL DIVERSITY \u2013 Diversity means many things to us, different brands, cultures, nationalities, genders, generations \u2013 even variety in our roles. You make us unique!\n\u2022 \u200bENTERPRISING SPIRIT- Every role adds value. We're committed to helping you develop and grow to realize your potential.\n\u2022 \u200bPOSITIVE IMPACT \u2013 Make it personal and help us feed the world.\n\u2022 \u200bINNOVATIVE TECHNOLOGIES - You can combine your love for technology with manufacturing excellence \u2013 and work alongside teams of people worldwide who share your enthusiasm.\n\u2022 \u200bMAKE THE MOST OF YOU \u2013 Benefits include health care and wellness plans and flexible and virtual work option\u2026\u2026\u2026.\n\n\u200b\u200b\n\nYour Workplace\n\nWe value inclusion and recognize the innovation a diverse workforce delivers to our farmers. Through our recruitment efforts, we are committed to building a team that includes a variety of experiences, backgrounds, cultures and perspectives.\n\nJoin us as we bring agriculture into the future and apply now!\n\nPlease note that this job posting is not designed to cover or contain a comprehensive listing of all required activities, duties, responsibilities, or benefits and may change at any time with or without notice.\n\n\u202f\n\nAGCO is proud to be an Equal Opportunity Employer",
    "url": "https://careers.agcocorp.com/job/Pune-Senior-AI-Platform-Engineer-MH/1311735300/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-24T00:00:00.000Z"
  },
  {
    "title": "AI & ML-Engineer",
    "company": "ProManage",
    "location": "Pune",
    "salary": "",
    "description": "Job Description:\n\u2022 Design and develop software solutions using suitable design patterns.\n\u2022 Adopt new technologies to provide innovative solutions.\n\u2022 Collaborate with cross-functional teams to translate business requirements into machine learning problems.\n\u2022 Integrate machine learning models into production systems.\n\u2022 Identify technical issues and provide resolution.\n\u2022 Develop and implement machine learning models for predictive analytics, recommendation systems, and more.\n\u2022 Stay up-to-date with AI and machine learning advancements.\n\u2022 Ensure scalable, efficient, and robust machine learning pipelines.\n\nQualifications:\n\u2022 BE or Master's in Computer Science.\n\u2022 2+ years of experience as a Machine Learning Engineer or AI Engineer.\n\u2022 Proficiency in Python, Scala, R, or similar programming languages.\n\u2022 Familiarity with cloud platforms like AWS, Google Cloud, or Microsoft Azure.\n\u2022 Strong understanding of machine learning algorithms and data structures.",
    "url": "https://in.bebee.com/job/50bd8a330ee52a0c40bccf7bf1970295?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-26T00:00:00.000Z"
  },
  {
    "title": "Generative AI Engineer",
    "company": "Ascendion",
    "location": "Pune",
    "salary": "",
    "description": "Position Details:\n\nJob Title: GenAI Engineer\n\nExperience : 3+ years\n\nLocation Options: Pune\n\nSkills : Python, Langchain, Langgraph, Autogen\n\nOverview:\n\nWe are actively seeking highly skilled GenAI Engineers . The ideal candidates will bring hands-on experience in developing and deploying Generative AI (GenAI) solutions from MVP to production.\n\nKey Skills:\n\u2022 Python, Langchain, Langgraph, Autogen\n\u2022 Ai agents build (multi-Agent orchestration)\n\u2022 Build and orchestrate AI agents, including multi-agent systems using frameworks like LangChain, LangGraph, and AutoGen.\n\u2022 Collaborate with cross-functional teams to integrate agents with external tools (e.g., GitHub, web UIs). Worked on integrating tools with agent ex., GitHub, ui etc\n\u2022 Work in an agile environment to rapidly prototype and transition MVPs to production. Worked on mvp to production for genai solution\n\u2022 Support and optimize RAG (Retrieval-Augmented Generation) pipelines.\n\u2022 Contribute to prompt engineering strategies and scalable GenAI infrastructure. Experience on prompt engineering and rag setup and support\n\u2022 Leverage Databricks for model development, data preparation, and orchestration. Proficiency in Databricks for ML/AI workflows.",
    "url": "https://in.jooble.org/jdp/-4269895446955593525?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-26T00:00:00.000Z"
  },
  {
    "title": "\u25b7 15h Left : Artificial Intelligence tester",
    "company": "Wipro",
    "location": "Pune",
    "salary": "",
    "description": "Job Title : AI Test Engineer\n\nDuration : Fulltime\n\nLocation : Pune / Kharadi\n\nJob Summary :\n\nWe are looking for a detail-oriented and analytical AI Tester to ensure the quality and reliability of our AI models and systems. The ideal candidate will have experience in testing AI / ML applications, a strong understanding of machine learning concepts, and expertise in designing test cases for complex AI systems. You will play a critical role in identifying issues, ensuring compliance with ethical AI standards, and improving the overall performance of AI solutions.\n\nKey Responsibilities :\n\n1. Test Planning and Strategy :\n\u2022 Develop comprehensive test plans and strategies for AI / ML models and systems.\n\u2022 Define testing methodologies, including functional, performance, and stress testing for AI applications.\n\n2. Test Case Design and Execution :\n\u2022 Design and execute test cases to validate AI models, algorithms, and workflows.\n\u2022 Test AI systems for accuracy, bias, fairness, and robustness.\n\u2022 Simulate real-world scenarios to evaluate the performance of AI models.\n\n3. Defect Identification and Reporting :\n\u2022 Identify, document, and report issues, bugs, and inconsistencies in AI systems.\n\u2022 Work closely with data scientists and engineers to resolve defects and improve model performance.\n\n4. Performance Monitoring :\n\u2022 Monitor the performance of AI models in production environments.\n\u2022 Validate model outputs against expected results and business requirements.\n\n5. Compliance and Ethical Testing :\n\u2022 Ensure AI systems comply with ethical AI principles, data privacy regulations, and organizational standards.\n\u2022 Test for unintended biases and ensure fairness in AI decision-making processes.\n\n6. Automation and Tools :\n\u2022 Develop and maintain automated testing frameworks for AI / ML systems.\n\u2022 Use testing tools and frameworks (e.g., Selenium, PyTest, or custom tools) to streamline testing processes.\n\n7. Collaboration :\n\u2022 Collaborate with data scientists, AI engineers, and product teams to understand requirements and testing needs.\n\u2022 Provide feedback and recommendations to improve AI model quality and reliability.\n\n8. Documentation :\n\u2022 Document test cases, results, and processes for future reference.\n\u2022 Prepare detailed reports on testing outcomes and areas for improvement.\n\nQualifications : Education :\n\u2022 Bachelor\u2019s or Master\u2019s degree in Computer Science, Software Engineering, Data Science, or a related field.\n\u2022 Experience :\n\u2022 3+ years of experience in software testing, with at least 1-2 years focused on AI / ML systems.\n\u2022 Hands-on experience with testing AI models, algorithms, and workflows.\n\u2022 Familiarity with machine learning concepts, frameworks (e.g., TensorFlow, PyTorch), and data pipelines.\n\u2022 Skills :\n\u2022 Strong understanding of testing methodologies and tools.\n\u2022 Proficiency in programming languages like Python or Java for test automation.\n\u2022 Knowledge of data validation, model evaluation metrics, and performance testing.\n\u2022 Familiarity with cloud platforms (e.g., AWS, Azure, Google Cloud) is a plus.\n\u2022 Strong analytical and problem-solving skills.\n\u2022 Certifications (Optional) :\n\u2022 ISTQB or other software testing certifications.\n\u2022 AI / ML-related certifications are a plus.\n\nKey Competencies :\n\u2022 Attention to detail and a commitment to quality.\n\u2022 Strong communication and collaboration skills.\n\u2022 Ability to work in a fast-paced, dynamic environment.\n\u2022 Passion for ensuring the reliability and fairness of AI systems.",
    "url": "https://in.talent.com/view?id=24fec1cb398a&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Architect, Applied AI Engineering",
    "company": "Icertis",
    "location": "Pune",
    "salary": "",
    "description": "We are seeking an experienced Python Architect with strong expertise in ML Engineering. The ideal candidate will take ownership of critical components of our product, design scalable ML systems, and mentor junior engineers. The role requires hands-on experience with containerized environments, Kubernetes, and distributed ML workflows.",
    "url": "https://iaaviz.fa.ocs.oraclecloud.com/hcmUI/CandidateExperience/en/sites/Jobs-at-Icertis/job/7020/?gh_src=Headline+job+boardutm_medium&utm_medium=getro.com&utm_source=google&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-27T00:00:00.000Z"
  },
  {
    "title": "AI Developer (Drive - 1st November'25)",
    "company": "Centre for Computational Technologies (CCTech)",
    "location": "Pune",
    "salary": "",
    "description": "\u2022 load_list_page(event)\"> Job listing\n\u2022 Job details\n\nJob Information\n\u2022 Date Opened 10/27/2025\n\u2022 Industry IT Services\n\u2022 Job Type Permanent\n\u2022 Work Experience 2-5 Years\n\u2022 City Pune City\n\u2022 State/Province Maharashtra\n\u2022 Country India\n\u2022 Zip/Postal Code 411001\n\nAbout Us\n\nCCTech's mission is to transform human life by the democratization of technology. We are a well established digital transformation company building the applications in the areas of CAD, CFD, Artificial Intelligence, Machine Learning, 3D Webapps, Augmented Reality, Digital Twin, and other enterprise applications.\n\nWe have two business divisions: product and consulting.\n\nsimulationHub is our flagship product and the manifestation of our vision. Currently, thousands of users use our CFD app in their upfront design process.\n\nOur consulting division, with its partners such as Autodesk Forge, AWS and Azure, is helping the world's leading engineering organizations, many of which are Fortune 500 list of companies, in achieving digital supremacy.\n\nJob Description\n\nWe are seeking a passionate and skilled AI Engineer with over 2+ years of hands-on experience to join our growing team. The ideal candidate will have an engineering background and a strong grasp of modern AI technologies, especially in Prompt Engineering, Agentic AI models, and production-grade AI workflows. You\u2019ll play a key role in building intelligent systems that augment and automate real-world business processes.\n\u2022 Design, develop, and deploy AI-powered solutions using LLMs and agentic frameworks.\n\u2022 Build and optimise prompt engineering strategies to ensure high-performance language model behaviour.\n\u2022 Create and maintain autonomous AI agents capable of executing complex multi-step tasks.\n\u2022 Develop, test, and iterate on real-world AI workflows integrated into broader applications.\n\u2022 Collaborate with product managers, designers, and engineers to translate business problems into scalable AI solutions.\n\u2022 Monitor and fine-tune AI models in production for accuracy, performance, and cost-effectiveness.\n\u2022 Stay current with emerging trends in generative AI, LLMs, agent-based architectures, and MLOps.\n\nRequirements\n\u2022 Bachelor\u2019s degree in Computer Science, Engineering, or related field.\n\u2022 2+ years of hands-on experience in AI/ML engineering or applied NLP.\n\u2022 Proven experience with Prompt Engineering and customizing large language model behavior.\n\u2022 Experience developing or integrating Agentic AI frameworks (e.g., LangChain, AutoGPT, etc.).\n\u2022 Strong understanding of LLMs (e.g., GPT-4, Claude, Mistral, Gemini, etc.) and how to apply them in workflow automation.\n\u2022 Demonstrated ability to deploy working AI solutions and pipelines in DEV & Production environments.\n\u2022 Proficient in Python and relevant AI libraries (Transformers, OpenAI SDK, LangChain, etc.).\n\u2022 Familiarity with RESTful APIs, cloud platforms (e.g., Azure, AWS, GCP), and version control tools (e.g., Git)\n\nNice To Have\n\u2022 Must be familiar with frameworks like langchain, llamaindex, langraph and have used them in project(s).\n\u2022 Must be familiar with RAG framework (vector databases).\n\u2022 Hands on computer vision tasks like object detection, image processing and OCR\"\n\nBenefits\n\u2022 Opportunity to work with a dynamic and fast-paced engineering IT organization.\n\u2022 Be part of a company that is passionate about transforming product development with technology.\n\ncheck(event) ; career-website-detail-template-2 => apply(record.id,meta)\" mousedown=\"lyte-button => check(event)\" final-style=\"background-color:#2185D0;border-color:#2185D0;color:white;\" final-class=\"lyte-button lyteBackgroundColorBtn lyteSuccess\" lyte-rendered=\"\">",
    "url": "https://in.linkedin.com/jobs/view/ai-developer-drive-1st-november-25-at-centre-for-computational-technologies-cctech-4319333749?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Sr. Content Marketer (Saas)",
    "company": "ExtraaEdge",
    "location": "Pune",
    "salary": "",
    "description": "Job Summary\n\nAs the Technical Content Writer, your role is pivotal to our marketing efforts. You\u2019ll play a key role in shaping our content narrative across multiple channels. You\u2019ll create high-quality, engaging, and technically sound content that communicates the value of our Education CRM, automation/cloud, and AI features to educational institutions. Beyond technical content, you\u2019ll craft compelling social stories, customer success highlights, and thought leadership pieces that position ExtraaEdge as the go-to brand in the Education CRM space. You will also play a critical part in enhancing our online visibility and driving organic traffic by creating content that not only informs but also ranks well on search engines\n\nDetailed Roles and Responsibilities\n\na) Content Creation:\n\n\u25cf Produce high-quality, technical content such as blog posts, whitepapers, case studies, eBooks, and website content that resonates with our target audience.\n\n\u25cf Produce social-first content (LinkedIn posts, carousels, short videos, email snippets), content for email nurture journeys and community management.\n\nb) Research:\n\n\u25cf Conduct in-depth research to gather information, industry insights, and best practices to support your content. Interview subject matter experts when necessary.\n\nc) SEO Optimization:\n\n\u25cf Opmize content for search engines (SEO) to enhance online visibility and a ract organic traffic. Collaborate with the SEO team to maximize content reach.\n\nd) Content Strategy:\n\n\u25cf Contribute to the development of the content strategy, aligning content with marketing goals and target audience needs.\n\ne) Editing and Proofreading:\n\n\u25cf Review and edit content for accuracy, clarity, and grammar. Ensure that all content is error free and aligns with the brand's voice and style.\n\nf) User-Centric Approach:\n\n\u25cf Write content that addresses the pain points, ques ons, and needs of our target audience. Strive to create content that educates and empowers readers.\n\ng) Collaboration:\n\n\u25cf Collaborate with the marketing team, designers, and subject matter experts to create content that supports marketing initiatives and campaigns.\n\nKPI\u2019s for the Role\n\na) Engagement Metrics (click-through rates (CTR), social media likes, shares, and comments)\n\nb) Conversion Rates (signing up for a newsletter, requesting a demo, downloading a resource)\n\nc) Website Traffic\n\nd) A/B Testing Results\n\ne) Content Performance (content downloads, shares, and views)\n\nf) Response TAT to marketing team\u2019s content needs\n\nRequirements\n\nQualifications\n\na) Proven experience as a Technical Content Writer (3-6 Years) is a must, preferably in SaaS, CRM, or EdTech domains.\n\nb) Solid understanding of SEO principles, on-page optimization techniques, and experience with SEO tools (e.g., SEMrush, Moz).\n\nc) Experience in conducting keyword research and implementing SEO strategies to enhance content performance is desirable\n\nSkills\n\na) Creativity and Technical Flair\n\nb) Detail Oriented\n\nc) Effective Communication\n\nd) Research Orientation\n\nBehavioral Skills\n\na) Customer-Centric Approach\n\nb) Ability to continuously prioritize\n\nc) Critical Thinking\n\nd) Strong Collaborative Skills\n\ne) Keen Learner",
    "url": "https://in.linkedin.com/jobs/view/sr-content-marketer-saas-at-extraaedge-4318028386?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-27T00:00:00.000Z"
  },
  {
    "title": "Part-Time Content Writer \u2013 Ideal for English & Journalism Students",
    "company": "Entry Level Remote Jobs",
    "location": "Pune",
    "salary": 20,
    "description": "Job Title: Part-Time Content Writer \u2013 Ideal for English & Journalism Students\n\nLocation: Remote / Work From Home\nJob Type: Part-Time\nExperience Level: Entry-Level / Student Internship\nStipend: \u20b94,000 \u2013 \u20b910,000/month (performance-based)\nJob Overview\n\nAre you a student passionate about writing and storytelling? We are looking for a Part-Time Content Writer to join our creative team. This role is perfect for English, Journalism, or Mass Communication students who want hands-on experience in content creation, SEO writing, and blogging \u2014 all while working remotely.\nKey Responsibilities\n\u2022 *\n\nWrite clear, engaging, and well-structured articles, blog posts, and web content\n\u2022 *\n\nConduct basic research to support content accuracy and depth\n\u2022 *\n\nFollow editorial guidelines and optimize content for SEO (training provided)\n\u2022 *\n\nEdit and proofread your content before submission\n\u2022 *\n\nCollaborate with the marketing team on topic ideas and calendar planning\n\u2022 *\n\nMeet weekly deadlines and word count targets\n\u2022 Eligibility & Requirements\n\u2022 *\n\nCurrently pursuing a degree in English, Journalism, Mass Communication, or similar field\n\u2022 *\n\nExcellent command of written English and grammar\n\u2022 *\n\nAbility to write in a variety of tones and formats\n\u2022 *\n\nBasic understanding of blog formatting and content structure\n\u2022 *\n\nPrior writing samples or a blog/portfolio is a bonus (not mandatory)\n\u2022 Perks & Benefits\n\u2022 *\n\nFlexible hours to suit your academic schedule\n\u2022 *\n\nInternship certificate and Letter of Recommendation\n\u2022 *\n\nLearn real-world SEO and content marketing skills\n\u2022 *\n\nOpportunity to work with editors and senior writers\n\u2022 *\n\nLong-term freelance or full-time writing opportunities based on performance\n\u2022 How to Apply\n\nSubmit your resume with:\n\u2022 *\n\n1\u20132 writing samples (blog, article, or academic piece)\n\u2022 *\n\nA brief note on your writing interests or favorite topics\n\u2022 *\n\nYour availability (hours per week)\n\u2022",
    "url": "https://theelitejob.com/job/16425/part-time-content-writer-%E2%80%93-ideal-for-english-journalism-students?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T23:00:00.000Z"
  },
  {
    "title": "Technical Writer \u2013 AMM/IPC/CMM/WDM",
    "company": "GLOINNT",
    "location": "Pune",
    "salary": "",
    "description": "Experience: 2\u20138 Years\n\nLocation: Pune\n\nNotice period : Immediate joiners\n\nKey Responsibilities:\n\u2022 Create, revise, and maintain CMM/IPC, AMM, WDM, SB, and ICA documents for aircraft interior products.\n\u2022 Develop illustrations and technical graphics to support documentation.\n\u2022 Author and maintain manuals in compliance with ATA iSpec2200, S1000D, and Boeing/Airbus documentation standards.\n\u2022 Evaluate and revise manuals, maintain indexes, and ensure documentation accuracy.\n\u2022 Translate engineering data into clear, compliant, and user-friendly publications.\n\u2022 Provide guidance, mentorship, and quality reviews for technical writing projects.\n\u2022 Participate in project meetings to align documentation with engineering deliverables.\n\nEducation & Experience:\n\u2022 Bachelor\u2019s degree in a technical or engineering discipline.\n\u2022 6\u20138 years of experience in aerospace technical writing or publications.\n\u2022 Hands-on experience in authoring S1000D-based manuals.\n\nRequired Skills:\n\u2022 Strong knowledge of aircraft systems, FAA documentation standards, and maintenance manuals.\n\u2022 Experience in CMM/IPC, AMM, WDM, SB, ICA documentation.\n\u2022 Proficiency in ATA iSpec2200, S1000D, and Boeing/Airbus technical guides.\n\u2022 Skilled in Framemaker, IsoDraw, QuarkXpress, Adobe Illustrator, Lattice XVL, Eagle Publishing System, and Microsoft Office.\n\u2022 Strong understanding of aerospace quality standards and document control.\n\u2022 Excellent communication, writing, and presentation skills.\n\u2022 Ability to manage multiple projects under tight deadlines.",
    "url": "https://www.glassdoor.co.in/job-listing/technical-writer-amm-ipc-cmm-wdm-gloinnt-JV_IC2856202_KO0,32_KE33,40.htm?jl=1009922678308&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Digital Media Content",
    "company": "IndiaIT360",
    "location": "Pune",
    "salary": "",
    "description": "Digital Media Content\n\nOur team seeks a creative and skilled Digital Media Content specialist to develop engaging content across various platforms.\n\u2022 Write and edit content copy for Social Media, B2B and B2C content for IT products, services, and solutions.\n\u2022 Create compelling podcasts and CXO engagement content.\n\u2022 Plan, create, and manage daily posts across LinkedIn, Twitter, Instagram, Facebook, and YouTube.\n\u2022 Develop monthly social media calendars and campaigns to increase engagement and followers.\n\nRequirements:\nMaster's degree in English, Communications, Marketing, Journalism, or related field.\n2-4 years of experience in content writing and social media management, preferably in the IT or technology sector.",
    "url": "https://in.bebee.com/job/1c5fa3004ee9a6c39eff0c1340b824da?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Content Writer for Global Health and Business Publication (Pune)",
    "company": "beBeeHealthcare",
    "location": "Pune",
    "salary": "",
    "description": "Job Description\n\nWe are seeking a skilled Content Writer to join our team in producing high-quality articles on healthcare, business, technology, policy, and culture.\n\nAs a Content Writer, you will be responsible for researching and writing insightful articles that appeal to industry leaders, executives, and individuals eager to stay ahead in tech, health, and business.\n\nYou will work closely with our in-house team to assist in the expansion of our reach and voice, collaborating on special projects and performing research using credible sources.\n\nRequired Skills and Qualifications\n\n- Passion and drive to write rigorous articles on a weekly or biweekly schedule\n- A keen interest in healthcare, business, tech, and global issues\n- Strong written and verbal communication skills in English\n- Ability to provide deeper analysis rather than surface-level reporting\n- Ability to contextualise news using data, archives, and credible sources\n\nPerks\n\n- Flexible schedule, with opportunities to work from home\n- Competitive compensation package\n- Opportunities for growth, bylines, and potential increase in pay as performance improves\n\nHow to Apply\n\nTo apply, please submit your CV, 2-3 writing samples, and a short video introducing yourself and explaining why you are interested in this position.",
    "url": "https://in.jobrapido.com/jobpreview/5780211759843377152?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-26T00:00:00.000Z"
  },
  {
    "title": "Student Content Writer for SEO",
    "company": "Frido",
    "location": "Pune",
    "salary": "",
    "description": "Key Responsibilities\nWrite clear, simple, and persuasive content that promotes Frido\u2019s mission and increases conversion rates on PDPs and LPs.\nConduct in-depth research on customer feedback, reviews, and market trends.\nPublish and repurpose existing customer reviews across websites and marketplaces.\nPlan and execute A/B tests by plotting the right reviews at the right places to improve conversion.\nCollaborate with the design and marketing teams to maintain consistency in brand voice, style, and messaging.\nStay updated on industry trends, competitor strategies, and content best practices.\n\nSkills & Qualifications\nExceptional written communication and storytelling skills.\nImpeccable grammar, punctuation, and spelling.\nAbility to research and craft compelling, customer-centric content.\nUnderstanding SEO and e-commerce content practices is a plus.\nAttention to detail with the ability to meet tight deadlines.\nCreativity combined with a strategic mindset.\n\nPreferred Qualifications\nFamiliarity with AI content tools and A/B testing methodologies.\nExperience with CMS platforms\nPortfolio of writing samples (academic, blogs, or creative work).\nPositive attitude and eagerness to learn.\nGraduate or college student with relevant skills (freshers are welcome).\n\nIdeal Profile\nWe\u2019re looking for someone curious about e-commerce, skilled with AI tools, and a data-driven approach. A strong passion for content creation, experimenting with messaging, and improving conversions will help you succeed in this role.",
    "url": "https://in.jooble.org/rjdp/-2787461149897713946?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-27T00:00:00.000Z"
  },
  {
    "title": "\u25b7 Apply Now: Content Writer (Pune)",
    "company": "Palmonas",
    "location": "Pune",
    "salary": "",
    "description": "Job Title: Content + Copy Writer\n\nBrand: Palmonas\n\nExperience: 2-3 years\n\nKey Responsibilities\n\n\u2022 Brand Storytelling: Craft engaging stories and campaigns that reflect Palmonas\u2019 modern-luxury aesthetic and tone of voice.\n\n\u2022 Content Writing: Create compelling, well-researched content for blogs, campaigns, and product stories.\n\n\u2022 Copywriting: Write clear, creative, and conversion-focused copy for ads, emails, website banners, product descriptions, and packaging.\n\n\u2022 Social Media Content: Develop catchy, scroll-stopping captions and ideas for Instagram and other digital platforms.\n\n\u2022 Website & Product Content: Write SEO-friendly product descriptions, collection stories, and landing page content that highlight craftsmanship and design.\n\n\u2022 Campaign Ideation: Collaborate with cross-functional teams to conceptualize and execute 360\u00b0 marketing campaigns.\n\n\u2022 Scriptwriting: Write short, engaging scripts for brand videos, influencer collaborations, and social media reels.\n\n\u2022 Brand Consistency: Maintain Palmonas\u2019 distinctive tone of voice across all communication touchpoints.\n\nSkills & Qualifications\n\n\u2022 Solid grasp of brand storytelling, tone, and consumer psychology.\n\n\u2022 Excellent command of English, grammar, and a flair for creative writing.\n\n\u2022 Prior experience in fashion, lifestyle, or jewellery brands is preferred.\n\n\u2022 Good understanding of social media trends and influencer-driven content.\n\n\u2022 Ability to turn ideas into catchy one-liners, campaign themes, and hooks.\n\n\u2022 Knowledge of SEO and basic digital marketing principles is a plus.",
    "url": "https://in.jobrapido.com/jobpreview/3586489249848885248?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-25T00:00:00.000Z"
  },
  {
    "title": "Brand Content Copywriter",
    "company": "Datacore Technologies",
    "location": "Pune",
    "salary": "",
    "description": "Total Yrs. of Experience : 6+ years\nRelevant Yrs. of experience : 6+ years\n\nDetailed JD :\nCreate clear, concise, and engaging content for internal and external audiences, including reports, presentations, and guides.\nTranslate technical information into user-friendly Business communication.\nEnsure consistency in tone, style, and branding across all written materials.\nStrong written and verbal communication abilities.\nContent Writer and PMO\n\nMandatory skills : PMO\n\nDesired skills : Content Writer\n\nDomain : Financial and Wealth management",
    "url": "https://in.jooble.org/rjdp/648105583529731116?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Proposal / Content Writer - Federal / Government Contracts (RFP, RFQ, RFI) ( USA & Canada)",
    "company": "Veracity Software Inc",
    "location": "Pune",
    "salary": "",
    "description": "Proposal / Content Writer - Federal / Government Contracts (RFP, RFQ, RFI) ( USA & Canada)\nProposal / Content Writer - Federal / Government Contracts (RFP, RFQ, RFI) ( USA & Canada)\n\n1 month ago Be among the first 25 applicants\n\nGet AI-powered advice on this job and more exclusive features.\n\nProposal Writing | RFP / RFQ / RFI Response Development | Technical Writing | Bid Management | Compliance Matrix Creation | Capture Planning I Pre bid meeting I Document Management\n\nFull Time\n\nPune, India / Remote\n\nWe are seeking an experienced Proposal Manager/Writer to lead the development and submission of comprehensive proposals in response to Federal, State RFQs, RFPs, and RFIs. This individual will play a key role in securing new contracts and ensuring compliance with client and regulatory requirements. The successful candidate will have a strong background in crafting detailed, visually engaging proposals, managing multiple tasks simultaneously, and collaborating with cross-functional teams.\n\nKey Responsibilities:\n\u2022 Develop and write comprehensive, compliant proposals in response to Federal, State RFQs, RFPs, and RFIs, contributing to the successful acquisition of multiple contracts.\n\u2022 Create detailed outlines, compliance matrices, and capability matrices to ensure alignment with proposal requirements, tailoring solutions to meet client expectations.\n\u2022 Manage task orders and ensure compliance with IDIQ (Indefinite Delivery/Indefinite Quantity) contracts, ensuring that all contractual obligations are met.\n\u2022 Collaborate closely with cross-functional teams, including technical and subject matter experts, to gather necessary content and ensure proposals adhere to regulatory, legal, and performance guidelines.\n\u2022 Produce high-quality proposal content, including narrative and visually engaging graphics, to enhance clarity and impact.\n\u2022 Streamline the proposal development process to enhance efficiency, reduce submission turnaround time, and improve the overall proposal quality.\n\u2022 Manage and track multiple proposals simultaneously, consistently delivering accurate, compliant, and well-organized documents within tight deadlines.\n\u2022 Maintain a strong focus on quality control, ensuring all proposals are fully compliant with solicitation requirements and exceed client expectations.\n\u2022 Recognized by management for creating compelling, visually appealing proposals that support business development objectives.\n\nQualifications:\n\u2022 Proven experience in proposal development and writing, particularly for Federal and State contracts.\n\u2022 Strong understanding of RFQs, RFPs, RFIs, and IDIQ contract structures.\n\u2022 Demonstrated ability to manage multiple proposals concurrently, meeting deadlines and maintaining a high standard of quality.\n\u2022 Experience collaborating with cross-functional teams, ensuring that proposals align with client expectations and compliance standards.\n\u2022 Exceptional written and verbal communication skills, with a keen eye for detail and quality.\n\u2022 Ability to create visually engaging proposal documents and presentations, incorporating graphics and other visual elements.\n\u2022 Strong organizational skills and ability to streamline processes for improved efficiency.\n\nSeniority level\n\u2022 Seniority level\nMid-Senior level\nEmployment type\n\u2022 Employment type\nContract\nJob function\n\u2022 Job function\nOther\n\u2022 Industries\nIT Services and IT Consulting\n\nReferrals increase your chances of interviewing at Veracity Software Inc by 2x\nSign in to set job alerts for \u201cContent Writer\u201d roles.\nTechnical Author (multiple roles and seniority levels)\nProposal Writer \u2013 Federal / Government Contracts (RFP, RFQ, RFI)\nContent & Brand Marketing Manager - Remote\n\nWe\u2019re unlocking community knowledge in a new way. Experts add insights directly into each article, started with the help of AI.",
    "url": "https://www.jobleads.com/in/job/proposal-content-writer-federal-government-contracts-rfp-rfq-rfi-usa-canada--pune-city--e289be9278bd4bee4420d8d16056f1a95?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-26T00:00:00.000Z"
  },
  {
    "title": "Political News Writer",
    "company": "MEA WorldWide",
    "location": "Pune",
    "salary": "",
    "description": "Job Title: Political News Writer\n\nWe're looking for a talented Political News Writer to join our fast-paced newsroom. The ideal candidate will have a strong grasp of US politics, sharp instincts, and the ability to break down complex developments into engaging stories.\n\nThe role involves tracking US politics, elections, Congress, press conferences, and policy debates to spot timely and trending stories. You'll need to develop unique angles that stand out in a crowded digital landscape and write clear, accurate, and engaging stories optimized for digital audiences.\n\nKey responsibilities include:\n\u2022 Tracking US politics and spotting timely and trending stories\n\u2022 Developing sharp, unique angles that stand out in a crowded media landscape\n\u2022 Writing clear, accurate, and engaging stories optimized for digital audiences\n\u2022 Crafting click-worthy headlines and strong leads that drive traffic and shares\n\u2022 Fact-checking swiftly using credible sources to ensure accuracy and credibility\n\u2022 Moderating social media for viral political chatter and reframing it into smart coverage\n\nWe offer competitive compensation based on experience, fully remote work, and the opportunity to work with a fast-growing global digital newsroom. If you thrive in the 24/7 news cycle, can write crisp copy under pressure, and know how to frame political stories in ways that spark conversation, this is the role for you.",
    "url": "https://in.bebee.com/job/65473fbd6a776f1a9794340bd88f5b53?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-26T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (Python/ GenAI/ AgenticAI)",
    "company": "Wolters Kluwer",
    "location": "Pune",
    "salary": "",
    "description": "Key Responsibilities\n\nActive Learner with Enthusiasm for Problem-Solving\n\nContinuously learn and apply new AI/ML techniques, including Generative AI, Agentic AI deep learning, and other emerging technologies. Demonstrate a passion for solving complex business challenges and experimenting with novel approaches to improve model performance.\n\nQuick Prototyping & Experimentation\n\nDevelop rapid prototypes to test new AI/GenAI/ML approaches and solutions for business problems. Implement proof-of-concept models quickly, enabling fast experimentation and iteration to assess feasibility before scaling to full development.\n\nSupport AI Product Development & Iteration\n\nCollaborate with lead/ senior data scientists and cross-functional teams to support the design, development, and deployment of AI-driven products. Contribute to the creation of prototypes and refine models based on business needs and feedback.\n\nModel Development and Optimization\n\nDesign, develop, and test machine learning, deep learning, and generative AI models, focusing on performance, scalability, and business relevance. Continuously refine and optimize models based on real-world results and metrics.\n\nData Preparation & Collaboration\n\nAssist in defining data requirements and support data engineers in building data pipelines. Clean and preprocess datasets, ensuring data quality and preparing it for use in machine learning applications. Collaborate closely with engineers to integrate models into production systems.\n\nResearch Support and Knowledge Sharing\n\nStay informed about the latest trends and research in AI/GenAI/ML and generative models, applying this knowledge to current projects. Actively participate in team discussions, contribute to the evaluation of new techniques, and share insights with peers to foster a collaborative learning environment.\n\nEssential Skills\n\u2022 Good knowledge of Python programming language, data engineering and data science ecosystem in Python.\n\u2022 Hands on experience in Generative AI, Agentic AI, LLM and Advance RAG techniques.\n\u2022 Hands on experience in developing and supporting Machine Learning solutions.\n\u2022 Hands on experience in developing Natural Language Processing (NLP) solutions\n\u2022 Hands on experience on SQL ecosystem\n\u2022 Hands on experience on Solr framework with Python\n\u2022 Experience of working on Linux and shell scripting\n\u2022 Basic statistical modelling knowledge\n\u2022 Strong Computer Science fundamentals are must. (Data structures, Algorithms, OS, Databases).\n\u2022 Good communication and organizational skills with significant attention to detail\n\u2022 Experience partnering with cross-functional teams of domain experts, engineers, data scientists, and production support teams.\n\u2022 Strong attention to detail with excellent problem-solving skills.\n\u2022 Desire and ability to thrive in a distributed technical environment while working on multiple projects simultaneously.\n\u2022 Passionate about latest technology trends with a strong desire for innovation.\n\u2022 Self-motivated, self-managing and able to work independently.\n\nEducation And Experience\n\u2022 Bachelor's degree (B.E/ B Tech. computer science, engineering, statistics/mathematics or a related field) from a four-year college or university, or equivalent, master\u2019s a plus.\n\u2022 Total at least 1 years of experience working on enterprise AI products\n\u2022 Experience in supporting software products or applications in the AI ML domain.\n\u2022 The above statements are intended to describe the general nature and level of work being performed by most people assigned to this job. They are not intended to be an exhaustive list of all duties and responsibilities and requirements.\n\nApplicants may be required to appear onsite at a Wolters Kluwer office as part of the recruitment process.",
    "url": "https://in.linkedin.com/jobs/view/data-scientist-python-genai-agenticai-at-wolters-kluwer-4319872554?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Scientist",
    "company": "Snowflake",
    "location": "Pune",
    "salary": "",
    "description": "Snowflake is about empowering enterprises to achieve their full potential \u2014 and people too. With a culture that\u2019s all in on impact, innovation, and collaboration, Snowflake is the sweet spot for building big, moving fast, and taking technology \u2014 and careers \u2014 to the next level.\n\nSnowflake is seeking a Data Scientist to join our expanding Enterprise AI & ML team. This role involves working on diverse AI/ML and data science initiatives, utilizing Snowflake's Data Cloud and Cortex AI. The successful candidate will design and develop scalable data science and machine learning solutions, build interactive AI applications, and collaborate on operationalizing intelligent systems to enhance data-driven decision-making throughout the company. This position focuses on applying data science, AI & ML skill sets to various domain specific business data problems across Snowflake.\n\nON THE ENTERPRISE AI & ML TEAM AT SNOWFLAKE, YOU WILL:\n\u2022 Design, prototype, and deploy data science and AI solutions.\n\u2022 Conduct end to end experimentation, including data exploration, feature engineering, model development, and validation.\n\u2022 Build and maintain Streamlit applications to visualize models, showcase insights, and enable business stakeholders to interact with AI driven solutions.\n\u2022 Develop and optimize LLM based applications, workflows, and operations; with a focus on retrieval, generation, semantic understanding and fine-tuning.\n\u2022 Partner cross functionally with data engineers, analysts, and product teams to translate ambiguous business problems into measurable outcomes.\n\nOUR IDEAL CANDIDATE WILL HAVE:\n\u2022 2 to 4 years of experience applying data science, machine learning, or AI techniques in real world business settings.\n\u2022 Strong programming skills in Python, proficiency in SQL for large scale data manipulation.\n\u2022 Familiarity with frameworks such as scikit-learn, XGBoost etc.\n\u2022 Understanding of LLM architectures, embeddings, vector search, and RAG pipelines.\n\u2022 Experience working on cloud platforms.\n\u2022 Strong analytical, storytelling, and communication skills to translate technical insights into actionable recommendations.\n\u2022 A mindset of curiosity, ownership, and collaboration, with an eagerness to work on open-ended problems.\n\u2022 Experience operationalizing AI & ML models in a production setting.\n\nSnowflake is growing fast, and we\u2019re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.\n\nHow do you want to make your impact?\n\nFor jobs located in the United States, please visit the job posting on the Snowflake Careers Site for salary and benefits information: careers.snowflake.com",
    "url": "https://careers.snowflake.com/us/en/job/SNCOUSE5563EEBE22F4F83ABADA6BD2B014860EXTERNALENUSF7C857F3DD284045B0C758E492307EC3/Data-Scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "Data Scientist  People Data Analytics & Insights",
    "company": "Syngenta",
    "location": "Pune",
    "salary": "",
    "description": "We are seeking a highly analytical and business-focused Data Scientist to join our People Analytics & Insights team. In this role, you will leverage advanced analytics, machine learning, and statistical modeling to uncover insights from workforce data, supporting strategic talent decisions across the organization. You will partner closely with HR, Talent Management, and business leaders to deliver data-driven solutions that enhance employee experience, improve workforce planning, and inform diversity, equity, and inclusion (DEI) strategies.\n\nKey Responsibilities:\n\u2022 Analyze large and complex HR datasets (e.g., engagement, attrition, performance, compensation, hiring) to uncover trends, patterns, and opportunities for business impact.\n\u2022 Build predictive and prescriptive models (e.g., attrition risk, career pathing, workforce segmentation) to support data-informed people strategies.\n\u2022 Translate business problems into analytical questions and communicate findings in clear, actionable terms to non-technical audiences.\n\u2022 Develop visualizations, dashboards, and storytelling tools to enhance insight delivery (e.g., in Tableau, Power BI, Workday Discovery Boards).\n\u2022 Partner with HR stakeholders to identify KPIs, define success metrics, and improve people-related decision-making through data.\n\u2022 Design and implement surveys, experiments (A/B testing), and causal inference models to evaluate the impact of HR programs and initiatives.\n\u2022 Ensure ethical data use and compliance with privacy and governance standards.\n\u2022 Stay current on industry best practices in people analytics, data science, and AI/ML in HR.\n\nCompany Description\n\nAt the Syngenta Group, our 56,000 people across more than 90 countries strive every day to transform agriculture through tailor-made solutions for the benefit of farmers, society and our planet \u2013 making us the world's most local agricultural technology and innovation partner.\n\nWebsite address - https://www.syngentagroup.com/\n\nLI page - https://www.linkedin.com/company/syngentagroup/posts/?feedView=all\n\nQualifications\n\u2022 Bachelor\u2019s or Master\u2019s degree in Data Science, Statistics, Computer Science, Industrial/Organizational Psychology, Economics, or a related field.\n\u2022 3\u20135+ years of experience in data science, analytics, or a similar role, ideally within HR or workforce analytics.\n\u2022 Proficiency in Python or R for statistical analysis and modeling.\n\u2022 Strong SQL skills for data extraction and manipulation.\n\u2022 Experience with data visualization tools (e.g., Tableau, Power BI, Workday Discovery Boards).\n\u2022 Solid understanding of machine learning algorithms, statistical modeling, and hypothesis testing.\n\u2022 Excellent communication skills, with the ability to explain complex analytical concepts to HR and business audiences.\n\u2022 Familiarity with Workday, SAP SuccessFactors, or other HRIS platforms is a plus.\n\nPreferred Skills:\n\u2022 Experience with natural language processing (NLP) on employee feedback or engagement data.\n\u2022 Knowledge of DEI analytics and workforce diversity measurement.\n\u2022 Exposure to cloud-based data platforms (e.g., AWS, GCP, Azure).\n\u2022 Understanding of HR functional areas like talent acquisition, performance management, and learning & development.\n\nKey Competencies:\n\u2022 Analytical Thinking & Problem Solving\n\u2022 Business Acumen & Strategic Mindset\n\u2022 Data Storytelling & Visualization\n\u2022 Collaboration & Stakeholder Management\n\u2022 Data Ethics & Privacy Awareness\n\nAdditional Information\n\nWL: 4A\n\nNote: Syngenta is an Equal Opportunity Employer and does not discriminate in recruitment, hiring, training, promotion or any other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, gender identity, marital or veteran status, disability, or any other legally protected status\n\nFollow us on: Twitter & LinkedIn\n\nhttps://twitter.com/SyngentaAPAC\n\nhttps://www.linkedin.com/company/syngenta/",
    "url": "https://jobs.syngenta.com/job/data-scientist-people-data-analytics-and-insights-in-in-pune-jid-14917?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Python Data Scientist / ML Engineer \u2013 Remote/Hybrid | AI, ML, Deep Learning | Only 4+ Years of Experience",
    "company": "Remotohire",
    "location": "Pune",
    "salary": "",
    "description": "Company: RemotoHire\n\nWork Mode: Remote / Hybrid\n\nExperience: 4\u20137 years\n\nAbout the Role:\n\nWe are hiring Python Data Scientists & ML Engineers to design and deploy intelligent systems, from predictive analytics to generative AI. You\u2019ll work with global clients on real-world AI/ML problems.\n\nKey Responsibilities:\n\u2022 Build ML models using scikit-learn, TensorFlow, PyTorch.\n\u2022 Work on NLP, Computer Vision, Generative AI, LLMs (GPT, LangChain).\n\u2022 Deploy ML pipelines on AWS SageMaker, Azure ML, GCP Vertex AI.\n\u2022 Handle data preprocessing, feature engineering, big data (Spark, Hadoop).\n\u2022 Optimize models for performance and scalability.\n\nRequired Skills:\n\u2022 Strong in Python, Pandas, NumPy, Matplotlib, Jupyter.\n\u2022 ML frameworks: scikit-learn, TensorFlow, PyTorch.\n\u2022 Cloud ML services: AWS, Azure, GCP.\n\u2022 Knowledge of MLOps, CI/CD for ML pipelines.\n\u2022 Bonus: Experience with AI Agents, RAG pipelines, and vector databases.\n\n\ud83d\udc49 Apply Now: https://www.oxcytech.com/developer-application\n\n\ud83d\udccc Note: While applying, please select \u201cPython Data Science / Machine Learning / AI\u201d from the Main dropdown.",
    "url": "https://in.linkedin.com/jobs/view/python-data-scientist-ml-engineer-%E2%80%93-remote-hybrid-ai-ml-deep-learning-only-4%2B-years-of-experience-at-remotohire-4331723103?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "(29 / 10 / 2025) Data Scientist",
    "company": "Tata Consultancy Services",
    "location": "Pune",
    "salary": "",
    "description": "Dear Candidate,\n\nGreetings from TATA Consultancy Services!!\n\nPosition- Data Scientist-Python\n\nExperience-4 to 8 years\n\nLocation- Chennai, Pune, Mumbai\n\nNotice Period- 0 to 60 days / Serving Notice Period\n\nKey Responsibilities :\n\u2022 Understand business process / business problems and device Machine Learning solutions to optimize business processes wherever possible.\n\u2022 Experience using statistical computer languages (Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\n\u2022 Formulating machine learning solutions to business metrics, designing features from the data available from many large data sources, training, evaluating, and deploying models in production\n\u2022 Developing high-performance algorithms for precision targeting, testing and implementing these algorithms in scalable, production-ready code; Interacting with other teams to define interfaces and understanding and resolving dependencies.\n\u2022 Developing coding in high-level languages such as R, Python, Java\n\u2022 Experience working with and creating data architectures.\n\u2022 Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages / drawbacks.\n\u2022 Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.\n\nNote : Note-Candidates who have previously worked at TCS not eligible to apply.\n\nOnly relevant experience candidates can apply.",
    "url": "https://in.talent.com/view?id=d99f903fffd8&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "\u25b7 Urgent! Data Scientist",
    "company": "Tata Consultancy Services",
    "location": "Pune",
    "salary": "",
    "description": "Dear Candidate,\n\nGreetings from TATA Consultancy Services!!\n\nPosition- Data Scientist-Python\n\nExperience-4 to 8 years\n\nLocation- Chennai, Pune, Mumbai\n\nNotice Period- 0 to 60 days / Serving Notice Period\n\nKey Responsibilities :\n\u2022 Understand business process / business problems and device Machine Learning solutions to optimize business processes wherever possible.\n\u2022 Experience using statistical computer languages (Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\n\u2022 Formulating machine learning solutions to business metrics, designing features from the data available from many large data sources, training, evaluating, and deploying models in production\n\u2022 Developing high-performance algorithms for precision targeting, testing and implementing these algorithms in scalable, production-ready code; Interacting with other teams to define interfaces and understanding and resolving dependencies.\n\u2022 Developing coding in high-level languages such as R, Python, Java\n\u2022 Experience working with and creating data architectures.\n\u2022 Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages / drawbacks.\n\u2022 Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.\n\nNote : Note-Candidates who have previously worked at TCS not eligible to apply.\n\nOnly relevant experience candidates can apply.",
    "url": "https://in.talent.com/view?id=820a7d06df0c&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Senior Data Scientist (Artificial Intelligence Machine Learning)",
    "company": "FIS Global",
    "location": "Pune",
    "salary": "",
    "description": "Position Type :\nFull time\n\nType Of Hire :\nExperienced (relevant combo of work and education)\n\nEducation Desired :\nBachelor of Engineering\n\nTravel Percentage :\n1 - 5%\n\nSenior Data Scientist (Artificial Intelligence Machine Learning)\n\nAre you curious, motivated, and forward-thinking? At FIS you\u2019ll have the opportunity to work on some of the most challenging and relevant issues in financial services and technology. Our talented people empower us, and we believe in being part of a team that is open, collaborative, entrepreneurial, passionate and above all fun.\n\nAbout the role:\n\u2022 We are looking for a talented and passionate Data Scientist willing to challenge themself and produce best in class AI enabled solution\n\u2022 You will be required to use the concepts of AIML, GenAI, LLMs, Sentiment analysis, etc.\n\u2022 The role requires creating correlation between different data points and do predictive, preventive analysis.\n\nAbout the Team :\n\nTeam provide solutions and services that help our clients grow, compete, and optimize their business. Our AIOPS team is creating AIML solution targeted to reduce the Enterprise MTTR through our world class product\n\nWhat you will be doing:\n\u2022 Employ machine learning and statistical modeling to create and enhance data driven products.\n\u2022 Analyze and extract insights from internal and external data.\n\u2022 Work with Big Data and transform complex datasets into more usable formats.\n\u2022 Work with a variety of data science tools and programming languages such as SAS, Python, R, Scala, SQL. Work independently and collaborate with other groups to solve complex problems.\n\u2022 Create and present analyses to internal and external partners and clients.\n\u2022 Will be working in 2 Pm to 11 Pm IST Shifts\n\nWhat you bring:\n\u2022 4 to 6 Years of machine learning, artificial intelligence, statistical modeling, data visualization, and data analysis\n\u2022 Proficient in data science tools and programming languages such as SAS, Python, R, Scala, SQL\n\u2022 Relevant degree in Artificial Intelligence Machine Learning\n\u2022 Experience or knowledge of cloud-based technology\n\u2022 Knowledge of financial services industry\n\nWhat we offer you:\n\u2022 A range of benefits designed to help support your lifestyle and wellbeing.\n\u2022 A multi-faceted job with a broad spectrum of responsibilities\n\u2022 A modern international work environment and a dedicated and innovative team\n\u2022 A broad range of professional education and personal development possibilities \u2013 FIS is your final career step.\n\nPrivacy Statement\n\nFIS is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how FIS protects personal information online, please see the Online Privacy Notice.\n\nSourcing Model\n\nRecruitment at FIS works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. FIS does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company.\n\n#pridepass",
    "url": "https://careers.fisglobal.com/us/en/job/FIGLUSJR0296204EXTERNAL/Senior-Data-Scientist-Artificial-Intelligence-Machine-Learning?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (Lead / Associate Architect) - 42146",
    "company": "Fission Labs",
    "location": "Pune",
    "salary": "",
    "description": "Role: Data Scientist (Lead / Associate Architect)\n\nExperience: 8+ years\n\nLocation: Hyderabad / Pune\n\nFission Labs, headquartered in Sunnyvale, with offices in Dallas & Hyderabad, Fission Labs is a leading software development company, specializing in crafting flexible, agile, and scalable solutions that propel businesses forward. With a comprehensive range of services, including product development, cloud engineering, big data analytics, QA, DevOps consulting, and AI/ML solutions, we empower clients to achieve sustainable digital transformation that aligns seamlessly with their business goals.\n\nWhat are we looking for!\n\nAs a Data Science professional at Fission Labs, you will be part of a high-impact team that designs and develops data-driven solutions for complex business challenges. You\u2019ll work on end-to-end AI and ML systems \u2014 from data exploration and model development to large-scale deployment and optimization in cloud environments.\n\nResponsibilities\n\u2022 Design and architect complex Generative AI solutions using AWS technologies.\n\u2022 Develop advanced AI architectures incorporating state-of-the-art GenAI technologies.\n\u2022 Create and implement Retrieval Augmented Generation (RAG) and GraphRAG solutions.\n\u2022 Architect scalable AI systems using AWS Bedrock and SageMaker.\n\u2022 Design and implement agentic AI systems with advanced reasoning capabilities.\n\u2022 Develop custom AI solutions leveraging vector databases and advanced machine learning techniques.\n\u2022 Evaluate and integrate emerging GenAI technologies and methodologies.\n\nTechnical Expertise Requirements\n\nGenerative AI Technologies\n\nExpert-level Understanding Of\n\u2022 Retrieval Augmented Generation (RAG)\n\u2022 GraphRAG methodologies\n\u2022 LoRA (Low-Rank Adaptation) techniques\n\u2022 Vector Database architectures\n\u2022 Agentic AI design principles\n\nAWS AI Services\n\nComprehensive Expertise In\n\u2022 AWS Bedrock\n\u2022 Amazon SageMaker\n\u2022 AWS AI/ML services ecosystem\n\u2022 Cloud-native AI solution design\n\nTechnical Skills\n\nAdvanced Python programming for AI/ML applications\n\nDeep Understanding Of\n\u2022 Large Language Models (LLMs)\n\u2022 Machine Learning architectures\n\u2022 Preferred Qualifications\n\u2022 AI model fine-tuning techniques\n\u2022 Prompt engineering\n\u2022 AI system design and integration\n\nCore Competencies\n\u2022 Advanced AI solution architecture\n\u2022 Machine learning model optimization\n\u2022 Cloud-native AI system design\n\u2022 Performance tuning of GenAI solutions\n\u2022 Enterprise AI strategy development\n\nTechnical Stack\n\u2022 Programming Languages: Python (required)\n\u2022 Cloud Platform: AWS\n\nAI Technologies\n\u2022 Bedrock\n\u2022 SageMaker\n\u2022 Vector Databases\n\nMachine Learning Frameworks\n\u2022 PyTorch\n\u2022 TensorFlow\n\u2022 Hugging Face\n\nAI Integration Tools\n\u2022 LangChain o LlamaIndex\n\nYou would enjoy\n\u2022 Opportunity to work on impactful technical challenges with global reach.\n\u2022 Vast opportunities for self-development, including online university access and knowledge sharing opportunities.\n\u2022 Sponsored Tech Talks & Hackathons to foster innovation and learning.\n\u2022 Generous benefits packages including health insurance, retirement benefits, flexible work hours, and more.\n\u2022 Supportive work environment with forums to explore passions beyond work.",
    "url": "https://in.linkedin.com/jobs/view/data-scientist-lead-associate-architect-42146-at-fission-labs-4333036595?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "\u25b7 Immediate Start : Manager, Data Science (Media / Market Research)",
    "company": "NielsenIQ",
    "location": "Pune",
    "salary": "",
    "description": "As a Data Science Manager you will have following key accountabilities :\n\nTeam Leadership : Build and lead a high-performing team of 6-8 Data Scientists and Machine Learning Engineers in our Pune hub. Foster a collaborative and inclusive team culture that encourages innovation and continuous learning.\n\nTechnical Communication : Explain Data Science principles, concepts, algorithms, and approaches in simple terms to diverse audiences, including non-technical stakeholders.\n\nBusiness Understanding : Utilize your solid business understanding to align with stakeholders, discuss requirements and feasibility, and manage expectations effectively. Ensure clear communication and understanding of project goals and outcomes.\n\nEducational Background :\n\nPhD or Master\u2019s degree in Computer Science, Engineering, Statistics, Mathematics, or a related field, with min 8+ years of experience as a Data Scientist.\n\nLeadership Experience :\n\nProven experience as a people manager and / or mentor, with a track record of developing and leading high-performing teams.\n\nLeadership Experience :\n\nProven experience as a people manager and / or mentor, with a track record of developing and leading high-performing teams\n\nCommunication Skills :\n\u2022 Ability to effectively communicate complex methodologies and technologies to both technical and non-technical audiences.\n\u2022 Strong problem-solving skills and an independent working style.\n\nTechnical Expertise :\n\u2022 Strong statistical and machine learning modeling skills, including statistical tests, classification, predictive modeling, handling of missing data, and sampling / weighting techniques.\n\u2022 Solid in analytical programming languages such as Python or R, along with their respective ecosystems.\n\u2022 Hands-on experience implementing these models in production systems.\n\u2022 Proficient in software development skills, including unit testing, CI / CD, and version control with Git, along with familiarity with computer science and engineering fundamentals such as data structures, software design principles, and testing strategies.\n\nPreferred qualifications\n\u2022 Experience in the Media industry\n\u2022 Experience working with cloud-based data services (AWS, Azure, or GCP)\n\u2022 Experience with Optimization techniques such as : linear programming, integer programming, genetic algorithms, constrained optimization is a plus",
    "url": "https://in.talent.com/view?id=c3e3e4ba1512&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "\u25b7 15h Left: Lead Data Scientist Gen Ai Pune",
    "company": "Yash Technologies",
    "location": "Pune",
    "salary": "",
    "description": "Job Overview:\n\nLocations- Indore/Pune/Hyderabad/Bangalore\n\nWe are looking for a AI/ML Developer to join our team of researchers, data scientists, and developers. You will work on cutting-edge AI solutions across industries such as commerce, agriculture, insurance, financial markets, and procurement. Your role involves developing and optimizing machine learning and generative AI models to solve real-world challenges.\n\nKey Responsibilities:\n\n\u2022 Develop and optimize ML, NLP, Deep Learning, and Generative AI models.\n\n\u2022 Research and implement state-of-the-art algorithms for supervised and unsupervised learning.\n\n\u2022 Work with large-scale datasets in distributed environments.\n\n\u2022 Understand business processes to select and apply the best ML approaches.\n\n\u2022 Ensure scalability and performance of ML solutions.\n\n\u2022 Collaborate with cross-functional teams, including product owners, designers, and developers.\n\n\u2022 Solve complex data integration and deployment challenges.\n\n\u2022 Communicate results effectively using data visualization.\n\n\u2022 Work in global teams across different time zones.\n\nRequired Skills & Experience:\n\n\u2022 Robust experience in Machine Learning, Deep Learning, NLP, and Generative AI.\n\n\u2022 Hands-on expertise in frameworks like TensorFlow, PyTorch, or Hugging Face Transformers.\n\n\u2022 Experience with LLMs (Large Language Models), model fine-tuning, and prompt engineering.\n\n\u2022 Proficiency in Python, R, or Scala for ML development.\n\n\u2022 Knowledge of cloud-based ML platforms (AWS, Azure, GCP).\n\n\u2022 Experience with big data processing (Spark, Hadoop, or Dask).\n\n\u2022 Ability to scale ML models from prototypes to production.\n\n\u2022 Solid analytical and problem-solving skills.\n\nIf you\u2019re passionate about pushing the boundaries of ML and GenAI, we\u2019d love to hear from you!",
    "url": "https://in.jobrapido.com/jobpreview/8719491990573547520?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Machine Learning Engineer (MLE) \u2013 Python | DS | DE | ETL | Azure | Databricks",
    "company": "Apptware",
    "location": "Pune",
    "salary": "",
    "description": "Job description\n\nPosition: Machine Learning Engineer (MLE) \u2013 Python | DS | DE | ETL | Azure | Databricks\n\n\ud83d\udd39 Experience: 4\u20138 years\n\n\ud83d\udd39 Location: Pune / Bangalore\n\n\ud83d\udd39 Employment Type: Full-time\n\nJob Description:\n\nWe are seeking an experienced Machine Learning Engineer (MLE) with strong expertise in Python, Data Science (DS), Data Engineering (DE), ETL, and Azure Databricks. The ideal candidate will design, build, and deploy scalable ML solutions while collaborating with data and engineering teams to solve complex business challenges.\n\nKey Responsibilities:\n\u2022 Design and implement end-to-end ML pipelines using Databricks and Azure.\n\u2022 Develop, train, and deploy machine learning models for various business use cases.\n\u2022 Perform data preprocessing, feature engineering, and model optimization on large datasets.\n\u2022 Integrate ML models with production systems and ensure performance monitoring.\n\u2022 Collaborate with cross-functional teams to understand business needs and deliver effective ML solutions.\n\u2022 Stay updated with the latest trends in ML, DL, and AI frameworks.\n\nRequired Skills:\n\u2022 Python (Advanced) \u2013 Must\n\u2022 Data Science (DS), Data Engineering (DE), and ETL \u2013 Must\n\u2022 Machine Learning (ML) \u2013 Must\n\u2022 Deep Learning (Basic Understanding) \u2013 Good to have\n\u2022 Natural Language Processing (NLP) \u2013 Basic Understanding\n\u2022 Computer Vision \u2013 Basic Understanding\n\u2022 Python for Image Processing \u2013 Basic Understanding\n\u2022 ML Frameworks (TensorFlow / PyTorch / Scikit-learn) \u2013 Must\n\u2022 Azure Cloud \u2013 Must\n\u2022 Databricks \u2013 Must\n\nGood to Have:\n\u2022 Experience with Agile Methodology\n\u2022 Exposure to MLOps and CI/CD pipelines\n\u2022 Familiarity with data visualization tools like Power BI or Tableau\n\nAdditional Details:\n\u2022 Immediate joiners preferred\n\u2022 Candidates with up to 30 days\u2019 notice period can be considered\n\nApply Here: https://forms.gle/PNgXBb3QJh57Uqd79",
    "url": "https://in.linkedin.com/jobs/view/machine-learning-engineer-mle-%E2%80%93-python-ds-de-etl-azure-databricks-at-apptware-4331708651?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "AI/ML Engineer-Automotive",
    "company": "Quest Global",
    "location": "Pune",
    "salary": "",
    "description": "Job Requirements\n\nWe are looking for an experienced AI/ML Engineer to design, develop and deploy machine learning algorithms on embedded platforms for the next generation automotive infotainment systems. This engineer will work on Android / Linux based applications that will process various sensor data and external input at real-time to predict various vehicle conditions and adjust vehicle operations accordingly.\n\nRoles & Responsibilities\n\u2022 Design, train, and optimize AI/ML models for real-time, edge-based deployment.\n\u2022 Work with multi-modal data sources (audio, vision, sensor, telematics) to build robust AI systems.\n\u2022 Develop end-to-end pipelines for data preprocessing, model training, evaluation, and deployment.\n\u2022 Implement algorithms optimized for embedded and resource-constrained platforms\n\u2022 Validate AI models with real-world automotive sensor datasets\n\u2022 Perform model optimization (quantization, pruning) for deployment on embedded SoCs\n\u2022 Collaborate with system architects, Application developers, and automotive domain experts to ensure end-to-end functionality\n\u2022 Stay up to date with AI/ML advancements and automotive industry trends\n\nWork Experience\n\nRequired Skills (Technical Competency):\n\u2022 4\u20135 years of proven development experience in AI/ML for embedded device\n\u2022 Strong expertise in deep learning frameworks (TensorFlow, PyTorch, ONNX).\n\u2022 Practical experience with edge/embedded AI (NVIDIA Jetson, Qualcomm, ARM).\n\u2022 Proficiency in NLP / Conversational AI / Speech interfaces ( ASR, TTS )\n\u2022 Solid programming skills in Python and C++/Java for optimization and integration.\n\u2022 Solid understanding of application development in embedded Linux / Android\n\u2022 Familiarity with automotive standards, protocols such as CAN\n\u2022 Good communication skills and great team spirit\n\nDesired Skills\n\u2022 Experience working with embedded Linux, Automotive Android\n\u2022 Knowledge of vehicle data interfaces (CAN, OBD-II, sensors).\n\u2022 Exposure to MLOps pipelines and cloud platforms (AWS/GCP/Azure).",
    "url": "https://in.linkedin.com/jobs/view/ai-ml-engineer-automotive-at-quest-global-4319585096?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "ML Engineer (CB35FT RM 3693)",
    "company": "Source-right",
    "location": "Pune",
    "salary": "",
    "description": "Position: ML Engineer (CB35FT RM 3693)\n\nWork mode : Work From Office\n\nKey Responsibilities\n\nDesign, develop, and maintain data pipelines for large-scale structured and unstructured\n\ndatasets\n\nApply ML/DL techniques for:\n\nCustomer segmentation\n\nAnomaly detection\n\nSales forecasting and pattern analysis\n\nRecommendation engines\n\nFine-tune and deploy machine learning models in production using best practices\n\nDesign, prompt, and integrate LLM-based modules for tasks like summarization, Q&A, and\n\ncode generation\n\nWork on multi-modal LLM tasks involving text, image (CV), and speech (ASR/TTS)\n\nDevelop and expose ML APIs using FastAPI/Docker for integration with other systems\n\nMonitor model performance and retrain/update models as required\n\nCollaborate with frontend/backend developers, data teams, and product managers\n\nRequired Skills & Experience\n\n3\u20135 years of hands-on experience in ML/Data Science/Data Engineering roles\n\nMin 2 years hands on experience in Microsoft SQL (T-SQL) Coding, SPOC, Complex SQL Joins,\n\nData Modelling\n\nProficient in Python, including libraries like pandas, scikit-learn, PyTorch or TensorFlow\n\nExperience in deploying ML models using FastAPI, Docker, and CI/CD pipelines\n\nSolid understanding of data preprocessing, ETL, and feature engineering\n\nExperience with deep learning and LLMs (e.g., OpenAI, HuggingFace, LLaMA, etc.)\n\nPractical experience with prompt engineering and LLM fine-tuning\n\nFamiliarity with multi-modal learning, Computer Vision (e.g., OpenCV, YOLO, CLIP), and Speech\n\nAI (e.g., Whisper, TTS engines)\n\nStrong understanding of ML lifecycle: training, evaluation, monitoring, deployment\n\nExperience with cloud platforms (Azure) is a plus\n\nAbility to write clean, modular, production-grade code\n\u2022 ******************************************************************************************************************************************\n\nJob Category: Others\n\nJob Type: Full Time\n\nJob Location: Pune\n\nExperience: 3 - 5 years\n\nNotice period: 0-30 days",
    "url": "https://www.glassdoor.co.in/job-listing/ml-engineer-cb35ft-rm-3693-source-right-JV_IC2856202_KO0,26_KE27,39.htm?jl=1009926843012&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "\u25b7 High Salary! Machine Learning Strategist",
    "company": "Cybage Software",
    "location": "Pune",
    "salary": "",
    "description": "Role Overview\n\nCybage is seeking a Practice Head for Machine Learning Systems to lead our AI / ML capability within the CDAI business unit. This is a strategic leadership role that blends deep technical expertise in applied ML systems with practice-building, client consulting, and outcome-based delivery experience.\n\nThe role requires someone who has built and scaled ML engineering practices in IT services or consulting environments, is able to guide solutioning at a technical level, and can also engage clients in executive workshops to define AI adoption roadmaps.\n\nKey Responsibilities\n\nPractice Leadership\n\u2022 Define the vision and roadmap for Cybage\u2019s Machine Learning Systems practice, aligned with industry trends and client priorities.\n\u2022 Build offerings and frameworks across ML model development, deployment, MLOps, generative AI, and responsible AI governance.\n\u2022 Develop accelerators, reference architectures, and reusable assets to differentiate Cybage in the market.\n\nClient Consulting & Business Growth\n\u2022 Lead consultative workshops with client executives to co-create ML / AI strategies, adoption roadmaps, and use-case portfolios.\n\u2022 Partner with sales and account teams to drive presales solutioning, proposal creation, and thought leadership.\n\u2022 Position Cybage as a strategic partner for ML-driven transformations that are measurable and outcome-driven.\n\nDelivery Excellence\n\u2022 Oversee delivery of ML programs spanning PoCs, pilots, and scaled deployments across industries.\n\u2022 Ensure robust MLOps and governance practices for model lifecycle management, monitoring, retraining, and compliance.\n\u2022 Provide architectural and technical guidance on ML stacks (e.g., TensorFlow, PyTorch, Hugging Face, MLflow, AWS Sagemaker, Azure ML, GCP Vertex AI, Databricks ML).\n\u2022 Drive service-based and outcome-based engagement models, ensuring predictability and value delivery.\n\nTeam & Capability Building\n\u2022 Build and mentor a high-performing team of ML engineers, data scientists, and solution architects.\n\u2022 Develop future leaders with consulting and solutioning depth, not just technical skill.\n\u2022 Foster collaboration across adjacent practices (Big Data, Cloud, Platform Engineering) to deliver end-to-end AI solutions.\n\nQualifications\n\nExperience\n\u2022 15+ years in IT services or consulting, with 7+ years in ML / AI leadership or architecture roles.\n\u2022 Proven ability to establish or grow an ML / AI practice, including team building, offering development, and client engagement.\n\u2022 Experience with end-to-end ML lifecycle : data prep, feature engineering, model training, evaluation, deployment, monitoring.\n\u2022 Exposure to service delivery models (consulting, managed services, outcome-based).\n\u2022 Strong background in applied ML use cases (forecasting, personalization, anomaly detection, NLP, computer vision, GenAI).\n\nSkills & Competencies\n\u2022 Technical bent : ability to deep-dive into ML architectures, pipelines, and MLOps practices.\n\u2022 Strategic mindset : connect ML initiatives to tangible business outcomes.\n\u2022 Leadership : experience in building practices and leading distributed teams (does not need to be at massive scale).\n\u2022 Client-facing presence : ability to run workshops, advise senior stakeholders, and simplify complex ML topics.\n\u2022 Knowledge of AI governance, ethics, and compliance (responsible AI, data privacy, bias mitigation).",
    "url": "https://in.talent.com/view?id=d678702da2f2&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-03T00:00:00.000Z"
  },
  {
    "title": "Python Data Scientist / ML Engineer \u2013 Remote/Hybrid | AI, ML, Deep Learning | Only 4+ Years of Experience",
    "company": "Remotohire",
    "location": "Pune",
    "salary": "",
    "description": "Company: RemotoHire\n\nWork Mode: Remote / Hybrid\n\nExperience: 4\u20137 years\n\nAbout the Role:\n\nWe are hiring Python Data Scientists & ML Engineers to design and deploy intelligent systems, from predictive analytics to generative AI. You\u2019ll work with global clients on real-world AI/ML problems.\n\nKey Responsibilities:\n\u2022 Build ML models using scikit-learn, TensorFlow, PyTorch.\n\u2022 Work on NLP, Computer Vision, Generative AI, LLMs (GPT, LangChain).\n\u2022 Deploy ML pipelines on AWS SageMaker, Azure ML, GCP Vertex AI.\n\u2022 Handle data preprocessing, feature engineering, big data (Spark, Hadoop).\n\u2022 Optimize models for performance and scalability.\n\nRequired Skills:\n\u2022 Strong in Python, Pandas, NumPy, Matplotlib, Jupyter.\n\u2022 ML frameworks: scikit-learn, TensorFlow, PyTorch.\n\u2022 Cloud ML services: AWS, Azure, GCP.\n\u2022 Knowledge of MLOps, CI/CD for ML pipelines.\n\u2022 Bonus: Experience with AI Agents, RAG pipelines, and vector databases.\n\n\ud83d\udc49 Apply Now: https://www.oxcytech.com/developer-application\n\n\ud83d\udccc Note: While applying, please select \u201cPython Data Science / Machine Learning / AI\u201d from the Main dropdown.",
    "url": "https://in.linkedin.com/jobs/view/python-data-scientist-ml-engineer-%E2%80%93-remote-hybrid-ai-ml-deep-learning-only-4%2B-years-of-experience-at-remotohire-4331723103?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Immediate Start! Generative AI Engineer (Pune)",
    "company": "Synechron",
    "location": "Pune",
    "salary": "",
    "description": "Greetings,\n\nWe have immediate opportunity for AI/ML Engineer \u2013 7 to 10 years\n\nSynechron\u2013 Pune, Hinjewadi\n\nJob Role: AI/ML Engineer\n\nJob Location: Pune, Hinjewadi\n\nAbout Company:\n\nAt Synechron, we believe in the power of digital to transform businesses for the better. Our global consulting firm combines creativity and innovative technology to deliver industry-leading digital solutions. Synechron's progressive technologies and optimization strategies span end-to-end Artificial Intelligence, Consulting, Digital, Cloud & DevOps, Data, and Software Engineering, servicing an array of noteworthy financial services and technology firms. Through research and development initiatives in our FinLabs we develop solutions for modernization, from Artificial Intelligence and Blockchain to Data Science models, Digital Underwriting, mobile-first applications and more. Over the last 20+ years, our company has been honoured with multiple employer awards, recognizing our commitment to our talented teams. With top clients to boast about, Synechron has a global workforce of 14,700+, and has 48 offices in 19 countries within key global markets. For more information on the company, please visit our website or LinkedIn community.\n\nDiversity, Equity, and Inclusion\n\nDiversity & Inclusion are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and an affirmative-action employer. Our Diversity, Equity, and Inclusion (DEI) initiative 'Same Difference' is committed to fostering an inclusive culture \u2013 promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We encourage applicants from across diverse backgrounds, race, ethnicities, religion, age, marital status, gender, sexual orientations, or disabilities to apply. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs, and more.\n\nAll employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant's gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.\n\nJob Description:\n\nWe are seeking a highly skilled AI/ML and GenAI Engineer for around 8-10 yrs with proven experience in designing, developing, and deploying sophisticated AI and NLP solutions. The ideal candidate will have hands-on expertise with large language models (LLMs), foundation models (FMs), and generative AI (GenAI). You will work on building end-to-end AI applications from scratch, transforming monolithic systems into scalable microservices, and integrating with cloud-based AI platforms like Azure, Amazon Bedrock, Gemini, and others.\n\nKey Responsibilities:\n\n- Design, develop, and optimize NLP models, including Large Language Models (LLMs) and Foundation Models (FMs).\n- Lead large data processing pipelines for training, fine-tuning, and deploying models on big data platforms.\n- Architect, build, and maintain scalable AI solutions incorporating MLOps best practices.\n- Transition legacy monolithic architectures into microservices-based systems for improved scalability and maintainability.\n- Build end-to-end AI applications from scratch, including model training, deployment, and integration.\n- Implement and optimize Retrieval-Augmented Generation (RAG) processes for enhanced contextual understanding.\n- Conduct thorough testing, validation, and debugging of AI/ML applications and pipelines.\n- Integrate AI solutions with cloud platforms such as Azure, Amazon Bedrock, Google Gemini, and other emerging frameworks.\n- Develop and maintain flexible, production-ready solutions supporting real-time and batch processing.\n- Collaborate with cross-functional teams to embed AI capabilities into customer-facing products and enterprise solutions.\n\nQualifications & Skills:\n\n- Proven experience in NLP, including transformer-based models, LLMs, and FMs.\n- Understanding of AI/MLOps workflows, CI/CD pipelines, model deployment, and monitoring.\n- Strong background in transforming monolithic architectures into microservices.\n- Experience with building AI applications from scratch, including model training and integrating with GenAI LLMs, tuning, and testing.\n- Expertise in testing/debugging AI applications, pipelines, and data workflows.\n- Practical knowledge of Retrieval-Augmented Generation (RAG) techniques.\n- Familiarity with GenAI, prompt engineering, and interaction with cloud AI platforms like Azure AI, Amazon Bedrock, Google Gemini.\n- Experience with integrating multiple LLM models and APIs for seamless application workflows.\n- Strong programming skills in Python and various AI coding libraries and frameworks.\n- Knowledge of containerization (Docker, Kubernetes) and cloud deployment.\n- Excellent problem-solving, debugging, and communication skills.\n\nQUALIFICATION:\n\nBachelor's or Master's degree in Computer Science, Engineering, or a related field\n\nIf you find this this prospect interesting kindly share your updated profile on bansi.hindocha@synechron.com\n\nWith below details (Mandatory)\n\nTotal Experience\n\nExperience in AI/ML-\n\nCurrent CTC-\n\nExpected CTC-\n\nNotice period-\n\nCurrent Location-\n\nReady to relocate to Pune-\n\nIf you had gone through any interviews in Synechron before? If Yes when\n\nRegards,\n\nBansi Hindocha\n\nbansi.hindocha@synechron.com",
    "url": "https://in.jobrapido.com/jobpreview/7637519772283830272?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "ML Engineer-AI Engineer-Machine Learning",
    "company": "EXL Talent Acquisition Team",
    "location": "Pune",
    "salary": "",
    "description": "We are seeking a skilled MLFlow 3 Engineer to join our Data & AI Engineering team. The ideal candidate will have hands-on experience in managing the end-to-end lifecycle of machine learning models using MLFlow 3.x, along with expertise in Python, Databricks, PySpark, and Azure. The role is a cusp between ML Engineering and MLOPs. You will work closely with data scientists, ML engineers, and DevOps teams to operationalize ML workflows, ensuring scalability, reliability, and compliance.",
    "url": "https://fa-ewjt-saasfaprod1.fa.ocs.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_2/job/5968/?source=jdpreferred.comutm_medium&utm_source=google&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "DevOps Engineer (with AI/ML) - 41778",
    "company": "Fission Labs",
    "location": "Pune",
    "salary": "",
    "description": "Role: DevOps Engineer (With AI/ML)\n\nExperience: 5+ years\n\nLocation: Hyderabad\n\nFission Labs, headquartered in Sunnyvale, with offices in Dallas & Hyderabad, Fission Labs is a leading software development company, specializing in crafting flexible, agile, and scalable solutions that propel businesses forward. With a comprehensive range of services, including product development, cloud engineering, big data analytics, QA, DevOps consulting, and AI/ML solutions, we empower clients to achieve sustainable digital transformation that aligns seamlessly with their business goals.\n\nWhat are we looking for!\n\nWe are seeking an experienced Senior Infrastructure Mgmt. Engineer with expertise in Azure and AWS, coupled with a strong background in AI/ML deployments. The ideal candidate will have a proven track record in designing, implementing, and maintaining scalable and secure cloud infrastructure on Azure and AWS platforms. Experience with GCP is a plus. The primary responsibility will be to lead the DevOps initiatives and ensure compliance with industry standards and regulations.\n\nResponsibilities\n\nLinux Expertise:\n\u2022 Possess in-depth knowledge of Linux operating systems, including CentOS, Ubuntu, and Red Hat, with expertise in shell scripting, package management, and system administration.\n\u2022 Configure and optimize Linux-based servers for performance, security, and resource utilization, including kernel tuning, file system management, and network configuration.\n\nCloud Expertise (AWS/Azure)\n\u2022 Demonstrate hands-on experience with a wide range of AWS and Azure services, including but not limited to EC2, S3, Lambda, RDS, Azure VMs, Azure Blob Storage, Azure Functions, etc.\n\u2022 Architect cloud solutions leveraging best practices and services offered by AWS and Azure, optimizing for scalability, reliability, and cost-effectiveness.\n\u2022 Implement and manage hybrid cloud environments, facilitating seamless integration and interoperability between AWS and Azure services.\n\nInfrastructure As Code (IAC)\n\u2022 Develop and maintain Infrastructure as Code (IAC) templates using tools such as Terraform or AWS CloudFormation, defining infrastructure components as code for automated provisioning and configuration.\n\u2022 Establish version control practices for IAC templates, ensuring traceability, auditability, and reproducibility of infrastructure changes.\n\nAI/ML Infrastructure Mgmt\n\u2022 Experience setting up cloud infrastructure stack, databases, service endpoints, GPU as well as CPU resource scaling, optimization etc.\n\u2022 Should have worked AIOps/MLOP\n\u2022 Should have worked on deploying AI/ML Apps using Docker and Kubernetes\n\u2022 Should have worked on scaling, high availability and reliability tasks for AI application\n\u2022 Should have worked on deploying and maintaining GPU clusters for AI/ML training and inference\n\nQualifications\n\u2022 6+ years of experience in Infrastructure Mgmt. roles, with a focus on cloud platforms (Azure and AWS Preferred).\n\u2022 Hands-on experience with operations (DevSecOps) principles and best practices.\n\u2022 Proficiency in scripting languages such as Python, PowerShell, or Bash.\n\u2022 Excellent communication and collaboration skills.\n\u2022 Certifications such as AWS Solution Architect Associate, AWS Cloud Practitioner, Azure DevOps Engineer Expert, Azure Administrator\n\u2022 Certified Kubernetes Administrator or relevant industry certifications are a plus.\n\nYou would enjoy\n\u2022 Opportunity to work on impactful technical challenges with global reach.\n\u2022 Vast opportunities for self-development, including online university access and knowledge sharing opportunities.\n\u2022 Sponsored Tech Talks & Hackathons to foster innovation and learning.\n\u2022 Generous benefits packages including health insurance, retirement benefits, flexible work hours, and more.\n\u2022 Supportive work environment with forums to explore passions beyond work.\n\nThis role presents a unique opportunity to contribute to the future of impactful business solutions while advancing your career in a collaborative and innovative environment.",
    "url": "https://in.linkedin.com/jobs/view/devops-engineer-with-ai-ml-41778-at-fission-labs-4333145831?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "AI/ML Platform Engineer",
    "company": "Johnson Controls",
    "location": "Pimpri-Chinchwad",
    "salary": "",
    "description": "Job Title: Senior Data Scientist \u2013 Data & Analytics\n\nJohnson Controls International (JCI) is seeking a Senior Data Scientist to join our innovative and impact-driven Data Science and Analytics team. This role is ideal for a seasoned expert with a deep understanding of machine learning, AI, and cloud data platforms, and a strong grasp of the latest advancements in Generative AI and Large Language Models (LLMs).\n\nAs a Senior Data Scientist, you will lead the development and deployment of scalable AI solutions\u2014including those powered by LLMs\u2014to accelerate digital transformation across our products, operations, and customer experiences. You'll play a critical role in shaping JCI\u2019s data science strategy, mentoring teams, and driving the use of AI to deliver measurable business value.\n\nHow You Will Do It\n\nAdvanced Analytics, LLMs & Modeling\n\u2022 Design and implement advanced machine learning models including deep learning, time-series forecasting, recommendation engines, and LLM-based solutions (e.g., GPT, LLaMA, Claude).\n\u2022 Develop use cases around enterprise search, document summarization, conversational AI, and automated knowledge retrieval using large language models.\n\u2022 Fine-tune or prompt-engineer foundation models (e.g., OpenAI, Azure OpenAI, Hugging Face) for domain-specific applications.\n\u2022 Evaluate and optimize LLM performance, latency, cost-effectiveness, and hallucination mitigation strategies for production use.\n\nData Strategy & Engineering Collaboration\n\u2022 Work closely with data and ML engineering teams to integrate LLM-powered applications into scalable, secure, and reliable pipelines.\n\u2022 Contribute to the development of retrieval-augmented generation (RAG) architectures using vector databases (e.g., FAISS, Azure Cognitive Search).\n\u2022 Support the deployment of models using MLOps principles, ensuring robust monitoring and lifecycle management.\n\nBusiness Impact & AI Strategy\n\u2022 Partner with cross-functional stakeholders to identify opportunities for applying LLMs and generative AI to solve complex business challenges.\n\u2022 Lead workshops or proofs-of-concept to demonstrate value of LLM use cases across business units.\n\u2022 Translate complex model outputs, including those from LLMs, into clear insights and decision support tools for non-technical audiences.\n\nThought Leadership & Mentorship\n\u2022 Act as an internal thought leader on AI and LLM innovation, keeping JCI at the forefront of industry advancements.\n\u2022 Mentor and upskill data science team members in advanced AI techniques, including transformer models and generative AI frameworks.\n\u2022 Contribute to strategic roadmaps for generative AI and model governance within the enterprise.\n\nQualifications & Experience\n\u2022 Education in Data Science, Artificial Intelligence, Computer Science, or related quantitative discipline.\n\u2022 5+ years of hands-on experience in data science, including at least 1\u20132 years working with LLMs or generative AI technologies.\n\u2022 Demonstrated success in deploying machine learning and NLP solutions at scale.\n\u2022 Proven experience with cloud AI platforms\u2014especially Azure OpenAI, Azure ML, Hugging Face, or AWS Bedrock.\n\nTechnical Expertise\n\u2022 Proficiency in Python and SQL, including libraries like Transformers (Hugging Face), LangChain, PyTorch, and TensorFlow.\n\u2022 Experience with prompt engineering, fine-tuning, and LLM orchestration tools.\n\u2022 Familiarity with data storage, retrieval systems, and vector databases.\n\u2022 Strong understanding of model evaluation techniques for generative AI, including factuality, relevance, and toxicity metrics.\n\nLeadership & Soft Skills\n\u2022 Strategic thinker with a strong ability to align AI initiatives to business goals.\n\u2022 Excellent communication and storytelling skills, especially in articulating the value of LLMs and advanced analytics.\n\u2022 Strong collaborator with a track record of influencing stakeholders across product, engineering, and executive teams.\n\nPreferred Qualifications\n\u2022 Experience with IoT, edge analytics, or smart building systems.\n\u2022 Familiarity with LLMOps, LangChain, Semantic Kernel, or similar orchestration frameworks.\n\u2022 Knowledge of data privacy and governance considerations specific to LLM usage in enterprise environments.",
    "url": "https://in.linkedin.com/jobs/view/ai-ml-platform-engineer-at-johnson-controls-4324739939?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Ai/ Ml Engineer Pune",
    "company": "Sava Healthcare",
    "location": "Pune",
    "salary": "",
    "description": "Key Responsibilities:\nDesign, build, and deploy AI/ML models for real-world business and manufacturing problems (e.g., predictive maintenance, process optimization, document automation, etc.).\nDevelop end-to-end AI web applications (backend + frontend) using frameworks like Flask, FastAPI, or Django for backend and React, Angular, or Vue for frontend.\nImplement and maintain data pipelines for model training and prediction.\nIntegrate trained models into scalable and user-friendly web interfaces.\nHost, monitor, and maintain AI applications on cloud or on-premise web servers (AWS, Azure, Google Cloud, or companys internal servers).\nCollaborate with IT, QA, and process teams to identify automation and AI opportunities.\nEnsure application security, reliability, and performance optimization.\nDocument model architecture, APIs, and deployment procedures.\n\nRequired Skills & Qualifications:\nBachelor\u2019s or Master\u2019s degree in Computer Science, Data Science, Artificial Intelligence, or related field.\nProven experience in AI/ML development and deployment.\nRobust programming skills in Python (TensorFlow, PyTorch, scikit-learn, OpenCV, etc.).\nProficiency in web frameworks (Flask, Django, FastAPI) and frontend technologies (HTML, CSS, JavaScript, React/Angular preferred).\nExperience in model deployment (Docker, REST API, Flask/FastAPI endpoints).\nFamiliarity with cloud platforms (AWS, Azure, or Google Cloud) and web hosting environments.\nKnowledge of database systems (MySQL, PostgreSQL, MongoDB).\nUnderstanding of version control (Git/GitHub) and CI/CD pipelines.\nRobust analytical thinking, problem-solving, and communication skills.",
    "url": "https://in.jobrapido.com/jobpreview/1449940021648818176?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "\u25b7 High Salary : Generative AI Engineer",
    "company": "Talent Corner HR Services Pvt Ltd",
    "location": "Pune",
    "salary": "",
    "description": "Experience Required : 4-6 Years\n\nJob Summary :\n\u2022 Proven experience in content management, data architecture, and AI\n\u2022 technologies\n\u2022 Design content structures that optimize the usability and retrieval of data by\n\u2022 LLMs and RAG systems.\n\u2022 Strong understanding of LLMs and RAG systems and their application in\n\u2022 business contexts.\n\u2022 Problem-solving skills with a proactive approach to identifying and addressing\n\u2022 challenges.\n\u2022 Design and maintain a robust data architecture that supports efficient content\n\u2022 retrieval and generation.\n\u2022 Ensure content is optimized for AI consumption, including proper formatting,\n\u2022 tagging, and metadata application.\n\u2022 Experience in JIRA, Confluence, Bit Bucket, Azure Repo etc.\n\u2022 Strong Computer Science fundamentals in object-oriented design, data\n\u2022 structures, design patterns and algorithm design.\n\u2022 Strong debug and troubleshooting skills.\n\u2022 Aware of CI / CD techniques and tools like Azure Pipeline.\n\nWhat do we expect from you?\n\u2022 Bachelor\u2019s or Master\u2019s degree in Computer Science, Information Technology, or a related field.\n\u2022 Proven experience in building Azure Cloud solutions.\n\u2022 Experience with content management systems (CMS) and data management tools.\n\u2022 Familiarity with AI / ML frameworks and libraries.\n\u2022 Knowledge of global content standards and regional data regulations.\n\u2022 Familiarity with CI / CD pipelines and version control systems such as Git.\n\u2022 Strong debug and troubleshooting skills.\n\u2022 Effective oral and written communication skills; ability to articulate clearly and concisely.\n\u2022 You have worked with Agile Methodologies following SCRUM.\n\nQualifications :\n\u2022 4 to 6 years of strong hands-on experience in Python programming\n\u2022 Minimum 2 years of experience working with AI tools and technologies\n\u2022 At least 1 year of experience as a Generative AI Content Architect\n\u2022 Successfully delivered 2\u20133 AI implementation projects or use cases\n\u2022 Solid understanding of AI solution implementation, including data architect and content management.",
    "url": "https://in.talent.com/view?id=bf7d30325688&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Data Scientist/Machine Learning Engineer Assistant vice president",
    "company": "Early Career",
    "location": "Pune",
    "salary": "",
    "description": "ML Solutions team within Markets OPS Technology is dedicated to developing solutions using Artificial Intelligence, Machine Learning and Generative AI. This team is a leader in creating new ideas, innovative technology solutions, and ground-breaking solutions for Markets Operations and Other Line of Businesses. We work closely with our clients and business partners to progress solutions from ideation to production by leveraging the entrepreneurial spirit and technological excellence.\n\nJob Description:\n\nThe ML Solutions team is seeking a Data Scientist/Machine Learning Engineer to drive the design, development, and deployment of innovative AI/ML and GenAI-based solutions. In this hands-on role, you will leverage your expertise to create a variety of AI models, guiding a team from initial concept to successful production. A key aspect involves mentoring team members and fostering their growth. You will collaborate closely with business partners and stakeholders, championing the adoption of these advanced technologies to enhance client experiences, deliver tangible value to our customers, and ensure adherence to regulatory requirements through cutting-edge technical solutions. This position offers a unique opportunity to shape the future of our AI initiatives and make a significant impact on the organization.\n\nKey Responsibilities:\n\u2022 Hands-On Execution and Delivery: Actively contribute to the development and delivery of AI solutions, driving innovation and excellence within the team. Take a hands-on approach to ensure AI models are successfully deployed into production environments, meeting high-quality standards and performance benchmarks.\n\u2022 Mentoring Young Talents: Mentoring team, guiding data analysts/ML engineers from concept to production. This involves fostering technical growth, providing project oversight, and ensuring adherence to best practices, ultimately building a high-performing and innovative team.\n\u2022 Quality Control: Ensure the quality and performance of generative AI models, conducting rigorous testing and evaluation.\n\u2022 Research and Development: Participate in research activities to explore and advance state-of-the-art generative AI techniques. Stay actively engaged in monitoring ongoing research efforts, keeping abreast of emerging trends, and ensuring that the Generative AI team remains at the forefront of the field.\n\u2022 Cross-Functional Collaboration: Collaborate effectively with various teams, including product managers, engineers, and data scientists, to integrate AI technologies into products and services.\n\nSkills & Qualifications:\n\u2022 8 to 13 years of Strong hands-on experience in Machine Learning, delivering complex solutions to production.\n\u2022 Experience with Generative AI technologies essential.\n\u2022 Understanding of concepts like supervised, unsupervised, clustering, embedding.\n\u2022 Knowledge of NLP, Name Entity Recognition, Computer Vision, Transformers, Large Language Models.\n\u2022 In-depth knowledge of deep learning and Generative AI frameworks such as, Langchain, Lang Graph, Crew AI or similar.\n\u2022 Experience with and other open-source frameworks/ libraries/ APIs like Hugging Face Transformers, Spacy, Pandas, scikit-learn, NumPy, OpenCV.\n\u2022 Experience in using Machine Learning/Deep Learning: XGBoost, LightGBM, TensorFlow, PyTorch, Keras.\n\u2022 Proficiency in Python Software Development, following Object-Oriented design patterns and best practices.\n\u2022 Strong background in mathematics: linear algebra, probability, statistics, and optimization.\n\u2022 Experience with evaluation, scoring with framework like ML Flow\n\u2022 Experience of Docker container and edited a Docker file, experience with K8s is a plus.\n\u2022 Experience with Postgres and Vector DBs a plus.\n\u2022 Excellent problem-solving skills and the ability to think creatively.\n\u2022 Strong communication and collaboration skills, with the ability to work effectively with cross-functional teams\n\u2022 Publications and contributions to the AI research community are a plus.\n\u2022 Master\u2019s degree/Ph. D. or equivalent experience in Computer Science, Data Science, Statistics, or a related field.\n\u2022 8-12 years of experience\n\nThis job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.\n\n------------------------------------------------------\n\nJob Family Group:\nTechnology\n\n------------------------------------------------------\n\nJob Family:\nApplications Development\n\n------------------------------------------------------\n\nTime Type:\nFull time\n\n------------------------------------------------------\n\nMost Relevant Skills\nPlease see the requirements listed above.\n\n------------------------------------------------------\n\nOther Relevant Skills\nData Science, Machine Learning.\n\n------------------------------------------------------\n\nCiti is an equal opportunity employer, and qualified candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other characteristic protected by law.\n\nIf you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.\n\nView Citi\u2019s EEO Policy Statement and the Know Your Rights poster.",
    "url": "https://jobs.citi.com/job/pune/data-scientist-machine-learning-engineer-assistant-vice-president/287/83901989456?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "AI/ML Platform Engineer",
    "company": "Johnson Controls International",
    "location": "Pune",
    "salary": "",
    "description": "Job Title: Senior Data Scientist \u2013 Data & Analytics\n\nJohnson Controls International (JCI) is seeking a Senior Data Scientist to join our innovative and impact-driven Data Science and Analytics team. This role is ideal for a seasoned expert with a deep understanding of machine learning, AI, and cloud data platforms, and a strong grasp of the latest advancements in Generative AI and Large Language Models (LLMs).\n\nAs a Senior Data Scientist, you will lead the development and deployment of scalable AI solutions\u2014including those powered by LLMs\u2014to accelerate digital transformation across our products, operations, and customer experiences. You'll play a critical role in shaping JCI\u2019s data science strategy, mentoring teams, and driving the use of AI to deliver measurable business value.\n\nHow you will do it\n\nAdvanced Analytics, LLMs & Modeling\n\u2022 Design and implement advanced machine learning models including deep learning, time-series forecasting, recommendation engines, and LLM-based solutions (e.g., GPT, LLaMA, Claude).\n\u2022 Develop use cases around enterprise search, document summarization, conversational AI, and automated knowledge retrieval using large language models.\n\u2022 Fine-tune or prompt-engineer foundation models (e.g., OpenAI, Azure OpenAI, Hugging Face) for domain-specific applications.\n\u2022 Evaluate and optimize LLM performance, latency, cost-effectiveness, and hallucination mitigation strategies for production use.\n\nData Strategy & Engineering Collaboration\n\u2022 Work closely with data and ML engineering teams to integrate LLM-powered applications into scalable, secure, and reliable pipelines.\n\u2022 Contribute to the development of retrieval-augmented generation (RAG) architectures using vector databases (e.g., FAISS, Azure Cognitive Search).\n\u2022 Support the deployment of models using MLOps principles, ensuring robust monitoring and lifecycle management.\n\nBusiness Impact & AI Strategy\n\u2022 Partner with cross-functional stakeholders to identify opportunities for applying LLMs and generative AI to solve complex business challenges.\n\u2022 Lead workshops or proofs-of-concept to demonstrate value of LLM use cases across business units.\n\u2022 Translate complex model outputs, including those from LLMs, into clear insights and decision support tools for non-technical audiences.\n\nThought Leadership & Mentorship\n\u2022 Act as an internal thought leader on AI and LLM innovation, keeping JCI at the forefront of industry advancements.\n\u2022 Mentor and upskill data science team members in advanced AI techniques, including transformer models and generative AI frameworks.\n\u2022 Contribute to strategic roadmaps for generative AI and model governance within the enterprise.\n\nQualifications & Experience\n\u2022 Education in Data Science, Artificial Intelligence, Computer Science, or related quantitative discipline.\n\u2022 5+ years of hands-on experience in data science, including at least 1\u20132 years working with LLMs or generative AI technologies.\n\u2022 Demonstrated success in deploying machine learning and NLP solutions at scale.\n\u2022 Proven experience with cloud AI platforms\u2014especially Azure OpenAI, Azure ML, Hugging Face, or AWS Bedrock.\n\nTechnical Expertise\n\u2022 Proficiency in Python and SQL, including libraries like Transformers (Hugging Face), LangChain, PyTorch, and TensorFlow.\n\u2022 Experience with prompt engineering, fine-tuning, and LLM orchestration tools.\n\u2022 Familiarity with data storage, retrieval systems, and vector databases.\n\u2022 Strong understanding of model evaluation techniques for generative AI, including factuality, relevance, and toxicity metrics.\n\nLeadership & Soft Skills\n\u2022 Strategic thinker with a strong ability to align AI initiatives to business goals.\n\u2022 Excellent communication and storytelling skills, especially in articulating the value of LLMs and advanced analytics.\n\u2022 Strong collaborator with a track record of influencing stakeholders across product, engineering, and executive teams.\n\nPreferred Qualifications\n\u2022 Experience with IoT, edge analytics, or smart building systems.\n\u2022 Familiarity with LLMOps, LangChain, Semantic Kernel, or similar orchestration frameworks.\n\u2022 Knowledge of data privacy and governance considerations specific to LLM usage in enterprise environments.",
    "url": "https://jobs.johnsoncontrols.com/job/WD30254347?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "AI Ml Engineer  Freshers",
    "company": "Agiliad",
    "location": "Pune",
    "salary": "",
    "description": "Required Skills:\n\u2022 Strong understanding of Machine Learning, Deep Learning, and Generative AI concepts.\n\u2022 Good knowledge of Python, TensorFlow, PyTorch, Keras, and Scikit-learn.\n\u2022 Understanding of Statistics, Linear Algebra, and Probability.\n\u2022 Familiarity with AI Ops tools, Docker, Git, and Azure is a plus.\n\u2022 Excellent problem-solving and analytical skills.\n\nEligibility Criteria:\n\u2022 Education: B.E/B.Tech/M.Tech/B.Sc/M.Sc in Computer Science, IT, AI/ML, or related fields.\n\u2022 Academic Performance: Minimum 80% or above in 10th, 12th, and Graduation.\n\u2022 Batch: 2024 / 2025 Pass-out.\n\u2022 Skill -Good Communication.",
    "url": "https://in.bebee.com/job/8cfee268fce41499651d7f3c4987aa05?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "\u25b7 (High Salary) Generative AI Engineer",
    "company": "Ascendion",
    "location": "Pune",
    "salary": "",
    "description": "Position Details :\n\nJob Title : GenAI Engineer\n\nExperience : 3+ years\n\nLocation Options : Pune\n\nSkills : Python, Langchain, Langgraph, Autogen\n\nOverview :\n\nWe are actively seeking highly skilled GenAI Engineers. The ideal candidates will bring hands-on experience in developing and deploying Generative AI (GenAI) solutions from MVP to production.\n\nKey Skills :\n\u2022 Python, Langchain, Langgraph, Autogen\n\u2022 Ai agents build (multi-Agent orchestration)\n\u2022 Build and orchestrate AI agents, including multi-agent systems using frameworks like LangChain, LangGraph, and AutoGen.\n\u2022 Collaborate with cross-functional teams to integrate agents with external tools (e.g., GitHub, web UIs). Worked on integrating tools with agent ex., GitHub, ui etc\n\u2022 Work in an agile environment to rapidly prototype and transition MVPs to production. Worked on mvp to production for genai solution\n\u2022 Support and optimize RAG (Retrieval-Augmented Generation) pipelines.\n\u2022 Contribute to prompt engineering strategies and scalable GenAI infrastructure. Experience on prompt engineering and rag setup and support\n\u2022 Leverage Databricks for model development, data preparation, and orchestration. Proficiency in Databricks for ML / AI workflows.",
    "url": "https://in.talent.com/view?id=aa56bd025e37&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Artificial Intelligence & Machine Learning Engineer",
    "company": "confidential",
    "location": "Pune",
    "salary": "",
    "description": "JOB DESCRIPTION\n\nJob Summary:\nAs a Machine Learning Engineer at Emerson, you will be responsible for developing, implementing, and optimizing machine learning models and systems. You will collaborate closely with data scientists, software engineers, and other collaborators to translate data insights into practical, scalable solutions\nDesign, build, and deploy machine learning models and algorithms to solve specific business problems. Optimize models for performance and scalability.\nWork with large data sets to preprocess, clean, and transform data for use in machine learning models. Develop and maintain data pipelines.\nMonitor and evaluate the performance of deployed models, making adjustments and improvements as needed to ensure accuracy and reliability.\nWork with multi-functional teams such as data scientists, analysts, and product managers to understand requirements and deliver machine learning solutions that meet business needs.\nKeep up with the latest research and trends in machine learning and artificial intelligence. Explore and implement new techniques and technologies to enhance model performance.\nDocument model development processes, code, and standard methodologies. Provide clear and comprehensive reports on model performance and metrics\nParticipate in regular Scrum events such as Sprint Planning, Sprint Review, and Sprint Retrospective\nInthisRole,YourResponsibilitiesWill b e:\nDesign, build, and deploy machine learning models and algorithms to solve specific business problems. Optimize models for performance and scalability.\nWork with large data sets to preprocess, clean, and transform data for use in machine learning models. Develop and maintain data pipelines.\nMonitor and evaluate the performance of deployed models, making adjustments and improvements as needed to ensure accuracy and reliability.\nWork with multi-functional teams such as data scientists, analysts, and product managers to understand requirements and deliver machine learning solutions that meet business needs.\nKeep up with the latest research and trends in machine learning and artificial intelligence. Explore and implement new techniques and technologies to enhance model performance.\nDocument model development processes, code, and standard methodologies. Provide clear and comprehensive reports on model performance and metrics\nParticipate in regular Scrum events such as Sprint Planning, Sprint Review, and Sprint Retrospective\nWhoYou Are:\n\nYou quickly and decisively act in constantly evolving, unexpected situations. You adjust communicationcontentandstyletomeettheneedsofdiversepartners.Youalwayskeeptheend in sight puts in extra effort to meet deadlines. You analyze multiple and diverse sources of informationtodefineproblemsaccuratelybeforemovingtosolutions.Youobservesituationaland group dynamics and select best-fit approach.\nForThisRole,YouWill Need:\nBachelor's degree in computer science, Data Science, Statistics, or a related field or a master's degree or higher is preferred.\nMore than 3 years of experience in machine learning engineering or a related role, with a strong track record of developing and deploying machine learning models.\nProficiency in programming languages such as Python or R. Experience with machine learning frameworks (e.g., Go, TensorFlow, PyTorch, scikit-learn).\nExperience with Azure Cognitive services\nExperience with data processing and manipulation tools and libraries (e.g., pandas, NumPy).\nStrong analytical and problem-solving skills, with the ability to handle complex and large-scale data sets.\nExperience with deploying machine learning models to production environments, including knowledge of containerization technologies (e.g., Docker or equivalent) and cloud platforms, Microsoft Azure is preferred\nExcellent verbal and written communication skills, with the ability to explain technical concepts to non-technical collaborators\nPreferredQualificationsthatSetYou Apart:\n\nPrior experience in engineering domain would be nice to have\nPrior experience in working with teams in Scaled Agile Framework (SAFe) is nice to have\nPossession of relevant certification/s in data science from reputed universities specializing in AI.\nFamiliarity with version control systems (e.g., Git) and CI/CD pipelines.\nUnderstanding of standard processes in software development and methodologies.",
    "url": "https://in.jooble.org/rjdp/-6265525461943023084?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Data AI Engineering Senior Associate",
    "company": "MSCI",
    "location": "Pune",
    "salary": "",
    "description": "Your Team Responsibilities\n\nThe AI Engineering team at MSCI is seeking a Senior Associate to help build and scale our internal platform for deploying intelligent agents. This platform enables developers and non-technical teams to quickly build, test, and deploy agents that interact with internal APIs and data while respecting entitlements and data boundaries.\n\nYou will work in close collaboration with engineers across cloud infrastructure, ML ops, and security to ensure the agent platform is robust, flexible, and easy to use. This role requires a passion for platform usability, developer experience, and pragmatic engineering in cross-cloud (Azure + GCP) environments.\n\nYour Key Responsibilities\n\u2022 Implement and improve internal tooling and runtimes for deploying agent-based applications across MSCI teams.\n\u2022 Integrate entitlement and data-privacy policies into AI workflows using internal security and identity layers.\n\u2022 Develop reusable libraries and interfaces for agents to interact with MSCI services via MCP and additional integrations.\n\u2022 Collaborate with UX and internal client teams to build low-friction, high-compliance agent deployment pathways.\n\u2022 Contribute to observability, sandboxing, and monitoring capabilities for agent executions and workflows.\n\nYour skills and experience that will help you excel\n\u2022 Strong experience building platforms or tooling used by other engineers, ideally in agentic or ML-enabled systems.\n\u2022 Proficient in Python, Typescript, or Go, with experience deploying apps or services in Azure and/or GCP.\n\u2022 Understanding of prompt engineering, LLM orchestration tools (e.g., LangChain, google ADK), and multi-agent patterns.\n\u2022 Familiarity with RBAC, authentication standards (OAuth, SAML), and entitlements in enterprise systems.\n\u2022 Enthusiastic about developer productivity and the impact of well-designed internal platforms.\n\nAbout MSCI\n\nWhat we offer you\n\u2022 Transparent compensation schemes and comprehensive employee benefits, tailored to your location, ensuring your financial security, health, and overall wellbeing.\n\u2022 Flexible working arrangements, advanced technology, and collaborative workspaces.\n\u2022 A culture of high performance and innovation where we experiment with new ideas and take responsibility for achieving results.\n\u2022 A global network of talented colleagues, who inspire, support, and share their expertise to innovate and deliver for our clients.\n\u2022 Global Orientation program to kickstart your journey, followed by access to our Learning@MSCI platform, LinkedIn Learning Pro and tailored learning opportunities for ongoing skills development.\n\u2022 Multi-directional career paths that offer professional growth and development through new challenges, internal mobility and expanded roles.\n\u2022 We actively nurture an environment that builds a sense of inclusion belonging and connection, including eight Employee Resource Groups. All Abilities, Asian Support Network, Black Leadership Network, Climate Action Network, Hola! MSCI, Pride & Allies, Women in Tech, and Women\u2019s Leadership Forum.\n\nAt MSCI we are passionate about what we do, and we are inspired by our purpose \u2013 to power better investment decisions. You\u2019ll be part of an industry-leading network of creative, curious, and entrepreneurial pioneers. This is a space where you can challenge yourself, set new standards and perform beyond expectations for yourself, our clients, and our industry.\n\nMSCI is a leading provider of critical decision support tools and services for the global investment community. With over 50 years of expertise in research, data, and technology, we power better investment decisions by enabling clients to understand and analyze key drivers of risk and return and confidently build more effective portfolios. We create industry-leading research-enhanced solutions that clients use to gain insight into and improve transparency across the investment process.\n\nMSCI Inc. is an equal opportunity employer. It is the policy of the firm to ensure equal employment opportunity without discrimination or harassment on the basis of race, color, religion, creed, age, sex, gender, gender identity, sexual orientation, national origin, citizenship, disability, marital and civil partnership/union status, pregnancy (including unlawful discrimination on the basis of a legally protected parental leave), veteran status, or any other characteristic protected by law. MSCI is also committed to working with and providing reasonable accommodations to individuals with disabilities. If you are an individual with a disability and would like to request a reasonable accommodation for any part of the application process, please email Disability.Assistance@msci.com and indicate the specifics of the assistance needed. Please note, this e-mail is intended only for individuals who are requesting a reasonable workplace accommodation; it is not intended for other inquiries.\n\nTo all recruitment agencies\n\nMSCI does not accept unsolicited CVs/Resumes. Please do not forward CVs/Resumes to any MSCI employee, location, or website. MSCI is not responsible for any fees related to unsolicited CVs/Resumes.\n\nNote on recruitment scams\n\nWe are aware of recruitment scams where fraudsters impersonating MSCI personnel may try and elicit personal information from job seekers. Read our full note on careers.msci.com",
    "url": "https://talentcommunity.msci.com/event-13931/jobs/4056?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-27T00:00:00.000Z"
  },
  {
    "title": "AI Solutions Lead",
    "company": "Syngenta",
    "location": "Pune",
    "salary": "",
    "description": "The AI Solutions Lead will be responsible for:\n\u2022 Architectural Leadership: Leading the design and architecture of AI solutions, ensuring scalability, maintainability, and optimal performance.\n\u2022 Technical Guidance: Collaborating with development teams to understand requirements and provide expert architectural guidance and support.\n\u2022 Business Alignment: Working closely with Product and Business stakeholders to understand their needs and ensure the AI platform effectively meets user requirements.\n\u2022 Cross-functional Collaboration: Partnering with cross-functional stakeholders to translate complex business requirements into robust technical solutions.\n\u2022 Solution Definition: Defining clear implementation approaches, algorithms, and code structures for AI solutions.\n\u2022 Successful Solution Delivery: Taking ultimate accountability for the successful end-to-end delivery of AI solutions, ensuring they are implemented, deployed, and operationalized effectively, meet defined business objectives, adhere to architectural designs and quality standards, and are delivered within project timelines.\n\u2022 Technology Scouting: Staying abreast of the latest trends and emerging technologies in the AI space, evaluating their potential impact, and recommending their introduction into Syngenta's ecosystem.\n\u2022 Experience Architecture: Defining, prototyping, and recommending technology solutions, detailing implementation designs, and identifying interfaces for integration with other products.\n\nCompany Description\n\nJoin Syngenta Group, a leader in agricultural innovation where technology meets purpose. As digital pioneers in AgTech, we're integrating AI across our value chain from smart breeding to precision agriculture. Our global team of 56,000 professionals is transforming sustainable farming worldwide. At Syngenta IT & Digital, your expertise will directly impact food security and shape the future of agriculture through cutting-edge technology.\n\nQualifications\n\u2022 Education:\n\u2022 Degree in Computer Science, AI, ML, Data Science, Engineering, or a related field.\n\u2022 Experience:\n\u2022 4+ years of progressive experience in designing, architecting, and leading the end-to-end delivery of complex AI/ML solutions in a cloud environment.\n\u2022 Demonstrated expertise in AI/ML solution architecture, including model development, deployment, MLOps (Machine Learning Operations), and scalable data pipelines.\n\u2022 Proven experience with major cloud platforms (e.g., AWS, Azure, GCP) and their AI/ML services, specifically in building and operationalizing AI solutions.\n\u2022 Strong understanding of SQL and NoSQL databases, and experience with data warehousing/data lake concepts relevant to AI/ML workloads.\n\u2022 Experience with SAP fundamentals and SAP Joule, or similar enterprise resource planning (ERP) systems, particularly concerning data integration for AI solutions.\n\u2022 Track record of successfully leading technical teams or projects, demonstrating strong project delivery capabilities.\n\u2022 Skills:\n\u2022 Deep technical expertise in AI/ML concepts, algorithms, and frameworks.\n\u2022 Proficiency in programming languages commonly used in AI/ML (e.g., Python, R, Java) for development, prototyping, and integration.\n\u2022 Strong architectural design skills for building scalable, robust, and maintainable AI systems that meet performance and security requirements.\n\u2022 Excellent analytical, critical thinking, and complex problem-solving abilities, with a proven capacity to translate complex business challenges into effective AI solutions.\n\u2022 Exceptional communication, presentation, and stakeholder management skills, with the ability to articulate complex technical concepts clearly to diverse audiences (technical and non-technical).\n\u2022 Ability to lead, mentor, and collaborate effectively within cross-functional and agile teams.\n\u2022 Demonstrated ability to prototype, evaluate, and recommend new technologies and innovative AI solutions, aligning with strategic business objectives.\n\nCritical success factors & key challenges\n\u2022 Solution Design Excellence: Demonstrating strong solution design, logical thinking, and reasoning skills.\n\u2022 Prototyping & Evaluation: Ability to deliver Proofs of Concept (POCs) and Minimum Viable Products (MVPs), and conduct technology evaluations using design thinking practices.\n\u2022 Strategic Prioritization: Orchestrating efforts to prioritize business initiatives across complex and evolving change agendas.\n\u2022 Stakeholder Management: Excellent communication and stakeholder management skills, including the ability to explain complex technical information to non-technical audiences.\n\u2022 Problem Solving & Decision Making: Strong capabilities in problem-solving and decision-making.\n\u2022 Team Leadership: Proven teamwork, team management, and leadership skills.\n\nAdditional Information\n\nWe are a leading, science-based agriculture company, empowering farmers to meet the demands of modern agriculture. Using cutting-edge innovation, we help farmers to grow resilient, healthy crops that can feed a growing global population, while promoting sustainable farming practices that protect and enhance our planet. Headquartered in Switzerland, we are a global agritech leader with more than 30,000 employees across over 90 countries.\n\nhttps://www.syngenta.com/company",
    "url": "https://jobs.syngenta.com/job/ai-solutions-lead-in-in-pune-jid-15234?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "ML Engineer II - Aws, Aws Cloud (Pune)",
    "company": "Peak Hire Solutions",
    "location": "Pune",
    "salary": "",
    "description": "Job Details\n\n- Job Title: ML Engineer II - Aws, Aws Cloud\n\n- Industry: Technology\n\n- Domain - Information technology (IT)\n\n- Experience Required: 6-12 years\n\n- Employment Type: Full Time\n\n- Job Location: Pune\n\n- CTC Range: Best in Industry\n\nJob Description:\n\nCore Responsibilities:\n\n? The MLE will design, build, test, and deploy scalable machine learning systems, optimizing model accuracy and efficiency\n\n? Model Development: Algorithms and architectures span traditional statistical methods to deep learning along with employing LLMs in up-to-date frameworks.\n\n? Data Preparation: Prepare, cleanse, and transform data for model training and evaluation.\n\n? Algorithm Implementation: Implement and optimize machine learning algorithms and statistical models.\n\n? System Integration: Integrate models into existing systems and workflows.\n\n? Model Deployment: Deploy models to production environments and monitor performance.\n\n? Collaboration: Work closely with data scientists, software engineers, and other stakeholders.\n\n? Continuous Improvement: Identify areas for improvement in model performance and systems.\n\nSkills:\n\n? Programming and Software Engineering: Knowledge of software engineering best practices (version control, testing, CI/CD).\n\n? Data Engineering: Ability to handle data pipelines, data cleaning, and feature engineering. Proficiency in SQL for data manipulation + Kafka, Chaossearch logs, etc for troubleshooting; Other tech touch points are ScyllaDB (like BigTable), OpenSearch, Neo4J graph\n\n? Model Deployment and Monitoring: MLOps Experience in deploying ML models to production environments.\n\n? Knowledge of model monitoring and performance evaluation.\n\nRequired experience:\n\n? Amazon SageMaker: Deep understanding of SageMaker's capabilities for building, training, and deploying ML models; understanding of the Sagemaker pipeline with ability to analyze gaps and recommend/implement improvements\n\n? AWS Cloud Infrastructure: Familiarity with S3, EC2, Lambda and using these services in\n\nML workflows\n\n? AWS data: Redshift, Glue\n\n? Containerization and Orchestration: Understanding of Docker and Kubernetes, and their implementation within AWS (EKS, ECS)\n\nSkills: Aws, Aws Cloud, Amazon Redshift, Eks\n\nMust-Haves\n\nAws, Aws Cloud, Amazon Redshift, Eks\n\nNP: Immediate \u2013 30 Days\n\nSkills:- Amazon Web Services (AWS), AWS CloudFormation, Amazon Redshift, Elastic Search, ECS, Docker, Kubernetes, Machine Learning (ML), MLOps, Neo4J, SQL, Algorithms, Architecture, Statistical Modeling, Large Language Models (LLM) and Deep Learning",
    "url": "https://in.jobrapido.com/jobpreview/6078549723050934272?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Senior Agentic AI Engineer",
    "company": "Teradata",
    "location": "Pune",
    "salary": "",
    "description": "Our Company:\n\nAt Teradata, we're not just managing data; we're unleashing its full potential. Our ClearScape Analytics\u2122 platform and pioneering Enterprise Vector Store are empowering the world's largest enterprises to derive unprecedented value from their most complex data. We're rapidly pushing the boundaries of what's possible with Artificial Intelligence, especially in the exciting realm of autonomous and agentic systems\n\nWe\u2019re building intelligent systems that go far beyond automation \u2014 they observe, reason, adapt, and drive complex decision-making across large-scale enterprise environments. As a member of our AI engineering team, you\u2019ll play a critical role in designing and deploying advanced AI agents that integrate deeply with business operations, turning data into insight, action, and measurable outcomes.\n\nYou\u2019ll work alongside a high-caliber team of AI researchers, engineers, and data scientists tackling some of the hardest problems in AI and enterprise software \u2014 from scalable multi-agent coordination and fine-tuned LLM applications, to real-time monitoring, drift detection, and closed-loop retraining systems.\n\nIf you're passionate about building intelligent systems that are not only powerful but observable, resilient, and production-ready, this role offers the opportunity to shape the future of enterprise AI from the ground up.\n\nWe are seeking a highly skilled Senior AI Engineer to drive the development and deployment of Agentic AI systems with a strong emphasis on AI observability and data platform integration. You will work at the forefront of cutting-edge AI research and its practical application\u2014designing, implementing, and monitoring intelligent agents capable of autonomous reasoning, decision-making, and continuous learning.\n\nIgnite the Future of AI at Teradata!\n\nWhat You'll Do: Shape the Way the World Understands Data\n\nAs a senior Agentic AI Engineer at Teradata, you\u2019ll build cutting-edge intelligent agents that transform how users explore data, derive insights, and automate workflows across industries such as healthcare, finance, and telecommunications.\n\nYou will:\n\u2022 Design and implement autonomous AI agents for semantic search, text-to-SQL translation, and analytical task execution.\n\u2022 Develop modular prompts, reasoning chains, and decision graphs tailored to complex enterprise use cases.\n\u2022 Enhance agent performance through experimentation with LLMs, prompt tuning, and advanced reasoning workflows.\n\u2022 Integrate agents with Teradata\u2019s Model Context Protocol (MCP) to enable seamless interaction with model development pipelines.\n\u2022 Build tools that allow agents to monitor training jobs, evaluate models, and interact with unstructured and structured data sources.\n\u2022 Work on retrieval-augmented generation (RAG) pipelines and extend agents to downstream ML systems.\n\nWho You'll Work With: Join Forces with the Best\n\nYou\u2019ll collaborate with a world-class team of AI architects, ML engineers, and domain experts at Silicon Valley, working together to build the next generation of enterprise AI systems.\n\nYou\u2019ll also work cross-functionally with:\n\u2022 Product managers and UX designers to craft agentic workflows that are intuitive and impactful.\n\u2022 Domain specialists to ensure solutions align with real-world business problems in regulated industries.\n\u2022 Infrastructure and platform teams responsible for training, evaluation, and scaling AI workloads.\n\nThis is a rare opportunity to shape foundational AI capabilities within a global, data-driven company.\n\nThis is a deeply collaborative environment where technical innovation meets real-world application, where your ideas are not only heard but implemented to shape the next generation of data interaction.\n\nWhat Makes You a Qualified Candidate: Skills in Action\n\u2022 5+ years of product engineering experience in AI/ML, with strong software development fundamentals.\n\u2022 Proficiency with LLM APIs (e. g. , OpenAI, Claude, Gemini) and agent frameworks such as AutoGen, LangGraph, AgentBuilder, or CrewAI.\n\u2022 Experience designing multi-step reasoning chains, prompt pipelines, or intelligent workflows.\n\u2022 Familiarity with agent evaluation metrics: correctness, latency, failure modes.\n\u2022 Passion for building production-grade systems that bring AI to life.\n\nWhat You Bring: Passion and Potential\n\u2022 Master\u2019s or Ph. D. in Computer Science, AI, or a related field, or equivalent industry experience.\n\u2022 Experience working with multimodal inputs, retrieval systems, or structured knowledge sources.\n\u2022 Deep understanding of enterprise data workflows and scalable AI architectures.\n\u2022 Prior exposure to MCP or similar orchestration/protocol systems.\n\nWhy We Think You\u2019ll Love Teradata\n\nWe prioritize a people-first culture because we know our people are at the very heart of our success. We embrace a flexible work model because we trust our people to make decisions about how, when, and where they work. We focus on well-being because we care about our people and their ability to thrive both personally and professionally. We are an anti-racist company because our dedication to Diversity, Equity, and Inclusion is more than a statement. It is a deep commitment to doing the work to foster an equitable environment that celebrates people for all of who they are.\n\nTeradata invites all identities and backgrounds in the workplace. We work with deliberation and intent to ensure we are cultivating collaboration and inclusivity across our global organization. We are proud to be an equal opportunity and affirmative action employer. We do not discriminate based upon race, color, ancestry, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related conditions), national origin, sexual orientation, age, citizenship, marital status, disability, medical condition, genetic information, gender identity or expression, military and veteran status, or any other legally protected status.",
    "url": "https://in.linkedin.com/jobs/view/senior-agentic-ai-engineer-at-teradata-4319335059?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "\u25b7 High Salary : Generative AI Engineer",
    "company": "Talent Corner HR Services Pvt Ltd",
    "location": "Pune",
    "salary": "",
    "description": "Experience Required : 4-6 Years\n\nJob Summary :\n\u2022 Proven experience in content management, data architecture, and AI\n\u2022 technologies\n\u2022 Design content structures that optimize the usability and retrieval of data by\n\u2022 LLMs and RAG systems.\n\u2022 Strong understanding of LLMs and RAG systems and their application in\n\u2022 business contexts.\n\u2022 Problem-solving skills with a proactive approach to identifying and addressing\n\u2022 challenges.\n\u2022 Design and maintain a robust data architecture that supports efficient content\n\u2022 retrieval and generation.\n\u2022 Ensure content is optimized for AI consumption, including proper formatting,\n\u2022 tagging, and metadata application.\n\u2022 Experience in JIRA, Confluence, Bit Bucket, Azure Repo etc.\n\u2022 Strong Computer Science fundamentals in object-oriented design, data\n\u2022 structures, design patterns and algorithm design.\n\u2022 Strong debug and troubleshooting skills.\n\u2022 Aware of CI / CD techniques and tools like Azure Pipeline.\n\nWhat do we expect from you?\n\u2022 Bachelor\u2019s or Master\u2019s degree in Computer Science, Information Technology, or a related field.\n\u2022 Proven experience in building Azure Cloud solutions.\n\u2022 Experience with content management systems (CMS) and data management tools.\n\u2022 Familiarity with AI / ML frameworks and libraries.\n\u2022 Knowledge of global content standards and regional data regulations.\n\u2022 Familiarity with CI / CD pipelines and version control systems such as Git.\n\u2022 Strong debug and troubleshooting skills.\n\u2022 Effective oral and written communication skills; ability to articulate clearly and concisely.\n\u2022 You have worked with Agile Methodologies following SCRUM.\n\nQualifications :\n\u2022 4 to 6 years of strong hands-on experience in Python programming\n\u2022 Minimum 2 years of experience working with AI tools and technologies\n\u2022 At least 1 year of experience as a Generative AI Content Architect\n\u2022 Successfully delivered 2\u20133 AI implementation projects or use cases\n\u2022 Solid understanding of AI solution implementation, including data architect and content management.",
    "url": "https://in.talent.com/view?id=bf7d30325688&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Data Scientist/Machine Learning Engineer Assistant vice president",
    "company": "Early Career",
    "location": "Pune",
    "salary": "",
    "description": "ML Solutions team within Markets OPS Technology is dedicated to developing solutions using Artificial Intelligence, Machine Learning and Generative AI. This team is a leader in creating new ideas, innovative technology solutions, and ground-breaking solutions for Markets Operations and Other Line of Businesses. We work closely with our clients and business partners to progress solutions from ideation to production by leveraging the entrepreneurial spirit and technological excellence.\n\nJob Description:\n\nThe ML Solutions team is seeking a Data Scientist/Machine Learning Engineer to drive the design, development, and deployment of innovative AI/ML and GenAI-based solutions. In this hands-on role, you will leverage your expertise to create a variety of AI models, guiding a team from initial concept to successful production. A key aspect involves mentoring team members and fostering their growth. You will collaborate closely with business partners and stakeholders, championing the adoption of these advanced technologies to enhance client experiences, deliver tangible value to our customers, and ensure adherence to regulatory requirements through cutting-edge technical solutions. This position offers a unique opportunity to shape the future of our AI initiatives and make a significant impact on the organization.\n\nKey Responsibilities:\n\u2022 Hands-On Execution and Delivery: Actively contribute to the development and delivery of AI solutions, driving innovation and excellence within the team. Take a hands-on approach to ensure AI models are successfully deployed into production environments, meeting high-quality standards and performance benchmarks.\n\u2022 Mentoring Young Talents: Mentoring team, guiding data analysts/ML engineers from concept to production. This involves fostering technical growth, providing project oversight, and ensuring adherence to best practices, ultimately building a high-performing and innovative team.\n\u2022 Quality Control: Ensure the quality and performance of generative AI models, conducting rigorous testing and evaluation.\n\u2022 Research and Development: Participate in research activities to explore and advance state-of-the-art generative AI techniques. Stay actively engaged in monitoring ongoing research efforts, keeping abreast of emerging trends, and ensuring that the Generative AI team remains at the forefront of the field.\n\u2022 Cross-Functional Collaboration: Collaborate effectively with various teams, including product managers, engineers, and data scientists, to integrate AI technologies into products and services.\n\nSkills & Qualifications:\n\u2022 8 to 13 years of Strong hands-on experience in Machine Learning, delivering complex solutions to production.\n\u2022 Experience with Generative AI technologies essential.\n\u2022 Understanding of concepts like supervised, unsupervised, clustering, embedding.\n\u2022 Knowledge of NLP, Name Entity Recognition, Computer Vision, Transformers, Large Language Models.\n\u2022 In-depth knowledge of deep learning and Generative AI frameworks such as, Langchain, Lang Graph, Crew AI or similar.\n\u2022 Experience with and other open-source frameworks/ libraries/ APIs like Hugging Face Transformers, Spacy, Pandas, scikit-learn, NumPy, OpenCV.\n\u2022 Experience in using Machine Learning/Deep Learning: XGBoost, LightGBM, TensorFlow, PyTorch, Keras.\n\u2022 Proficiency in Python Software Development, following Object-Oriented design patterns and best practices.\n\u2022 Strong background in mathematics: linear algebra, probability, statistics, and optimization.\n\u2022 Experience with evaluation, scoring with framework like ML Flow\n\u2022 Experience of Docker container and edited a Docker file, experience with K8s is a plus.\n\u2022 Experience with Postgres and Vector DBs a plus.\n\u2022 Excellent problem-solving skills and the ability to think creatively.\n\u2022 Strong communication and collaboration skills, with the ability to work effectively with cross-functional teams\n\u2022 Publications and contributions to the AI research community are a plus.\n\u2022 Master\u2019s degree/Ph. D. or equivalent experience in Computer Science, Data Science, Statistics, or a related field.\n\u2022 8-12 years of experience\n\nThis job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.\n\n------------------------------------------------------\n\nJob Family Group:\nTechnology\n\n------------------------------------------------------\n\nJob Family:\nApplications Development\n\n------------------------------------------------------\n\nTime Type:\nFull time\n\n------------------------------------------------------\n\nMost Relevant Skills\nPlease see the requirements listed above.\n\n------------------------------------------------------\n\nOther Relevant Skills\nData Science, Machine Learning.\n\n------------------------------------------------------\n\nCiti is an equal opportunity employer, and qualified candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other characteristic protected by law.\n\nIf you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.\n\nView Citi\u2019s EEO Policy Statement and the Know Your Rights poster.",
    "url": "https://jobs.citi.com/job/pune/data-scientist-machine-learning-engineer-assistant-vice-president/287/83901989456?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "AI/ML Platform Engineer",
    "company": "Johnson Controls International",
    "location": "Pune",
    "salary": "",
    "description": "Job Title: Senior Data Scientist \u2013 Data & Analytics\n\nJohnson Controls International (JCI) is seeking a Senior Data Scientist to join our innovative and impact-driven Data Science and Analytics team. This role is ideal for a seasoned expert with a deep understanding of machine learning, AI, and cloud data platforms, and a strong grasp of the latest advancements in Generative AI and Large Language Models (LLMs).\n\nAs a Senior Data Scientist, you will lead the development and deployment of scalable AI solutions\u2014including those powered by LLMs\u2014to accelerate digital transformation across our products, operations, and customer experiences. You'll play a critical role in shaping JCI\u2019s data science strategy, mentoring teams, and driving the use of AI to deliver measurable business value.\n\nHow you will do it\n\nAdvanced Analytics, LLMs & Modeling\n\u2022 Design and implement advanced machine learning models including deep learning, time-series forecasting, recommendation engines, and LLM-based solutions (e.g., GPT, LLaMA, Claude).\n\u2022 Develop use cases around enterprise search, document summarization, conversational AI, and automated knowledge retrieval using large language models.\n\u2022 Fine-tune or prompt-engineer foundation models (e.g., OpenAI, Azure OpenAI, Hugging Face) for domain-specific applications.\n\u2022 Evaluate and optimize LLM performance, latency, cost-effectiveness, and hallucination mitigation strategies for production use.\n\nData Strategy & Engineering Collaboration\n\u2022 Work closely with data and ML engineering teams to integrate LLM-powered applications into scalable, secure, and reliable pipelines.\n\u2022 Contribute to the development of retrieval-augmented generation (RAG) architectures using vector databases (e.g., FAISS, Azure Cognitive Search).\n\u2022 Support the deployment of models using MLOps principles, ensuring robust monitoring and lifecycle management.\n\nBusiness Impact & AI Strategy\n\u2022 Partner with cross-functional stakeholders to identify opportunities for applying LLMs and generative AI to solve complex business challenges.\n\u2022 Lead workshops or proofs-of-concept to demonstrate value of LLM use cases across business units.\n\u2022 Translate complex model outputs, including those from LLMs, into clear insights and decision support tools for non-technical audiences.\n\nThought Leadership & Mentorship\n\u2022 Act as an internal thought leader on AI and LLM innovation, keeping JCI at the forefront of industry advancements.\n\u2022 Mentor and upskill data science team members in advanced AI techniques, including transformer models and generative AI frameworks.\n\u2022 Contribute to strategic roadmaps for generative AI and model governance within the enterprise.\n\nQualifications & Experience\n\u2022 Education in Data Science, Artificial Intelligence, Computer Science, or related quantitative discipline.\n\u2022 5+ years of hands-on experience in data science, including at least 1\u20132 years working with LLMs or generative AI technologies.\n\u2022 Demonstrated success in deploying machine learning and NLP solutions at scale.\n\u2022 Proven experience with cloud AI platforms\u2014especially Azure OpenAI, Azure ML, Hugging Face, or AWS Bedrock.\n\nTechnical Expertise\n\u2022 Proficiency in Python and SQL, including libraries like Transformers (Hugging Face), LangChain, PyTorch, and TensorFlow.\n\u2022 Experience with prompt engineering, fine-tuning, and LLM orchestration tools.\n\u2022 Familiarity with data storage, retrieval systems, and vector databases.\n\u2022 Strong understanding of model evaluation techniques for generative AI, including factuality, relevance, and toxicity metrics.\n\nLeadership & Soft Skills\n\u2022 Strategic thinker with a strong ability to align AI initiatives to business goals.\n\u2022 Excellent communication and storytelling skills, especially in articulating the value of LLMs and advanced analytics.\n\u2022 Strong collaborator with a track record of influencing stakeholders across product, engineering, and executive teams.\n\nPreferred Qualifications\n\u2022 Experience with IoT, edge analytics, or smart building systems.\n\u2022 Familiarity with LLMOps, LangChain, Semantic Kernel, or similar orchestration frameworks.\n\u2022 Knowledge of data privacy and governance considerations specific to LLM usage in enterprise environments.",
    "url": "https://jobs.johnsoncontrols.com/job/WD30254347?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "AI Ml Engineer  Freshers",
    "company": "Agiliad",
    "location": "Pune",
    "salary": "",
    "description": "Required Skills:\n\u2022 Strong understanding of Machine Learning, Deep Learning, and Generative AI concepts.\n\u2022 Good knowledge of Python, TensorFlow, PyTorch, Keras, and Scikit-learn.\n\u2022 Understanding of Statistics, Linear Algebra, and Probability.\n\u2022 Familiarity with AI Ops tools, Docker, Git, and Azure is a plus.\n\u2022 Excellent problem-solving and analytical skills.\n\nEligibility Criteria:\n\u2022 Education: B.E/B.Tech/M.Tech/B.Sc/M.Sc in Computer Science, IT, AI/ML, or related fields.\n\u2022 Academic Performance: Minimum 80% or above in 10th, 12th, and Graduation.\n\u2022 Batch: 2024 / 2025 Pass-out.\n\u2022 Skill -Good Communication.",
    "url": "https://in.bebee.com/job/8cfee268fce41499651d7f3c4987aa05?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "\u25b7 (High Salary) Generative AI Engineer",
    "company": "Ascendion",
    "location": "Pune",
    "salary": "",
    "description": "Position Details :\n\nJob Title : GenAI Engineer\n\nExperience : 3+ years\n\nLocation Options : Pune\n\nSkills : Python, Langchain, Langgraph, Autogen\n\nOverview :\n\nWe are actively seeking highly skilled GenAI Engineers. The ideal candidates will bring hands-on experience in developing and deploying Generative AI (GenAI) solutions from MVP to production.\n\nKey Skills :\n\u2022 Python, Langchain, Langgraph, Autogen\n\u2022 Ai agents build (multi-Agent orchestration)\n\u2022 Build and orchestrate AI agents, including multi-agent systems using frameworks like LangChain, LangGraph, and AutoGen.\n\u2022 Collaborate with cross-functional teams to integrate agents with external tools (e.g., GitHub, web UIs). Worked on integrating tools with agent ex., GitHub, ui etc\n\u2022 Work in an agile environment to rapidly prototype and transition MVPs to production. Worked on mvp to production for genai solution\n\u2022 Support and optimize RAG (Retrieval-Augmented Generation) pipelines.\n\u2022 Contribute to prompt engineering strategies and scalable GenAI infrastructure. Experience on prompt engineering and rag setup and support\n\u2022 Leverage Databricks for model development, data preparation, and orchestration. Proficiency in Databricks for ML / AI workflows.",
    "url": "https://in.talent.com/view?id=aa56bd025e37&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Artificial Intelligence & Machine Learning Engineer",
    "company": "confidential",
    "location": "Pune",
    "salary": "",
    "description": "JOB DESCRIPTION\n\nJob Summary:\nAs a Machine Learning Engineer at Emerson, you will be responsible for developing, implementing, and optimizing machine learning models and systems. You will collaborate closely with data scientists, software engineers, and other collaborators to translate data insights into practical, scalable solutions\nDesign, build, and deploy machine learning models and algorithms to solve specific business problems. Optimize models for performance and scalability.\nWork with large data sets to preprocess, clean, and transform data for use in machine learning models. Develop and maintain data pipelines.\nMonitor and evaluate the performance of deployed models, making adjustments and improvements as needed to ensure accuracy and reliability.\nWork with multi-functional teams such as data scientists, analysts, and product managers to understand requirements and deliver machine learning solutions that meet business needs.\nKeep up with the latest research and trends in machine learning and artificial intelligence. Explore and implement new techniques and technologies to enhance model performance.\nDocument model development processes, code, and standard methodologies. Provide clear and comprehensive reports on model performance and metrics\nParticipate in regular Scrum events such as Sprint Planning, Sprint Review, and Sprint Retrospective\nInthisRole,YourResponsibilitiesWill b e:\nDesign, build, and deploy machine learning models and algorithms to solve specific business problems. Optimize models for performance and scalability.\nWork with large data sets to preprocess, clean, and transform data for use in machine learning models. Develop and maintain data pipelines.\nMonitor and evaluate the performance of deployed models, making adjustments and improvements as needed to ensure accuracy and reliability.\nWork with multi-functional teams such as data scientists, analysts, and product managers to understand requirements and deliver machine learning solutions that meet business needs.\nKeep up with the latest research and trends in machine learning and artificial intelligence. Explore and implement new techniques and technologies to enhance model performance.\nDocument model development processes, code, and standard methodologies. Provide clear and comprehensive reports on model performance and metrics\nParticipate in regular Scrum events such as Sprint Planning, Sprint Review, and Sprint Retrospective\nWhoYou Are:\n\nYou quickly and decisively act in constantly evolving, unexpected situations. You adjust communicationcontentandstyletomeettheneedsofdiversepartners.Youalwayskeeptheend in sight puts in extra effort to meet deadlines. You analyze multiple and diverse sources of informationtodefineproblemsaccuratelybeforemovingtosolutions.Youobservesituationaland group dynamics and select best-fit approach.\nForThisRole,YouWill Need:\nBachelor's degree in computer science, Data Science, Statistics, or a related field or a master's degree or higher is preferred.\nMore than 3 years of experience in machine learning engineering or a related role, with a strong track record of developing and deploying machine learning models.\nProficiency in programming languages such as Python or R. Experience with machine learning frameworks (e.g., Go, TensorFlow, PyTorch, scikit-learn).\nExperience with Azure Cognitive services\nExperience with data processing and manipulation tools and libraries (e.g., pandas, NumPy).\nStrong analytical and problem-solving skills, with the ability to handle complex and large-scale data sets.\nExperience with deploying machine learning models to production environments, including knowledge of containerization technologies (e.g., Docker or equivalent) and cloud platforms, Microsoft Azure is preferred\nExcellent verbal and written communication skills, with the ability to explain technical concepts to non-technical collaborators\nPreferredQualificationsthatSetYou Apart:\n\nPrior experience in engineering domain would be nice to have\nPrior experience in working with teams in Scaled Agile Framework (SAFe) is nice to have\nPossession of relevant certification/s in data science from reputed universities specializing in AI.\nFamiliarity with version control systems (e.g., Git) and CI/CD pipelines.\nUnderstanding of standard processes in software development and methodologies.",
    "url": "https://in.jooble.org/rjdp/-6265525461943023084?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Data AI Engineering Senior Associate",
    "company": "MSCI",
    "location": "Pune",
    "salary": "",
    "description": "Your Team Responsibilities\n\nThe AI Engineering team at MSCI is seeking a Senior Associate to help build and scale our internal platform for deploying intelligent agents. This platform enables developers and non-technical teams to quickly build, test, and deploy agents that interact with internal APIs and data while respecting entitlements and data boundaries.\n\nYou will work in close collaboration with engineers across cloud infrastructure, ML ops, and security to ensure the agent platform is robust, flexible, and easy to use. This role requires a passion for platform usability, developer experience, and pragmatic engineering in cross-cloud (Azure + GCP) environments.\n\nYour Key Responsibilities\n\u2022 Implement and improve internal tooling and runtimes for deploying agent-based applications across MSCI teams.\n\u2022 Integrate entitlement and data-privacy policies into AI workflows using internal security and identity layers.\n\u2022 Develop reusable libraries and interfaces for agents to interact with MSCI services via MCP and additional integrations.\n\u2022 Collaborate with UX and internal client teams to build low-friction, high-compliance agent deployment pathways.\n\u2022 Contribute to observability, sandboxing, and monitoring capabilities for agent executions and workflows.\n\nYour skills and experience that will help you excel\n\u2022 Strong experience building platforms or tooling used by other engineers, ideally in agentic or ML-enabled systems.\n\u2022 Proficient in Python, Typescript, or Go, with experience deploying apps or services in Azure and/or GCP.\n\u2022 Understanding of prompt engineering, LLM orchestration tools (e.g., LangChain, google ADK), and multi-agent patterns.\n\u2022 Familiarity with RBAC, authentication standards (OAuth, SAML), and entitlements in enterprise systems.\n\u2022 Enthusiastic about developer productivity and the impact of well-designed internal platforms.\n\nAbout MSCI\n\nWhat we offer you\n\u2022 Transparent compensation schemes and comprehensive employee benefits, tailored to your location, ensuring your financial security, health, and overall wellbeing.\n\u2022 Flexible working arrangements, advanced technology, and collaborative workspaces.\n\u2022 A culture of high performance and innovation where we experiment with new ideas and take responsibility for achieving results.\n\u2022 A global network of talented colleagues, who inspire, support, and share their expertise to innovate and deliver for our clients.\n\u2022 Global Orientation program to kickstart your journey, followed by access to our Learning@MSCI platform, LinkedIn Learning Pro and tailored learning opportunities for ongoing skills development.\n\u2022 Multi-directional career paths that offer professional growth and development through new challenges, internal mobility and expanded roles.\n\u2022 We actively nurture an environment that builds a sense of inclusion belonging and connection, including eight Employee Resource Groups. All Abilities, Asian Support Network, Black Leadership Network, Climate Action Network, Hola! MSCI, Pride & Allies, Women in Tech, and Women\u2019s Leadership Forum.\n\nAt MSCI we are passionate about what we do, and we are inspired by our purpose \u2013 to power better investment decisions. You\u2019ll be part of an industry-leading network of creative, curious, and entrepreneurial pioneers. This is a space where you can challenge yourself, set new standards and perform beyond expectations for yourself, our clients, and our industry.\n\nMSCI is a leading provider of critical decision support tools and services for the global investment community. With over 50 years of expertise in research, data, and technology, we power better investment decisions by enabling clients to understand and analyze key drivers of risk and return and confidently build more effective portfolios. We create industry-leading research-enhanced solutions that clients use to gain insight into and improve transparency across the investment process.\n\nMSCI Inc. is an equal opportunity employer. It is the policy of the firm to ensure equal employment opportunity without discrimination or harassment on the basis of race, color, religion, creed, age, sex, gender, gender identity, sexual orientation, national origin, citizenship, disability, marital and civil partnership/union status, pregnancy (including unlawful discrimination on the basis of a legally protected parental leave), veteran status, or any other characteristic protected by law. MSCI is also committed to working with and providing reasonable accommodations to individuals with disabilities. If you are an individual with a disability and would like to request a reasonable accommodation for any part of the application process, please email Disability.Assistance@msci.com and indicate the specifics of the assistance needed. Please note, this e-mail is intended only for individuals who are requesting a reasonable workplace accommodation; it is not intended for other inquiries.\n\nTo all recruitment agencies\n\nMSCI does not accept unsolicited CVs/Resumes. Please do not forward CVs/Resumes to any MSCI employee, location, or website. MSCI is not responsible for any fees related to unsolicited CVs/Resumes.\n\nNote on recruitment scams\n\nWe are aware of recruitment scams where fraudsters impersonating MSCI personnel may try and elicit personal information from job seekers. Read our full note on careers.msci.com",
    "url": "https://talentcommunity.msci.com/event-13931/jobs/4056?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-27T00:00:00.000Z"
  },
  {
    "title": "AI Solutions Lead",
    "company": "Syngenta",
    "location": "Pune",
    "salary": "",
    "description": "The AI Solutions Lead will be responsible for:\n\u2022 Architectural Leadership: Leading the design and architecture of AI solutions, ensuring scalability, maintainability, and optimal performance.\n\u2022 Technical Guidance: Collaborating with development teams to understand requirements and provide expert architectural guidance and support.\n\u2022 Business Alignment: Working closely with Product and Business stakeholders to understand their needs and ensure the AI platform effectively meets user requirements.\n\u2022 Cross-functional Collaboration: Partnering with cross-functional stakeholders to translate complex business requirements into robust technical solutions.\n\u2022 Solution Definition: Defining clear implementation approaches, algorithms, and code structures for AI solutions.\n\u2022 Successful Solution Delivery: Taking ultimate accountability for the successful end-to-end delivery of AI solutions, ensuring they are implemented, deployed, and operationalized effectively, meet defined business objectives, adhere to architectural designs and quality standards, and are delivered within project timelines.\n\u2022 Technology Scouting: Staying abreast of the latest trends and emerging technologies in the AI space, evaluating their potential impact, and recommending their introduction into Syngenta's ecosystem.\n\u2022 Experience Architecture: Defining, prototyping, and recommending technology solutions, detailing implementation designs, and identifying interfaces for integration with other products.\n\nCompany Description\n\nJoin Syngenta Group, a leader in agricultural innovation where technology meets purpose. As digital pioneers in AgTech, we're integrating AI across our value chain from smart breeding to precision agriculture. Our global team of 56,000 professionals is transforming sustainable farming worldwide. At Syngenta IT & Digital, your expertise will directly impact food security and shape the future of agriculture through cutting-edge technology.\n\nQualifications\n\u2022 Education:\n\u2022 Degree in Computer Science, AI, ML, Data Science, Engineering, or a related field.\n\u2022 Experience:\n\u2022 4+ years of progressive experience in designing, architecting, and leading the end-to-end delivery of complex AI/ML solutions in a cloud environment.\n\u2022 Demonstrated expertise in AI/ML solution architecture, including model development, deployment, MLOps (Machine Learning Operations), and scalable data pipelines.\n\u2022 Proven experience with major cloud platforms (e.g., AWS, Azure, GCP) and their AI/ML services, specifically in building and operationalizing AI solutions.\n\u2022 Strong understanding of SQL and NoSQL databases, and experience with data warehousing/data lake concepts relevant to AI/ML workloads.\n\u2022 Experience with SAP fundamentals and SAP Joule, or similar enterprise resource planning (ERP) systems, particularly concerning data integration for AI solutions.\n\u2022 Track record of successfully leading technical teams or projects, demonstrating strong project delivery capabilities.\n\u2022 Skills:\n\u2022 Deep technical expertise in AI/ML concepts, algorithms, and frameworks.\n\u2022 Proficiency in programming languages commonly used in AI/ML (e.g., Python, R, Java) for development, prototyping, and integration.\n\u2022 Strong architectural design skills for building scalable, robust, and maintainable AI systems that meet performance and security requirements.\n\u2022 Excellent analytical, critical thinking, and complex problem-solving abilities, with a proven capacity to translate complex business challenges into effective AI solutions.\n\u2022 Exceptional communication, presentation, and stakeholder management skills, with the ability to articulate complex technical concepts clearly to diverse audiences (technical and non-technical).\n\u2022 Ability to lead, mentor, and collaborate effectively within cross-functional and agile teams.\n\u2022 Demonstrated ability to prototype, evaluate, and recommend new technologies and innovative AI solutions, aligning with strategic business objectives.\n\nCritical success factors & key challenges\n\u2022 Solution Design Excellence: Demonstrating strong solution design, logical thinking, and reasoning skills.\n\u2022 Prototyping & Evaluation: Ability to deliver Proofs of Concept (POCs) and Minimum Viable Products (MVPs), and conduct technology evaluations using design thinking practices.\n\u2022 Strategic Prioritization: Orchestrating efforts to prioritize business initiatives across complex and evolving change agendas.\n\u2022 Stakeholder Management: Excellent communication and stakeholder management skills, including the ability to explain complex technical information to non-technical audiences.\n\u2022 Problem Solving & Decision Making: Strong capabilities in problem-solving and decision-making.\n\u2022 Team Leadership: Proven teamwork, team management, and leadership skills.\n\nAdditional Information\n\nWe are a leading, science-based agriculture company, empowering farmers to meet the demands of modern agriculture. Using cutting-edge innovation, we help farmers to grow resilient, healthy crops that can feed a growing global population, while promoting sustainable farming practices that protect and enhance our planet. Headquartered in Switzerland, we are a global agritech leader with more than 30,000 employees across over 90 countries.\n\nhttps://www.syngenta.com/company",
    "url": "https://jobs.syngenta.com/job/ai-solutions-lead-in-in-pune-jid-15234?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "ML Engineer II - Aws, Aws Cloud (Pune)",
    "company": "Peak Hire Solutions",
    "location": "Pune",
    "salary": "",
    "description": "Job Details\n\n- Job Title: ML Engineer II - Aws, Aws Cloud\n\n- Industry: Technology\n\n- Domain - Information technology (IT)\n\n- Experience Required: 6-12 years\n\n- Employment Type: Full Time\n\n- Job Location: Pune\n\n- CTC Range: Best in Industry\n\nJob Description:\n\nCore Responsibilities:\n\n? The MLE will design, build, test, and deploy scalable machine learning systems, optimizing model accuracy and efficiency\n\n? Model Development: Algorithms and architectures span traditional statistical methods to deep learning along with employing LLMs in up-to-date frameworks.\n\n? Data Preparation: Prepare, cleanse, and transform data for model training and evaluation.\n\n? Algorithm Implementation: Implement and optimize machine learning algorithms and statistical models.\n\n? System Integration: Integrate models into existing systems and workflows.\n\n? Model Deployment: Deploy models to production environments and monitor performance.\n\n? Collaboration: Work closely with data scientists, software engineers, and other stakeholders.\n\n? Continuous Improvement: Identify areas for improvement in model performance and systems.\n\nSkills:\n\n? Programming and Software Engineering: Knowledge of software engineering best practices (version control, testing, CI/CD).\n\n? Data Engineering: Ability to handle data pipelines, data cleaning, and feature engineering. Proficiency in SQL for data manipulation + Kafka, Chaossearch logs, etc for troubleshooting; Other tech touch points are ScyllaDB (like BigTable), OpenSearch, Neo4J graph\n\n? Model Deployment and Monitoring: MLOps Experience in deploying ML models to production environments.\n\n? Knowledge of model monitoring and performance evaluation.\n\nRequired experience:\n\n? Amazon SageMaker: Deep understanding of SageMaker's capabilities for building, training, and deploying ML models; understanding of the Sagemaker pipeline with ability to analyze gaps and recommend/implement improvements\n\n? AWS Cloud Infrastructure: Familiarity with S3, EC2, Lambda and using these services in\n\nML workflows\n\n? AWS data: Redshift, Glue\n\n? Containerization and Orchestration: Understanding of Docker and Kubernetes, and their implementation within AWS (EKS, ECS)\n\nSkills: Aws, Aws Cloud, Amazon Redshift, Eks\n\nMust-Haves\n\nAws, Aws Cloud, Amazon Redshift, Eks\n\nNP: Immediate \u2013 30 Days\n\nSkills:- Amazon Web Services (AWS), AWS CloudFormation, Amazon Redshift, Elastic Search, ECS, Docker, Kubernetes, Machine Learning (ML), MLOps, Neo4J, SQL, Algorithms, Architecture, Statistical Modeling, Large Language Models (LLM) and Deep Learning",
    "url": "https://in.jobrapido.com/jobpreview/6078549723050934272?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Senior Agentic AI Engineer",
    "company": "Teradata",
    "location": "Pune",
    "salary": "",
    "description": "Our Company:\n\nAt Teradata, we're not just managing data; we're unleashing its full potential. Our ClearScape Analytics\u2122 platform and pioneering Enterprise Vector Store are empowering the world's largest enterprises to derive unprecedented value from their most complex data. We're rapidly pushing the boundaries of what's possible with Artificial Intelligence, especially in the exciting realm of autonomous and agentic systems\n\nWe\u2019re building intelligent systems that go far beyond automation \u2014 they observe, reason, adapt, and drive complex decision-making across large-scale enterprise environments. As a member of our AI engineering team, you\u2019ll play a critical role in designing and deploying advanced AI agents that integrate deeply with business operations, turning data into insight, action, and measurable outcomes.\n\nYou\u2019ll work alongside a high-caliber team of AI researchers, engineers, and data scientists tackling some of the hardest problems in AI and enterprise software \u2014 from scalable multi-agent coordination and fine-tuned LLM applications, to real-time monitoring, drift detection, and closed-loop retraining systems.\n\nIf you're passionate about building intelligent systems that are not only powerful but observable, resilient, and production-ready, this role offers the opportunity to shape the future of enterprise AI from the ground up.\n\nWe are seeking a highly skilled Senior AI Engineer to drive the development and deployment of Agentic AI systems with a strong emphasis on AI observability and data platform integration. You will work at the forefront of cutting-edge AI research and its practical application\u2014designing, implementing, and monitoring intelligent agents capable of autonomous reasoning, decision-making, and continuous learning.\n\nIgnite the Future of AI at Teradata!\n\nWhat You'll Do: Shape the Way the World Understands Data\n\nAs a senior Agentic AI Engineer at Teradata, you\u2019ll build cutting-edge intelligent agents that transform how users explore data, derive insights, and automate workflows across industries such as healthcare, finance, and telecommunications.\n\nYou will:\n\u2022 Design and implement autonomous AI agents for semantic search, text-to-SQL translation, and analytical task execution.\n\u2022 Develop modular prompts, reasoning chains, and decision graphs tailored to complex enterprise use cases.\n\u2022 Enhance agent performance through experimentation with LLMs, prompt tuning, and advanced reasoning workflows.\n\u2022 Integrate agents with Teradata\u2019s Model Context Protocol (MCP) to enable seamless interaction with model development pipelines.\n\u2022 Build tools that allow agents to monitor training jobs, evaluate models, and interact with unstructured and structured data sources.\n\u2022 Work on retrieval-augmented generation (RAG) pipelines and extend agents to downstream ML systems.\n\nWho You'll Work With: Join Forces with the Best\n\nYou\u2019ll collaborate with a world-class team of AI architects, ML engineers, and domain experts at Silicon Valley, working together to build the next generation of enterprise AI systems.\n\nYou\u2019ll also work cross-functionally with:\n\u2022 Product managers and UX designers to craft agentic workflows that are intuitive and impactful.\n\u2022 Domain specialists to ensure solutions align with real-world business problems in regulated industries.\n\u2022 Infrastructure and platform teams responsible for training, evaluation, and scaling AI workloads.\n\nThis is a rare opportunity to shape foundational AI capabilities within a global, data-driven company.\n\nThis is a deeply collaborative environment where technical innovation meets real-world application, where your ideas are not only heard but implemented to shape the next generation of data interaction.\n\nWhat Makes You a Qualified Candidate: Skills in Action\n\u2022 5+ years of product engineering experience in AI/ML, with strong software development fundamentals.\n\u2022 Proficiency with LLM APIs (e. g. , OpenAI, Claude, Gemini) and agent frameworks such as AutoGen, LangGraph, AgentBuilder, or CrewAI.\n\u2022 Experience designing multi-step reasoning chains, prompt pipelines, or intelligent workflows.\n\u2022 Familiarity with agent evaluation metrics: correctness, latency, failure modes.\n\u2022 Passion for building production-grade systems that bring AI to life.\n\nWhat You Bring: Passion and Potential\n\u2022 Master\u2019s or Ph. D. in Computer Science, AI, or a related field, or equivalent industry experience.\n\u2022 Experience working with multimodal inputs, retrieval systems, or structured knowledge sources.\n\u2022 Deep understanding of enterprise data workflows and scalable AI architectures.\n\u2022 Prior exposure to MCP or similar orchestration/protocol systems.\n\nWhy We Think You\u2019ll Love Teradata\n\nWe prioritize a people-first culture because we know our people are at the very heart of our success. We embrace a flexible work model because we trust our people to make decisions about how, when, and where they work. We focus on well-being because we care about our people and their ability to thrive both personally and professionally. We are an anti-racist company because our dedication to Diversity, Equity, and Inclusion is more than a statement. It is a deep commitment to doing the work to foster an equitable environment that celebrates people for all of who they are.\n\nTeradata invites all identities and backgrounds in the workplace. We work with deliberation and intent to ensure we are cultivating collaboration and inclusivity across our global organization. We are proud to be an equal opportunity and affirmative action employer. We do not discriminate based upon race, color, ancestry, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related conditions), national origin, sexual orientation, age, citizenship, marital status, disability, medical condition, genetic information, gender identity or expression, military and veteran status, or any other legally protected status.",
    "url": "https://in.linkedin.com/jobs/view/senior-agentic-ai-engineer-at-teradata-4319335059?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Data Scientist/Machine Learning Engineer Assistant vice president",
    "company": "Early Career",
    "location": "Pune",
    "salary": "",
    "description": "ML Solutions team within Markets OPS Technology is dedicated to developing solutions using Artificial Intelligence, Machine Learning and Generative AI. This team is a leader in creating new ideas, innovative technology solutions, and ground-breaking solutions for Markets Operations and Other Line of Businesses. We work closely with our clients and business partners to progress solutions from ideation to production by leveraging the entrepreneurial spirit and technological excellence.\n\nJob Description:\n\nThe ML Solutions team is seeking a Data Scientist/Machine Learning Engineer to drive the design, development, and deployment of innovative AI/ML and GenAI-based solutions. In this hands-on role, you will leverage your expertise to create a variety of AI models, guiding a team from initial concept to successful production. A key aspect involves mentoring team members and fostering their growth. You will collaborate closely with business partners and stakeholders, championing the adoption of these advanced technologies to enhance client experiences, deliver tangible value to our customers, and ensure adherence to regulatory requirements through cutting-edge technical solutions. This position offers a unique opportunity to shape the future of our AI initiatives and make a significant impact on the organization.\n\nKey Responsibilities:\n\u2022 Hands-On Execution and Delivery: Actively contribute to the development and delivery of AI solutions, driving innovation and excellence within the team. Take a hands-on approach to ensure AI models are successfully deployed into production environments, meeting high-quality standards and performance benchmarks.\n\u2022 Mentoring Young Talents: Mentoring team, guiding data analysts/ML engineers from concept to production. This involves fostering technical growth, providing project oversight, and ensuring adherence to best practices, ultimately building a high-performing and innovative team.\n\u2022 Quality Control: Ensure the quality and performance of generative AI models, conducting rigorous testing and evaluation.\n\u2022 Research and Development: Participate in research activities to explore and advance state-of-the-art generative AI techniques. Stay actively engaged in monitoring ongoing research efforts, keeping abreast of emerging trends, and ensuring that the Generative AI team remains at the forefront of the field.\n\u2022 Cross-Functional Collaboration: Collaborate effectively with various teams, including product managers, engineers, and data scientists, to integrate AI technologies into products and services.\n\nSkills & Qualifications:\n\u2022 8 to 13 years of Strong hands-on experience in Machine Learning, delivering complex solutions to production.\n\u2022 Experience with Generative AI technologies essential.\n\u2022 Understanding of concepts like supervised, unsupervised, clustering, embedding.\n\u2022 Knowledge of NLP, Name Entity Recognition, Computer Vision, Transformers, Large Language Models.\n\u2022 In-depth knowledge of deep learning and Generative AI frameworks such as, Langchain, Lang Graph, Crew AI or similar.\n\u2022 Experience with and other open-source frameworks/ libraries/ APIs like Hugging Face Transformers, Spacy, Pandas, scikit-learn, NumPy, OpenCV.\n\u2022 Experience in using Machine Learning/Deep Learning: XGBoost, LightGBM, TensorFlow, PyTorch, Keras.\n\u2022 Proficiency in Python Software Development, following Object-Oriented design patterns and best practices.\n\u2022 Strong background in mathematics: linear algebra, probability, statistics, and optimization.\n\u2022 Experience with evaluation, scoring with framework like ML Flow\n\u2022 Experience of Docker container and edited a Docker file, experience with K8s is a plus.\n\u2022 Experience with Postgres and Vector DBs a plus.\n\u2022 Excellent problem-solving skills and the ability to think creatively.\n\u2022 Strong communication and collaboration skills, with the ability to work effectively with cross-functional teams\n\u2022 Publications and contributions to the AI research community are a plus.\n\u2022 Master\u2019s degree/Ph. D. or equivalent experience in Computer Science, Data Science, Statistics, or a related field.\n\u2022 8-12 years of experience\n\nThis job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.\n\n------------------------------------------------------\n\nJob Family Group:\nTechnology\n\n------------------------------------------------------\n\nJob Family:\nApplications Development\n\n------------------------------------------------------\n\nTime Type:\nFull time\n\n------------------------------------------------------\n\nMost Relevant Skills\nPlease see the requirements listed above.\n\n------------------------------------------------------\n\nOther Relevant Skills\nData Science, Machine Learning.\n\n------------------------------------------------------\n\nCiti is an equal opportunity employer, and qualified candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other characteristic protected by law.\n\nIf you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.\n\nView Citi\u2019s EEO Policy Statement and the Know Your Rights poster.",
    "url": "https://jobs.citi.com/job/pune/data-scientist-machine-learning-engineer-assistant-vice-president/287/83901989456?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "AI/ML Platform Engineer",
    "company": "Johnson Controls International",
    "location": "Pune",
    "salary": "",
    "description": "Job Title: Senior Data Scientist \u2013 Data & Analytics\n\nJohnson Controls International (JCI) is seeking a Senior Data Scientist to join our innovative and impact-driven Data Science and Analytics team. This role is ideal for a seasoned expert with a deep understanding of machine learning, AI, and cloud data platforms, and a strong grasp of the latest advancements in Generative AI and Large Language Models (LLMs).\n\nAs a Senior Data Scientist, you will lead the development and deployment of scalable AI solutions\u2014including those powered by LLMs\u2014to accelerate digital transformation across our products, operations, and customer experiences. You'll play a critical role in shaping JCI\u2019s data science strategy, mentoring teams, and driving the use of AI to deliver measurable business value.\n\nHow you will do it\n\nAdvanced Analytics, LLMs & Modeling\n\u2022 Design and implement advanced machine learning models including deep learning, time-series forecasting, recommendation engines, and LLM-based solutions (e.g., GPT, LLaMA, Claude).\n\u2022 Develop use cases around enterprise search, document summarization, conversational AI, and automated knowledge retrieval using large language models.\n\u2022 Fine-tune or prompt-engineer foundation models (e.g., OpenAI, Azure OpenAI, Hugging Face) for domain-specific applications.\n\u2022 Evaluate and optimize LLM performance, latency, cost-effectiveness, and hallucination mitigation strategies for production use.\n\nData Strategy & Engineering Collaboration\n\u2022 Work closely with data and ML engineering teams to integrate LLM-powered applications into scalable, secure, and reliable pipelines.\n\u2022 Contribute to the development of retrieval-augmented generation (RAG) architectures using vector databases (e.g., FAISS, Azure Cognitive Search).\n\u2022 Support the deployment of models using MLOps principles, ensuring robust monitoring and lifecycle management.\n\nBusiness Impact & AI Strategy\n\u2022 Partner with cross-functional stakeholders to identify opportunities for applying LLMs and generative AI to solve complex business challenges.\n\u2022 Lead workshops or proofs-of-concept to demonstrate value of LLM use cases across business units.\n\u2022 Translate complex model outputs, including those from LLMs, into clear insights and decision support tools for non-technical audiences.\n\nThought Leadership & Mentorship\n\u2022 Act as an internal thought leader on AI and LLM innovation, keeping JCI at the forefront of industry advancements.\n\u2022 Mentor and upskill data science team members in advanced AI techniques, including transformer models and generative AI frameworks.\n\u2022 Contribute to strategic roadmaps for generative AI and model governance within the enterprise.\n\nQualifications & Experience\n\u2022 Education in Data Science, Artificial Intelligence, Computer Science, or related quantitative discipline.\n\u2022 5+ years of hands-on experience in data science, including at least 1\u20132 years working with LLMs or generative AI technologies.\n\u2022 Demonstrated success in deploying machine learning and NLP solutions at scale.\n\u2022 Proven experience with cloud AI platforms\u2014especially Azure OpenAI, Azure ML, Hugging Face, or AWS Bedrock.\n\nTechnical Expertise\n\u2022 Proficiency in Python and SQL, including libraries like Transformers (Hugging Face), LangChain, PyTorch, and TensorFlow.\n\u2022 Experience with prompt engineering, fine-tuning, and LLM orchestration tools.\n\u2022 Familiarity with data storage, retrieval systems, and vector databases.\n\u2022 Strong understanding of model evaluation techniques for generative AI, including factuality, relevance, and toxicity metrics.\n\nLeadership & Soft Skills\n\u2022 Strategic thinker with a strong ability to align AI initiatives to business goals.\n\u2022 Excellent communication and storytelling skills, especially in articulating the value of LLMs and advanced analytics.\n\u2022 Strong collaborator with a track record of influencing stakeholders across product, engineering, and executive teams.\n\nPreferred Qualifications\n\u2022 Experience with IoT, edge analytics, or smart building systems.\n\u2022 Familiarity with LLMOps, LangChain, Semantic Kernel, or similar orchestration frameworks.\n\u2022 Knowledge of data privacy and governance considerations specific to LLM usage in enterprise environments.",
    "url": "https://jobs.johnsoncontrols.com/job/WD30254347?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "AI Ml Engineer  Freshers",
    "company": "Agiliad",
    "location": "Pune",
    "salary": "",
    "description": "Required Skills:\n\u2022 Strong understanding of Machine Learning, Deep Learning, and Generative AI concepts.\n\u2022 Good knowledge of Python, TensorFlow, PyTorch, Keras, and Scikit-learn.\n\u2022 Understanding of Statistics, Linear Algebra, and Probability.\n\u2022 Familiarity with AI Ops tools, Docker, Git, and Azure is a plus.\n\u2022 Excellent problem-solving and analytical skills.\n\nEligibility Criteria:\n\u2022 Education: B.E/B.Tech/M.Tech/B.Sc/M.Sc in Computer Science, IT, AI/ML, or related fields.\n\u2022 Academic Performance: Minimum 80% or above in 10th, 12th, and Graduation.\n\u2022 Batch: 2024 / 2025 Pass-out.\n\u2022 Skill -Good Communication.",
    "url": "https://in.bebee.com/job/8cfee268fce41499651d7f3c4987aa05?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "\u25b7 High Salary : Generative AI Engineer",
    "company": "Talent Corner HR Services Pvt Ltd",
    "location": "Pune",
    "salary": "",
    "description": "Experience Required : 4-6 Years\n\nJob Summary :\n\u2022 Proven experience in content management, data architecture, and AI\n\u2022 technologies\n\u2022 Design content structures that optimize the usability and retrieval of data by\n\u2022 LLMs and RAG systems.\n\u2022 Strong understanding of LLMs and RAG systems and their application in\n\u2022 business contexts.\n\u2022 Problem-solving skills with a proactive approach to identifying and addressing\n\u2022 challenges.\n\u2022 Design and maintain a robust data architecture that supports efficient content\n\u2022 retrieval and generation.\n\u2022 Ensure content is optimized for AI consumption, including proper formatting,\n\u2022 tagging, and metadata application.\n\u2022 Experience in JIRA, Confluence, Bit Bucket, Azure Repo etc.\n\u2022 Strong Computer Science fundamentals in object-oriented design, data\n\u2022 structures, design patterns and algorithm design.\n\u2022 Strong debug and troubleshooting skills.\n\u2022 Aware of CI / CD techniques and tools like Azure Pipeline.\n\nWhat do we expect from you?\n\u2022 Bachelor\u2019s or Master\u2019s degree in Computer Science, Information Technology, or a related field.\n\u2022 Proven experience in building Azure Cloud solutions.\n\u2022 Experience with content management systems (CMS) and data management tools.\n\u2022 Familiarity with AI / ML frameworks and libraries.\n\u2022 Knowledge of global content standards and regional data regulations.\n\u2022 Familiarity with CI / CD pipelines and version control systems such as Git.\n\u2022 Strong debug and troubleshooting skills.\n\u2022 Effective oral and written communication skills; ability to articulate clearly and concisely.\n\u2022 You have worked with Agile Methodologies following SCRUM.\n\nQualifications :\n\u2022 4 to 6 years of strong hands-on experience in Python programming\n\u2022 Minimum 2 years of experience working with AI tools and technologies\n\u2022 At least 1 year of experience as a Generative AI Content Architect\n\u2022 Successfully delivered 2\u20133 AI implementation projects or use cases\n\u2022 Solid understanding of AI solution implementation, including data architect and content management.",
    "url": "https://in.talent.com/view?id=bf7d30325688&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Artificial Intelligence & Machine Learning Engineer",
    "company": "confidential",
    "location": "Pune",
    "salary": "",
    "description": "JOB DESCRIPTION\n\nJob Summary:\nAs a Machine Learning Engineer at Emerson, you will be responsible for developing, implementing, and optimizing machine learning models and systems. You will collaborate closely with data scientists, software engineers, and other collaborators to translate data insights into practical, scalable solutions\nDesign, build, and deploy machine learning models and algorithms to solve specific business problems. Optimize models for performance and scalability.\nWork with large data sets to preprocess, clean, and transform data for use in machine learning models. Develop and maintain data pipelines.\nMonitor and evaluate the performance of deployed models, making adjustments and improvements as needed to ensure accuracy and reliability.\nWork with multi-functional teams such as data scientists, analysts, and product managers to understand requirements and deliver machine learning solutions that meet business needs.\nKeep up with the latest research and trends in machine learning and artificial intelligence. Explore and implement new techniques and technologies to enhance model performance.\nDocument model development processes, code, and standard methodologies. Provide clear and comprehensive reports on model performance and metrics\nParticipate in regular Scrum events such as Sprint Planning, Sprint Review, and Sprint Retrospective\nInthisRole,YourResponsibilitiesWill b e:\nDesign, build, and deploy machine learning models and algorithms to solve specific business problems. Optimize models for performance and scalability.\nWork with large data sets to preprocess, clean, and transform data for use in machine learning models. Develop and maintain data pipelines.\nMonitor and evaluate the performance of deployed models, making adjustments and improvements as needed to ensure accuracy and reliability.\nWork with multi-functional teams such as data scientists, analysts, and product managers to understand requirements and deliver machine learning solutions that meet business needs.\nKeep up with the latest research and trends in machine learning and artificial intelligence. Explore and implement new techniques and technologies to enhance model performance.\nDocument model development processes, code, and standard methodologies. Provide clear and comprehensive reports on model performance and metrics\nParticipate in regular Scrum events such as Sprint Planning, Sprint Review, and Sprint Retrospective\nWhoYou Are:\n\nYou quickly and decisively act in constantly evolving, unexpected situations. You adjust communicationcontentandstyletomeettheneedsofdiversepartners.Youalwayskeeptheend in sight puts in extra effort to meet deadlines. You analyze multiple and diverse sources of informationtodefineproblemsaccuratelybeforemovingtosolutions.Youobservesituationaland group dynamics and select best-fit approach.\nForThisRole,YouWill Need:\nBachelor's degree in computer science, Data Science, Statistics, or a related field or a master's degree or higher is preferred.\nMore than 3 years of experience in machine learning engineering or a related role, with a strong track record of developing and deploying machine learning models.\nProficiency in programming languages such as Python or R. Experience with machine learning frameworks (e.g., Go, TensorFlow, PyTorch, scikit-learn).\nExperience with Azure Cognitive services\nExperience with data processing and manipulation tools and libraries (e.g., pandas, NumPy).\nStrong analytical and problem-solving skills, with the ability to handle complex and large-scale data sets.\nExperience with deploying machine learning models to production environments, including knowledge of containerization technologies (e.g., Docker or equivalent) and cloud platforms, Microsoft Azure is preferred\nExcellent verbal and written communication skills, with the ability to explain technical concepts to non-technical collaborators\nPreferredQualificationsthatSetYou Apart:\n\nPrior experience in engineering domain would be nice to have\nPrior experience in working with teams in Scaled Agile Framework (SAFe) is nice to have\nPossession of relevant certification/s in data science from reputed universities specializing in AI.\nFamiliarity with version control systems (e.g., Git) and CI/CD pipelines.\nUnderstanding of standard processes in software development and methodologies.",
    "url": "https://in.jooble.org/rjdp/-6265525461943023084?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Data AI Engineering Senior Associate",
    "company": "MSCI",
    "location": "Pune",
    "salary": "",
    "description": "Your Team Responsibilities\n\nThe AI Engineering team at MSCI is seeking a Senior Associate to help build and scale our internal platform for deploying intelligent agents. This platform enables developers and non-technical teams to quickly build, test, and deploy agents that interact with internal APIs and data while respecting entitlements and data boundaries.\n\nYou will work in close collaboration with engineers across cloud infrastructure, ML ops, and security to ensure the agent platform is robust, flexible, and easy to use. This role requires a passion for platform usability, developer experience, and pragmatic engineering in cross-cloud (Azure + GCP) environments.\n\nYour Key Responsibilities\n\u2022 Implement and improve internal tooling and runtimes for deploying agent-based applications across MSCI teams.\n\u2022 Integrate entitlement and data-privacy policies into AI workflows using internal security and identity layers.\n\u2022 Develop reusable libraries and interfaces for agents to interact with MSCI services via MCP and additional integrations.\n\u2022 Collaborate with UX and internal client teams to build low-friction, high-compliance agent deployment pathways.\n\u2022 Contribute to observability, sandboxing, and monitoring capabilities for agent executions and workflows.\n\nYour skills and experience that will help you excel\n\u2022 Strong experience building platforms or tooling used by other engineers, ideally in agentic or ML-enabled systems.\n\u2022 Proficient in Python, Typescript, or Go, with experience deploying apps or services in Azure and/or GCP.\n\u2022 Understanding of prompt engineering, LLM orchestration tools (e.g., LangChain, google ADK), and multi-agent patterns.\n\u2022 Familiarity with RBAC, authentication standards (OAuth, SAML), and entitlements in enterprise systems.\n\u2022 Enthusiastic about developer productivity and the impact of well-designed internal platforms.\n\nAbout MSCI\n\nWhat we offer you\n\u2022 Transparent compensation schemes and comprehensive employee benefits, tailored to your location, ensuring your financial security, health, and overall wellbeing.\n\u2022 Flexible working arrangements, advanced technology, and collaborative workspaces.\n\u2022 A culture of high performance and innovation where we experiment with new ideas and take responsibility for achieving results.\n\u2022 A global network of talented colleagues, who inspire, support, and share their expertise to innovate and deliver for our clients.\n\u2022 Global Orientation program to kickstart your journey, followed by access to our Learning@MSCI platform, LinkedIn Learning Pro and tailored learning opportunities for ongoing skills development.\n\u2022 Multi-directional career paths that offer professional growth and development through new challenges, internal mobility and expanded roles.\n\u2022 We actively nurture an environment that builds a sense of inclusion belonging and connection, including eight Employee Resource Groups. All Abilities, Asian Support Network, Black Leadership Network, Climate Action Network, Hola! MSCI, Pride & Allies, Women in Tech, and Women\u2019s Leadership Forum.\n\nAt MSCI we are passionate about what we do, and we are inspired by our purpose \u2013 to power better investment decisions. You\u2019ll be part of an industry-leading network of creative, curious, and entrepreneurial pioneers. This is a space where you can challenge yourself, set new standards and perform beyond expectations for yourself, our clients, and our industry.\n\nMSCI is a leading provider of critical decision support tools and services for the global investment community. With over 50 years of expertise in research, data, and technology, we power better investment decisions by enabling clients to understand and analyze key drivers of risk and return and confidently build more effective portfolios. We create industry-leading research-enhanced solutions that clients use to gain insight into and improve transparency across the investment process.\n\nMSCI Inc. is an equal opportunity employer. It is the policy of the firm to ensure equal employment opportunity without discrimination or harassment on the basis of race, color, religion, creed, age, sex, gender, gender identity, sexual orientation, national origin, citizenship, disability, marital and civil partnership/union status, pregnancy (including unlawful discrimination on the basis of a legally protected parental leave), veteran status, or any other characteristic protected by law. MSCI is also committed to working with and providing reasonable accommodations to individuals with disabilities. If you are an individual with a disability and would like to request a reasonable accommodation for any part of the application process, please email Disability.Assistance@msci.com and indicate the specifics of the assistance needed. Please note, this e-mail is intended only for individuals who are requesting a reasonable workplace accommodation; it is not intended for other inquiries.\n\nTo all recruitment agencies\n\nMSCI does not accept unsolicited CVs/Resumes. Please do not forward CVs/Resumes to any MSCI employee, location, or website. MSCI is not responsible for any fees related to unsolicited CVs/Resumes.\n\nNote on recruitment scams\n\nWe are aware of recruitment scams where fraudsters impersonating MSCI personnel may try and elicit personal information from job seekers. Read our full note on careers.msci.com",
    "url": "https://talentcommunity.msci.com/event-13931/jobs/4056?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-27T00:00:00.000Z"
  },
  {
    "title": "AI Solutions Lead",
    "company": "Syngenta",
    "location": "Pune",
    "salary": "",
    "description": "The AI Solutions Lead will be responsible for:\n\u2022 Architectural Leadership: Leading the design and architecture of AI solutions, ensuring scalability, maintainability, and optimal performance.\n\u2022 Technical Guidance: Collaborating with development teams to understand requirements and provide expert architectural guidance and support.\n\u2022 Business Alignment: Working closely with Product and Business stakeholders to understand their needs and ensure the AI platform effectively meets user requirements.\n\u2022 Cross-functional Collaboration: Partnering with cross-functional stakeholders to translate complex business requirements into robust technical solutions.\n\u2022 Solution Definition: Defining clear implementation approaches, algorithms, and code structures for AI solutions.\n\u2022 Successful Solution Delivery: Taking ultimate accountability for the successful end-to-end delivery of AI solutions, ensuring they are implemented, deployed, and operationalized effectively, meet defined business objectives, adhere to architectural designs and quality standards, and are delivered within project timelines.\n\u2022 Technology Scouting: Staying abreast of the latest trends and emerging technologies in the AI space, evaluating their potential impact, and recommending their introduction into Syngenta's ecosystem.\n\u2022 Experience Architecture: Defining, prototyping, and recommending technology solutions, detailing implementation designs, and identifying interfaces for integration with other products.\n\nCompany Description\n\nJoin Syngenta Group, a leader in agricultural innovation where technology meets purpose. As digital pioneers in AgTech, we're integrating AI across our value chain from smart breeding to precision agriculture. Our global team of 56,000 professionals is transforming sustainable farming worldwide. At Syngenta IT & Digital, your expertise will directly impact food security and shape the future of agriculture through cutting-edge technology.\n\nQualifications\n\u2022 Education:\n\u2022 Degree in Computer Science, AI, ML, Data Science, Engineering, or a related field.\n\u2022 Experience:\n\u2022 4+ years of progressive experience in designing, architecting, and leading the end-to-end delivery of complex AI/ML solutions in a cloud environment.\n\u2022 Demonstrated expertise in AI/ML solution architecture, including model development, deployment, MLOps (Machine Learning Operations), and scalable data pipelines.\n\u2022 Proven experience with major cloud platforms (e.g., AWS, Azure, GCP) and their AI/ML services, specifically in building and operationalizing AI solutions.\n\u2022 Strong understanding of SQL and NoSQL databases, and experience with data warehousing/data lake concepts relevant to AI/ML workloads.\n\u2022 Experience with SAP fundamentals and SAP Joule, or similar enterprise resource planning (ERP) systems, particularly concerning data integration for AI solutions.\n\u2022 Track record of successfully leading technical teams or projects, demonstrating strong project delivery capabilities.\n\u2022 Skills:\n\u2022 Deep technical expertise in AI/ML concepts, algorithms, and frameworks.\n\u2022 Proficiency in programming languages commonly used in AI/ML (e.g., Python, R, Java) for development, prototyping, and integration.\n\u2022 Strong architectural design skills for building scalable, robust, and maintainable AI systems that meet performance and security requirements.\n\u2022 Excellent analytical, critical thinking, and complex problem-solving abilities, with a proven capacity to translate complex business challenges into effective AI solutions.\n\u2022 Exceptional communication, presentation, and stakeholder management skills, with the ability to articulate complex technical concepts clearly to diverse audiences (technical and non-technical).\n\u2022 Ability to lead, mentor, and collaborate effectively within cross-functional and agile teams.\n\u2022 Demonstrated ability to prototype, evaluate, and recommend new technologies and innovative AI solutions, aligning with strategic business objectives.\n\nCritical success factors & key challenges\n\u2022 Solution Design Excellence: Demonstrating strong solution design, logical thinking, and reasoning skills.\n\u2022 Prototyping & Evaluation: Ability to deliver Proofs of Concept (POCs) and Minimum Viable Products (MVPs), and conduct technology evaluations using design thinking practices.\n\u2022 Strategic Prioritization: Orchestrating efforts to prioritize business initiatives across complex and evolving change agendas.\n\u2022 Stakeholder Management: Excellent communication and stakeholder management skills, including the ability to explain complex technical information to non-technical audiences.\n\u2022 Problem Solving & Decision Making: Strong capabilities in problem-solving and decision-making.\n\u2022 Team Leadership: Proven teamwork, team management, and leadership skills.\n\nAdditional Information\n\nWe are a leading, science-based agriculture company, empowering farmers to meet the demands of modern agriculture. Using cutting-edge innovation, we help farmers to grow resilient, healthy crops that can feed a growing global population, while promoting sustainable farming practices that protect and enhance our planet. Headquartered in Switzerland, we are a global agritech leader with more than 30,000 employees across over 90 countries.\n\nhttps://www.syngenta.com/company",
    "url": "https://jobs.syngenta.com/job/ai-solutions-lead-in-in-pune-jid-15234?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "ML Engineer II - Aws, Aws Cloud (Pune)",
    "company": "Peak Hire Solutions",
    "location": "Pune",
    "salary": "",
    "description": "Job Details\n\n- Job Title: ML Engineer II - Aws, Aws Cloud\n\n- Industry: Technology\n\n- Domain - Information technology (IT)\n\n- Experience Required: 6-12 years\n\n- Employment Type: Full Time\n\n- Job Location: Pune\n\n- CTC Range: Best in Industry\n\nJob Description:\n\nCore Responsibilities:\n\n? The MLE will design, build, test, and deploy scalable machine learning systems, optimizing model accuracy and efficiency\n\n? Model Development: Algorithms and architectures span traditional statistical methods to deep learning along with employing LLMs in up-to-date frameworks.\n\n? Data Preparation: Prepare, cleanse, and transform data for model training and evaluation.\n\n? Algorithm Implementation: Implement and optimize machine learning algorithms and statistical models.\n\n? System Integration: Integrate models into existing systems and workflows.\n\n? Model Deployment: Deploy models to production environments and monitor performance.\n\n? Collaboration: Work closely with data scientists, software engineers, and other stakeholders.\n\n? Continuous Improvement: Identify areas for improvement in model performance and systems.\n\nSkills:\n\n? Programming and Software Engineering: Knowledge of software engineering best practices (version control, testing, CI/CD).\n\n? Data Engineering: Ability to handle data pipelines, data cleaning, and feature engineering. Proficiency in SQL for data manipulation + Kafka, Chaossearch logs, etc for troubleshooting; Other tech touch points are ScyllaDB (like BigTable), OpenSearch, Neo4J graph\n\n? Model Deployment and Monitoring: MLOps Experience in deploying ML models to production environments.\n\n? Knowledge of model monitoring and performance evaluation.\n\nRequired experience:\n\n? Amazon SageMaker: Deep understanding of SageMaker's capabilities for building, training, and deploying ML models; understanding of the Sagemaker pipeline with ability to analyze gaps and recommend/implement improvements\n\n? AWS Cloud Infrastructure: Familiarity with S3, EC2, Lambda and using these services in\n\nML workflows\n\n? AWS data: Redshift, Glue\n\n? Containerization and Orchestration: Understanding of Docker and Kubernetes, and their implementation within AWS (EKS, ECS)\n\nSkills: Aws, Aws Cloud, Amazon Redshift, Eks\n\nMust-Haves\n\nAws, Aws Cloud, Amazon Redshift, Eks\n\nNP: Immediate \u2013 30 Days\n\nSkills:- Amazon Web Services (AWS), AWS CloudFormation, Amazon Redshift, Elastic Search, ECS, Docker, Kubernetes, Machine Learning (ML), MLOps, Neo4J, SQL, Algorithms, Architecture, Statistical Modeling, Large Language Models (LLM) and Deep Learning",
    "url": "https://in.jobrapido.com/jobpreview/6078549723050934272?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "\u25b7 (High Salary) Generative AI Engineer",
    "company": "Ascendion",
    "location": "Pune",
    "salary": "",
    "description": "Position Details :\n\nJob Title : GenAI Engineer\n\nExperience : 3+ years\n\nLocation Options : Pune\n\nSkills : Python, Langchain, Langgraph, Autogen\n\nOverview :\n\nWe are actively seeking highly skilled GenAI Engineers. The ideal candidates will bring hands-on experience in developing and deploying Generative AI (GenAI) solutions from MVP to production.\n\nKey Skills :\n\u2022 Python, Langchain, Langgraph, Autogen\n\u2022 Ai agents build (multi-Agent orchestration)\n\u2022 Build and orchestrate AI agents, including multi-agent systems using frameworks like LangChain, LangGraph, and AutoGen.\n\u2022 Collaborate with cross-functional teams to integrate agents with external tools (e.g., GitHub, web UIs). Worked on integrating tools with agent ex., GitHub, ui etc\n\u2022 Work in an agile environment to rapidly prototype and transition MVPs to production. Worked on mvp to production for genai solution\n\u2022 Support and optimize RAG (Retrieval-Augmented Generation) pipelines.\n\u2022 Contribute to prompt engineering strategies and scalable GenAI infrastructure. Experience on prompt engineering and rag setup and support\n\u2022 Leverage Databricks for model development, data preparation, and orchestration. Proficiency in Databricks for ML / AI workflows.",
    "url": "https://in.talent.com/view?id=aa56bd025e37&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Machine Learning Engineer (MLE) \u2013 Python | DS | DE | ETL | Azure | Databricks",
    "company": "Apptware",
    "location": "Pune",
    "salary": "",
    "description": "Job description\n\nPosition: Machine Learning Engineer (MLE) \u2013 Python | DS | DE | ETL | Azure | Databricks\n\n\ud83d\udd39 Experience: 4\u20138 years\n\n\ud83d\udd39 Location: Pune / Bangalore\n\n\ud83d\udd39 Employment Type: Full-time\n\nJob Description:\n\nWe are seeking an experienced Machine Learning Engineer (MLE) with strong expertise in Python, Data Science (DS), Data Engineering (DE), ETL, and Azure Databricks. The ideal candidate will design, build, and deploy scalable ML solutions while collaborating with data and engineering teams to solve complex business challenges.\n\nKey Responsibilities:\n\u2022 Design and implement end-to-end ML pipelines using Databricks and Azure.\n\u2022 Develop, train, and deploy machine learning models for various business use cases.\n\u2022 Perform data preprocessing, feature engineering, and model optimization on large datasets.\n\u2022 Integrate ML models with production systems and ensure performance monitoring.\n\u2022 Collaborate with cross-functional teams to understand business needs and deliver effective ML solutions.\n\u2022 Stay updated with the latest trends in ML, DL, and AI frameworks.\n\nRequired Skills:\n\u2022 Python (Advanced) \u2013 Must\n\u2022 Data Science (DS), Data Engineering (DE), and ETL \u2013 Must\n\u2022 Machine Learning (ML) \u2013 Must\n\u2022 Deep Learning (Basic Understanding) \u2013 Good to have\n\u2022 Natural Language Processing (NLP) \u2013 Basic Understanding\n\u2022 Computer Vision \u2013 Basic Understanding\n\u2022 Python for Image Processing \u2013 Basic Understanding\n\u2022 ML Frameworks (TensorFlow / PyTorch / Scikit-learn) \u2013 Must\n\u2022 Azure Cloud \u2013 Must\n\u2022 Databricks \u2013 Must\n\nGood to Have:\n\u2022 Experience with Agile Methodology\n\u2022 Exposure to MLOps and CI/CD pipelines\n\u2022 Familiarity with data visualization tools like Power BI or Tableau\n\nAdditional Details:\n\u2022 Immediate joiners preferred\n\u2022 Candidates with up to 30 days\u2019 notice period can be considered\n\nApply Here: https://forms.gle/PNgXBb3QJh57Uqd79",
    "url": "https://in.linkedin.com/jobs/view/machine-learning-engineer-mle-%E2%80%93-python-ds-de-etl-azure-databricks-at-apptware-4331708651?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "AI/ML Engineer-Automotive",
    "company": "Quest Global",
    "location": "Pune",
    "salary": "",
    "description": "Job Requirements\n\nWe are looking for an experienced AI/ML Engineer to design, develop and deploy machine learning algorithms on embedded platforms for the next generation automotive infotainment systems. This engineer will work on Android / Linux based applications that will process various sensor data and external input at real-time to predict various vehicle conditions and adjust vehicle operations accordingly.\n\nRoles & Responsibilities\n\u2022 Design, train, and optimize AI/ML models for real-time, edge-based deployment.\n\u2022 Work with multi-modal data sources (audio, vision, sensor, telematics) to build robust AI systems.\n\u2022 Develop end-to-end pipelines for data preprocessing, model training, evaluation, and deployment.\n\u2022 Implement algorithms optimized for embedded and resource-constrained platforms\n\u2022 Validate AI models with real-world automotive sensor datasets\n\u2022 Perform model optimization (quantization, pruning) for deployment on embedded SoCs\n\u2022 Collaborate with system architects, Application developers, and automotive domain experts to ensure end-to-end functionality\n\u2022 Stay up to date with AI/ML advancements and automotive industry trends\n\nWork Experience\n\nRequired Skills (Technical Competency):\n\u2022 4\u20135 years of proven development experience in AI/ML for embedded device\n\u2022 Strong expertise in deep learning frameworks (TensorFlow, PyTorch, ONNX).\n\u2022 Practical experience with edge/embedded AI (NVIDIA Jetson, Qualcomm, ARM).\n\u2022 Proficiency in NLP / Conversational AI / Speech interfaces ( ASR, TTS )\n\u2022 Solid programming skills in Python and C++/Java for optimization and integration.\n\u2022 Solid understanding of application development in embedded Linux / Android\n\u2022 Familiarity with automotive standards, protocols such as CAN\n\u2022 Good communication skills and great team spirit\n\nDesired Skills\n\u2022 Experience working with embedded Linux, Automotive Android\n\u2022 Knowledge of vehicle data interfaces (CAN, OBD-II, sensors).\n\u2022 Exposure to MLOps pipelines and cloud platforms (AWS/GCP/Azure).",
    "url": "https://in.linkedin.com/jobs/view/ai-ml-engineer-automotive-at-quest-global-4319585096?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "ML Engineer (CB35FT RM 3693)",
    "company": "Source-right",
    "location": "Pune",
    "salary": "",
    "description": "Position: ML Engineer (CB35FT RM 3693)\n\nWork mode : Work From Office\n\nKey Responsibilities\n\nDesign, develop, and maintain data pipelines for large-scale structured and unstructured\n\ndatasets\n\nApply ML/DL techniques for:\n\nCustomer segmentation\n\nAnomaly detection\n\nSales forecasting and pattern analysis\n\nRecommendation engines\n\nFine-tune and deploy machine learning models in production using best practices\n\nDesign, prompt, and integrate LLM-based modules for tasks like summarization, Q&A, and\n\ncode generation\n\nWork on multi-modal LLM tasks involving text, image (CV), and speech (ASR/TTS)\n\nDevelop and expose ML APIs using FastAPI/Docker for integration with other systems\n\nMonitor model performance and retrain/update models as required\n\nCollaborate with frontend/backend developers, data teams, and product managers\n\nRequired Skills & Experience\n\n3\u20135 years of hands-on experience in ML/Data Science/Data Engineering roles\n\nMin 2 years hands on experience in Microsoft SQL (T-SQL) Coding, SPOC, Complex SQL Joins,\n\nData Modelling\n\nProficient in Python, including libraries like pandas, scikit-learn, PyTorch or TensorFlow\n\nExperience in deploying ML models using FastAPI, Docker, and CI/CD pipelines\n\nSolid understanding of data preprocessing, ETL, and feature engineering\n\nExperience with deep learning and LLMs (e.g., OpenAI, HuggingFace, LLaMA, etc.)\n\nPractical experience with prompt engineering and LLM fine-tuning\n\nFamiliarity with multi-modal learning, Computer Vision (e.g., OpenCV, YOLO, CLIP), and Speech\n\nAI (e.g., Whisper, TTS engines)\n\nStrong understanding of ML lifecycle: training, evaluation, monitoring, deployment\n\nExperience with cloud platforms (Azure) is a plus\n\nAbility to write clean, modular, production-grade code\n\u2022 ******************************************************************************************************************************************\n\nJob Category: Others\n\nJob Type: Full Time\n\nJob Location: Pune\n\nExperience: 3 - 5 years\n\nNotice period: 0-30 days",
    "url": "https://www.glassdoor.co.in/job-listing/ml-engineer-cb35ft-rm-3693-source-right-JV_IC2856202_KO0,26_KE27,39.htm?jl=1009926843012&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "Python Data Scientist / ML Engineer \u2013 Remote/Hybrid | AI, ML, Deep Learning | Only 4+ Years of Experience",
    "company": "Remotohire",
    "location": "Pune",
    "salary": "",
    "description": "Company: RemotoHire\n\nWork Mode: Remote / Hybrid\n\nExperience: 4\u20137 years\n\nAbout the Role:\n\nWe are hiring Python Data Scientists & ML Engineers to design and deploy intelligent systems, from predictive analytics to generative AI. You\u2019ll work with global clients on real-world AI/ML problems.\n\nKey Responsibilities:\n\u2022 Build ML models using scikit-learn, TensorFlow, PyTorch.\n\u2022 Work on NLP, Computer Vision, Generative AI, LLMs (GPT, LangChain).\n\u2022 Deploy ML pipelines on AWS SageMaker, Azure ML, GCP Vertex AI.\n\u2022 Handle data preprocessing, feature engineering, big data (Spark, Hadoop).\n\u2022 Optimize models for performance and scalability.\n\nRequired Skills:\n\u2022 Strong in Python, Pandas, NumPy, Matplotlib, Jupyter.\n\u2022 ML frameworks: scikit-learn, TensorFlow, PyTorch.\n\u2022 Cloud ML services: AWS, Azure, GCP.\n\u2022 Knowledge of MLOps, CI/CD for ML pipelines.\n\u2022 Bonus: Experience with AI Agents, RAG pipelines, and vector databases.\n\n\ud83d\udc49 Apply Now: https://www.oxcytech.com/developer-application\n\n\ud83d\udccc Note: While applying, please select \u201cPython Data Science / Machine Learning / AI\u201d from the Main dropdown.",
    "url": "https://in.linkedin.com/jobs/view/python-data-scientist-ml-engineer-%E2%80%93-remote-hybrid-ai-ml-deep-learning-only-4%2B-years-of-experience-at-remotohire-4331723103?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Immediate Start! Generative AI Engineer (Pune)",
    "company": "Synechron",
    "location": "Pune",
    "salary": "",
    "description": "Greetings,\n\nWe have immediate opportunity for AI/ML Engineer \u2013 7 to 10 years\n\nSynechron\u2013 Pune, Hinjewadi\n\nJob Role: AI/ML Engineer\n\nJob Location: Pune, Hinjewadi\n\nAbout Company:\n\nAt Synechron, we believe in the power of digital to transform businesses for the better. Our global consulting firm combines creativity and innovative technology to deliver industry-leading digital solutions. Synechron's progressive technologies and optimization strategies span end-to-end Artificial Intelligence, Consulting, Digital, Cloud & DevOps, Data, and Software Engineering, servicing an array of noteworthy financial services and technology firms. Through research and development initiatives in our FinLabs we develop solutions for modernization, from Artificial Intelligence and Blockchain to Data Science models, Digital Underwriting, mobile-first applications and more. Over the last 20+ years, our company has been honoured with multiple employer awards, recognizing our commitment to our talented teams. With top clients to boast about, Synechron has a global workforce of 14,700+, and has 48 offices in 19 countries within key global markets. For more information on the company, please visit our website or LinkedIn community.\n\nDiversity, Equity, and Inclusion\n\nDiversity & Inclusion are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and an affirmative-action employer. Our Diversity, Equity, and Inclusion (DEI) initiative 'Same Difference' is committed to fostering an inclusive culture \u2013 promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We encourage applicants from across diverse backgrounds, race, ethnicities, religion, age, marital status, gender, sexual orientations, or disabilities to apply. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs, and more.\n\nAll employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant's gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.\n\nJob Description:\n\nWe are seeking a highly skilled AI/ML and GenAI Engineer for around 8-10 yrs with proven experience in designing, developing, and deploying sophisticated AI and NLP solutions. The ideal candidate will have hands-on expertise with large language models (LLMs), foundation models (FMs), and generative AI (GenAI). You will work on building end-to-end AI applications from scratch, transforming monolithic systems into scalable microservices, and integrating with cloud-based AI platforms like Azure, Amazon Bedrock, Gemini, and others.\n\nKey Responsibilities:\n\n- Design, develop, and optimize NLP models, including Large Language Models (LLMs) and Foundation Models (FMs).\n- Lead large data processing pipelines for training, fine-tuning, and deploying models on big data platforms.\n- Architect, build, and maintain scalable AI solutions incorporating MLOps best practices.\n- Transition legacy monolithic architectures into microservices-based systems for improved scalability and maintainability.\n- Build end-to-end AI applications from scratch, including model training, deployment, and integration.\n- Implement and optimize Retrieval-Augmented Generation (RAG) processes for enhanced contextual understanding.\n- Conduct thorough testing, validation, and debugging of AI/ML applications and pipelines.\n- Integrate AI solutions with cloud platforms such as Azure, Amazon Bedrock, Google Gemini, and other emerging frameworks.\n- Develop and maintain flexible, production-ready solutions supporting real-time and batch processing.\n- Collaborate with cross-functional teams to embed AI capabilities into customer-facing products and enterprise solutions.\n\nQualifications & Skills:\n\n- Proven experience in NLP, including transformer-based models, LLMs, and FMs.\n- Understanding of AI/MLOps workflows, CI/CD pipelines, model deployment, and monitoring.\n- Strong background in transforming monolithic architectures into microservices.\n- Experience with building AI applications from scratch, including model training and integrating with GenAI LLMs, tuning, and testing.\n- Expertise in testing/debugging AI applications, pipelines, and data workflows.\n- Practical knowledge of Retrieval-Augmented Generation (RAG) techniques.\n- Familiarity with GenAI, prompt engineering, and interaction with cloud AI platforms like Azure AI, Amazon Bedrock, Google Gemini.\n- Experience with integrating multiple LLM models and APIs for seamless application workflows.\n- Strong programming skills in Python and various AI coding libraries and frameworks.\n- Knowledge of containerization (Docker, Kubernetes) and cloud deployment.\n- Excellent problem-solving, debugging, and communication skills.\n\nQUALIFICATION:\n\nBachelor's or Master's degree in Computer Science, Engineering, or a related field\n\nIf you find this this prospect interesting kindly share your updated profile on bansi.hindocha@synechron.com\n\nWith below details (Mandatory)\n\nTotal Experience\n\nExperience in AI/ML-\n\nCurrent CTC-\n\nExpected CTC-\n\nNotice period-\n\nCurrent Location-\n\nReady to relocate to Pune-\n\nIf you had gone through any interviews in Synechron before? If Yes when\n\nRegards,\n\nBansi Hindocha\n\nbansi.hindocha@synechron.com",
    "url": "https://in.jobrapido.com/jobpreview/7637519772283830272?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "ML Engineer-AI Engineer-Machine Learning",
    "company": "EXL Talent Acquisition Team",
    "location": "Pune",
    "salary": "",
    "description": "We are seeking a skilled MLFlow 3 Engineer to join our Data & AI Engineering team. The ideal candidate will have hands-on experience in managing the end-to-end lifecycle of machine learning models using MLFlow 3.x, along with expertise in Python, Databricks, PySpark, and Azure. The role is a cusp between ML Engineering and MLOPs. You will work closely with data scientists, ML engineers, and DevOps teams to operationalize ML workflows, ensuring scalability, reliability, and compliance.",
    "url": "https://fa-ewjt-saasfaprod1.fa.ocs.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_2/job/5968/?source=jdpreferred.comutm_medium&utm_source=google&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "DevOps Engineer (with AI/ML) - 41778",
    "company": "Fission Labs",
    "location": "Pune",
    "salary": "",
    "description": "Role: DevOps Engineer (With AI/ML)\n\nExperience: 5+ years\n\nLocation: Hyderabad\n\nFission Labs, headquartered in Sunnyvale, with offices in Dallas & Hyderabad, Fission Labs is a leading software development company, specializing in crafting flexible, agile, and scalable solutions that propel businesses forward. With a comprehensive range of services, including product development, cloud engineering, big data analytics, QA, DevOps consulting, and AI/ML solutions, we empower clients to achieve sustainable digital transformation that aligns seamlessly with their business goals.\n\nWhat are we looking for!\n\nWe are seeking an experienced Senior Infrastructure Mgmt. Engineer with expertise in Azure and AWS, coupled with a strong background in AI/ML deployments. The ideal candidate will have a proven track record in designing, implementing, and maintaining scalable and secure cloud infrastructure on Azure and AWS platforms. Experience with GCP is a plus. The primary responsibility will be to lead the DevOps initiatives and ensure compliance with industry standards and regulations.\n\nResponsibilities\n\nLinux Expertise:\n\u2022 Possess in-depth knowledge of Linux operating systems, including CentOS, Ubuntu, and Red Hat, with expertise in shell scripting, package management, and system administration.\n\u2022 Configure and optimize Linux-based servers for performance, security, and resource utilization, including kernel tuning, file system management, and network configuration.\n\nCloud Expertise (AWS/Azure)\n\u2022 Demonstrate hands-on experience with a wide range of AWS and Azure services, including but not limited to EC2, S3, Lambda, RDS, Azure VMs, Azure Blob Storage, Azure Functions, etc.\n\u2022 Architect cloud solutions leveraging best practices and services offered by AWS and Azure, optimizing for scalability, reliability, and cost-effectiveness.\n\u2022 Implement and manage hybrid cloud environments, facilitating seamless integration and interoperability between AWS and Azure services.\n\nInfrastructure As Code (IAC)\n\u2022 Develop and maintain Infrastructure as Code (IAC) templates using tools such as Terraform or AWS CloudFormation, defining infrastructure components as code for automated provisioning and configuration.\n\u2022 Establish version control practices for IAC templates, ensuring traceability, auditability, and reproducibility of infrastructure changes.\n\nAI/ML Infrastructure Mgmt\n\u2022 Experience setting up cloud infrastructure stack, databases, service endpoints, GPU as well as CPU resource scaling, optimization etc.\n\u2022 Should have worked AIOps/MLOP\n\u2022 Should have worked on deploying AI/ML Apps using Docker and Kubernetes\n\u2022 Should have worked on scaling, high availability and reliability tasks for AI application\n\u2022 Should have worked on deploying and maintaining GPU clusters for AI/ML training and inference\n\nQualifications\n\u2022 6+ years of experience in Infrastructure Mgmt. roles, with a focus on cloud platforms (Azure and AWS Preferred).\n\u2022 Hands-on experience with operations (DevSecOps) principles and best practices.\n\u2022 Proficiency in scripting languages such as Python, PowerShell, or Bash.\n\u2022 Excellent communication and collaboration skills.\n\u2022 Certifications such as AWS Solution Architect Associate, AWS Cloud Practitioner, Azure DevOps Engineer Expert, Azure Administrator\n\u2022 Certified Kubernetes Administrator or relevant industry certifications are a plus.\n\nYou would enjoy\n\u2022 Opportunity to work on impactful technical challenges with global reach.\n\u2022 Vast opportunities for self-development, including online university access and knowledge sharing opportunities.\n\u2022 Sponsored Tech Talks & Hackathons to foster innovation and learning.\n\u2022 Generous benefits packages including health insurance, retirement benefits, flexible work hours, and more.\n\u2022 Supportive work environment with forums to explore passions beyond work.\n\nThis role presents a unique opportunity to contribute to the future of impactful business solutions while advancing your career in a collaborative and innovative environment.",
    "url": "https://in.linkedin.com/jobs/view/devops-engineer-with-ai-ml-41778-at-fission-labs-4333145831?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "[Immediate Start] Generative AI Engineer",
    "company": "Vsynergize AI",
    "location": "Pune",
    "salary": "",
    "description": "We are looking for a talented and driven AI Engineer with a strong foundation in Python,\n\nNatural Language Processing, and experience working with Large Language Models (LLMs).\n\nThis is an exciting opportunity to be at the forefront of AI development, working on real-world\n\nproblems involving cutting-edge technologies such as prompt engineering, cloud-based\n\ndeployments, and conversational AI.\n\nKey Responsibilities :\n\u2022 Design, build, and optimize AI models, particularly those leveraging LLMs.\n\u2022 Engineer prompts for effective interaction with foundational models (OpenAI, Claude,\n\netc.).\n\u2022 Develop and integrate APIs for scalable AI-powered solutions.\n\u2022 Deploy backend services and AI models on cloud platforms (AWS, GCP, Azure).\n\u2022 Work on NLP tasks such as text classification, summarization, semantic search, etc.\n\u2022 Collaborate with cross-functional teams to understand business needs and translate\n\nthem into AI solutions.\n\u2022 Ensure model and code quality through testing, performance evaluation, and\n\ndocumentation.\n\u2022 Continuously explore new advancements in AI and contribute to improving internal tools\n\nand workflows.\n\nRequired Skills & Experience :\n\u2022 2+ years of experience in software development with a focus on AI / ML.\n\u2022 Strong proficiency in Python.\n\u2022 Knowledge of frameworks like LangChain, RAG, or vector databases (e.g., FAISS,\n\nPinecone).\n\u2022 Hands-on experience with LLMs, prompt engineering, and NLP techniques.\n\u2022 Familiarity with API development and third-party API integrations.\n\u2022 Experience working with cloud platforms (AWS, Google Cloud, Azure).\n\u2022 Understanding of backend services and deployment best practices.\n\u2022 Solid knowledge of data modeling, with a focus on language data.\n\u2022 Strong problem-solving skills and critical thinking.\n\u2022 Excellent communication and collaboration abilities.\n\nNice to Have\n\u2022 Experience with MLOps tools and practices.\n\u2022 Model deployment and lifecycle management.\n\u2022 Experience building conversational AI tools (chatbots, voice bots, virtual assistants).\n\nWhy Join Us?\n\u2022 Work on innovative AI solutions with real-world impact.\n\u2022 Opportunity to learn and grow in a collaborative, fast-paced environment.\n\u2022 Flexible work culture and supportive team.",
    "url": "https://in.talent.com/view?id=b9d8ee149c5c&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "AI/ML Platform Engineer",
    "company": "Johnson Controls",
    "location": "Pimpri-Chinchwad",
    "salary": "",
    "description": "Job Title: Senior Data Scientist \u2013 Data & Analytics\n\nJohnson Controls International (JCI) is seeking a Senior Data Scientist to join our innovative and impact-driven Data Science and Analytics team. This role is ideal for a seasoned expert with a deep understanding of machine learning, AI, and cloud data platforms, and a strong grasp of the latest advancements in Generative AI and Large Language Models (LLMs).\n\nAs a Senior Data Scientist, you will lead the development and deployment of scalable AI solutions\u2014including those powered by LLMs\u2014to accelerate digital transformation across our products, operations, and customer experiences. You'll play a critical role in shaping JCI\u2019s data science strategy, mentoring teams, and driving the use of AI to deliver measurable business value.\n\nHow You Will Do It\n\nAdvanced Analytics, LLMs & Modeling\n\u2022 Design and implement advanced machine learning models including deep learning, time-series forecasting, recommendation engines, and LLM-based solutions (e.g., GPT, LLaMA, Claude).\n\u2022 Develop use cases around enterprise search, document summarization, conversational AI, and automated knowledge retrieval using large language models.\n\u2022 Fine-tune or prompt-engineer foundation models (e.g., OpenAI, Azure OpenAI, Hugging Face) for domain-specific applications.\n\u2022 Evaluate and optimize LLM performance, latency, cost-effectiveness, and hallucination mitigation strategies for production use.\n\nData Strategy & Engineering Collaboration\n\u2022 Work closely with data and ML engineering teams to integrate LLM-powered applications into scalable, secure, and reliable pipelines.\n\u2022 Contribute to the development of retrieval-augmented generation (RAG) architectures using vector databases (e.g., FAISS, Azure Cognitive Search).\n\u2022 Support the deployment of models using MLOps principles, ensuring robust monitoring and lifecycle management.\n\nBusiness Impact & AI Strategy\n\u2022 Partner with cross-functional stakeholders to identify opportunities for applying LLMs and generative AI to solve complex business challenges.\n\u2022 Lead workshops or proofs-of-concept to demonstrate value of LLM use cases across business units.\n\u2022 Translate complex model outputs, including those from LLMs, into clear insights and decision support tools for non-technical audiences.\n\nThought Leadership & Mentorship\n\u2022 Act as an internal thought leader on AI and LLM innovation, keeping JCI at the forefront of industry advancements.\n\u2022 Mentor and upskill data science team members in advanced AI techniques, including transformer models and generative AI frameworks.\n\u2022 Contribute to strategic roadmaps for generative AI and model governance within the enterprise.\n\nQualifications & Experience\n\u2022 Education in Data Science, Artificial Intelligence, Computer Science, or related quantitative discipline.\n\u2022 5+ years of hands-on experience in data science, including at least 1\u20132 years working with LLMs or generative AI technologies.\n\u2022 Demonstrated success in deploying machine learning and NLP solutions at scale.\n\u2022 Proven experience with cloud AI platforms\u2014especially Azure OpenAI, Azure ML, Hugging Face, or AWS Bedrock.\n\nTechnical Expertise\n\u2022 Proficiency in Python and SQL, including libraries like Transformers (Hugging Face), LangChain, PyTorch, and TensorFlow.\n\u2022 Experience with prompt engineering, fine-tuning, and LLM orchestration tools.\n\u2022 Familiarity with data storage, retrieval systems, and vector databases.\n\u2022 Strong understanding of model evaluation techniques for generative AI, including factuality, relevance, and toxicity metrics.\n\nLeadership & Soft Skills\n\u2022 Strategic thinker with a strong ability to align AI initiatives to business goals.\n\u2022 Excellent communication and storytelling skills, especially in articulating the value of LLMs and advanced analytics.\n\u2022 Strong collaborator with a track record of influencing stakeholders across product, engineering, and executive teams.\n\nPreferred Qualifications\n\u2022 Experience with IoT, edge analytics, or smart building systems.\n\u2022 Familiarity with LLMOps, LangChain, Semantic Kernel, or similar orchestration frameworks.\n\u2022 Knowledge of data privacy and governance considerations specific to LLM usage in enterprise environments.",
    "url": "https://in.linkedin.com/jobs/view/ai-ml-platform-engineer-at-johnson-controls-4324739939?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "EncureIT Systems - Gen AI/ML Developer",
    "company": "EncureIT",
    "location": "Pune",
    "salary": "",
    "description": "Senior AI/ML Engineer\n\nLocation : Pune, Maharashtra\n\nExperience : 4-6 years\n\nEmployment : Full-time\n\nRole Overview :\n\nWe are seeking a Senior AI/ML Engineer to lead the design, development, and deployment of advanced AI solutions across Generative AI, Deep Learning, and traditional ML. This role requires not only strong technical expertise but also leadership in mentoring junior engineers, coordinating with cross-functional teams, and directly engaging with clients to understand problems and deliver impactful solutions.\n\nYou will take ownership of end-to-end AI/ML initiatives from business problem definition and data strategy to production deployment and ongoing optimization while ensuring scalability, robustness, and innovation in AI-driven products.\n\nKey Responsibilities :\n\nLeadership & Client Communication :\n\n- Act as the technical lead for AI/ML projects, ensuring timely and high-quality delivery.\n\n- Communicate directly with clients to gather requirements, present solutions, and provide technical insights.\n\n- Lead technical discussions, demos, and presentations with clients and stakeholders.\n\n- Coordinate and mentor junior AI/ML engineers, providing guidance on project tasks and technical challenges.\n\nEnd-to-End AI/ML Lifecycle :\n\n- Drive problem scoping, data collection, model development, deployment, monitoring, and continuous iteration.\n\n- Translate complex business requirements into scalable ML/AI solutions.\n\nModel Development (Generative + Traditional) :\n\n- Build, fine-tune, and optimize transformer-based LLMs (GPT, BERT, LLaMA), GANs, diffusion models, and multimodal AI systems.\n\n- Develop and improve ML/DL models for computer vision (CNNs, R-CNN, YOLO, etc.), NLP, and recommendation systems.\n\nData Engineering & Pipelines :\n\n- Architect robust data pipelines (ETL/ELT), data labeling, preprocessing, and augmentation frameworks.\n\n- Ensure versioning, reproducibility, and data governance practices.\n\nMLOps & Deployment :\n\n- Lead model containerization (Docker), microservice/API deployment, and CI/CD pipeline setup for ML.\n\n- Implement monitoring, drift detection, scaling, and performance tracking for deployed models.\n\nTroubleshooting & Optimization :\n\n- Solve advanced AI challenges : hallucinations, overfitting, bias, imbalance, latency, and model interpretability.\n\n- Optimize models for accuracy, efficiency, and cost.\n\nInnovation & Research :\n\n- Stay at the forefront of GenAI, RAG frameworks, LangChain, and emerging ML research.\n\n- Prototype and evaluate new architectures, libraries, and deployment approaches.\n\nCollaboration & Documentation :\n\n- Partner with product managers, DevOps, backend engineers, and clients to deliver integrated AI solutions.\n\n- Document experiments, frameworks, and deployment architectures for team adoption and client transparency.\n\nRequired Skills :\n\n- Bachelor's/Master's in Computer Science, AI, Data Science, or related field.\n\n- 4-6 years of proven experience in ML/AI roles, with at least 2 years in leading/mentoring roles.\n\n- Proficient in Python, ML/DL frameworks (PyTorch, TensorFlow, Hugging Face, scikit-learn).\n\n- Expertise in LLM fine-tuning, generative models, and traditional ML.\n\n- Strong grasp of AI/ML project lifecycle, MLOps, and cloud deployment (AWS/GCP/Azure).\n\n- Skilled in data workflows, feature engineering, dataset versioning, and reproducibility.\n\n- Hands-on experience with Docker, REST APIs, Git, and CI/CD pipelines.\n\n- Excellent problem-solving, analytical, and debugging abilities.\n\n- Strong communication skills with ability to manage client expectations.\n\nPreferred Skills :\n\n- Hands-on projects with ChatGPT, LLaMA, Stable Diffusion, multimodal AI, or vector DBs (FAISS, Pinecone, Weaviate).\n\n- Experience in RAG pipelines, prompt engineering, and production-level GenAI applications.\n\n- Proven track record of leading teams, mentoring juniors, or client delivery.\n\n- Contributions to open-source AI/ML projects, publications, or GitHub portfolio.\n\n- Awareness of AI ethics, fairness, compliance, and data privacy regulations.",
    "url": "https://www.hirist.tech/j/encureit-systems-gen-ai-ml-developer-1568015?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Ai/ Ml Engineer Pune",
    "company": "Sava Healthcare",
    "location": "Pune",
    "salary": "",
    "description": "Key Responsibilities:\nDesign, build, and deploy AI/ML models for real-world business and manufacturing problems (e.g., predictive maintenance, process optimization, document automation, etc.).\nDevelop end-to-end AI web applications (backend + frontend) using frameworks like Flask, FastAPI, or Django for backend and React, Angular, or Vue for frontend.\nImplement and maintain data pipelines for model training and prediction.\nIntegrate trained models into scalable and user-friendly web interfaces.\nHost, monitor, and maintain AI applications on cloud or on-premise web servers (AWS, Azure, Google Cloud, or companys internal servers).\nCollaborate with IT, QA, and process teams to identify automation and AI opportunities.\nEnsure application security, reliability, and performance optimization.\nDocument model architecture, APIs, and deployment procedures.\n\nRequired Skills & Qualifications:\nBachelor\u2019s or Master\u2019s degree in Computer Science, Data Science, Artificial Intelligence, or related field.\nProven experience in AI/ML development and deployment.\nRobust programming skills in Python (TensorFlow, PyTorch, scikit-learn, OpenCV, etc.).\nProficiency in web frameworks (Flask, Django, FastAPI) and frontend technologies (HTML, CSS, JavaScript, React/Angular preferred).\nExperience in model deployment (Docker, REST API, Flask/FastAPI endpoints).\nFamiliarity with cloud platforms (AWS, Azure, or Google Cloud) and web hosting environments.\nKnowledge of database systems (MySQL, PostgreSQL, MongoDB).\nUnderstanding of version control (Git/GitHub) and CI/CD pipelines.\nRobust analytical thinking, problem-solving, and communication skills.",
    "url": "https://in.jobrapido.com/jobpreview/1449940021648818176?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Senior AI-ML Engineer [Apply in 3 Minutes]",
    "company": "Myridius x Aethereus",
    "location": "Pune",
    "salary": "",
    "description": "About Us\n\nAethereus is now part of Myridius, formerly known as RCG Global Services. This strategic integration combines Aethereus\u2019 expertise in cutting-edge solutions with Myridius\u2019 legacy of delivering transformative business outcomes. At Aethereus, we are passionate about outcomes. We are a team of strategists, designers, architects and tinkerers who are passionate about business outcomes led by technology platforms.\n\nWe are a Salesforce boutique focused on US, Europe, Australia and India. We are one of the select few players who approach Salesforce engagements with twin focus on vertical specific and Industry 4.0 driven propositions. Our team of professionals have rich experience in Salesforce platform and deep connects in the Salesforce ecosystem and work on the cutting edge clouds, often closely with Salesforce. We are agile and nimble and constantly looking to deliver value to our clients - from rapid Salesforce implementations to improving the ROI from existing investments.\n\nExperience Required\n\n8-10 years in ML with recent experiences in AI engineering with focus on production-grade implementations.\n\nRole Overview\n\nWe're seeking a seasoned AI / ML Engineer to architect and deploy advanced generative AI solutions using AWS Bedrock. You'll work independently with minimal supervision, engage directly with clients, and drive technical excellence in cutting-edge AI initiatives.\n\nKey Responsibilities\n\u2022 Design and implement production-ready generative AI solutions using AWS Bedrock and related services\n\u2022 Build and deploy agentic AI frameworks and multi-agent systems\n\u2022 Lead client-facing technical discussions, requirement gathering, and solution presentations\n\u2022 Architect end-to-end ML pipelines from prototyping to production deployment\n\u2022 Evaluate and integrate latest LLMs, RAG architectures, and prompt engineering techniques\n\u2022 Mentor junior engineers and establish best practices for AI / ML development.\n\nRequired Skills\n\nAWS & Cloud\n\u2022 Extensive hands-on experience with AWS Bedrock (Claude, Titan, Llama models)\n\u2022 Strong knowledge of AWS SageMaker, Lambda, S3, EC2, and other ML services\n\u2022 Experience with cloud-based ML infrastructure and cost optimization\n\nGenerative AI & LLMs\n\u2022 Deep expertise in latest LLM technologies and foundation models\n\u2022 Proven track record with RAG (Retrieval Augmented Generation) systems\n\u2022 Advanced prompt engineering and fine-tuning experience\n\u2022 Knowledge of vector databases (Pinecone, Weaviate, OpenSearch)\n\nAgentic Frameworks\n\u2022 Hands-on experience with any of the LangChain, LlamaIndex, AutoGen, Google ADK, or OpenAI SDK.\n\u2022 Building multi-agent systems and autonomous AI workflows\n\u2022 Tool integration and function calling implementations\n\nCore ML / AI\n\u2022 Strong foundation in machine learning algorithms and deep learning\n\u2022 Experience with PyTorch, TensorFlow, Hugging Face Transformers\n\u2022 MLOps practices : CI / CD, model versioning, monitoring, and governance\n\nSoftware Engineering\n\u2022 Proficient in Python with clean, maintainable code practices\n\u2022 API development (REST / GraphQL) and microservices architecture\n\u2022 Version control (Git), containerization (Docker / Kubernetes)\n\nSoft Skills\n\u2022 Excellent communication skills for client interactions and technical presentations\n\u2022 Self-driven with ability to work independently and make architectural decisions\n\u2022 Strong problem-solving mindset with business acumen\n\u2022 Comfortable navigating ambiguity and driving projects to completion\n\nPreferred Qualifications\n\u2022 Experience with enterprise AI deployments and compliance requirements\n\u2022 Knowledge of AI safety, responsible AI practices, and bias mitigation\n\u2022 Contributions to open-source AI / ML projects\n\u2022 Publication record or speaking engagements in AI / ML domain\n\u2022 AWS certifications (ML Specialty, Solutions Architect)\n\nWhat We Offer\n\u2022 Opportunity to work on cutting-edge AI projects\n\u2022 Direct client engagement and visibility\n\u2022 Collaborative environment with innovation focus\n\u2022 Professional development and certification support",
    "url": "https://in.talent.com/view?id=9b77fcadd592&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Machine Learning Strategist [Immediate Start]",
    "company": "Cybage Software",
    "location": "Pune",
    "salary": "",
    "description": "Role Overview\nCybage is seeking a Practice Head for Machine Learning Systems to lead our AI/ML capability within the CDAI business unit. This is a strategic leadership role that blends deep technical expertise in applied ML systems with practice-building, client consulting, and outcome-based delivery experience.\nThe role requires someone who has built and scaled ML engineering practices in IT services or consulting environments, is able to guide solutioning at a technical level, and can also engage clients in executive workshops to define AI adoption roadmaps.\nKey Responsibilities\nPractice Leadership\n- Define the vision and roadmap for Cybage\u2019s Machine Learning Systems practice, aligned with industry trends and client priorities.\n- Build offerings and frameworks across ML model development, deployment, MLOps, generative AI, and responsible AI governance.\n- Develop accelerators, reference architectures, and reusable assets to differentiate Cybage in the market.\nClient Consulting & Business Growth\n- Lead consultative workshops with client executives to co-create ML/AI strategies, adoption roadmaps, and use-case portfolios.\n- Partner with sales and account teams to drive presales solutioning, proposal creation, and thought leadership.\n- Position Cybage as a strategic partner for ML-driven transformations that are measurable and outcome-driven.\nDelivery Excellence\n- Oversee delivery of ML programs spanning PoCs, pilots, and scaled deployments across industries.\n- Ensure robust MLOps and governance practices for model lifecycle management, monitoring, retraining, and compliance.\n- Provide architectural and technical guidance on ML stacks (e.g., TensorFlow, PyTorch, Hugging Face, MLflow, AWS Sagemaker, Azure ML, GCP Vertex AI, Databricks ML).\n- Drive service-based and outcome-based engagement models, ensuring predictability and value delivery.\nTeam & Capability Building\n- Build and mentor a high-performing team of ML engineers, data scientists, and solution architects.\n- Develop future leaders with consulting and solutioning depth, not just technical skill.\n- Foster collaboration across adjacent practices (Big Data, Cloud, Platform Engineering) to deliver end-to-end AI solutions.\nQualifications\nExperience\n- 15+ years in IT services or consulting, with 7+ years in ML/AI leadership or architecture roles.\n- Proven ability to establish or grow an ML/AI practice, including team building, offering development, and client engagement.\n- Experience with end-to-end ML lifecycle: data prep, feature engineering, model training, evaluation, deployment, monitoring.\n- Exposure to service delivery models (consulting, managed services, outcome-based).\n- Strong background in applied ML use cases (forecasting, personalization, anomaly detection, NLP, computer vision, GenAI).\nSkills & Competencies\n- Technical bent: ability to deep-dive into ML architectures, pipelines, and MLOps practices.\n- Strategic mindset: connect ML initiatives to tangible business outcomes.\n- Leadership: experience in building practices and leading distributed teams (does not need to be at massive scale).\n- Client-facing presence: ability to run workshops, advise senior stakeholders, and simplify complex ML topics.\n- Knowledge of AI governance, ethics, and compliance (responsible AI, data privacy, bias mitigation).",
    "url": "https://in.jobrapido.com/jobpreview/8000578511775465472?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "\u25b7 [Urgent Search] AI / ML Data Engineer",
    "company": "Tata Consultancy Services",
    "location": "Pune",
    "salary": "",
    "description": "Role : AI / ML Data Engineer\n\nExperience Required : 5 to 8 Years\n\nLocation : Pune (Onsite )\n\nDrive Type : Walk-In Interview\n\nWalk-In Date & Time : 1st Nov\n\nMust-Have Technical Skills\n\nAI / Machine Learning (Model Development & Deployment)\n\nAzure Cloud Platform (ADF, Data Lake, Synapse, Azure ML, DevOps)\n\nAzure Databricks (ADB)\n\nPySpark (Advanced Data Transformation & Big Data Processing)\n\nKey Responsibilities\n\nDesign and develop AI / ML-driven data pipelines using Azure & Databricks\n\nWork on end-to-end ML lifecycle \u2014 data prep, modeling, deployment\n\nImplement PySpark-based large-scale data processing workflows\n\nCollaborate with data scientists and business stakeholders to deliver insights\n\nOptimize data models for scalability, performance, and reliability on Azure\n\nAdhere to banking data security and compliance standards\n\nPreferred / Nice-to-Have\n\nExperience in Banking, Financial Services, or Investment Domain\n\nKnowledge of MLOps, Azure ML pipelines, Feature Store\n\nStrong analytical & problem-solving mindset\n\nThanks & Regards ,\n\nSomesh Singh\n\nTCS AI. Cloud Recruiter\n\nTalent Acquisition Group\n\nWebsite : : http : / / www.tcs.com\n\nE-Mail : - somesh.singh7@tcs.com\n\nLinkedIn : - linkdin.com / in / mrsomeshsingh\n\nTo Register for Jobs, Visit : https : / / ibegin.tcs.com / iBegin / register\n\nAddress : - Tower-2, Okaya Centre Plot No. B-5,Sector - 62 Noida.",
    "url": "https://in.talent.com/view?id=0baf49350fe9&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Artificial Intelligence Engineer (Pune, Bangalore, Chennai, Hyderabad)",
    "company": "Dexian India",
    "location": "Pune",
    "salary": "",
    "description": "Skill-Set:\n\u2022 AI Engineers \u2013 Very Strong Python Dev - with specialization in the back-end\n\u2022 Experienced in building AI use cases - such as RAG - Augmented generation/machine learning\n\u2022 Focus on LLMs\n\u2022 Need them to hit the ground running and working immediately - major deadlines\n\u2022 Create models accordingly\n\u2022 Job Description:\n\nDexian is seeking an experienced AI Engineer to design and implement scalable AI-driven solutions. The engineer should have experience with LLMs (Claude via Azure OpenAI models), RAG, fine-tuning, and related AI/ML domains. The engineer should be skilled in programming languages such as Python, and proficient with cloud-based AI platforms and frameworks. The role requires strong analytical thinking, a deep understanding of model training and evaluation, and the ability to translate business requirements into technical solutions that deliver measurable impact.\n\nQualifications:\n\u2022 Experience in developing AI/NLP solutions using LLMs (OpenAI, Claude, etc.)\n\u2022 Python (or similar) development skills with experience in working with CSV/JSON/XML input formats\n\u2022 Familiarity with cloud-based LLM services such as Azure OpenAI\n\u2022 Experience fine-tuning LLMs / SLMs\n\u2022 Experience with Retrieval-Augmented Generation (RAG) is a plus\n\u2022 Experience with data processing, data analysis, and building data pipelines\n\u2022 Solid understanding of rule-based processing and data-driven content generation\n\nNice-to-Have Skills:\n\u2022 Experience with lightweight local development for AI proof-of-concepts\n\u2022 Prior work on e-commerce, retail, or marketing content generation\n\u2022 Deploying applications on cloud infrastructure such as Azure, AWS, GCP\n\u2022 Building scalable cloud solutions\n\nFamiliarity with databases (SQL, NoSQL)",
    "url": "https://in.linkedin.com/jobs/view/artificial-intelligence-engineer-pune-bangalore-chennai-hyderabad-at-dexian-india-4320006809?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Ai/ml Architect / Engineering Lead Pune (India)",
    "company": "Intellect Design Arena",
    "location": "Pune",
    "salary": "",
    "description": "About the Role:\n\nWere looking for a Technology Leader in AI/ML and Generative AI with solid experience in architecting, designing, and delivering enterprise-grade AI platforms. The ideal candidate will combine deep hands-on expertise in LLMs, RAG, Agentic AI, and Azure AI Services with enterprise architecture and engineering leadership skills.\n\nYou will drive the AI-first transformation journey for large enterprises, build AI-powered digital expert systems, and lead teams to deliver scalable, secure, and business-aligned AI solutions.\n\nKey Responsibilities:\nArchitect and implement AI/ML and Generative AI platforms for large-scale enterprise adoption.\nDesign and productionize AI-powered systems for Banking use cases such as onboarding, payments, and cash management.\nDevelop RAG pipelines, Agentic AI workflows, and LLMOps frameworks using LangChain, LangGraph, and Hugging Face.\nIntegrate solutions with Core Banking, ERP, H2H, and API platforms ensuring scalability, security, and compliance.\nLead and mentor high-performing engineering teams following Agile/DevOps best practices.\nEvaluate and integrate emerging AI ecosystems (OpenAI, Anthropic, Mistral, Azure OpenAI, GCP Vertex AI).\nCollaborate with product and business leaders to align AI initiatives with enterprise strategy and measurable ROI.\n\nTechnical Skills & Expertise:\nGenerative AI & LLMs: GPT-4, LLaMA, Claude, RAG, Agentic AI, LangChain, LangGraph, LlamaIndex\nAI/ML Engineering: Deep Learning, NLP, Python, FastAPI, MLFlow, PyTorch, TensorFlow, Keras\nCloud & Platform Engineering: Azure AI Services, Azure OpenAI, Synapse, Azure ML Studio, AWS, GCP\nData & Integration: Kafka, ETL pipelines, APIs, vector DBs (Chroma, Pinecone, Azure AI Search)\nArchitecture: Cloud-native, microservices, event-driven systems, Kubernetes, Docker, CI/CD\n\nWhy Join:\nDrive end-to-end AI/GenAI transformation across global BFSI clients\nLead high-impact AI innovation and modernization programs\nWork with cutting-edge AI ecosystems and enterprise-grade LLM deployments",
    "url": "https://in.jobrapido.com/jobpreview/4945039546476658688?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "AI/ML Intern",
    "company": "Innovartic Solutions Pvt Ltd.",
    "location": "Pune",
    "salary": "",
    "description": "Key Responsibilitie\n\u2022 Develop, train, and deploy machine learning and deep learning models.\n\u2022 Perform data preprocessing, feature engineering, and exploratory data analysis (EDA).\n\u2022 Build scalable ML pipelines and integrate models into production systems.\n\u2022 Evaluate model performance and optimize for accuracy, efficiency, and scalability.\n\u2022 Research and implement state-of-the-art algorithms in areas such as NLP, computer vision, or recommendation systems.\n\u2022 Collaborate with cross-functional teams to identify AI opportunities and deliver innovative solutions.\n\u2022 Stay up to date with advancements in AI/ML, frameworks, and tools.\n\nJob Type: Full-time\n\nPay: From \u20b912,000.00 per month\n\nWork Location: In person",
    "url": "https://www.glassdoor.co.in/job-listing/ai-ml-intern-innovartic-solutions-pvt-ltd-JV_IC2856202_KO0,12_KE13,41.htm?jl=1009926588842&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Cloud ML Engineer (AWS)_Manager_Lead_Pune (Pune)",
    "company": "Vodafone",
    "location": "Pune",
    "salary": "",
    "description": "About VOIS\n\nVOIS (Vodafone Intelligent Solutions) is a strategic arm of Vodafone Group Plc, creating value and enhancing quality and efficiency across 28 countries, and operating from 7 locations: Albania, Egypt, Hungary, India, Romania, Spain and the UK.\n\nOver 29,000 highly skilled individuals are dedicated to being Vodafone Group's partner of choice for talent, technology, and transformation. We deliver the best services across IT, Business Intelligence Services, Customer Operations, Business Operations, HR, Finance, Supply Chain, HR Operations, and many more.\n\nEstablished in 2006, VOIS has evolved into a global, multi-functional organisation, a Centre of Excellence for Intelligent Solutions focused on adding value and delivering business outcomes for Vodafone.\n\nAbout VOIS India:\n\nIn 2009, VOIS started operating in India and now has established global delivery centres in Pune, Bangalore and Ahmedabad. With more than 14,500 employees, _VOIS India supports global markets and group functions of Vodafone, and delivers best-in-class customer experience through multi-functional services in the areas of Information Technology, Networks, Business Intelligence and Analytics, Digital Business Solutions (Robotics & AI), Commercial Operations (Consumer & Business), Intelligent Operations, Finance Operations, Supply Chain Operations and HR Operations and more.\n\nRole Purpose\n\nThe Cloud ML Engineer delivers through self and others to: * Use their knowledge of ML/AI and combine it with programming and software engineering skills to enable easier use of and access to machine learning models and analyses\n\n- Support local markets and group functions in obtaining business value from the ML\n\nMust have technical / professional qualifications:\n\n- 3-year IT or IS degree or diploma or related field is essential\n- Advanced degree in Computer Science/Math/Statistics or a related discipline would be an advantage\n- Relevant cloud certification at professional or associate level\n- 5+ years of relevant experience as AI/ML Engineer\n- 5+ years BI or related software development\n- Agile exposure, Kanban or Scrum\n\nKey performance indicators:\n\n- Speed of ML model implementation\n- Model performance and reliability\n- Maximize effective usage of system resources to balance compute resources, network usage and costs objectives\n\nVOIS Equal Opportunity Employer Commitment\n\nVOIS is proud to be an Equal Employment Opportunity Employer. We celebrate differences and we welcome and value diverse people and insights. We believe that being authentically human and inclusive powers our employees' growth and enables them to create a positive impact on themselves and society. We do not discriminate based on age, colour, gender (including pregnancy, childbirth, or related medical conditions), gender identity, gender expression, national origin, race, religion, sexual orientation, status as an individual with a disability, or other applicable legally protected characteristics.As a result of living and breathing our commitment, our employees have helped us get certified as a Great Place to Work in India for four years running. We have been also highlighted among the Top 10 Best Workplaces for Millennials, Equity, and Inclusion, Top 50 Best Workplaces for Women, Top 25 Best Workplaces in IT & IT-BPM and 10th Overall Best Workplaces in India by the Great Place to Work Institute in 2024. These achievements position us among a select group of trustworthy and high-performing companies which put their employees at the heart of everything they do.By joining us, you are part of our commitment. We look forward to welcoming you into our family which represents a variety of cultures, backgrounds, perspectives, and skills! Apply now, and we'll be in touch!\n\nVodafone is committed to attracting, developing and retaining the very best people by offering a engaging and inclusive workplace in which talent is truly recognised and rewarded. We are committed to promoting Inclusion for All with the belief that diversity plays an important role in the success of our business. We actively encourage everyone to consider becoming a part of our journey.",
    "url": "https://in.jobrapido.com/jobpreview/1717098257454202880?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Software Engineer - Python (AI, KG & CyberSecurity)",
    "company": "Skydda.ai",
    "location": "Pune",
    "salary": "",
    "description": "Location: Pune\n\nExperience: 2\u20134 years\n\nType: Full-time\n\nHow to Apply: Info at the end of the job post\n\nAbout Us\n\nSkydda.ai is building an AI-powered Security Operations Center (AI SOC) that helps security teams detect, investigate, and respond to threats faster and smarter.\n\nWe apply AI reasoning, intelligent automation, and scalable engineering to strengthen modern SOC operations against evolving cyber threats.\n\nRole Overview\n\nWe are hiring a Software Engineer \u2013 Python to work across core product initiatives involving Python-based backend, intelligent automation, and security data workflows.\n\nDepending on your strengths and interest, you may work on projects involving:\n\u2022 AI-Agents\n\u2022 AI-driven features\n\u2022 Knowledge graph engineering\n\u2022 Natural Language Interfaces\n\u2022 Data mapping, enrichment, and integration\n\nIf you're passionate about solving real-world engineering challenges and advancing security through smart systems \u2014 this role is for you.\n\nWhat You\u2019ll Do\n\u2022 Develop and maintain backend components and services in Python.\n\u2022 Work with security data \u2014 structuring, processing, and transforming it at scale.\n\u2022 Integrate advanced reasoning and automation capabilities into product features.\n\u2022 Collaborate with cross-functional teams (security experts, AI engineers, product).\n\u2022 Write clean, testable, and well-documented code.\n\u2022 Ensure performance, reliability, and security across services.\n\nWhat You\u2019ll Bring\n\u2022 2\u20134 years of professional backend development experience with Python.\n\u2022 Strong understanding of REST APIs, data models, and JSON handling.\n\u2022 Confidence in debugging distributed systems and asynchronous workflows.\n\u2022 Strong fundamentals in data structures and software design.\n\u2022 Self-driven, eager to learn, and comfortable in fast-paced environments.\n\nNice to Have\n\u2022 Experience with AI or NLP-based applications.\n\u2022 Exposure to knowledge graph concepts or graph-like data structures.\n\u2022 Familiarity with CI/CD, Docker, or Kubernetes.\n\u2022 Interest in cybersecurity and security operations use cases.\n\u2022 Understanding of secure authentication methods (OAuth2, OIDC).\n\nWhy Join Skydda.ai\n\u2022 Work at the intersection of AI + cybersecurity, solving high-impact challenges.\n\u2022 Build technology that helps security teams detect and respond faster.\n\u2022 High ownership, rapid learning, and strong mentorship opportunities.\n\u2022 Remote-first and flexible working culture.\n\u2022 Competitive compensation with meaningful product influence.\n\nHow to Apply\n\nIf you're excited to build scalable Python systems that power next-gen SOC operations, we\u2019d love to meet you!\n\nPlease include your resume along with the following:\n\u2022 Are you currently based in Pune?\n\u2022 How many years of professional work experience do you have (excluding internships)?\n\u2022 What is your current CTC?\n\u2022 What is your expected CTC?\n\u2022 What is your notice period?",
    "url": "https://wellfound.com/jobs/3536287-software-engineer-python-ai-kg-cybersecurity?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "\u25b7 High Salary : Generative AI Engineer",
    "company": "Talent Corner HR Services Pvt Ltd",
    "location": "Pune",
    "salary": "",
    "description": "Experience Required : 4-6 Years\n\nJob Summary :\n\u2022 Proven experience in content management, data architecture, and AI\n\u2022 technologies\n\u2022 Design content structures that optimize the usability and retrieval of data by\n\u2022 LLMs and RAG systems.\n\u2022 Strong understanding of LLMs and RAG systems and their application in\n\u2022 business contexts.\n\u2022 Problem-solving skills with a proactive approach to identifying and addressing\n\u2022 challenges.\n\u2022 Design and maintain a robust data architecture that supports efficient content\n\u2022 retrieval and generation.\n\u2022 Ensure content is optimized for AI consumption, including proper formatting,\n\u2022 tagging, and metadata application.\n\u2022 Experience in JIRA, Confluence, Bit Bucket, Azure Repo etc.\n\u2022 Strong Computer Science fundamentals in object-oriented design, data\n\u2022 structures, design patterns and algorithm design.\n\u2022 Strong debug and troubleshooting skills.\n\u2022 Aware of CI / CD techniques and tools like Azure Pipeline.\n\nWhat do we expect from you?\n\u2022 Bachelor\u2019s or Master\u2019s degree in Computer Science, Information Technology, or a related field.\n\u2022 Proven experience in building Azure Cloud solutions.\n\u2022 Experience with content management systems (CMS) and data management tools.\n\u2022 Familiarity with AI / ML frameworks and libraries.\n\u2022 Knowledge of global content standards and regional data regulations.\n\u2022 Familiarity with CI / CD pipelines and version control systems such as Git.\n\u2022 Strong debug and troubleshooting skills.\n\u2022 Effective oral and written communication skills; ability to articulate clearly and concisely.\n\u2022 You have worked with Agile Methodologies following SCRUM.\n\nQualifications :\n\u2022 4 to 6 years of strong hands-on experience in Python programming\n\u2022 Minimum 2 years of experience working with AI tools and technologies\n\u2022 At least 1 year of experience as a Generative AI Content Architect\n\u2022 Successfully delivered 2\u20133 AI implementation projects or use cases\n\u2022 Solid understanding of AI solution implementation, including data architect and content management.",
    "url": "https://in.talent.com/view?id=bf7d30325688&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (Python/ GenAI/ AgenticAI)",
    "company": "Wolters Kluwer",
    "location": "Pune",
    "salary": "",
    "description": "Key Responsibilities\n\nActive Learner with Enthusiasm for Problem-Solving\n\nContinuously learn and apply new AI/ML techniques, including Generative AI, Agentic AI deep learning, and other emerging technologies. Demonstrate a passion for solving complex business challenges and experimenting with novel approaches to improve model performance.\n\nQuick Prototyping & Experimentation\n\nDevelop rapid prototypes to test new AI/GenAI/ML approaches and solutions for business problems. Implement proof-of-concept models quickly, enabling fast experimentation and iteration to assess feasibility before scaling to full development.\n\nSupport AI Product Development & Iteration\n\nCollaborate with lead/ senior data scientists and cross-functional teams to support the design, development, and deployment of AI-driven products. Contribute to the creation of prototypes and refine models based on business needs and feedback.\n\nModel Development and Optimization\n\nDesign, develop, and test machine learning, deep learning, and generative AI models, focusing on performance, scalability, and business relevance. Continuously refine and optimize models based on real-world results and metrics.\n\nData Preparation & Collaboration\n\nAssist in defining data requirements and support data engineers in building data pipelines. Clean and preprocess datasets, ensuring data quality and preparing it for use in machine learning applications. Collaborate closely with engineers to integrate models into production systems.\n\nResearch Support and Knowledge Sharing\n\nStay informed about the latest trends and research in AI/GenAI/ML and generative models, applying this knowledge to current projects. Actively participate in team discussions, contribute to the evaluation of new techniques, and share insights with peers to foster a collaborative learning environment.\n\nEssential Skills\n\u2022 Good knowledge of Python programming language, data engineering and data science ecosystem in Python.\n\u2022 Hands on experience in Generative AI, Agentic AI, LLM and Advance RAG techniques.\n\u2022 Hands on experience in developing and supporting Machine Learning solutions.\n\u2022 Hands on experience in developing Natural Language Processing (NLP) solutions\n\u2022 Hands on experience on SQL ecosystem\n\u2022 Hands on experience on Solr framework with Python\n\u2022 Experience of working on Linux and shell scripting\n\u2022 Basic statistical modelling knowledge\n\u2022 Strong Computer Science fundamentals are must. (Data structures, Algorithms, OS, Databases).\n\u2022 Good communication and organizational skills with significant attention to detail\n\u2022 Experience partnering with cross-functional teams of domain experts, engineers, data scientists, and production support teams.\n\u2022 Strong attention to detail with excellent problem-solving skills.\n\u2022 Desire and ability to thrive in a distributed technical environment while working on multiple projects simultaneously.\n\u2022 Passionate about latest technology trends with a strong desire for innovation.\n\u2022 Self-motivated, self-managing and able to work independently.\n\nEducation And Experience\n\u2022 Bachelor's degree (B.E/ B Tech. computer science, engineering, statistics/mathematics or a related field) from a four-year college or university, or equivalent, master\u2019s a plus.\n\u2022 Total at least 1 years of experience working on enterprise AI products\n\u2022 Experience in supporting software products or applications in the AI ML domain.\n\u2022 The above statements are intended to describe the general nature and level of work being performed by most people assigned to this job. They are not intended to be an exhaustive list of all duties and responsibilities and requirements.\n\nApplicants may be required to appear onsite at a Wolters Kluwer office as part of the recruitment process.",
    "url": "https://in.linkedin.com/jobs/view/data-scientist-python-genai-agenticai-at-wolters-kluwer-4319872554?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Scientist",
    "company": "Snowflake",
    "location": "Pune",
    "salary": "",
    "description": "Snowflake is about empowering enterprises to achieve their full potential \u2014 and people too. With a culture that\u2019s all in on impact, innovation, and collaboration, Snowflake is the sweet spot for building big, moving fast, and taking technology \u2014 and careers \u2014 to the next level.\n\nSnowflake is seeking a Data Scientist to join our expanding Enterprise AI & ML team. This role involves working on diverse AI/ML and data science initiatives, utilizing Snowflake's Data Cloud and Cortex AI. The successful candidate will design and develop scalable data science and machine learning solutions, build interactive AI applications, and collaborate on operationalizing intelligent systems to enhance data-driven decision-making throughout the company. This position focuses on applying data science, AI & ML skill sets to various domain specific business data problems across Snowflake.\n\nON THE ENTERPRISE AI & ML TEAM AT SNOWFLAKE, YOU WILL:\n\u2022 Design, prototype, and deploy data science and AI solutions.\n\u2022 Conduct end to end experimentation, including data exploration, feature engineering, model development, and validation.\n\u2022 Build and maintain Streamlit applications to visualize models, showcase insights, and enable business stakeholders to interact with AI driven solutions.\n\u2022 Develop and optimize LLM based applications, workflows, and operations; with a focus on retrieval, generation, semantic understanding and fine-tuning.\n\u2022 Partner cross functionally with data engineers, analysts, and product teams to translate ambiguous business problems into measurable outcomes.\n\nOUR IDEAL CANDIDATE WILL HAVE:\n\u2022 2 to 4 years of experience applying data science, machine learning, or AI techniques in real world business settings.\n\u2022 Strong programming skills in Python, proficiency in SQL for large scale data manipulation.\n\u2022 Familiarity with frameworks such as scikit-learn, XGBoost etc.\n\u2022 Understanding of LLM architectures, embeddings, vector search, and RAG pipelines.\n\u2022 Experience working on cloud platforms.\n\u2022 Strong analytical, storytelling, and communication skills to translate technical insights into actionable recommendations.\n\u2022 A mindset of curiosity, ownership, and collaboration, with an eagerness to work on open-ended problems.\n\u2022 Experience operationalizing AI & ML models in a production setting.\n\nSnowflake is growing fast, and we\u2019re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.\n\nHow do you want to make your impact?\n\nFor jobs located in the United States, please visit the job posting on the Snowflake Careers Site for salary and benefits information: careers.snowflake.com",
    "url": "https://careers.snowflake.com/us/en/job/SNCOUSE5563EEBE22F4F83ABADA6BD2B014860EXTERNALENUSF7C857F3DD284045B0C758E492307EC3/Data-Scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "Data Scientist  People Data Analytics & Insights",
    "company": "Syngenta",
    "location": "Pune",
    "salary": "",
    "description": "We are seeking a highly analytical and business-focused Data Scientist to join our People Analytics & Insights team. In this role, you will leverage advanced analytics, machine learning, and statistical modeling to uncover insights from workforce data, supporting strategic talent decisions across the organization. You will partner closely with HR, Talent Management, and business leaders to deliver data-driven solutions that enhance employee experience, improve workforce planning, and inform diversity, equity, and inclusion (DEI) strategies.\n\nKey Responsibilities:\n\u2022 Analyze large and complex HR datasets (e.g., engagement, attrition, performance, compensation, hiring) to uncover trends, patterns, and opportunities for business impact.\n\u2022 Build predictive and prescriptive models (e.g., attrition risk, career pathing, workforce segmentation) to support data-informed people strategies.\n\u2022 Translate business problems into analytical questions and communicate findings in clear, actionable terms to non-technical audiences.\n\u2022 Develop visualizations, dashboards, and storytelling tools to enhance insight delivery (e.g., in Tableau, Power BI, Workday Discovery Boards).\n\u2022 Partner with HR stakeholders to identify KPIs, define success metrics, and improve people-related decision-making through data.\n\u2022 Design and implement surveys, experiments (A/B testing), and causal inference models to evaluate the impact of HR programs and initiatives.\n\u2022 Ensure ethical data use and compliance with privacy and governance standards.\n\u2022 Stay current on industry best practices in people analytics, data science, and AI/ML in HR.\n\nCompany Description\n\nAt the Syngenta Group, our 56,000 people across more than 90 countries strive every day to transform agriculture through tailor-made solutions for the benefit of farmers, society and our planet \u2013 making us the world's most local agricultural technology and innovation partner.\n\nWebsite address - https://www.syngentagroup.com/\n\nLI page - https://www.linkedin.com/company/syngentagroup/posts/?feedView=all\n\nQualifications\n\u2022 Bachelor\u2019s or Master\u2019s degree in Data Science, Statistics, Computer Science, Industrial/Organizational Psychology, Economics, or a related field.\n\u2022 3\u20135+ years of experience in data science, analytics, or a similar role, ideally within HR or workforce analytics.\n\u2022 Proficiency in Python or R for statistical analysis and modeling.\n\u2022 Strong SQL skills for data extraction and manipulation.\n\u2022 Experience with data visualization tools (e.g., Tableau, Power BI, Workday Discovery Boards).\n\u2022 Solid understanding of machine learning algorithms, statistical modeling, and hypothesis testing.\n\u2022 Excellent communication skills, with the ability to explain complex analytical concepts to HR and business audiences.\n\u2022 Familiarity with Workday, SAP SuccessFactors, or other HRIS platforms is a plus.\n\nPreferred Skills:\n\u2022 Experience with natural language processing (NLP) on employee feedback or engagement data.\n\u2022 Knowledge of DEI analytics and workforce diversity measurement.\n\u2022 Exposure to cloud-based data platforms (e.g., AWS, GCP, Azure).\n\u2022 Understanding of HR functional areas like talent acquisition, performance management, and learning & development.\n\nKey Competencies:\n\u2022 Analytical Thinking & Problem Solving\n\u2022 Business Acumen & Strategic Mindset\n\u2022 Data Storytelling & Visualization\n\u2022 Collaboration & Stakeholder Management\n\u2022 Data Ethics & Privacy Awareness\n\nAdditional Information\n\nWL: 4A\n\nNote: Syngenta is an Equal Opportunity Employer and does not discriminate in recruitment, hiring, training, promotion or any other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, gender identity, marital or veteran status, disability, or any other legally protected status\n\nFollow us on: Twitter & LinkedIn\n\nhttps://twitter.com/SyngentaAPAC\n\nhttps://www.linkedin.com/company/syngenta/",
    "url": "https://jobs.syngenta.com/job/data-scientist-people-data-analytics-and-insights-in-in-pune-jid-14917?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "(29 / 10 / 2025) Data Scientist",
    "company": "Tata Consultancy Services",
    "location": "Pune",
    "salary": "",
    "description": "Dear Candidate,\n\nGreetings from TATA Consultancy Services!!\n\nPosition- Data Scientist-Python\n\nExperience-4 to 8 years\n\nLocation- Chennai, Pune, Mumbai\n\nNotice Period- 0 to 60 days / Serving Notice Period\n\nKey Responsibilities :\n\u2022 Understand business process / business problems and device Machine Learning solutions to optimize business processes wherever possible.\n\u2022 Experience using statistical computer languages (Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\n\u2022 Formulating machine learning solutions to business metrics, designing features from the data available from many large data sources, training, evaluating, and deploying models in production\n\u2022 Developing high-performance algorithms for precision targeting, testing and implementing these algorithms in scalable, production-ready code; Interacting with other teams to define interfaces and understanding and resolving dependencies.\n\u2022 Developing coding in high-level languages such as R, Python, Java\n\u2022 Experience working with and creating data architectures.\n\u2022 Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages / drawbacks.\n\u2022 Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.\n\nNote : Note-Candidates who have previously worked at TCS not eligible to apply.\n\nOnly relevant experience candidates can apply.",
    "url": "https://in.talent.com/view?id=d99f903fffd8&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Python Data Scientist / ML Engineer \u2013 Remote/Hybrid | AI, ML, Deep Learning | Only 4+ Years of Experience",
    "company": "Remotohire",
    "location": "Pune",
    "salary": "",
    "description": "Company: RemotoHire\n\nWork Mode: Remote / Hybrid\n\nExperience: 4\u20137 years\n\nAbout the Role:\n\nWe are hiring Python Data Scientists & ML Engineers to design and deploy intelligent systems, from predictive analytics to generative AI. You\u2019ll work with global clients on real-world AI/ML problems.\n\nKey Responsibilities:\n\u2022 Build ML models using scikit-learn, TensorFlow, PyTorch.\n\u2022 Work on NLP, Computer Vision, Generative AI, LLMs (GPT, LangChain).\n\u2022 Deploy ML pipelines on AWS SageMaker, Azure ML, GCP Vertex AI.\n\u2022 Handle data preprocessing, feature engineering, big data (Spark, Hadoop).\n\u2022 Optimize models for performance and scalability.\n\nRequired Skills:\n\u2022 Strong in Python, Pandas, NumPy, Matplotlib, Jupyter.\n\u2022 ML frameworks: scikit-learn, TensorFlow, PyTorch.\n\u2022 Cloud ML services: AWS, Azure, GCP.\n\u2022 Knowledge of MLOps, CI/CD for ML pipelines.\n\u2022 Bonus: Experience with AI Agents, RAG pipelines, and vector databases.\n\n\ud83d\udc49 Apply Now: https://www.oxcytech.com/developer-application\n\n\ud83d\udccc Note: While applying, please select \u201cPython Data Science / Machine Learning / AI\u201d from the Main dropdown.",
    "url": "https://in.linkedin.com/jobs/view/python-data-scientist-ml-engineer-%E2%80%93-remote-hybrid-ai-ml-deep-learning-only-4%2B-years-of-experience-at-remotohire-4331723103?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "\u25b7 Urgent! Data Scientist",
    "company": "Tata Consultancy Services",
    "location": "Pune",
    "salary": "",
    "description": "Dear Candidate,\n\nGreetings from TATA Consultancy Services!!\n\nPosition- Data Scientist-Python\n\nExperience-4 to 8 years\n\nLocation- Chennai, Pune, Mumbai\n\nNotice Period- 0 to 60 days / Serving Notice Period\n\nKey Responsibilities :\n\u2022 Understand business process / business problems and device Machine Learning solutions to optimize business processes wherever possible.\n\u2022 Experience using statistical computer languages (Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\n\u2022 Formulating machine learning solutions to business metrics, designing features from the data available from many large data sources, training, evaluating, and deploying models in production\n\u2022 Developing high-performance algorithms for precision targeting, testing and implementing these algorithms in scalable, production-ready code; Interacting with other teams to define interfaces and understanding and resolving dependencies.\n\u2022 Developing coding in high-level languages such as R, Python, Java\n\u2022 Experience working with and creating data architectures.\n\u2022 Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages / drawbacks.\n\u2022 Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.\n\nNote : Note-Candidates who have previously worked at TCS not eligible to apply.\n\nOnly relevant experience candidates can apply.",
    "url": "https://in.talent.com/view?id=820a7d06df0c&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Senior Data Scientist (Artificial Intelligence Machine Learning)",
    "company": "FIS Global",
    "location": "Pune",
    "salary": "",
    "description": "Position Type :\nFull time\n\nType Of Hire :\nExperienced (relevant combo of work and education)\n\nEducation Desired :\nBachelor of Engineering\n\nTravel Percentage :\n1 - 5%\n\nSenior Data Scientist (Artificial Intelligence Machine Learning)\n\nAre you curious, motivated, and forward-thinking? At FIS you\u2019ll have the opportunity to work on some of the most challenging and relevant issues in financial services and technology. Our talented people empower us, and we believe in being part of a team that is open, collaborative, entrepreneurial, passionate and above all fun.\n\nAbout the role:\n\u2022 We are looking for a talented and passionate Data Scientist willing to challenge themself and produce best in class AI enabled solution\n\u2022 You will be required to use the concepts of AIML, GenAI, LLMs, Sentiment analysis, etc.\n\u2022 The role requires creating correlation between different data points and do predictive, preventive analysis.\n\nAbout the Team :\n\nTeam provide solutions and services that help our clients grow, compete, and optimize their business. Our AIOPS team is creating AIML solution targeted to reduce the Enterprise MTTR through our world class product\n\nWhat you will be doing:\n\u2022 Employ machine learning and statistical modeling to create and enhance data driven products.\n\u2022 Analyze and extract insights from internal and external data.\n\u2022 Work with Big Data and transform complex datasets into more usable formats.\n\u2022 Work with a variety of data science tools and programming languages such as SAS, Python, R, Scala, SQL. Work independently and collaborate with other groups to solve complex problems.\n\u2022 Create and present analyses to internal and external partners and clients.\n\u2022 Will be working in 2 Pm to 11 Pm IST Shifts\n\nWhat you bring:\n\u2022 4 to 6 Years of machine learning, artificial intelligence, statistical modeling, data visualization, and data analysis\n\u2022 Proficient in data science tools and programming languages such as SAS, Python, R, Scala, SQL\n\u2022 Relevant degree in Artificial Intelligence Machine Learning\n\u2022 Experience or knowledge of cloud-based technology\n\u2022 Knowledge of financial services industry\n\nWhat we offer you:\n\u2022 A range of benefits designed to help support your lifestyle and wellbeing.\n\u2022 A multi-faceted job with a broad spectrum of responsibilities\n\u2022 A modern international work environment and a dedicated and innovative team\n\u2022 A broad range of professional education and personal development possibilities \u2013 FIS is your final career step.\n\nPrivacy Statement\n\nFIS is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how FIS protects personal information online, please see the Online Privacy Notice.\n\nSourcing Model\n\nRecruitment at FIS works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. FIS does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company.\n\n#pridepass",
    "url": "https://careers.fisglobal.com/us/en/job/FIGLUSJR0296204EXTERNAL/Senior-Data-Scientist-Artificial-Intelligence-Machine-Learning?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (Lead / Associate Architect) - 42146",
    "company": "Fission Labs",
    "location": "Pune",
    "salary": "",
    "description": "Role: Data Scientist (Lead / Associate Architect)\n\nExperience: 8+ years\n\nLocation: Hyderabad / Pune\n\nFission Labs, headquartered in Sunnyvale, with offices in Dallas & Hyderabad, Fission Labs is a leading software development company, specializing in crafting flexible, agile, and scalable solutions that propel businesses forward. With a comprehensive range of services, including product development, cloud engineering, big data analytics, QA, DevOps consulting, and AI/ML solutions, we empower clients to achieve sustainable digital transformation that aligns seamlessly with their business goals.\n\nWhat are we looking for!\n\nAs a Data Science professional at Fission Labs, you will be part of a high-impact team that designs and develops data-driven solutions for complex business challenges. You\u2019ll work on end-to-end AI and ML systems \u2014 from data exploration and model development to large-scale deployment and optimization in cloud environments.\n\nResponsibilities\n\u2022 Design and architect complex Generative AI solutions using AWS technologies.\n\u2022 Develop advanced AI architectures incorporating state-of-the-art GenAI technologies.\n\u2022 Create and implement Retrieval Augmented Generation (RAG) and GraphRAG solutions.\n\u2022 Architect scalable AI systems using AWS Bedrock and SageMaker.\n\u2022 Design and implement agentic AI systems with advanced reasoning capabilities.\n\u2022 Develop custom AI solutions leveraging vector databases and advanced machine learning techniques.\n\u2022 Evaluate and integrate emerging GenAI technologies and methodologies.\n\nTechnical Expertise Requirements\n\nGenerative AI Technologies\n\nExpert-level Understanding Of\n\u2022 Retrieval Augmented Generation (RAG)\n\u2022 GraphRAG methodologies\n\u2022 LoRA (Low-Rank Adaptation) techniques\n\u2022 Vector Database architectures\n\u2022 Agentic AI design principles\n\nAWS AI Services\n\nComprehensive Expertise In\n\u2022 AWS Bedrock\n\u2022 Amazon SageMaker\n\u2022 AWS AI/ML services ecosystem\n\u2022 Cloud-native AI solution design\n\nTechnical Skills\n\nAdvanced Python programming for AI/ML applications\n\nDeep Understanding Of\n\u2022 Large Language Models (LLMs)\n\u2022 Machine Learning architectures\n\u2022 Preferred Qualifications\n\u2022 AI model fine-tuning techniques\n\u2022 Prompt engineering\n\u2022 AI system design and integration\n\nCore Competencies\n\u2022 Advanced AI solution architecture\n\u2022 Machine learning model optimization\n\u2022 Cloud-native AI system design\n\u2022 Performance tuning of GenAI solutions\n\u2022 Enterprise AI strategy development\n\nTechnical Stack\n\u2022 Programming Languages: Python (required)\n\u2022 Cloud Platform: AWS\n\nAI Technologies\n\u2022 Bedrock\n\u2022 SageMaker\n\u2022 Vector Databases\n\nMachine Learning Frameworks\n\u2022 PyTorch\n\u2022 TensorFlow\n\u2022 Hugging Face\n\nAI Integration Tools\n\u2022 LangChain o LlamaIndex\n\nYou would enjoy\n\u2022 Opportunity to work on impactful technical challenges with global reach.\n\u2022 Vast opportunities for self-development, including online university access and knowledge sharing opportunities.\n\u2022 Sponsored Tech Talks & Hackathons to foster innovation and learning.\n\u2022 Generous benefits packages including health insurance, retirement benefits, flexible work hours, and more.\n\u2022 Supportive work environment with forums to explore passions beyond work.",
    "url": "https://in.linkedin.com/jobs/view/data-scientist-lead-associate-architect-42146-at-fission-labs-4333036595?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "\u25b7 Immediate Start : Manager, Data Science (Media / Market Research)",
    "company": "NielsenIQ",
    "location": "Pune",
    "salary": "",
    "description": "As a Data Science Manager you will have following key accountabilities :\n\nTeam Leadership : Build and lead a high-performing team of 6-8 Data Scientists and Machine Learning Engineers in our Pune hub. Foster a collaborative and inclusive team culture that encourages innovation and continuous learning.\n\nTechnical Communication : Explain Data Science principles, concepts, algorithms, and approaches in simple terms to diverse audiences, including non-technical stakeholders.\n\nBusiness Understanding : Utilize your solid business understanding to align with stakeholders, discuss requirements and feasibility, and manage expectations effectively. Ensure clear communication and understanding of project goals and outcomes.\n\nEducational Background :\n\nPhD or Master\u2019s degree in Computer Science, Engineering, Statistics, Mathematics, or a related field, with min 8+ years of experience as a Data Scientist.\n\nLeadership Experience :\n\nProven experience as a people manager and / or mentor, with a track record of developing and leading high-performing teams.\n\nLeadership Experience :\n\nProven experience as a people manager and / or mentor, with a track record of developing and leading high-performing teams\n\nCommunication Skills :\n\u2022 Ability to effectively communicate complex methodologies and technologies to both technical and non-technical audiences.\n\u2022 Strong problem-solving skills and an independent working style.\n\nTechnical Expertise :\n\u2022 Strong statistical and machine learning modeling skills, including statistical tests, classification, predictive modeling, handling of missing data, and sampling / weighting techniques.\n\u2022 Solid in analytical programming languages such as Python or R, along with their respective ecosystems.\n\u2022 Hands-on experience implementing these models in production systems.\n\u2022 Proficient in software development skills, including unit testing, CI / CD, and version control with Git, along with familiarity with computer science and engineering fundamentals such as data structures, software design principles, and testing strategies.\n\nPreferred qualifications\n\u2022 Experience in the Media industry\n\u2022 Experience working with cloud-based data services (AWS, Azure, or GCP)\n\u2022 Experience with Optimization techniques such as : linear programming, integer programming, genetic algorithms, constrained optimization is a plus",
    "url": "https://in.talent.com/view?id=c3e3e4ba1512&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "\u25b7 15h Left: Lead Data Scientist Gen Ai Pune",
    "company": "Yash Technologies",
    "location": "Pune",
    "salary": "",
    "description": "Job Overview:\n\nLocations- Indore/Pune/Hyderabad/Bangalore\n\nWe are looking for a AI/ML Developer to join our team of researchers, data scientists, and developers. You will work on cutting-edge AI solutions across industries such as commerce, agriculture, insurance, financial markets, and procurement. Your role involves developing and optimizing machine learning and generative AI models to solve real-world challenges.\n\nKey Responsibilities:\n\n\u2022 Develop and optimize ML, NLP, Deep Learning, and Generative AI models.\n\n\u2022 Research and implement state-of-the-art algorithms for supervised and unsupervised learning.\n\n\u2022 Work with large-scale datasets in distributed environments.\n\n\u2022 Understand business processes to select and apply the best ML approaches.\n\n\u2022 Ensure scalability and performance of ML solutions.\n\n\u2022 Collaborate with cross-functional teams, including product owners, designers, and developers.\n\n\u2022 Solve complex data integration and deployment challenges.\n\n\u2022 Communicate results effectively using data visualization.\n\n\u2022 Work in global teams across different time zones.\n\nRequired Skills & Experience:\n\n\u2022 Robust experience in Machine Learning, Deep Learning, NLP, and Generative AI.\n\n\u2022 Hands-on expertise in frameworks like TensorFlow, PyTorch, or Hugging Face Transformers.\n\n\u2022 Experience with LLMs (Large Language Models), model fine-tuning, and prompt engineering.\n\n\u2022 Proficiency in Python, R, or Scala for ML development.\n\n\u2022 Knowledge of cloud-based ML platforms (AWS, Azure, GCP).\n\n\u2022 Experience with big data processing (Spark, Hadoop, or Dask).\n\n\u2022 Ability to scale ML models from prototypes to production.\n\n\u2022 Solid analytical and problem-solving skills.\n\nIf you\u2019re passionate about pushing the boundaries of ML and GenAI, we\u2019d love to hear from you!",
    "url": "https://in.jobrapido.com/jobpreview/8719491990573547520?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Machine Learning Engineer (MLE) \u2013 Python | DS | DE | ETL | Azure | Databricks",
    "company": "Apptware",
    "location": "Pune",
    "salary": "",
    "description": "Job description\n\nPosition: Machine Learning Engineer (MLE) \u2013 Python | DS | DE | ETL | Azure | Databricks\n\n\ud83d\udd39 Experience: 4\u20138 years\n\n\ud83d\udd39 Location: Pune / Bangalore\n\n\ud83d\udd39 Employment Type: Full-time\n\nJob Description:\n\nWe are seeking an experienced Machine Learning Engineer (MLE) with strong expertise in Python, Data Science (DS), Data Engineering (DE), ETL, and Azure Databricks. The ideal candidate will design, build, and deploy scalable ML solutions while collaborating with data and engineering teams to solve complex business challenges.\n\nKey Responsibilities:\n\u2022 Design and implement end-to-end ML pipelines using Databricks and Azure.\n\u2022 Develop, train, and deploy machine learning models for various business use cases.\n\u2022 Perform data preprocessing, feature engineering, and model optimization on large datasets.\n\u2022 Integrate ML models with production systems and ensure performance monitoring.\n\u2022 Collaborate with cross-functional teams to understand business needs and deliver effective ML solutions.\n\u2022 Stay updated with the latest trends in ML, DL, and AI frameworks.\n\nRequired Skills:\n\u2022 Python (Advanced) \u2013 Must\n\u2022 Data Science (DS), Data Engineering (DE), and ETL \u2013 Must\n\u2022 Machine Learning (ML) \u2013 Must\n\u2022 Deep Learning (Basic Understanding) \u2013 Good to have\n\u2022 Natural Language Processing (NLP) \u2013 Basic Understanding\n\u2022 Computer Vision \u2013 Basic Understanding\n\u2022 Python for Image Processing \u2013 Basic Understanding\n\u2022 ML Frameworks (TensorFlow / PyTorch / Scikit-learn) \u2013 Must\n\u2022 Azure Cloud \u2013 Must\n\u2022 Databricks \u2013 Must\n\nGood to Have:\n\u2022 Experience with Agile Methodology\n\u2022 Exposure to MLOps and CI/CD pipelines\n\u2022 Familiarity with data visualization tools like Power BI or Tableau\n\nAdditional Details:\n\u2022 Immediate joiners preferred\n\u2022 Candidates with up to 30 days\u2019 notice period can be considered\n\nApply Here: https://forms.gle/PNgXBb3QJh57Uqd79",
    "url": "https://in.linkedin.com/jobs/view/machine-learning-engineer-mle-%E2%80%93-python-ds-de-etl-azure-databricks-at-apptware-4331708651?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Sr Data Scientist",
    "company": "Birlasoft Limited",
    "location": "Pune",
    "salary": "",
    "description": "Area(s) of responsibility\n\nData Scientist experience (8 to 10) - 5B\n\n5 years of relevant work experience as a data scientist\n\nExperience designing and building statistical forecasting models.\n\nExperience in Python, AWS Cloud Services SageMaker,Comprehend, Amazon Bedrock for generative AI and Open AI\n\nExperience designing and building machine learning models.\n\nLead the end-to-end development of AI/ML solutions, from problem definition to production deployment.\n\nStrong programming skills in Python and experience with libraries like TensorFlow, PyTorch, Scikit-learn.\n\nMinimum 2 years of experience in Azure Cloud using Natural Language API\n\nExperience designing and building statistical forecasting models.\n\nExperience in Ingesting data from API and Databases\n\nExperience designing and building machine learning models.\n\nHands-on experience with LLMs and GenAI frameworks\n\nExperience in Django, Flask web frameworks\n\nExperience designing and building optimization models., including expertise with statistical data analysis\n\nMandatory Skillset: Python, AWS Cloud Services SageMaker, Comprehend, Amazon Bedrock for generative AI and Open AI",
    "url": "https://jobs.birlasoft.com/job/Pune-Sr-Data-Scientist-INDI/45605844/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Senior Data Scientist (Artificial Intelligence Machine Learning)",
    "company": "FIS Global",
    "location": "Pune",
    "salary": "",
    "description": "Position Type :\n\nFull time\n\nType Of Hire :\n\nExperienced (relevant combo of work and education)\n\nEducation Desired :\n\nBachelor of Engineering\n\nTravel Percentage :\n\n1 - 5%\n\nSenior Data Scientist (Artificial Intelligence Machine Learning)\n\nAre you curious, motivated, and forward-thinking? At FIS you\u2019ll have the opportunity to work on some of the most challenging and relevant issues in financial services and technology. Our talented people empower us, and we believe in being part of a team that is open, collaborative, entrepreneurial, passionate and above all fun.\n\nAbout the role:\n\u2022 We are looking for a talented and passionate Data Scientist willing to challenge themself and produce best in class AI enabled solution\n\u2022 You will be required to use the concepts of AIML, GenAI, LLMs, Sentiment analysis, etc.\n\u2022 The role requires creating correlation between different data points and do predictive, preventive analysis.\n\nAbout the Team :\n\nTeam provide solutions and services that help our clients grow, compete, and optimize their business. Our AIOPS team is creating AIML solution targeted to reduce the Enterprise MTTR through our world class product\n\nWhat you will be doing:\n\u2022 Employ machine learning and statistical modeling to create and enhance data driven products.\n\u2022 Analyze and extract insights from internal and external data.\n\u2022 Work with Big Data and transform complex datasets into more usable formats.\n\u2022 Work with a variety of data science tools and programming languages such as SAS, Python, R, Scala, SQL. Work independently and collaborate with other groups to solve complex problems.\n\u2022 Create and present analyses to internal and external partners and clients.\n\u2022 Will be working in 2 Pm to 11 Pm IST Shifts\n\nWhat you bring:\n\u2022 4 to 6 Years of machine learning, artificial intelligence, statistical modeling, data visualization, and data analysis\n\u2022 Proficient in data science tools and programming languages such as SAS, Python, R, Scala, SQL\n\u2022 Relevant degree in Artificial Intelligence Machine Learning\n\u2022 Experience or knowledge of cloud-based technology\n\u2022 Knowledge of financial services industry\n\nWhat we offer you:\n\u2022 A range of benefits designed to help support your lifestyle and wellbeing.\n\u2022 A multi-faceted job with a broad spectrum of responsibilities\n\u2022 A modern international work environment and a dedicated and innovative team\n\u2022 A broad range of professional education and personal development possibilities \u2013 FIS is your final career step.\n\nPrivacy Statement\n\nFIS is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how FIS protects personal information online, please see the Online Privacy Notice.\n\nSourcing Model\n\nRecruitment at FIS works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. FIS does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company.\n\n#pridepass",
    "url": "https://www.glassdoor.co.in/job-listing/senior-data-scientist-artificial-intelligence-machine-learning-fis-global-JV_IC2856202_KO0,62_KE63,73.htm?jl=1009714190836&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Enterprise Data Analyst",
    "company": "Snowflake",
    "location": "Pune",
    "salary": "",
    "description": "Snowflake is about empowering enterprises to achieve their full potential \u2014 and people too. With a culture that\u2019s all in on impact, innovation, and collaboration, Snowflake is the sweet spot for building big, moving fast, and taking technology \u2014 and careers \u2014 to the next level.\n\nSnowflake is seeking a Data Scientist to join our expanding Enterprise AI & ML team. This role involves working on diverse AI/ML and data science initiatives, utilizing Snowflake's Data Cloud and Cortex AI. The successful candidate will design and develop scalable data science and machine learning solutions, build interactive AI applications, and collaborate on operationalizing intelligent systems to enhance data-driven decision-making throughout the company. This position focuses on applying data science, AI & ML skill sets to various domain specific business data problems across Snowflake.\n\nON THE DATA SCIENCE & ANALYTICS TEAM AT SNOWFLAKE, YOU WILL:\n\u2022 Design, prototype, and deploy data science and AI solutions.\n\u2022 Conduct end to end experimentation, including data exploration, feature engineering, model development, and validation.\n\u2022 Build and maintain Streamlit applications to visualize models, showcase insights, and enable business stakeholders to interact with AI driven solutions.\n\u2022 Develop and optimize LLM based applications, workflows, and operations; with a focus on retrieval, generation, semantic understanding and fine-tuning.\n\u2022 Partner cross functionally with data engineers, analysts, and product teams to translate ambiguous business problems into measurable outcomes.\n\nOUR IDEAL CANDIDATE WILL HAVE:\n\u2022 2 to 4 years of experience applying data science, machine learning, or AI techniques in real world business settings.\n\u2022 Strong programming skills in Python, proficiency in SQL for large scale data manipulation.\n\u2022 Familiarity with frameworks such as scikit-learn, XGBoost etc.\n\u2022 Understanding of LLM architectures, embeddings, vector search, and RAG pipelines.\n\u2022 Experience working on cloud platforms.\n\u2022 Strong analytical, storytelling, and communication skills to translate technical insights into actionable recommendations.\n\u2022 A mindset of curiosity, ownership, and collaboration, with an eagerness to work on open-ended problems.\n\u2022 Experience operationalizing AI & ML models in a production setting.\n\nSnowflake is growing fast, and we\u2019re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.\n\nHow do you want to make your impact?\n\nFor jobs located in the United States, please visit the job posting on the Snowflake Careers Site for salary and benefits information: careers.snowflake.com",
    "url": "https://builtin.com/job/enterprise-data-analyst/7508278?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "TechVerito Software Solutions - Senior Data Scientist - Machine Learning/Artificial Intelligence (Pune)",
    "company": "TechVerito",
    "location": "Pune",
    "salary": "",
    "description": "Description :\nAbout the Role\nWe are looking for a Senior Data Scientist to lead the development and deployment of machine learning models that drive key business decisions.\nYou will translate complex business problems into actionable ML solutions, from experimentation to production.\nKey Responsibilities :\n- Lead end-to-end development of Machine Learning models for areas such as prediction, classification, and recommendation.\n- Design, implement, and validate models using rigorous statistical methods and ML best practices.\n- Develop robust ETL/ELT pipelines to ensure high-quality data for model training and inference.\n- Collaborate with Data Engineering and DevOps teams to productionize models and monitor their performance in a live setting.\n- Communicate complex analytical insights and model outcomes to technical and non-technical stakeholders.\n- Research and apply cutting-edge techniques in the fields of AI, Deep Learning, and NLP.\nTechnical Skills Required :\n- Languages: Expert proficiency in Python (NumPy, Pandas, SciPy, Scikit-learn).\n- ML/DL Frameworks: Hands-on experience with TensorFlow or PyTorch.\n- Big Data: Experience with SQL and distributed processing frameworks like Spark (PySpark).\n- Cloud & MLOps: Familiarity with deploying and managing models on cloud platforms (AWS SageMaker, Azure ML, or GCP AI Platform).\nKnowledge of MLOps tools (e., MLflow, Kubeflow) is highly desirable.\n- Statistics: Strong foundation in statistics, probability, and experimental design (A/B testing).\nQualifications :\n- Master's or Ph. in Computer Science, Statistics, Mathematics, or a related quantitative field.\n- 4+ years of hands-on experience in a Data Scientist role, with a focus on building and deploying ML models\n\n(ref:hirist.tech)",
    "url": "https://in.jobrapido.com/jobpreview/8149968057129762816?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Industry Consultant - Manufacturing + Data Science",
    "company": "Khoobi Consulting",
    "location": "IN",
    "salary": "",
    "description": "Responsibility:\n\n- Help customers identify opportunities of monetizing their data assets to drive growth and profitability.\n\n- Understand customer's engineering, supply chain and production planning requirements and design digital solutions for customers that have AI and AI-Agents embedded in them.\n\n- Act as a bridge between customer business stakeholders and development teams comprising of Data Scientists and Solution Architects.\n\n- Publish Whitepapers on topics covering application of AI to solve domain specific issues and drive growth in the industry.\n\nEssential Skills:\n\n- Ability to manage senior customer stakeholders.\n\n- Ability to help customers understand how Industry 4.0 practices can be applied in their environment.\n\n- Ability to lead requirement gathering and solutioning workshops with customers.\n\n- Ability to understand the latest development in AI research and relate them to areas where they can be applied.\n\nExperience:\n\n- Overall 15 20 years.\n\nDomain:\n\n- Minimum 10 years in Manufacturing (Production Planning, Maintenance, Automation, Control Systems, Supply Chain).\n\n- Preferred Experience in Actual Automation and Control Systems experience preferred.\n\nTechnical: Minimum 5 years in Control Systems data, Digital Applications implementation.\n\nKnowledge:\n\n- Strong in applying Statistics knowledge.\n\n- Machine Learning / Deep Learning / LLM / Agents.\n\nQualifications.\n\n- Masters or Bachelor's degree in Computer Science, Engineering or related field.\n\nWorking Arrangements.\n\n- 100% work from office.",
    "url": "https://www.iimjobs.com/j/industry-consultant-manufacturing-data-science-1632852?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Science Instructor",
    "company": "Itvedant Education Pvt. Ltd.",
    "location": "Pune",
    "salary": "",
    "description": "Responsibilities:\n\n\u25cf Conducting classroom and online lectures on programming languages (Data Science, Python,\n\nData Analytics) and related technologies to students\n\n\u25cf Assigning and evaluating coursework, quizzes, and projects\n\n\u25cf Providing one-on-one assistance and mentoring to students as required\n\n\u25cf Ensuring that the course curriculum is up-to-date and relevant to industry standards\n\n\u25cf Collaborating with other trainers and course developers to develop new training materials\n\n\u25cf Maintaining accurate student records and progress reports\n\n\u25cf Creating a positive and engaging learning environment for students\n\n\u25cf Participating in faculty meetings, staff development programs, and other professional\n\ndevelopment activities as required\n\n\u25cf Staying up-to-date with the latest trends and developments and related technologies\n\nRequirements:\n\n\u25cf A Bachelor's or Master's degree in Computer Science or a related field\n\n\u25cf A minimum of 1 years of experience as a trainer\n\n\u25cf Excellent communication and interpersonal skills\n\n\u25cf Strong knowledge of Python, Machine Learning, Data Science, Data Analytics, Deep\n\nLearning, NLP and related technologies\n\n\u25cf Experience working with databases such as PostgreSQL and MySQL\n\n\u25cf A passion for teaching and helping students achieve their career goals\n\n\u25cf Ability to work independently as well as in a team environment",
    "url": "https://in.linkedin.com/jobs/view/data-science-instructor-at-itvedant-education-pvt-ltd-4320264933?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "AI ML Python data science trainer",
    "company": "myinternship.in",
    "location": "Pune",
    "salary": "",
    "description": "Looking for an experienced AI, ML, Data Science & Analytics Trainer to deliver engaging, hands-on sessions covering Python, Machine Learning, and Power BI.\nShould have strong practical knowledge, real-world project exposure, and passion for teaching.\nResponsible for curriculum delivery, student mentoring, and guiding on live projects.\n\nJob Type: Full-time\n\nWork Location: In person",
    "url": "https://www.glassdoor.co.in/job-listing/ai-ml-python-data-science-trainer-myinternship-in-JV_IC2856202_KO0,33_KE34,49.htm?jl=1009923636335&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Business Sales Head- Data Science",
    "company": "Cinecraft",
    "location": "Pune",
    "salary": "",
    "description": "Position: Business Head \u2013 Data Science\n\nLocation: Pune, Maharashtra\nInstitute: Cinecraft Digital Academy\n\nAbout the Role:\nWe are seeking a dynamic and experienced Business Head \u2013 Data Science to lead our Data Science, AI, and Analytics division. The ideal candidate will drive business growth, oversee academic excellence, and build strong industry partnerships to strengthen our position as a leading digital education brand.\n\nKey Responsibilities:\n\nAchieve admission and revenue targets for Data Science & AI programs.\nLead academic planning, curriculum upgrades, and faculty management.\nCollaborate with marketing for lead generation and brand building.\nDevelop industry tie-ups for placements, projects, and internships.\nManage team performance and ensure smooth operations.\nStay updated with market trends and identify new course opportunities.\n\nRequirements:\n\nGraduate/Postgraduate in Data Science, Computer Science, or Business/ MBA.\n3+ years of experience in education management, EdTech, or training industry working towards admissions.\nStrong knowledge of Data Science, AI, and analytics ecosystem.\n\nExcellent leadership, communication, and business development skills.\n\nWhat We Offer:\nCompetitive salary with performance incentives.\nGrowth-driven, creative work environment.\nOpportunity to lead an expanding digital education brand.\n\nMore about this Business Sales Head- Data Science job\n\nCinecraft is aggressively hiring for the job profile of Business Sales Head- Data Science at Pune in Pawar Quarter (Hotel Raviraj) locality. Kindly go through the FAQs below to get all answers related to the given job.\n\n1. How much salary can I expect as a Business Sales Head- Data Science in Cinecraft in Pune?\n\nAns. You can expect a minimum salary of 40,000 INR and can go up to 60,000 INR. The salary offered will depend on your skills, experience and performance in the interview.\n\n2. What is the eligibility criteria to apply for Business Sales Head- Data Science in Cinecraft in Pune?\n\nAns. The candidate should have completed Graduate degree and people who have 3 to 31 years are eligible to apply for this job. You can apply for more jobs in Pune to get hired quickly.\n\n3. Is there any specific skill required for this job?\n\nAns. The candidate should have Good (Intermediate / Advanced) English skills and sound communication skills for this job.\n\n4. Who can apply for this job?\n\nAns. Only Male candidates can apply for this job.\n\n5. Is it a work from home job?\n\nAns. No, it\u2019s not a work from home job and can\u2019t be done online. You can explore and apply for other work from home jobs in Pune at apna.\n\n6. Are there any charges or deposits required while applying for the role or while joining?\n\nAns. No work-related deposit needs to be made during your employment with the company.\n\n7. How can I apply for this job?\n\nAns. Go to the apna app and apply for this job. Click on the apply button and call HR directly to schedule your interview.\n\n8. What is the last date to apply?\n\nAns. The last date to apply for this job is 12-Nov-2025.\n\nFor more details, download apna app and find Full Time jobs in Pune. Through apna, you can find jobs in 74 cities across India. Join NOW!",
    "url": "https://apna.co/job/pune/business-sales-head-data-science-879117150?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "AIML (Data Scientist)",
    "company": "WOW Softech",
    "location": "Pune",
    "salary": "",
    "description": "Role & responsibilities\n\nData Scientist,\n\u2022 At least 4+ years of significant experience in data Science, developing video analytics/image processing software\n\u2022 Knowledge required on- ffmpeg, Deep Learning and Deep Stream SDK using Nvidia Jetson Nano\n\u2022 Demonstrated ability in troubleshooting and hardware/software trade-offs\n\nPreferred candidate profile",
    "url": "https://in.bebee.com/job/242610eeb2baec709223c052a199eb7e?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Data Science Offshore Lead (Life Sciences)",
    "company": "ProLegion",
    "location": "Pune",
    "salary": "",
    "description": "Job Title: Data Science Offshore Lead (Life Sciences)\n\nLocation: Pune, Maharashtra, India\n\nDuration: Contractual\n\nRoles and Responsibilities\n\u2022 Lead and manage offshore data science projects specifically in the life sciences sector, ensuring alignment with overall business goals.\n\u2022 Coordinate with cross-functional teams to ensure the seamless execution of data-driven initiatives, providing leadership and direction as needed.\n\u2022 Develop and implement robust data science models and algorithms to address key business questions within life sciences.\n\u2022 Facilitate communication between onshore and offshore teams to ensure project objectives are met effectively and efficiently.\n\u2022 Maintain a comprehensive understanding of the latest advancements in data science and machine learning, applying cutting-edge approaches as appropriate to ongoing projects.\n\u2022 Ensure continuous quality improvement and risk management across all project phases, delivering high-quality outputs on time and within budget.\n\u2022 Conduct regular progress reviews with stakeholders, addressing any issues or concerns promptly and effectively.\n\nRequired Qualifications\n\u2022 Proven experience in leading data science teams, preferably within the life sciences sector, showcasing successful project delivery and team management.\n\u2022 Strong knowledge and practical experience in applying data science and machine learning techniques to real-world problems.\n\u2022 Advanced degree in a relevant field such as Data Science, Computer Science, or Life Sciences with a solid foundation in quantitative and analytical skills.\n\u2022 Demonstrated project management skills with the ability to oversee multiple projects simultaneously, managing resources and timelines effectively.\n\u2022 Excellent communication and interpersonal skills, with the capability to liaise effectively with diverse teams and stakeholders across global locations.\n\u2022 Strong problem-solving and decision-making skills, able to translate complex data insights into actionable strategies.\n\u2022 Proficiency in programming languages commonly used in data science, such as Python or R, and experience with data visualisation tools.\n\nKey Responsibilities\n\u2022 Lead offshore data science operations in Pune, Maharashtra, India, ensuring the delivery of high-quality analytical solutions to the life sciences industry.\n\u2022 Partner with global stakeholders to define project scopes, objectives, and success metrics, aligning them with strategic priorities.\n\u2022 Foster a collaborative and innovative work environment, championing best practices and continuous improvement in data science methodologies.\n\u2022 Mentor and develop talent within the team, providing guidance, feedback, and career development opportunities to junior team members.\n\u2022 Identify opportunities for growth and expansion of data science capabilities within life sciences projects, advocating for investment in new tools and technologies.\n\u2022 Ensure regulatory compliance and ethical standards are met in all analytical processes and project deliveries.\n\u2022 Drive the adoption of automated, efficient workflows, enhancing the analytical capabilities and performance across all offshore operations.",
    "url": "https://in.linkedin.com/jobs/view/data-science-offshore-lead-life-sciences-at-prolegion-4333352948?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "\u25b7 Urgent Data Scientist Pune",
    "company": "Terragig",
    "location": "Pune",
    "salary": "",
    "description": "We are looking for Data Science off-shore Lead \u2013 Life Sciences Domain\n\nLocation - Pune\n\nJob Type - Fulltime\n\nnotice period - 45 days\n\nExperience - 6+ Years\n\nRequired Skills:\n\nData Science , AI, ML, GenAI, MLOps , Life Sciences Domain\n\nRoles and responsibilities\nLead data science efforts (AI, ML, GenAI, analytical formulation) for multiple client engagements in Life Sciences domain.\nManage end-to-end Data Science project lifecycle from problem comprehension, analytical solution development to final delivery.\nAct as primary point of contact for client interactions, presentations, and requirement elicitation.\nGuide teams on advanced data science techniques ensuring alignment with business objectives.\nCollaborate cross-functionally with domain experts, business stakeholders, and technical teams to deliver robust analytical solutions.\nExpert knowledge of data science algorithms, methodologies, and end-to-end lifecycle (AI/ML/GenAI), MLOps and post deployment service of AI models\nSolid comprehension of complex Life Sciences problems\nExceptional articulation skills to communicate technical concepts clearly to both technical and business stakeholders.\nAdvanced analytical skills for strategic problem-solving and actionable insight generation.",
    "url": "https://in.jobrapido.com/jobpreview/8900853684796129280?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "YASH Technologies - Senior Data Scientist - NLP / RAG",
    "company": "Yash Technologies",
    "location": "Pune",
    "salary": "",
    "description": "Description : Job Overview :\n\nWe are looking for a Sr. Data Scientist to join our team of researchers, data scientists, and developers.\n\nKey Responsibilities :\n\u2022 Develop and optimize and lead ML, NLP, Deep Learning, and Generative AI model / projects.\n\u2022 Research and implement state-of-the-art algorithms for supervised and unsupervised learning.\n\u2022 Work with large-scale datasets in distributed environments.\n\u2022 Understand business processes to select and apply the best ML approaches.\n\u2022 Ensure scalability and performance of ML solutions.\n\u2022 Collaborate with cross-functional teams, including product owners, designers, and developers.\n\u2022 Solve complex data integration and deployment challenges.\n\u2022 Communicate results effectively using data visualization.\n\u2022 Work in global teams across different time zones.\n\nRequired Skills & Experience :\n\u2022 Strong experience in Machine Learning, Deep Learning, NLP, and Generative AI.\n\u2022 Hands-on expertise in frameworks like TensorFlow, PyTorch, or Hugging Face Transformers.\n\u2022 Experience with LLMs (Large Language Models), model fine-tuning, and prompt engineering.\n\u2022 Proficiency in Python, R, or Scala for ML development.\n\u2022 Knowledge of cloud-based ML platforms (AWS, Azure, GCP).\n\u2022 Experience with big data processing (Spark, Hadoop, or Dask).\n\u2022 Ability to scale ML models from prototypes to production.\n\u2022 Strong analytical and problem-solving skills.\n\n(ref : hirist.tech)",
    "url": "https://in.talent.com/view?id=e01fc7bb3d8d&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Scientist-Artificial Intelligence",
    "company": "IBM",
    "location": "Pune",
    "salary": "",
    "description": "Introduction\n\nIn this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology.\n\nYour Role And Responsibilities\n\u2022 As an Associate Data Scientist at IBM, you will work to solve business problems using leading edge and open-source tools such as Python, R, and TensorFlow, combined with IBM tools and our AI application suites. You will prepare, analyze, and understand data to deliver insight, predict emerging trends, and provide recommendations to stakeholders.\n\u2022 In your role, you may be responsible for:\n\u2022 Implementing and validating predictive and prescriptive models and creating and maintaining statistical models with a focus on big data & incorporating machine learning. techniques in your projects\n\u2022 Writing programs to cleanse and integrate data in an efficient and reusable manner\n\u2022 Working in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors\n\u2022 Communicating with internal and external clients to understand and define business needs and appropriate modelling techniques to provide analytical solutions.\n\u2022 Evaluating modelling results and communicating the results to technical and non-technical audiences.\n\nPreferred Education\n\nMaster's Degree\n\nRequired Technical And Professional Expertise\n\u2022 Proof of Concept (POC) Development: Develop POCs to validate and showcase the feasibility and effectiveness of the proposed AI solutions.\n\u2022 Collaborate with development teams to implement and iterate on POCs, ensuring alignment with customer requirements and expectations.\n\u2022 Help in showcasing the ability of Gen AI code assistant to refactor/rewrite and document code from one language to another, particularly COBOL to JAVA through rapid prototypes/ PoC\n\u2022 Document solution architectures, design decisions, implementation details, and lessons learned.\n\u2022 Create technical documentation, white papers, and best practice guides.\n\nPreferred Technical And Professional Experience\n\u2022 Strong programming skills, with proficiency in Python and experience with AI frameworks such as TensorFlow, PyTorch, Keras or Hugging Face.\n\u2022 Understanding in the usage of libraries such as SciKit Learn, Pandas, Matplotlib, etc. Familiarity with cloud platforms\n\u2022 Experience and working knowledge in COBOL & JAVA would be preferred.",
    "url": "https://www.foundit.in/job/data-scientist-artificial-intelligence-ibm-pune-37616817?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (AI_ML & Analytics) (Pune)",
    "company": "Quloi",
    "location": "Pune",
    "salary": "",
    "description": "Work with Product to shape requirements and easy solution flows including light UI with DevOps on data compute, deployments, partner with Frontend Backend to integrate models into our MERN + GraphQL platform. done ML solution to production.",
    "url": "https://in.jobrapido.com/jobpreview/2846817867691720704?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Blucognition- Data Scientist (Risk Strategy)",
    "company": "Nexthire",
    "location": "Pune",
    "salary": "",
    "description": "Role: Data Scientist / Risk Strategy\nExperience: 3+ Years\nLocation: Remote\nSkills Required: SQL, Python, R, Databricks, Credit Risk Strategy building, Credit Risk Solutions\n\nAbout bluCognition:\n\nBluCognition is an AI/ML based company specializing in risk analytics, data conversion and data enrichment capabilities. Founded some very named senior professionals from the financial services industry, the company is headquartered in the US, with the delivery centre based in Pune.\n\nWe build all our solutions while leveraging the latest technology stack in AI, ML and NLP combined with decades of experience in risk management at some of the largest financial services firms in the world. Our clients are some of the biggest and the most progressive names in the financial services industry.\n\nWe are entering a significant growth phase and are looking for individuals with entrepreneurial mindset who wants us to join in this exciting journey.\n\nPosition: Data Scientist (Risk strategy, SME)\nAbout the role\nAs Data Scientist in the credit risk strategy team, you will leverage your creative and critical thinking skills\nto develop best-in-class risk management strategies that have a meaningful impact on the client's\nbusiness. These strategies will support the client's credit and fraud risk, customer experience, marketing\nverticals and beyond.\nHaving you aboard will enable us to stay aligned with market trends by improving the turnaround time\nfor developing and implementing risk strategies, allowing for quicker iterations and broader coverage in\naddressing business challenges through scientific methods. The core KPIs for this position include\nadditional revenue generated and costs saved from releases. This role also supports compliance,\ndocumentation, and knowledge sharing in risk strategies.\nWhat you'll do\nDevelop, validate and deploy risk management strategies using a combination of sophisticated data analytics and domain expertise\nExtract and explore data, validate data integrity, perform ad hoc analysis, evaluate new data sources for usage in strategy development\nMaintain robust documentation of approach and techniques used; including objectives, assumptions, performance, weaknesses, and limitations\nBe ready to adapt to new tools/libraries/technologies/platforms\nActively partner with engineers to validate & deploy scalable solutions\nCollaborate to gather insight from partners across the organization\nFurther develop expertise in data science and engineering through self-study, project exposure and guidance of senior team members\nWhat you'll bring\nDegree in a quantitative field (e.g., computer science, data science, engineering, economics, mathematics, etc.). Advanced degree preferred\n3+ years of Data Science experience\n2+ years in financial services\nExperience building and implementing risk strategies in production\nDeep understanding of segmentation techniques such as decision trees\nExperience in banking sector with exposure to risk management analytics\nProficient with Python\nProficient with SQL\nPractical experience using Spark is a plus\nUnderstanding of statistical modeling techniques is a plus\nTechnical understanding of algorithm complexity, probability & statistics\nSelf-driven with an aptitude for independent research & problem-solving\nAbility to multi-task in a fast-paced environment is essential",
    "url": "https://www.recruit.net/job/blucognition-data-scientist-risk-strategy-jobs/ED604CCD08826865?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Senior Analyst, Big Data Analytics & Engineering",
    "company": "Mastercard",
    "location": "Pune",
    "salary": "",
    "description": "Our Purpose\n\nMastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we\u2019re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.\n\nTitle and Summary\n\nSenior Analyst, Big Data Analytics & Engineering\n\nAbout Mastercard\nMastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.\nOur decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.\n\nPosition Overview:\n\nThe candidate for this position will focus on Data Unification across different data assets, enabling a single unified view of data from multiple sources and support the development of new innovative data driven products, services and actionable insights that will help business to take decisions.\n\nExperience with LLMs or generative AI for automation to build data pipelines & AI - Enhanced Data Processing.\n\nThe Role:\nWe are seeking a Senior Analyst, Data Unification & Analytics who will:\n\n\u2022 Perform data ingestion, aggregation, processing to drive and enable relevant insights from available data sets.\n\u2022 Partner with various teams (i.e., Product Manager, Data Science, Platform Strategy, Technology) on data needs/requirements in order to deliver data solutions that generate business value.\n\u2022 Manipulate and analyze complex, high-volume, high-dimensionality data from varying sources using a variety of tools and data analysis techniques.\n\u2022 Identify innovative ideas and deliver proof of concepts, prototypes to deliver against the existing and future needs and propose new products, services and enhancements.\n\u2022 Integrate new data assets which increase the value proposition for our customers and enhance our existing solutions and services.\n\u2022 Analyse large volumes of transaction and product data to generate insights and actionable recommendations to drive business growth\n\u2022 Collect and synthesize feedback from clients, development, product and sales teams for new solutions or product enhancements.\n\u2022 Apply knowledge of metrics, measurements, and benchmarking to complex and demanding solutions.\n\nAll about You\n\u2022 Good understanding of Python \u2013 Pandas, Numpy, PySpark and Impala.\n\u2022 Experience in doing data analysis and extraction on Hadoop.\n\u2022 Experience with Enterprise Business Intelligence Platform/Data platform.\n\u2022 Strong SQL and higher-level programming languages with solid knowledge of data mining, machine learning algorithms and tools\n\u2022 Experience with data integration tools \u2013 ETL/ELT tools (i.e. Apache NiFi, Azure Data Factory, Pentaho, Talend)\n\u2022 Experience with Graph Database is a plus.\n\u2022 Experience in hands-on data modeling, programming, querying, data mining and report development using large volumes of granular data to deliver business intelligence and custom reporting solutions.\n\u2022 Exposure to collecting and/or working with data including standardizing, summarizing, offering initial observations and highlighting inconsistencies.\n\u2022 Strong understanding of the application of analytical methods and data visualization to support business decisions.\n\u2022 Ability to understand complex operational systems and analytics/business intelligence tools for the delivery of information products and analytical offerings to a large, global user base.\n\u2022 Able to work in a fast-paced, deadline-driven environment as part of a team and as an individual contributor\n\u2022 Ability to easily move between business, analytical, and technical teams and articulate solution requirements for each group\n\nCorporate Security Responsibility\n\nAll activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:\n\u2022 Abide by Mastercard\u2019s security policies and practices;\n\u2022 Ensure the confidentiality and integrity of the information being accessed;\n\u2022 Report any suspected information security violation or breach, and\n\u2022 Complete all periodic mandatory security trainings in accordance with Mastercard\u2019s guidelines.",
    "url": "https://careers.mastercard.com/us/en/job/R-262901/Senior-Analyst-Big-Data-Analytics-Engineering?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Urgent Search! Senior Data Scientist Pune",
    "company": "Elevarae",
    "location": "Pune",
    "salary": "",
    "description": "We\u2019re Hiring \u2013 Data Science Offshore Leads (Life Sciences | PI \u2013 Oil & Energy)\n\nElevarae is hiring two experienced Data Science Offshore Leads for our client, a global technology leader driving innovation across industries. These are immediate requirements for hybrid roles based in Pune \u2014 ideal for professionals ready to join immediately or within a short notice period.\nLocation: Pune (Hybrid)\nExperience: 8\u201312 years\nEducation: Bachelor\u2019s and Master\u2019s in Engineering/Technology\nJoin: Immediate to Early Joiners\n\nOpen Positions:\n\nData Science Offshore Lead \u2013 Life Sciences Domain\n\nData Science Offshore Lead \u2013 PI, Oil & Energy Domain\n\nKey Responsibilities\nLead and execute multiple Tier-1 client projects involving advanced Data Science techniques (AI, ML, GenAI).\nManage the complete Data Science lifecycle \u2014 from problem comprehension and analytical solution development to deployment and post-delivery support.\nAct as the primary client contact for discussions, presentations, and requirement gathering.\nGuide cross-functional teams and ensure technical excellence and business alignment.\nCollaborate with domain experts, business stakeholders, and engineering teams to deliver high-impact analytical solutions.\n\nEssential Skills (Must Have)\nDeep expertise in AI/ML/GenAI algorithms, methodologies, and end-to-end lifecycle including MLOps and post-deployment model support.\nRobust comprehension of complex business problems in Life Sciences or Oil & Energy domains.\nExceptional articulation and communication skills to bridge technical and business perspectives.\nAdvanced analytical and problem-solving ability for actionable insights and strategic outcomes.\n\nAdditional Skills (Valuable to Have)\nExposure to cloud platforms (AWS / Azure / GCP), DevOps, and deployment frameworks.\nExperience leading agile teams and using agile methodology.\nFamiliarity with data visualization tools (Tableau, Power BI).\nUnderstanding of data engineering principles and big data ecosystems.\n\nIf you\u2019re an experienced Data Science skilled looking to make an impact in complex, high-visibility projects \u2014 we\u2019d love to hear from you.\nHiring #DataScience #AI #ML #GenAI #LifeSciences #OilAndEnergy #Elevarae #DataScienceJobs #HybridWork #ImmediateJoiners #PuneJobs",
    "url": "https://in.jobrapido.com/jobpreview/5956365943658512384?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Scientist/Machine Learning Engineer Assistant vice president",
    "company": "Early Career",
    "location": "Pune",
    "salary": "",
    "description": "ML Solutions team within Markets OPS Technology is dedicated to developing solutions using Artificial Intelligence, Machine Learning and Generative AI. This team is a leader in creating new ideas, innovative technology solutions, and ground-breaking solutions for Markets Operations and Other Line of Businesses. We work closely with our clients and business partners to progress solutions from ideation to production by leveraging the entrepreneurial spirit and technological excellence.\n\nJob Description:\n\nThe ML Solutions team is seeking a Data Scientist/Machine Learning Engineer to drive the design, development, and deployment of innovative AI/ML and GenAI-based solutions. In this hands-on role, you will leverage your expertise to create a variety of AI models, guiding a team from initial concept to successful production. A key aspect involves mentoring team members and fostering their growth. You will collaborate closely with business partners and stakeholders, championing the adoption of these advanced technologies to enhance client experiences, deliver tangible value to our customers, and ensure adherence to regulatory requirements through cutting-edge technical solutions. This position offers a unique opportunity to shape the future of our AI initiatives and make a significant impact on the organization.\n\nKey Responsibilities:\n\u2022 Hands-On Execution and Delivery: Actively contribute to the development and delivery of AI solutions, driving innovation and excellence within the team. Take a hands-on approach to ensure AI models are successfully deployed into production environments, meeting high-quality standards and performance benchmarks.\n\u2022 Mentoring Young Talents: Mentoring team, guiding data analysts/ML engineers from concept to production. This involves fostering technical growth, providing project oversight, and ensuring adherence to best practices, ultimately building a high-performing and innovative team.\n\u2022 Quality Control: Ensure the quality and performance of generative AI models, conducting rigorous testing and evaluation.\n\u2022 Research and Development: Participate in research activities to explore and advance state-of-the-art generative AI techniques. Stay actively engaged in monitoring ongoing research efforts, keeping abreast of emerging trends, and ensuring that the Generative AI team remains at the forefront of the field.\n\u2022 Cross-Functional Collaboration: Collaborate effectively with various teams, including product managers, engineers, and data scientists, to integrate AI technologies into products and services.\n\nSkills & Qualifications:\n\u2022 8 to 13 years of Strong hands-on experience in Machine Learning, delivering complex solutions to production.\n\u2022 Experience with Generative AI technologies essential.\n\u2022 Understanding of concepts like supervised, unsupervised, clustering, embedding.\n\u2022 Knowledge of NLP, Name Entity Recognition, Computer Vision, Transformers, Large Language Models.\n\u2022 In-depth knowledge of deep learning and Generative AI frameworks such as, Langchain, Lang Graph, Crew AI or similar.\n\u2022 Experience with and other open-source frameworks/ libraries/ APIs like Hugging Face Transformers, Spacy, Pandas, scikit-learn, NumPy, OpenCV.\n\u2022 Experience in using Machine Learning/Deep Learning: XGBoost, LightGBM, TensorFlow, PyTorch, Keras.\n\u2022 Proficiency in Python Software Development, following Object-Oriented design patterns and best practices.\n\u2022 Strong background in mathematics: linear algebra, probability, statistics, and optimization.\n\u2022 Experience with evaluation, scoring with framework like ML Flow\n\u2022 Experience of Docker container and edited a Docker file, experience with K8s is a plus.\n\u2022 Experience with Postgres and Vector DBs a plus.\n\u2022 Excellent problem-solving skills and the ability to think creatively.\n\u2022 Strong communication and collaboration skills, with the ability to work effectively with cross-functional teams\n\u2022 Publications and contributions to the AI research community are a plus.\n\u2022 Master\u2019s degree/Ph. D. or equivalent experience in Computer Science, Data Science, Statistics, or a related field.\n\u2022 8-12 years of experience\n\nThis job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.\n\n------------------------------------------------------\n\nJob Family Group:\nTechnology\n\n------------------------------------------------------\n\nJob Family:\nApplications Development\n\n------------------------------------------------------\n\nTime Type:\nFull time\n\n------------------------------------------------------\n\nMost Relevant Skills\nPlease see the requirements listed above.\n\n------------------------------------------------------\n\nOther Relevant Skills\nData Science, Machine Learning.\n\n------------------------------------------------------\n\nCiti is an equal opportunity employer, and qualified candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other characteristic protected by law.\n\nIf you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.\n\nView Citi\u2019s EEO Policy Statement and the Know Your Rights poster.",
    "url": "https://jobs.citi.com/job/pune/data-scientist-machine-learning-engineer-assistant-vice-president/287/83901989456?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Senior Data Scientist, Data Science, Engineering",
    "company": "Mastercard",
    "location": "Pune",
    "salary": "",
    "description": "Our Purpose\n\nMastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we\u2019re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.\n\nTitle and Summary\nSenior Data ScientistOverview:\nAt Mastercard, we\u2019re building the future of intelligent infrastructure\u2014where data science meets automation, and AI drives operational excellence. We are looking for a Senior Data Scientist to join our Engineering team and lead the transformation of massive operations datasets into predictive insights and autonomous systems.\nThis role is ideal for someone passionate about building scalable machine learning solutions, developing Large Language Models (LLMs), and pioneering agentic AI systems that optimize engineering workflows and decision-making.\n\nRole:\nAs a Senior Data Scientist, you will:\n\u2022 Analyze large-scale operations data to build predictive models for system performance, anomaly detection, and proactive interventions.\n\u2022 Design, fine-tune, and deploy domain-specific LLMs to support internal tooling, documentation synthesis, and intelligent automation.\n\u2022 Develop agentic AI systems that autonomously interact with infrastructure, make decisions, and execute tasks with minimal human input.\n\u2022 Collaborate with engineering and product teams to ensure robust data pipelines and scalable model deployment.\n\u2022 Work closely with the AI COE team, domain experts and full stack developers to build and deploy interactive dashboards, providing the best, most engaging insights and UX for our users.\n\u2022 Engage with the wider Mastercard data science community, sharing best practice, knowledge, and insights, in support of collaborative, fulfilling work and value creation.\n\nAll About You:\n\u2022 An undergraduate degree or higher in Computer Science, Data Science, Econometrics, Mathematics, Statistics, or similar field of study.\n\u2022 Multi-project, hands-on experience of the end-to-end data science process in relation to large, complex data. From problem framing to results communication and solution deployment, you will be able to demonstrate having played a key part in a range of successfully delivered projects.\n\u2022 Strong background in predictive analytics and modelling using large operational datasets.\n\u2022 Expert level Python coding experience, including knowledge and experience of the principal Python Data Science / Machine Learning (ML) library ecosystem.\n\u2022 Hands-on experience with LLM architectures, and Agentic AI development.\n\u2022 Familiarity with agentic AI frameworks (e.g., LangGraph, OpenAI/LLaMA) and autonomous decision systems.\n\u2022 Proficiency in cloud platforms and big data ecosystems (Databricks).\n\u2022 Excellent communication skills and ability to work cross-functionally.\n\nCorporate Security Responsibility\n\nAll activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:\n\u2022 Abide by Mastercard\u2019s security policies and practices;\n\u2022 Ensure the confidentiality and integrity of the information being accessed;\n\u2022 Report any suspected information security violation or breach, and\n\u2022 Complete all periodic mandatory security trainings in accordance with Mastercard\u2019s guidelines.",
    "url": "https://simplify.jobs/p/51718324-a696-46dd-8807-dcac744a74dc/Senior-Data-Scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Data Science Offshore Lead (Life Sciences)",
    "company": "ProLegion",
    "location": "Pune",
    "salary": "",
    "description": "Job Title: Data Science Offshore Lead (Life Sciences)\n\nLocation: Pune, Maharashtra, India\n\nDuration: Contractual\n\nRoles and Responsibilities\n\u2022 Lead and manage offshore data science projects specifically in the life sciences sector, ensuring alignment with overall business goals.\n\u2022 Coordinate with cross-functional teams to ensure the seamless execution of data-driven initiatives, providing leadership and direction as needed.\n\u2022 Develop and implement robust data science models and algorithms to address key business questions within life sciences.\n\u2022 Facilitate communication between onshore and offshore teams to ensure project objectives are met effectively and efficiently.\n\u2022 Maintain a comprehensive understanding of the latest advancements in data science and machine learning, applying cutting-edge approaches as appropriate to ongoing projects.\n\u2022 Ensure continuous quality improvement and risk management across all project phases, delivering high-quality outputs on time and within budget.\n\u2022 Conduct regular progress reviews with stakeholders, addressing any issues or concerns promptly and effectively.\n\nRequired Qualifications\n\u2022 Proven experience in leading data science teams, preferably within the life sciences sector, showcasing successful project delivery and team management.\n\u2022 Strong knowledge and practical experience in applying data science and machine learning techniques to real-world problems.\n\u2022 Advanced degree in a relevant field such as Data Science, Computer Science, or Life Sciences with a solid foundation in quantitative and analytical skills.\n\u2022 Demonstrated project management skills with the ability to oversee multiple projects simultaneously, managing resources and timelines effectively.\n\u2022 Excellent communication and interpersonal skills, with the capability to liaise effectively with diverse teams and stakeholders across global locations.\n\u2022 Strong problem-solving and decision-making skills, able to translate complex data insights into actionable strategies.\n\u2022 Proficiency in programming languages commonly used in data science, such as Python or R, and experience with data visualisation tools.\n\nKey Responsibilities\n\u2022 Lead offshore data science operations in Pune, Maharashtra, India, ensuring the delivery of high-quality analytical solutions to the life sciences industry.\n\u2022 Partner with global stakeholders to define project scopes, objectives, and success metrics, aligning them with strategic priorities.\n\u2022 Foster a collaborative and innovative work environment, championing best practices and continuous improvement in data science methodologies.\n\u2022 Mentor and develop talent within the team, providing guidance, feedback, and career development opportunities to junior team members.\n\u2022 Identify opportunities for growth and expansion of data science capabilities within life sciences projects, advocating for investment in new tools and technologies.\n\u2022 Ensure regulatory compliance and ethical standards are met in all analytical processes and project deliveries.\n\u2022 Drive the adoption of automated, efficient workflows, enhancing the analytical capabilities and performance across all offshore operations.",
    "url": "https://in.linkedin.com/jobs/view/data-science-offshore-lead-life-sciences-at-prolegion-4333352948?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "\u25b7 Urgent Data Scientist Pune",
    "company": "Terragig",
    "location": "Pune",
    "salary": "",
    "description": "We are looking for Data Science off-shore Lead \u2013 Life Sciences Domain\n\nLocation - Pune\n\nJob Type - Fulltime\n\nnotice period - 45 days\n\nExperience - 6+ Years\n\nRequired Skills:\n\nData Science , AI, ML, GenAI, MLOps , Life Sciences Domain\n\nRoles and responsibilities\nLead data science efforts (AI, ML, GenAI, analytical formulation) for multiple client engagements in Life Sciences domain.\nManage end-to-end Data Science project lifecycle from problem comprehension, analytical solution development to final delivery.\nAct as primary point of contact for client interactions, presentations, and requirement elicitation.\nGuide teams on advanced data science techniques ensuring alignment with business objectives.\nCollaborate cross-functionally with domain experts, business stakeholders, and technical teams to deliver robust analytical solutions.\nExpert knowledge of data science algorithms, methodologies, and end-to-end lifecycle (AI/ML/GenAI), MLOps and post deployment service of AI models\nSolid comprehension of complex Life Sciences problems\nExceptional articulation skills to communicate technical concepts clearly to both technical and business stakeholders.\nAdvanced analytical skills for strategic problem-solving and actionable insight generation.",
    "url": "https://in.jobrapido.com/jobpreview/8900853684796129280?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "YASH Technologies - Senior Data Scientist - NLP / RAG",
    "company": "Yash Technologies",
    "location": "Pune",
    "salary": "",
    "description": "Description : Job Overview :\n\nWe are looking for a Sr. Data Scientist to join our team of researchers, data scientists, and developers.\n\nKey Responsibilities :\n\u2022 Develop and optimize and lead ML, NLP, Deep Learning, and Generative AI model / projects.\n\u2022 Research and implement state-of-the-art algorithms for supervised and unsupervised learning.\n\u2022 Work with large-scale datasets in distributed environments.\n\u2022 Understand business processes to select and apply the best ML approaches.\n\u2022 Ensure scalability and performance of ML solutions.\n\u2022 Collaborate with cross-functional teams, including product owners, designers, and developers.\n\u2022 Solve complex data integration and deployment challenges.\n\u2022 Communicate results effectively using data visualization.\n\u2022 Work in global teams across different time zones.\n\nRequired Skills & Experience :\n\u2022 Strong experience in Machine Learning, Deep Learning, NLP, and Generative AI.\n\u2022 Hands-on expertise in frameworks like TensorFlow, PyTorch, or Hugging Face Transformers.\n\u2022 Experience with LLMs (Large Language Models), model fine-tuning, and prompt engineering.\n\u2022 Proficiency in Python, R, or Scala for ML development.\n\u2022 Knowledge of cloud-based ML platforms (AWS, Azure, GCP).\n\u2022 Experience with big data processing (Spark, Hadoop, or Dask).\n\u2022 Ability to scale ML models from prototypes to production.\n\u2022 Strong analytical and problem-solving skills.\n\n(ref : hirist.tech)",
    "url": "https://in.talent.com/view?id=e01fc7bb3d8d&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Scientist-Artificial Intelligence",
    "company": "IBM",
    "location": "Pune",
    "salary": "",
    "description": "Introduction\n\nIn this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology.\n\nYour Role And Responsibilities\n\u2022 As an Associate Data Scientist at IBM, you will work to solve business problems using leading edge and open-source tools such as Python, R, and TensorFlow, combined with IBM tools and our AI application suites. You will prepare, analyze, and understand data to deliver insight, predict emerging trends, and provide recommendations to stakeholders.\n\u2022 In your role, you may be responsible for:\n\u2022 Implementing and validating predictive and prescriptive models and creating and maintaining statistical models with a focus on big data & incorporating machine learning. techniques in your projects\n\u2022 Writing programs to cleanse and integrate data in an efficient and reusable manner\n\u2022 Working in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors\n\u2022 Communicating with internal and external clients to understand and define business needs and appropriate modelling techniques to provide analytical solutions.\n\u2022 Evaluating modelling results and communicating the results to technical and non-technical audiences.\n\nPreferred Education\n\nMaster's Degree\n\nRequired Technical And Professional Expertise\n\u2022 Proof of Concept (POC) Development: Develop POCs to validate and showcase the feasibility and effectiveness of the proposed AI solutions.\n\u2022 Collaborate with development teams to implement and iterate on POCs, ensuring alignment with customer requirements and expectations.\n\u2022 Help in showcasing the ability of Gen AI code assistant to refactor/rewrite and document code from one language to another, particularly COBOL to JAVA through rapid prototypes/ PoC\n\u2022 Document solution architectures, design decisions, implementation details, and lessons learned.\n\u2022 Create technical documentation, white papers, and best practice guides.\n\nPreferred Technical And Professional Experience\n\u2022 Strong programming skills, with proficiency in Python and experience with AI frameworks such as TensorFlow, PyTorch, Keras or Hugging Face.\n\u2022 Understanding in the usage of libraries such as SciKit Learn, Pandas, Matplotlib, etc. Familiarity with cloud platforms\n\u2022 Experience and working knowledge in COBOL & JAVA would be preferred.",
    "url": "https://www.foundit.in/job/data-scientist-artificial-intelligence-ibm-pune-37616817?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (AI_ML & Analytics) (Pune)",
    "company": "Quloi",
    "location": "Pune",
    "salary": "",
    "description": "Work with Product to shape requirements and easy solution flows including light UI with DevOps on data compute, deployments, partner with Frontend Backend to integrate models into our MERN + GraphQL platform. done ML solution to production.",
    "url": "https://in.jobrapido.com/jobpreview/2846817867691720704?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Blucognition- Data Scientist (Risk Strategy)",
    "company": "Nexthire",
    "location": "Pune",
    "salary": "",
    "description": "Role: Data Scientist / Risk Strategy\nExperience: 3+ Years\nLocation: Remote\nSkills Required: SQL, Python, R, Databricks, Credit Risk Strategy building, Credit Risk Solutions\n\nAbout bluCognition:\n\nBluCognition is an AI/ML based company specializing in risk analytics, data conversion and data enrichment capabilities. Founded some very named senior professionals from the financial services industry, the company is headquartered in the US, with the delivery centre based in Pune.\n\nWe build all our solutions while leveraging the latest technology stack in AI, ML and NLP combined with decades of experience in risk management at some of the largest financial services firms in the world. Our clients are some of the biggest and the most progressive names in the financial services industry.\n\nWe are entering a significant growth phase and are looking for individuals with entrepreneurial mindset who wants us to join in this exciting journey.\n\nPosition: Data Scientist (Risk strategy, SME)\nAbout the role\nAs Data Scientist in the credit risk strategy team, you will leverage your creative and critical thinking skills\nto develop best-in-class risk management strategies that have a meaningful impact on the client's\nbusiness. These strategies will support the client's credit and fraud risk, customer experience, marketing\nverticals and beyond.\nHaving you aboard will enable us to stay aligned with market trends by improving the turnaround time\nfor developing and implementing risk strategies, allowing for quicker iterations and broader coverage in\naddressing business challenges through scientific methods. The core KPIs for this position include\nadditional revenue generated and costs saved from releases. This role also supports compliance,\ndocumentation, and knowledge sharing in risk strategies.\nWhat you'll do\nDevelop, validate and deploy risk management strategies using a combination of sophisticated data analytics and domain expertise\nExtract and explore data, validate data integrity, perform ad hoc analysis, evaluate new data sources for usage in strategy development\nMaintain robust documentation of approach and techniques used; including objectives, assumptions, performance, weaknesses, and limitations\nBe ready to adapt to new tools/libraries/technologies/platforms\nActively partner with engineers to validate & deploy scalable solutions\nCollaborate to gather insight from partners across the organization\nFurther develop expertise in data science and engineering through self-study, project exposure and guidance of senior team members\nWhat you'll bring\nDegree in a quantitative field (e.g., computer science, data science, engineering, economics, mathematics, etc.). Advanced degree preferred\n3+ years of Data Science experience\n2+ years in financial services\nExperience building and implementing risk strategies in production\nDeep understanding of segmentation techniques such as decision trees\nExperience in banking sector with exposure to risk management analytics\nProficient with Python\nProficient with SQL\nPractical experience using Spark is a plus\nUnderstanding of statistical modeling techniques is a plus\nTechnical understanding of algorithm complexity, probability & statistics\nSelf-driven with an aptitude for independent research & problem-solving\nAbility to multi-task in a fast-paced environment is essential",
    "url": "https://www.recruit.net/job/blucognition-data-scientist-risk-strategy-jobs/ED604CCD08826865?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Senior Analyst, Big Data Analytics & Engineering",
    "company": "Mastercard",
    "location": "Pune",
    "salary": "",
    "description": "Our Purpose\n\nMastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we\u2019re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.\n\nTitle and Summary\n\nSenior Analyst, Big Data Analytics & Engineering\n\nAbout Mastercard\nMastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.\nOur decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.\n\nPosition Overview:\n\nThe candidate for this position will focus on Data Unification across different data assets, enabling a single unified view of data from multiple sources and support the development of new innovative data driven products, services and actionable insights that will help business to take decisions.\n\nExperience with LLMs or generative AI for automation to build data pipelines & AI - Enhanced Data Processing.\n\nThe Role:\nWe are seeking a Senior Analyst, Data Unification & Analytics who will:\n\n\u2022 Perform data ingestion, aggregation, processing to drive and enable relevant insights from available data sets.\n\u2022 Partner with various teams (i.e., Product Manager, Data Science, Platform Strategy, Technology) on data needs/requirements in order to deliver data solutions that generate business value.\n\u2022 Manipulate and analyze complex, high-volume, high-dimensionality data from varying sources using a variety of tools and data analysis techniques.\n\u2022 Identify innovative ideas and deliver proof of concepts, prototypes to deliver against the existing and future needs and propose new products, services and enhancements.\n\u2022 Integrate new data assets which increase the value proposition for our customers and enhance our existing solutions and services.\n\u2022 Analyse large volumes of transaction and product data to generate insights and actionable recommendations to drive business growth\n\u2022 Collect and synthesize feedback from clients, development, product and sales teams for new solutions or product enhancements.\n\u2022 Apply knowledge of metrics, measurements, and benchmarking to complex and demanding solutions.\n\nAll about You\n\u2022 Good understanding of Python \u2013 Pandas, Numpy, PySpark and Impala.\n\u2022 Experience in doing data analysis and extraction on Hadoop.\n\u2022 Experience with Enterprise Business Intelligence Platform/Data platform.\n\u2022 Strong SQL and higher-level programming languages with solid knowledge of data mining, machine learning algorithms and tools\n\u2022 Experience with data integration tools \u2013 ETL/ELT tools (i.e. Apache NiFi, Azure Data Factory, Pentaho, Talend)\n\u2022 Experience with Graph Database is a plus.\n\u2022 Experience in hands-on data modeling, programming, querying, data mining and report development using large volumes of granular data to deliver business intelligence and custom reporting solutions.\n\u2022 Exposure to collecting and/or working with data including standardizing, summarizing, offering initial observations and highlighting inconsistencies.\n\u2022 Strong understanding of the application of analytical methods and data visualization to support business decisions.\n\u2022 Ability to understand complex operational systems and analytics/business intelligence tools for the delivery of information products and analytical offerings to a large, global user base.\n\u2022 Able to work in a fast-paced, deadline-driven environment as part of a team and as an individual contributor\n\u2022 Ability to easily move between business, analytical, and technical teams and articulate solution requirements for each group\n\nCorporate Security Responsibility\n\nAll activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:\n\u2022 Abide by Mastercard\u2019s security policies and practices;\n\u2022 Ensure the confidentiality and integrity of the information being accessed;\n\u2022 Report any suspected information security violation or breach, and\n\u2022 Complete all periodic mandatory security trainings in accordance with Mastercard\u2019s guidelines.",
    "url": "https://careers.mastercard.com/us/en/job/R-262901/Senior-Analyst-Big-Data-Analytics-Engineering?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Urgent Search! Senior Data Scientist Pune",
    "company": "Elevarae",
    "location": "Pune",
    "salary": "",
    "description": "We\u2019re Hiring \u2013 Data Science Offshore Leads (Life Sciences | PI \u2013 Oil & Energy)\n\nElevarae is hiring two experienced Data Science Offshore Leads for our client, a global technology leader driving innovation across industries. These are immediate requirements for hybrid roles based in Pune \u2014 ideal for professionals ready to join immediately or within a short notice period.\nLocation: Pune (Hybrid)\nExperience: 8\u201312 years\nEducation: Bachelor\u2019s and Master\u2019s in Engineering/Technology\nJoin: Immediate to Early Joiners\n\nOpen Positions:\n\nData Science Offshore Lead \u2013 Life Sciences Domain\n\nData Science Offshore Lead \u2013 PI, Oil & Energy Domain\n\nKey Responsibilities\nLead and execute multiple Tier-1 client projects involving advanced Data Science techniques (AI, ML, GenAI).\nManage the complete Data Science lifecycle \u2014 from problem comprehension and analytical solution development to deployment and post-delivery support.\nAct as the primary client contact for discussions, presentations, and requirement gathering.\nGuide cross-functional teams and ensure technical excellence and business alignment.\nCollaborate with domain experts, business stakeholders, and engineering teams to deliver high-impact analytical solutions.\n\nEssential Skills (Must Have)\nDeep expertise in AI/ML/GenAI algorithms, methodologies, and end-to-end lifecycle including MLOps and post-deployment model support.\nRobust comprehension of complex business problems in Life Sciences or Oil & Energy domains.\nExceptional articulation and communication skills to bridge technical and business perspectives.\nAdvanced analytical and problem-solving ability for actionable insights and strategic outcomes.\n\nAdditional Skills (Valuable to Have)\nExposure to cloud platforms (AWS / Azure / GCP), DevOps, and deployment frameworks.\nExperience leading agile teams and using agile methodology.\nFamiliarity with data visualization tools (Tableau, Power BI).\nUnderstanding of data engineering principles and big data ecosystems.\n\nIf you\u2019re an experienced Data Science skilled looking to make an impact in complex, high-visibility projects \u2014 we\u2019d love to hear from you.\nHiring #DataScience #AI #ML #GenAI #LifeSciences #OilAndEnergy #Elevarae #DataScienceJobs #HybridWork #ImmediateJoiners #PuneJobs",
    "url": "https://in.jobrapido.com/jobpreview/5956365943658512384?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Scientist/Machine Learning Engineer Assistant vice president",
    "company": "Early Career",
    "location": "Pune",
    "salary": "",
    "description": "ML Solutions team within Markets OPS Technology is dedicated to developing solutions using Artificial Intelligence, Machine Learning and Generative AI. This team is a leader in creating new ideas, innovative technology solutions, and ground-breaking solutions for Markets Operations and Other Line of Businesses. We work closely with our clients and business partners to progress solutions from ideation to production by leveraging the entrepreneurial spirit and technological excellence.\n\nJob Description:\n\nThe ML Solutions team is seeking a Data Scientist/Machine Learning Engineer to drive the design, development, and deployment of innovative AI/ML and GenAI-based solutions. In this hands-on role, you will leverage your expertise to create a variety of AI models, guiding a team from initial concept to successful production. A key aspect involves mentoring team members and fostering their growth. You will collaborate closely with business partners and stakeholders, championing the adoption of these advanced technologies to enhance client experiences, deliver tangible value to our customers, and ensure adherence to regulatory requirements through cutting-edge technical solutions. This position offers a unique opportunity to shape the future of our AI initiatives and make a significant impact on the organization.\n\nKey Responsibilities:\n\u2022 Hands-On Execution and Delivery: Actively contribute to the development and delivery of AI solutions, driving innovation and excellence within the team. Take a hands-on approach to ensure AI models are successfully deployed into production environments, meeting high-quality standards and performance benchmarks.\n\u2022 Mentoring Young Talents: Mentoring team, guiding data analysts/ML engineers from concept to production. This involves fostering technical growth, providing project oversight, and ensuring adherence to best practices, ultimately building a high-performing and innovative team.\n\u2022 Quality Control: Ensure the quality and performance of generative AI models, conducting rigorous testing and evaluation.\n\u2022 Research and Development: Participate in research activities to explore and advance state-of-the-art generative AI techniques. Stay actively engaged in monitoring ongoing research efforts, keeping abreast of emerging trends, and ensuring that the Generative AI team remains at the forefront of the field.\n\u2022 Cross-Functional Collaboration: Collaborate effectively with various teams, including product managers, engineers, and data scientists, to integrate AI technologies into products and services.\n\nSkills & Qualifications:\n\u2022 8 to 13 years of Strong hands-on experience in Machine Learning, delivering complex solutions to production.\n\u2022 Experience with Generative AI technologies essential.\n\u2022 Understanding of concepts like supervised, unsupervised, clustering, embedding.\n\u2022 Knowledge of NLP, Name Entity Recognition, Computer Vision, Transformers, Large Language Models.\n\u2022 In-depth knowledge of deep learning and Generative AI frameworks such as, Langchain, Lang Graph, Crew AI or similar.\n\u2022 Experience with and other open-source frameworks/ libraries/ APIs like Hugging Face Transformers, Spacy, Pandas, scikit-learn, NumPy, OpenCV.\n\u2022 Experience in using Machine Learning/Deep Learning: XGBoost, LightGBM, TensorFlow, PyTorch, Keras.\n\u2022 Proficiency in Python Software Development, following Object-Oriented design patterns and best practices.\n\u2022 Strong background in mathematics: linear algebra, probability, statistics, and optimization.\n\u2022 Experience with evaluation, scoring with framework like ML Flow\n\u2022 Experience of Docker container and edited a Docker file, experience with K8s is a plus.\n\u2022 Experience with Postgres and Vector DBs a plus.\n\u2022 Excellent problem-solving skills and the ability to think creatively.\n\u2022 Strong communication and collaboration skills, with the ability to work effectively with cross-functional teams\n\u2022 Publications and contributions to the AI research community are a plus.\n\u2022 Master\u2019s degree/Ph. D. or equivalent experience in Computer Science, Data Science, Statistics, or a related field.\n\u2022 8-12 years of experience\n\nThis job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.\n\n------------------------------------------------------\n\nJob Family Group:\nTechnology\n\n------------------------------------------------------\n\nJob Family:\nApplications Development\n\n------------------------------------------------------\n\nTime Type:\nFull time\n\n------------------------------------------------------\n\nMost Relevant Skills\nPlease see the requirements listed above.\n\n------------------------------------------------------\n\nOther Relevant Skills\nData Science, Machine Learning.\n\n------------------------------------------------------\n\nCiti is an equal opportunity employer, and qualified candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other characteristic protected by law.\n\nIf you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.\n\nView Citi\u2019s EEO Policy Statement and the Know Your Rights poster.",
    "url": "https://jobs.citi.com/job/pune/data-scientist-machine-learning-engineer-assistant-vice-president/287/83901989456?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Senior Data Scientist, Data Science, Engineering",
    "company": "Mastercard",
    "location": "Pune",
    "salary": "",
    "description": "Our Purpose\n\nMastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we\u2019re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.\n\nTitle and Summary\nSenior Data ScientistOverview:\nAt Mastercard, we\u2019re building the future of intelligent infrastructure\u2014where data science meets automation, and AI drives operational excellence. We are looking for a Senior Data Scientist to join our Engineering team and lead the transformation of massive operations datasets into predictive insights and autonomous systems.\nThis role is ideal for someone passionate about building scalable machine learning solutions, developing Large Language Models (LLMs), and pioneering agentic AI systems that optimize engineering workflows and decision-making.\n\nRole:\nAs a Senior Data Scientist, you will:\n\u2022 Analyze large-scale operations data to build predictive models for system performance, anomaly detection, and proactive interventions.\n\u2022 Design, fine-tune, and deploy domain-specific LLMs to support internal tooling, documentation synthesis, and intelligent automation.\n\u2022 Develop agentic AI systems that autonomously interact with infrastructure, make decisions, and execute tasks with minimal human input.\n\u2022 Collaborate with engineering and product teams to ensure robust data pipelines and scalable model deployment.\n\u2022 Work closely with the AI COE team, domain experts and full stack developers to build and deploy interactive dashboards, providing the best, most engaging insights and UX for our users.\n\u2022 Engage with the wider Mastercard data science community, sharing best practice, knowledge, and insights, in support of collaborative, fulfilling work and value creation.\n\nAll About You:\n\u2022 An undergraduate degree or higher in Computer Science, Data Science, Econometrics, Mathematics, Statistics, or similar field of study.\n\u2022 Multi-project, hands-on experience of the end-to-end data science process in relation to large, complex data. From problem framing to results communication and solution deployment, you will be able to demonstrate having played a key part in a range of successfully delivered projects.\n\u2022 Strong background in predictive analytics and modelling using large operational datasets.\n\u2022 Expert level Python coding experience, including knowledge and experience of the principal Python Data Science / Machine Learning (ML) library ecosystem.\n\u2022 Hands-on experience with LLM architectures, and Agentic AI development.\n\u2022 Familiarity with agentic AI frameworks (e.g., LangGraph, OpenAI/LLaMA) and autonomous decision systems.\n\u2022 Proficiency in cloud platforms and big data ecosystems (Databricks).\n\u2022 Excellent communication skills and ability to work cross-functionally.\n\nCorporate Security Responsibility\n\nAll activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:\n\u2022 Abide by Mastercard\u2019s security policies and practices;\n\u2022 Ensure the confidentiality and integrity of the information being accessed;\n\u2022 Report any suspected information security violation or breach, and\n\u2022 Complete all periodic mandatory security trainings in accordance with Mastercard\u2019s guidelines.",
    "url": "https://simplify.jobs/p/51718324-a696-46dd-8807-dcac744a74dc/Senior-Data-Scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Urgent Search! Senior Data Scientist Pune",
    "company": "Elevarae",
    "location": "Pune",
    "salary": "",
    "description": "We\u2019re Hiring \u2013 Data Science Offshore Leads (Life Sciences | PI \u2013 Oil & Energy)\n\nElevarae is hiring two experienced Data Science Offshore Leads for our client, a global technology leader driving innovation across industries. These are immediate requirements for hybrid roles based in Pune \u2014 ideal for professionals ready to join immediately or within a short notice period.\nLocation: Pune (Hybrid)\nExperience: 8\u201312 years\nEducation: Bachelor\u2019s and Master\u2019s in Engineering/Technology\nJoin: Immediate to Early Joiners\n\nOpen Positions:\n\nData Science Offshore Lead \u2013 Life Sciences Domain\n\nData Science Offshore Lead \u2013 PI, Oil & Energy Domain\n\nKey Responsibilities\nLead and execute multiple Tier-1 client projects involving advanced Data Science techniques (AI, ML, GenAI).\nManage the complete Data Science lifecycle \u2014 from problem comprehension and analytical solution development to deployment and post-delivery support.\nAct as the primary client contact for discussions, presentations, and requirement gathering.\nGuide cross-functional teams and ensure technical excellence and business alignment.\nCollaborate with domain experts, business stakeholders, and engineering teams to deliver high-impact analytical solutions.\n\nEssential Skills (Must Have)\nDeep expertise in AI/ML/GenAI algorithms, methodologies, and end-to-end lifecycle including MLOps and post-deployment model support.\nRobust comprehension of complex business problems in Life Sciences or Oil & Energy domains.\nExceptional articulation and communication skills to bridge technical and business perspectives.\nAdvanced analytical and problem-solving ability for actionable insights and strategic outcomes.\n\nAdditional Skills (Valuable to Have)\nExposure to cloud platforms (AWS / Azure / GCP), DevOps, and deployment frameworks.\nExperience leading agile teams and using agile methodology.\nFamiliarity with data visualization tools (Tableau, Power BI).\nUnderstanding of data engineering principles and big data ecosystems.\n\nIf you\u2019re an experienced Data Science skilled looking to make an impact in complex, high-visibility projects \u2014 we\u2019d love to hear from you.\nHiring #DataScience #AI #ML #GenAI #LifeSciences #OilAndEnergy #Elevarae #DataScienceJobs #HybridWork #ImmediateJoiners #PuneJobs",
    "url": "https://in.jobrapido.com/jobpreview/5956365943658512384?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "YASH Technologies - Senior Data Scientist - NLP / RAG",
    "company": "Yash Technologies",
    "location": "Pune",
    "salary": "",
    "description": "Description : Job Overview :\n\nWe are looking for a Sr. Data Scientist to join our team of researchers, data scientists, and developers.\n\nKey Responsibilities :\n\u2022 Develop and optimize and lead ML, NLP, Deep Learning, and Generative AI model / projects.\n\u2022 Research and implement state-of-the-art algorithms for supervised and unsupervised learning.\n\u2022 Work with large-scale datasets in distributed environments.\n\u2022 Understand business processes to select and apply the best ML approaches.\n\u2022 Ensure scalability and performance of ML solutions.\n\u2022 Collaborate with cross-functional teams, including product owners, designers, and developers.\n\u2022 Solve complex data integration and deployment challenges.\n\u2022 Communicate results effectively using data visualization.\n\u2022 Work in global teams across different time zones.\n\nRequired Skills & Experience :\n\u2022 Strong experience in Machine Learning, Deep Learning, NLP, and Generative AI.\n\u2022 Hands-on expertise in frameworks like TensorFlow, PyTorch, or Hugging Face Transformers.\n\u2022 Experience with LLMs (Large Language Models), model fine-tuning, and prompt engineering.\n\u2022 Proficiency in Python, R, or Scala for ML development.\n\u2022 Knowledge of cloud-based ML platforms (AWS, Azure, GCP).\n\u2022 Experience with big data processing (Spark, Hadoop, or Dask).\n\u2022 Ability to scale ML models from prototypes to production.\n\u2022 Strong analytical and problem-solving skills.\n\n(ref : hirist.tech)",
    "url": "https://in.talent.com/view?id=e01fc7bb3d8d&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "\u25b7 Urgent Data Scientist Pune",
    "company": "Terragig",
    "location": "Pune",
    "salary": "",
    "description": "We are looking for Data Science off-shore Lead \u2013 Life Sciences Domain\n\nLocation - Pune\n\nJob Type - Fulltime\n\nnotice period - 45 days\n\nExperience - 6+ Years\n\nRequired Skills:\n\nData Science , AI, ML, GenAI, MLOps , Life Sciences Domain\n\nRoles and responsibilities\nLead data science efforts (AI, ML, GenAI, analytical formulation) for multiple client engagements in Life Sciences domain.\nManage end-to-end Data Science project lifecycle from problem comprehension, analytical solution development to final delivery.\nAct as primary point of contact for client interactions, presentations, and requirement elicitation.\nGuide teams on advanced data science techniques ensuring alignment with business objectives.\nCollaborate cross-functionally with domain experts, business stakeholders, and technical teams to deliver robust analytical solutions.\nExpert knowledge of data science algorithms, methodologies, and end-to-end lifecycle (AI/ML/GenAI), MLOps and post deployment service of AI models\nSolid comprehension of complex Life Sciences problems\nExceptional articulation skills to communicate technical concepts clearly to both technical and business stakeholders.\nAdvanced analytical skills for strategic problem-solving and actionable insight generation.",
    "url": "https://in.jobrapido.com/jobpreview/8900853684796129280?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Scientist-Artificial Intelligence",
    "company": "IBM",
    "location": "Pune",
    "salary": "",
    "description": "Introduction\n\nIn this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology.\n\nYour Role And Responsibilities\n\u2022 As an Associate Data Scientist at IBM, you will work to solve business problems using leading edge and open-source tools such as Python, R, and TensorFlow, combined with IBM tools and our AI application suites. You will prepare, analyze, and understand data to deliver insight, predict emerging trends, and provide recommendations to stakeholders.\n\u2022 In your role, you may be responsible for:\n\u2022 Implementing and validating predictive and prescriptive models and creating and maintaining statistical models with a focus on big data & incorporating machine learning. techniques in your projects\n\u2022 Writing programs to cleanse and integrate data in an efficient and reusable manner\n\u2022 Working in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors\n\u2022 Communicating with internal and external clients to understand and define business needs and appropriate modelling techniques to provide analytical solutions.\n\u2022 Evaluating modelling results and communicating the results to technical and non-technical audiences.\n\nPreferred Education\n\nMaster's Degree\n\nRequired Technical And Professional Expertise\n\u2022 Proof of Concept (POC) Development: Develop POCs to validate and showcase the feasibility and effectiveness of the proposed AI solutions.\n\u2022 Collaborate with development teams to implement and iterate on POCs, ensuring alignment with customer requirements and expectations.\n\u2022 Help in showcasing the ability of Gen AI code assistant to refactor/rewrite and document code from one language to another, particularly COBOL to JAVA through rapid prototypes/ PoC\n\u2022 Document solution architectures, design decisions, implementation details, and lessons learned.\n\u2022 Create technical documentation, white papers, and best practice guides.\n\nPreferred Technical And Professional Experience\n\u2022 Strong programming skills, with proficiency in Python and experience with AI frameworks such as TensorFlow, PyTorch, Keras or Hugging Face.\n\u2022 Understanding in the usage of libraries such as SciKit Learn, Pandas, Matplotlib, etc. Familiarity with cloud platforms\n\u2022 Experience and working knowledge in COBOL & JAVA would be preferred.",
    "url": "https://www.foundit.in/job/data-scientist-artificial-intelligence-ibm-pune-37616817?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Blucognition- Data Scientist (Risk Strategy)",
    "company": "Nexthire",
    "location": "Pune",
    "salary": "",
    "description": "Role: Data Scientist / Risk Strategy\nExperience: 3+ Years\nLocation: Remote\nSkills Required: SQL, Python, R, Databricks, Credit Risk Strategy building, Credit Risk Solutions\n\nAbout bluCognition:\n\nBluCognition is an AI/ML based company specializing in risk analytics, data conversion and data enrichment capabilities. Founded some very named senior professionals from the financial services industry, the company is headquartered in the US, with the delivery centre based in Pune.\n\nWe build all our solutions while leveraging the latest technology stack in AI, ML and NLP combined with decades of experience in risk management at some of the largest financial services firms in the world. Our clients are some of the biggest and the most progressive names in the financial services industry.\n\nWe are entering a significant growth phase and are looking for individuals with entrepreneurial mindset who wants us to join in this exciting journey.\n\nPosition: Data Scientist (Risk strategy, SME)\nAbout the role\nAs Data Scientist in the credit risk strategy team, you will leverage your creative and critical thinking skills\nto develop best-in-class risk management strategies that have a meaningful impact on the client's\nbusiness. These strategies will support the client's credit and fraud risk, customer experience, marketing\nverticals and beyond.\nHaving you aboard will enable us to stay aligned with market trends by improving the turnaround time\nfor developing and implementing risk strategies, allowing for quicker iterations and broader coverage in\naddressing business challenges through scientific methods. The core KPIs for this position include\nadditional revenue generated and costs saved from releases. This role also supports compliance,\ndocumentation, and knowledge sharing in risk strategies.\nWhat you'll do\nDevelop, validate and deploy risk management strategies using a combination of sophisticated data analytics and domain expertise\nExtract and explore data, validate data integrity, perform ad hoc analysis, evaluate new data sources for usage in strategy development\nMaintain robust documentation of approach and techniques used; including objectives, assumptions, performance, weaknesses, and limitations\nBe ready to adapt to new tools/libraries/technologies/platforms\nActively partner with engineers to validate & deploy scalable solutions\nCollaborate to gather insight from partners across the organization\nFurther develop expertise in data science and engineering through self-study, project exposure and guidance of senior team members\nWhat you'll bring\nDegree in a quantitative field (e.g., computer science, data science, engineering, economics, mathematics, etc.). Advanced degree preferred\n3+ years of Data Science experience\n2+ years in financial services\nExperience building and implementing risk strategies in production\nDeep understanding of segmentation techniques such as decision trees\nExperience in banking sector with exposure to risk management analytics\nProficient with Python\nProficient with SQL\nPractical experience using Spark is a plus\nUnderstanding of statistical modeling techniques is a plus\nTechnical understanding of algorithm complexity, probability & statistics\nSelf-driven with an aptitude for independent research & problem-solving\nAbility to multi-task in a fast-paced environment is essential",
    "url": "https://www.recruit.net/job/blucognition-data-scientist-risk-strategy-jobs/ED604CCD08826865?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (AI_ML & Analytics) (Pune)",
    "company": "Quloi",
    "location": "Pune",
    "salary": "",
    "description": "Work with Product to shape requirements and easy solution flows including light UI with DevOps on data compute, deployments, partner with Frontend Backend to integrate models into our MERN + GraphQL platform. done ML solution to production.",
    "url": "https://in.jobrapido.com/jobpreview/2846817867691720704?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Senior Analyst, Big Data Analytics & Engineering",
    "company": "Mastercard",
    "location": "Pune",
    "salary": "",
    "description": "Our Purpose\n\nMastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we\u2019re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.\n\nTitle and Summary\n\nSenior Analyst, Big Data Analytics & Engineering\n\nAbout Mastercard\nMastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.\nOur decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.\n\nPosition Overview:\n\nThe candidate for this position will focus on Data Unification across different data assets, enabling a single unified view of data from multiple sources and support the development of new innovative data driven products, services and actionable insights that will help business to take decisions.\n\nExperience with LLMs or generative AI for automation to build data pipelines & AI - Enhanced Data Processing.\n\nThe Role:\nWe are seeking a Senior Analyst, Data Unification & Analytics who will:\n\n\u2022 Perform data ingestion, aggregation, processing to drive and enable relevant insights from available data sets.\n\u2022 Partner with various teams (i.e., Product Manager, Data Science, Platform Strategy, Technology) on data needs/requirements in order to deliver data solutions that generate business value.\n\u2022 Manipulate and analyze complex, high-volume, high-dimensionality data from varying sources using a variety of tools and data analysis techniques.\n\u2022 Identify innovative ideas and deliver proof of concepts, prototypes to deliver against the existing and future needs and propose new products, services and enhancements.\n\u2022 Integrate new data assets which increase the value proposition for our customers and enhance our existing solutions and services.\n\u2022 Analyse large volumes of transaction and product data to generate insights and actionable recommendations to drive business growth\n\u2022 Collect and synthesize feedback from clients, development, product and sales teams for new solutions or product enhancements.\n\u2022 Apply knowledge of metrics, measurements, and benchmarking to complex and demanding solutions.\n\nAll about You\n\u2022 Good understanding of Python \u2013 Pandas, Numpy, PySpark and Impala.\n\u2022 Experience in doing data analysis and extraction on Hadoop.\n\u2022 Experience with Enterprise Business Intelligence Platform/Data platform.\n\u2022 Strong SQL and higher-level programming languages with solid knowledge of data mining, machine learning algorithms and tools\n\u2022 Experience with data integration tools \u2013 ETL/ELT tools (i.e. Apache NiFi, Azure Data Factory, Pentaho, Talend)\n\u2022 Experience with Graph Database is a plus.\n\u2022 Experience in hands-on data modeling, programming, querying, data mining and report development using large volumes of granular data to deliver business intelligence and custom reporting solutions.\n\u2022 Exposure to collecting and/or working with data including standardizing, summarizing, offering initial observations and highlighting inconsistencies.\n\u2022 Strong understanding of the application of analytical methods and data visualization to support business decisions.\n\u2022 Ability to understand complex operational systems and analytics/business intelligence tools for the delivery of information products and analytical offerings to a large, global user base.\n\u2022 Able to work in a fast-paced, deadline-driven environment as part of a team and as an individual contributor\n\u2022 Ability to easily move between business, analytical, and technical teams and articulate solution requirements for each group\n\nCorporate Security Responsibility\n\nAll activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:\n\u2022 Abide by Mastercard\u2019s security policies and practices;\n\u2022 Ensure the confidentiality and integrity of the information being accessed;\n\u2022 Report any suspected information security violation or breach, and\n\u2022 Complete all periodic mandatory security trainings in accordance with Mastercard\u2019s guidelines.",
    "url": "https://careers.mastercard.com/us/en/job/R-262901/Senior-Analyst-Big-Data-Analytics-Engineering?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Scientist/Machine Learning Engineer Assistant vice president",
    "company": "Early Career",
    "location": "Pune",
    "salary": "",
    "description": "ML Solutions team within Markets OPS Technology is dedicated to developing solutions using Artificial Intelligence, Machine Learning and Generative AI. This team is a leader in creating new ideas, innovative technology solutions, and ground-breaking solutions for Markets Operations and Other Line of Businesses. We work closely with our clients and business partners to progress solutions from ideation to production by leveraging the entrepreneurial spirit and technological excellence.\n\nJob Description:\n\nThe ML Solutions team is seeking a Data Scientist/Machine Learning Engineer to drive the design, development, and deployment of innovative AI/ML and GenAI-based solutions. In this hands-on role, you will leverage your expertise to create a variety of AI models, guiding a team from initial concept to successful production. A key aspect involves mentoring team members and fostering their growth. You will collaborate closely with business partners and stakeholders, championing the adoption of these advanced technologies to enhance client experiences, deliver tangible value to our customers, and ensure adherence to regulatory requirements through cutting-edge technical solutions. This position offers a unique opportunity to shape the future of our AI initiatives and make a significant impact on the organization.\n\nKey Responsibilities:\n\u2022 Hands-On Execution and Delivery: Actively contribute to the development and delivery of AI solutions, driving innovation and excellence within the team. Take a hands-on approach to ensure AI models are successfully deployed into production environments, meeting high-quality standards and performance benchmarks.\n\u2022 Mentoring Young Talents: Mentoring team, guiding data analysts/ML engineers from concept to production. This involves fostering technical growth, providing project oversight, and ensuring adherence to best practices, ultimately building a high-performing and innovative team.\n\u2022 Quality Control: Ensure the quality and performance of generative AI models, conducting rigorous testing and evaluation.\n\u2022 Research and Development: Participate in research activities to explore and advance state-of-the-art generative AI techniques. Stay actively engaged in monitoring ongoing research efforts, keeping abreast of emerging trends, and ensuring that the Generative AI team remains at the forefront of the field.\n\u2022 Cross-Functional Collaboration: Collaborate effectively with various teams, including product managers, engineers, and data scientists, to integrate AI technologies into products and services.\n\nSkills & Qualifications:\n\u2022 8 to 13 years of Strong hands-on experience in Machine Learning, delivering complex solutions to production.\n\u2022 Experience with Generative AI technologies essential.\n\u2022 Understanding of concepts like supervised, unsupervised, clustering, embedding.\n\u2022 Knowledge of NLP, Name Entity Recognition, Computer Vision, Transformers, Large Language Models.\n\u2022 In-depth knowledge of deep learning and Generative AI frameworks such as, Langchain, Lang Graph, Crew AI or similar.\n\u2022 Experience with and other open-source frameworks/ libraries/ APIs like Hugging Face Transformers, Spacy, Pandas, scikit-learn, NumPy, OpenCV.\n\u2022 Experience in using Machine Learning/Deep Learning: XGBoost, LightGBM, TensorFlow, PyTorch, Keras.\n\u2022 Proficiency in Python Software Development, following Object-Oriented design patterns and best practices.\n\u2022 Strong background in mathematics: linear algebra, probability, statistics, and optimization.\n\u2022 Experience with evaluation, scoring with framework like ML Flow\n\u2022 Experience of Docker container and edited a Docker file, experience with K8s is a plus.\n\u2022 Experience with Postgres and Vector DBs a plus.\n\u2022 Excellent problem-solving skills and the ability to think creatively.\n\u2022 Strong communication and collaboration skills, with the ability to work effectively with cross-functional teams\n\u2022 Publications and contributions to the AI research community are a plus.\n\u2022 Master\u2019s degree/Ph. D. or equivalent experience in Computer Science, Data Science, Statistics, or a related field.\n\u2022 8-12 years of experience\n\nThis job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.\n\n------------------------------------------------------\n\nJob Family Group:\nTechnology\n\n------------------------------------------------------\n\nJob Family:\nApplications Development\n\n------------------------------------------------------\n\nTime Type:\nFull time\n\n------------------------------------------------------\n\nMost Relevant Skills\nPlease see the requirements listed above.\n\n------------------------------------------------------\n\nOther Relevant Skills\nData Science, Machine Learning.\n\n------------------------------------------------------\n\nCiti is an equal opportunity employer, and qualified candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other characteristic protected by law.\n\nIf you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.\n\nView Citi\u2019s EEO Policy Statement and the Know Your Rights poster.",
    "url": "https://jobs.citi.com/job/pune/data-scientist-machine-learning-engineer-assistant-vice-president/287/83901989456?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Machine Learning Engineer (MLE) \u2013 Python | DS | DE | ETL | Azure | Databricks",
    "company": "Apptware",
    "location": "Pune",
    "salary": "",
    "description": "Job description\n\nPosition: Machine Learning Engineer (MLE) \u2013 Python | DS | DE | ETL | Azure | Databricks\n\n\ud83d\udd39 Experience: 4\u20138 years\n\n\ud83d\udd39 Location: Pune / Bangalore\n\n\ud83d\udd39 Employment Type: Full-time\n\nJob Description:\n\nWe are seeking an experienced Machine Learning Engineer (MLE) with strong expertise in Python, Data Science (DS), Data Engineering (DE), ETL, and Azure Databricks. The ideal candidate will design, build, and deploy scalable ML solutions while collaborating with data and engineering teams to solve complex business challenges.\n\nKey Responsibilities:\n\u2022 Design and implement end-to-end ML pipelines using Databricks and Azure.\n\u2022 Develop, train, and deploy machine learning models for various business use cases.\n\u2022 Perform data preprocessing, feature engineering, and model optimization on large datasets.\n\u2022 Integrate ML models with production systems and ensure performance monitoring.\n\u2022 Collaborate with cross-functional teams to understand business needs and deliver effective ML solutions.\n\u2022 Stay updated with the latest trends in ML, DL, and AI frameworks.\n\nRequired Skills:\n\u2022 Python (Advanced) \u2013 Must\n\u2022 Data Science (DS), Data Engineering (DE), and ETL \u2013 Must\n\u2022 Machine Learning (ML) \u2013 Must\n\u2022 Deep Learning (Basic Understanding) \u2013 Good to have\n\u2022 Natural Language Processing (NLP) \u2013 Basic Understanding\n\u2022 Computer Vision \u2013 Basic Understanding\n\u2022 Python for Image Processing \u2013 Basic Understanding\n\u2022 ML Frameworks (TensorFlow / PyTorch / Scikit-learn) \u2013 Must\n\u2022 Azure Cloud \u2013 Must\n\u2022 Databricks \u2013 Must\n\nGood to Have:\n\u2022 Experience with Agile Methodology\n\u2022 Exposure to MLOps and CI/CD pipelines\n\u2022 Familiarity with data visualization tools like Power BI or Tableau\n\nAdditional Details:\n\u2022 Immediate joiners preferred\n\u2022 Candidates with up to 30 days\u2019 notice period can be considered\n\nApply Here: https://forms.gle/PNgXBb3QJh57Uqd79",
    "url": "https://in.linkedin.com/jobs/view/machine-learning-engineer-mle-%E2%80%93-python-ds-de-etl-azure-databricks-at-apptware-4331708651?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Senior Data Scientist, Data Science, Engineering",
    "company": "Mastercard",
    "location": "Pune",
    "salary": "",
    "description": "Our Purpose\n\nMastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we\u2019re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.\n\nTitle and Summary\nSenior Data ScientistOverview:\nAt Mastercard, we\u2019re building the future of intelligent infrastructure\u2014where data science meets automation, and AI drives operational excellence. We are looking for a Senior Data Scientist to join our Engineering team and lead the transformation of massive operations datasets into predictive insights and autonomous systems.\nThis role is ideal for someone passionate about building scalable machine learning solutions, developing Large Language Models (LLMs), and pioneering agentic AI systems that optimize engineering workflows and decision-making.\n\nRole:\nAs a Senior Data Scientist, you will:\n\u2022 Analyze large-scale operations data to build predictive models for system performance, anomaly detection, and proactive interventions.\n\u2022 Design, fine-tune, and deploy domain-specific LLMs to support internal tooling, documentation synthesis, and intelligent automation.\n\u2022 Develop agentic AI systems that autonomously interact with infrastructure, make decisions, and execute tasks with minimal human input.\n\u2022 Collaborate with engineering and product teams to ensure robust data pipelines and scalable model deployment.\n\u2022 Work closely with the AI COE team, domain experts and full stack developers to build and deploy interactive dashboards, providing the best, most engaging insights and UX for our users.\n\u2022 Engage with the wider Mastercard data science community, sharing best practice, knowledge, and insights, in support of collaborative, fulfilling work and value creation.\n\nAll About You:\n\u2022 An undergraduate degree or higher in Computer Science, Data Science, Econometrics, Mathematics, Statistics, or similar field of study.\n\u2022 Multi-project, hands-on experience of the end-to-end data science process in relation to large, complex data. From problem framing to results communication and solution deployment, you will be able to demonstrate having played a key part in a range of successfully delivered projects.\n\u2022 Strong background in predictive analytics and modelling using large operational datasets.\n\u2022 Expert level Python coding experience, including knowledge and experience of the principal Python Data Science / Machine Learning (ML) library ecosystem.\n\u2022 Hands-on experience with LLM architectures, and Agentic AI development.\n\u2022 Familiarity with agentic AI frameworks (e.g., LangGraph, OpenAI/LLaMA) and autonomous decision systems.\n\u2022 Proficiency in cloud platforms and big data ecosystems (Databricks).\n\u2022 Excellent communication skills and ability to work cross-functionally.\n\nCorporate Security Responsibility\n\nAll activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:\n\u2022 Abide by Mastercard\u2019s security policies and practices;\n\u2022 Ensure the confidentiality and integrity of the information being accessed;\n\u2022 Report any suspected information security violation or breach, and\n\u2022 Complete all periodic mandatory security trainings in accordance with Mastercard\u2019s guidelines.",
    "url": "https://simplify.jobs/p/51718324-a696-46dd-8807-dcac744a74dc/Senior-Data-Scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Machine Learning Engineer (MLE) \u2013 Python | DS | DE | ETL | Azure | Databricks",
    "company": "Apptware",
    "location": "Pune",
    "salary": "",
    "description": "Job description\n\nPosition: Machine Learning Engineer (MLE) \u2013 Python | DS | DE | ETL | Azure | Databricks\n\n\ud83d\udd39 Experience: 4\u20138 years\n\n\ud83d\udd39 Location: Pune / Bangalore\n\n\ud83d\udd39 Employment Type: Full-time\n\nJob Description:\n\nWe are seeking an experienced Machine Learning Engineer (MLE) with strong expertise in Python, Data Science (DS), Data Engineering (DE), ETL, and Azure Databricks. The ideal candidate will design, build, and deploy scalable ML solutions while collaborating with data and engineering teams to solve complex business challenges.\n\nKey Responsibilities:\n\u2022 Design and implement end-to-end ML pipelines using Databricks and Azure.\n\u2022 Develop, train, and deploy machine learning models for various business use cases.\n\u2022 Perform data preprocessing, feature engineering, and model optimization on large datasets.\n\u2022 Integrate ML models with production systems and ensure performance monitoring.\n\u2022 Collaborate with cross-functional teams to understand business needs and deliver effective ML solutions.\n\u2022 Stay updated with the latest trends in ML, DL, and AI frameworks.\n\nRequired Skills:\n\u2022 Python (Advanced) \u2013 Must\n\u2022 Data Science (DS), Data Engineering (DE), and ETL \u2013 Must\n\u2022 Machine Learning (ML) \u2013 Must\n\u2022 Deep Learning (Basic Understanding) \u2013 Good to have\n\u2022 Natural Language Processing (NLP) \u2013 Basic Understanding\n\u2022 Computer Vision \u2013 Basic Understanding\n\u2022 Python for Image Processing \u2013 Basic Understanding\n\u2022 ML Frameworks (TensorFlow / PyTorch / Scikit-learn) \u2013 Must\n\u2022 Azure Cloud \u2013 Must\n\u2022 Databricks \u2013 Must\n\nGood to Have:\n\u2022 Experience with Agile Methodology\n\u2022 Exposure to MLOps and CI/CD pipelines\n\u2022 Familiarity with data visualization tools like Power BI or Tableau\n\nAdditional Details:\n\u2022 Immediate joiners preferred\n\u2022 Candidates with up to 30 days\u2019 notice period can be considered\n\nApply Here: https://forms.gle/PNgXBb3QJh57Uqd79",
    "url": "https://in.linkedin.com/jobs/view/machine-learning-engineer-mle-%E2%80%93-python-ds-de-etl-azure-databricks-at-apptware-4331708651?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Sr Data Scientist",
    "company": "Birlasoft Limited",
    "location": "Pune",
    "salary": "",
    "description": "Area(s) of responsibility\n\nData Scientist experience (8 to 10) - 5B\n\n5 years of relevant work experience as a data scientist\n\nExperience designing and building statistical forecasting models.\n\nExperience in Python, AWS Cloud Services SageMaker,Comprehend, Amazon Bedrock for generative AI and Open AI\n\nExperience designing and building machine learning models.\n\nLead the end-to-end development of AI/ML solutions, from problem definition to production deployment.\n\nStrong programming skills in Python and experience with libraries like TensorFlow, PyTorch, Scikit-learn.\n\nMinimum 2 years of experience in Azure Cloud using Natural Language API\n\nExperience designing and building statistical forecasting models.\n\nExperience in Ingesting data from API and Databases\n\nExperience designing and building machine learning models.\n\nHands-on experience with LLMs and GenAI frameworks\n\nExperience in Django, Flask web frameworks\n\nExperience designing and building optimization models., including expertise with statistical data analysis\n\nMandatory Skillset: Python, AWS Cloud Services SageMaker, Comprehend, Amazon Bedrock for generative AI and Open AI",
    "url": "https://jobs.birlasoft.com/job/Pune-Sr-Data-Scientist-INDI/45605844/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Senior Data Scientist (Artificial Intelligence Machine Learning)",
    "company": "FIS Global",
    "location": "Pune",
    "salary": "",
    "description": "Position Type :\n\nFull time\n\nType Of Hire :\n\nExperienced (relevant combo of work and education)\n\nEducation Desired :\n\nBachelor of Engineering\n\nTravel Percentage :\n\n1 - 5%\n\nSenior Data Scientist (Artificial Intelligence Machine Learning)\n\nAre you curious, motivated, and forward-thinking? At FIS you\u2019ll have the opportunity to work on some of the most challenging and relevant issues in financial services and technology. Our talented people empower us, and we believe in being part of a team that is open, collaborative, entrepreneurial, passionate and above all fun.\n\nAbout the role:\n\u2022 We are looking for a talented and passionate Data Scientist willing to challenge themself and produce best in class AI enabled solution\n\u2022 You will be required to use the concepts of AIML, GenAI, LLMs, Sentiment analysis, etc.\n\u2022 The role requires creating correlation between different data points and do predictive, preventive analysis.\n\nAbout the Team :\n\nTeam provide solutions and services that help our clients grow, compete, and optimize their business. Our AIOPS team is creating AIML solution targeted to reduce the Enterprise MTTR through our world class product\n\nWhat you will be doing:\n\u2022 Employ machine learning and statistical modeling to create and enhance data driven products.\n\u2022 Analyze and extract insights from internal and external data.\n\u2022 Work with Big Data and transform complex datasets into more usable formats.\n\u2022 Work with a variety of data science tools and programming languages such as SAS, Python, R, Scala, SQL. Work independently and collaborate with other groups to solve complex problems.\n\u2022 Create and present analyses to internal and external partners and clients.\n\u2022 Will be working in 2 Pm to 11 Pm IST Shifts\n\nWhat you bring:\n\u2022 4 to 6 Years of machine learning, artificial intelligence, statistical modeling, data visualization, and data analysis\n\u2022 Proficient in data science tools and programming languages such as SAS, Python, R, Scala, SQL\n\u2022 Relevant degree in Artificial Intelligence Machine Learning\n\u2022 Experience or knowledge of cloud-based technology\n\u2022 Knowledge of financial services industry\n\nWhat we offer you:\n\u2022 A range of benefits designed to help support your lifestyle and wellbeing.\n\u2022 A multi-faceted job with a broad spectrum of responsibilities\n\u2022 A modern international work environment and a dedicated and innovative team\n\u2022 A broad range of professional education and personal development possibilities \u2013 FIS is your final career step.\n\nPrivacy Statement\n\nFIS is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how FIS protects personal information online, please see the Online Privacy Notice.\n\nSourcing Model\n\nRecruitment at FIS works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. FIS does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company.\n\n#pridepass",
    "url": "https://www.glassdoor.co.in/job-listing/senior-data-scientist-artificial-intelligence-machine-learning-fis-global-JV_IC2856202_KO0,62_KE63,73.htm?jl=1009714190836&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "TechVerito Software Solutions - Senior Data Scientist - Machine Learning/Artificial Intelligence (Pune)",
    "company": "TechVerito",
    "location": "Pune",
    "salary": "",
    "description": "Description :\nAbout the Role\nWe are looking for a Senior Data Scientist to lead the development and deployment of machine learning models that drive key business decisions.\nYou will translate complex business problems into actionable ML solutions, from experimentation to production.\nKey Responsibilities :\n- Lead end-to-end development of Machine Learning models for areas such as prediction, classification, and recommendation.\n- Design, implement, and validate models using rigorous statistical methods and ML best practices.\n- Develop robust ETL/ELT pipelines to ensure high-quality data for model training and inference.\n- Collaborate with Data Engineering and DevOps teams to productionize models and monitor their performance in a live setting.\n- Communicate complex analytical insights and model outcomes to technical and non-technical stakeholders.\n- Research and apply cutting-edge techniques in the fields of AI, Deep Learning, and NLP.\nTechnical Skills Required :\n- Languages: Expert proficiency in Python (NumPy, Pandas, SciPy, Scikit-learn).\n- ML/DL Frameworks: Hands-on experience with TensorFlow or PyTorch.\n- Big Data: Experience with SQL and distributed processing frameworks like Spark (PySpark).\n- Cloud & MLOps: Familiarity with deploying and managing models on cloud platforms (AWS SageMaker, Azure ML, or GCP AI Platform).\nKnowledge of MLOps tools (e., MLflow, Kubeflow) is highly desirable.\n- Statistics: Strong foundation in statistics, probability, and experimental design (A/B testing).\nQualifications :\n- Master's or Ph. in Computer Science, Statistics, Mathematics, or a related quantitative field.\n- 4+ years of hands-on experience in a Data Scientist role, with a focus on building and deploying ML models\n\n(ref:hirist.tech)",
    "url": "https://in.jobrapido.com/jobpreview/8149968057129762816?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Industry Consultant - Manufacturing + Data Science",
    "company": "Khoobi Consulting",
    "location": "IN",
    "salary": "",
    "description": "Responsibility:\n\n- Help customers identify opportunities of monetizing their data assets to drive growth and profitability.\n\n- Understand customer's engineering, supply chain and production planning requirements and design digital solutions for customers that have AI and AI-Agents embedded in them.\n\n- Act as a bridge between customer business stakeholders and development teams comprising of Data Scientists and Solution Architects.\n\n- Publish Whitepapers on topics covering application of AI to solve domain specific issues and drive growth in the industry.\n\nEssential Skills:\n\n- Ability to manage senior customer stakeholders.\n\n- Ability to help customers understand how Industry 4.0 practices can be applied in their environment.\n\n- Ability to lead requirement gathering and solutioning workshops with customers.\n\n- Ability to understand the latest development in AI research and relate them to areas where they can be applied.\n\nExperience:\n\n- Overall 15 20 years.\n\nDomain:\n\n- Minimum 10 years in Manufacturing (Production Planning, Maintenance, Automation, Control Systems, Supply Chain).\n\n- Preferred Experience in Actual Automation and Control Systems experience preferred.\n\nTechnical: Minimum 5 years in Control Systems data, Digital Applications implementation.\n\nKnowledge:\n\n- Strong in applying Statistics knowledge.\n\n- Machine Learning / Deep Learning / LLM / Agents.\n\nQualifications.\n\n- Masters or Bachelor's degree in Computer Science, Engineering or related field.\n\nWorking Arrangements.\n\n- 100% work from office.",
    "url": "https://www.iimjobs.com/j/industry-consultant-manufacturing-data-science-1632852?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Science Instructor",
    "company": "Itvedant Education Pvt. Ltd.",
    "location": "Pune",
    "salary": "",
    "description": "Responsibilities:\n\n\u25cf Conducting classroom and online lectures on programming languages (Data Science, Python,\n\nData Analytics) and related technologies to students\n\n\u25cf Assigning and evaluating coursework, quizzes, and projects\n\n\u25cf Providing one-on-one assistance and mentoring to students as required\n\n\u25cf Ensuring that the course curriculum is up-to-date and relevant to industry standards\n\n\u25cf Collaborating with other trainers and course developers to develop new training materials\n\n\u25cf Maintaining accurate student records and progress reports\n\n\u25cf Creating a positive and engaging learning environment for students\n\n\u25cf Participating in faculty meetings, staff development programs, and other professional\n\ndevelopment activities as required\n\n\u25cf Staying up-to-date with the latest trends and developments and related technologies\n\nRequirements:\n\n\u25cf A Bachelor's or Master's degree in Computer Science or a related field\n\n\u25cf A minimum of 1 years of experience as a trainer\n\n\u25cf Excellent communication and interpersonal skills\n\n\u25cf Strong knowledge of Python, Machine Learning, Data Science, Data Analytics, Deep\n\nLearning, NLP and related technologies\n\n\u25cf Experience working with databases such as PostgreSQL and MySQL\n\n\u25cf A passion for teaching and helping students achieve their career goals\n\n\u25cf Ability to work independently as well as in a team environment",
    "url": "https://in.linkedin.com/jobs/view/data-science-instructor-at-itvedant-education-pvt-ltd-4320264933?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Enterprise Data Analyst",
    "company": "Snowflake",
    "location": "Pune",
    "salary": "",
    "description": "Snowflake is about empowering enterprises to achieve their full potential \u2014 and people too. With a culture that\u2019s all in on impact, innovation, and collaboration, Snowflake is the sweet spot for building big, moving fast, and taking technology \u2014 and careers \u2014 to the next level.\n\nSnowflake is seeking a Data Scientist to join our expanding Enterprise AI & ML team. This role involves working on diverse AI/ML and data science initiatives, utilizing Snowflake's Data Cloud and Cortex AI. The successful candidate will design and develop scalable data science and machine learning solutions, build interactive AI applications, and collaborate on operationalizing intelligent systems to enhance data-driven decision-making throughout the company. This position focuses on applying data science, AI & ML skill sets to various domain specific business data problems across Snowflake.\n\nON THE DATA SCIENCE & ANALYTICS TEAM AT SNOWFLAKE, YOU WILL:\n\u2022 Design, prototype, and deploy data science and AI solutions.\n\u2022 Conduct end to end experimentation, including data exploration, feature engineering, model development, and validation.\n\u2022 Build and maintain Streamlit applications to visualize models, showcase insights, and enable business stakeholders to interact with AI driven solutions.\n\u2022 Develop and optimize LLM based applications, workflows, and operations; with a focus on retrieval, generation, semantic understanding and fine-tuning.\n\u2022 Partner cross functionally with data engineers, analysts, and product teams to translate ambiguous business problems into measurable outcomes.\n\nOUR IDEAL CANDIDATE WILL HAVE:\n\u2022 2 to 4 years of experience applying data science, machine learning, or AI techniques in real world business settings.\n\u2022 Strong programming skills in Python, proficiency in SQL for large scale data manipulation.\n\u2022 Familiarity with frameworks such as scikit-learn, XGBoost etc.\n\u2022 Understanding of LLM architectures, embeddings, vector search, and RAG pipelines.\n\u2022 Experience working on cloud platforms.\n\u2022 Strong analytical, storytelling, and communication skills to translate technical insights into actionable recommendations.\n\u2022 A mindset of curiosity, ownership, and collaboration, with an eagerness to work on open-ended problems.\n\u2022 Experience operationalizing AI & ML models in a production setting.\n\nSnowflake is growing fast, and we\u2019re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.\n\nHow do you want to make your impact?\n\nFor jobs located in the United States, please visit the job posting on the Snowflake Careers Site for salary and benefits information: careers.snowflake.com",
    "url": "https://builtin.com/job/enterprise-data-analyst/7508278?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Business Sales Head- Data Science",
    "company": "Cinecraft",
    "location": "Pune",
    "salary": "",
    "description": "Position: Business Head \u2013 Data Science\n\nLocation: Pune, Maharashtra\nInstitute: Cinecraft Digital Academy\n\nAbout the Role:\nWe are seeking a dynamic and experienced Business Head \u2013 Data Science to lead our Data Science, AI, and Analytics division. The ideal candidate will drive business growth, oversee academic excellence, and build strong industry partnerships to strengthen our position as a leading digital education brand.\n\nKey Responsibilities:\n\nAchieve admission and revenue targets for Data Science & AI programs.\nLead academic planning, curriculum upgrades, and faculty management.\nCollaborate with marketing for lead generation and brand building.\nDevelop industry tie-ups for placements, projects, and internships.\nManage team performance and ensure smooth operations.\nStay updated with market trends and identify new course opportunities.\n\nRequirements:\n\nGraduate/Postgraduate in Data Science, Computer Science, or Business/ MBA.\n3+ years of experience in education management, EdTech, or training industry working towards admissions.\nStrong knowledge of Data Science, AI, and analytics ecosystem.\n\nExcellent leadership, communication, and business development skills.\n\nWhat We Offer:\nCompetitive salary with performance incentives.\nGrowth-driven, creative work environment.\nOpportunity to lead an expanding digital education brand.\n\nMore about this Business Sales Head- Data Science job\n\nCinecraft is aggressively hiring for the job profile of Business Sales Head- Data Science at Pune in Pawar Quarter (Hotel Raviraj) locality. Kindly go through the FAQs below to get all answers related to the given job.\n\n1. How much salary can I expect as a Business Sales Head- Data Science in Cinecraft in Pune?\n\nAns. You can expect a minimum salary of 40,000 INR and can go up to 60,000 INR. The salary offered will depend on your skills, experience and performance in the interview.\n\n2. What is the eligibility criteria to apply for Business Sales Head- Data Science in Cinecraft in Pune?\n\nAns. The candidate should have completed Graduate degree and people who have 3 to 31 years are eligible to apply for this job. You can apply for more jobs in Pune to get hired quickly.\n\n3. Is there any specific skill required for this job?\n\nAns. The candidate should have Good (Intermediate / Advanced) English skills and sound communication skills for this job.\n\n4. Who can apply for this job?\n\nAns. Only Male candidates can apply for this job.\n\n5. Is it a work from home job?\n\nAns. No, it\u2019s not a work from home job and can\u2019t be done online. You can explore and apply for other work from home jobs in Pune at apna.\n\n6. Are there any charges or deposits required while applying for the role or while joining?\n\nAns. No work-related deposit needs to be made during your employment with the company.\n\n7. How can I apply for this job?\n\nAns. Go to the apna app and apply for this job. Click on the apply button and call HR directly to schedule your interview.\n\n8. What is the last date to apply?\n\nAns. The last date to apply for this job is 12-Nov-2025.\n\nFor more details, download apna app and find Full Time jobs in Pune. Through apna, you can find jobs in 74 cities across India. Join NOW!",
    "url": "https://apna.co/job/pune/business-sales-head-data-science-879117150?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "AI ML Python data science trainer",
    "company": "myinternship.in",
    "location": "Pune",
    "salary": "",
    "description": "Looking for an experienced AI, ML, Data Science & Analytics Trainer to deliver engaging, hands-on sessions covering Python, Machine Learning, and Power BI.\nShould have strong practical knowledge, real-world project exposure, and passion for teaching.\nResponsible for curriculum delivery, student mentoring, and guiding on live projects.\n\nJob Type: Full-time\n\nWork Location: In person",
    "url": "https://www.glassdoor.co.in/job-listing/ai-ml-python-data-science-trainer-myinternship-in-JV_IC2856202_KO0,33_KE34,49.htm?jl=1009923636335&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Sr Data Scientist",
    "company": "Birlasoft Limited",
    "location": "Pune",
    "salary": "",
    "description": "Area(s) of responsibility\n\nData Scientist experience (8 to 10) - 5B\n\n5 years of relevant work experience as a data scientist\n\nExperience designing and building statistical forecasting models.\n\nExperience in Python, AWS Cloud Services SageMaker,Comprehend, Amazon Bedrock for generative AI and Open AI\n\nExperience designing and building machine learning models.\n\nLead the end-to-end development of AI/ML solutions, from problem definition to production deployment.\n\nStrong programming skills in Python and experience with libraries like TensorFlow, PyTorch, Scikit-learn.\n\nMinimum 2 years of experience in Azure Cloud using Natural Language API\n\nExperience designing and building statistical forecasting models.\n\nExperience in Ingesting data from API and Databases\n\nExperience designing and building machine learning models.\n\nHands-on experience with LLMs and GenAI frameworks\n\nExperience in Django, Flask web frameworks\n\nExperience designing and building optimization models., including expertise with statistical data analysis\n\nMandatory Skillset: Python, AWS Cloud Services SageMaker, Comprehend, Amazon Bedrock for generative AI and Open AI",
    "url": "https://jobs.birlasoft.com/job/Pune-Sr-Data-Scientist-INDI/45605844/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Senior Data Scientist (Artificial Intelligence Machine Learning)",
    "company": "FIS Global",
    "location": "Pune",
    "salary": "",
    "description": "Position Type :\n\nFull time\n\nType Of Hire :\n\nExperienced (relevant combo of work and education)\n\nEducation Desired :\n\nBachelor of Engineering\n\nTravel Percentage :\n\n1 - 5%\n\nSenior Data Scientist (Artificial Intelligence Machine Learning)\n\nAre you curious, motivated, and forward-thinking? At FIS you\u2019ll have the opportunity to work on some of the most challenging and relevant issues in financial services and technology. Our talented people empower us, and we believe in being part of a team that is open, collaborative, entrepreneurial, passionate and above all fun.\n\nAbout the role:\n\u2022 We are looking for a talented and passionate Data Scientist willing to challenge themself and produce best in class AI enabled solution\n\u2022 You will be required to use the concepts of AIML, GenAI, LLMs, Sentiment analysis, etc.\n\u2022 The role requires creating correlation between different data points and do predictive, preventive analysis.\n\nAbout the Team :\n\nTeam provide solutions and services that help our clients grow, compete, and optimize their business. Our AIOPS team is creating AIML solution targeted to reduce the Enterprise MTTR through our world class product\n\nWhat you will be doing:\n\u2022 Employ machine learning and statistical modeling to create and enhance data driven products.\n\u2022 Analyze and extract insights from internal and external data.\n\u2022 Work with Big Data and transform complex datasets into more usable formats.\n\u2022 Work with a variety of data science tools and programming languages such as SAS, Python, R, Scala, SQL. Work independently and collaborate with other groups to solve complex problems.\n\u2022 Create and present analyses to internal and external partners and clients.\n\u2022 Will be working in 2 Pm to 11 Pm IST Shifts\n\nWhat you bring:\n\u2022 4 to 6 Years of machine learning, artificial intelligence, statistical modeling, data visualization, and data analysis\n\u2022 Proficient in data science tools and programming languages such as SAS, Python, R, Scala, SQL\n\u2022 Relevant degree in Artificial Intelligence Machine Learning\n\u2022 Experience or knowledge of cloud-based technology\n\u2022 Knowledge of financial services industry\n\nWhat we offer you:\n\u2022 A range of benefits designed to help support your lifestyle and wellbeing.\n\u2022 A multi-faceted job with a broad spectrum of responsibilities\n\u2022 A modern international work environment and a dedicated and innovative team\n\u2022 A broad range of professional education and personal development possibilities \u2013 FIS is your final career step.\n\nPrivacy Statement\n\nFIS is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how FIS protects personal information online, please see the Online Privacy Notice.\n\nSourcing Model\n\nRecruitment at FIS works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. FIS does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company.\n\n#pridepass",
    "url": "https://www.glassdoor.co.in/job-listing/senior-data-scientist-artificial-intelligence-machine-learning-fis-global-JV_IC2856202_KO0,62_KE63,73.htm?jl=1009714190836&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Enterprise Data Analyst",
    "company": "Snowflake",
    "location": "Pune",
    "salary": "",
    "description": "Snowflake is about empowering enterprises to achieve their full potential \u2014 and people too. With a culture that\u2019s all in on impact, innovation, and collaboration, Snowflake is the sweet spot for building big, moving fast, and taking technology \u2014 and careers \u2014 to the next level.\n\nSnowflake is seeking a Data Scientist to join our expanding Enterprise AI & ML team. This role involves working on diverse AI/ML and data science initiatives, utilizing Snowflake's Data Cloud and Cortex AI. The successful candidate will design and develop scalable data science and machine learning solutions, build interactive AI applications, and collaborate on operationalizing intelligent systems to enhance data-driven decision-making throughout the company. This position focuses on applying data science, AI & ML skill sets to various domain specific business data problems across Snowflake.\n\nON THE DATA SCIENCE & ANALYTICS TEAM AT SNOWFLAKE, YOU WILL:\n\u2022 Design, prototype, and deploy data science and AI solutions.\n\u2022 Conduct end to end experimentation, including data exploration, feature engineering, model development, and validation.\n\u2022 Build and maintain Streamlit applications to visualize models, showcase insights, and enable business stakeholders to interact with AI driven solutions.\n\u2022 Develop and optimize LLM based applications, workflows, and operations; with a focus on retrieval, generation, semantic understanding and fine-tuning.\n\u2022 Partner cross functionally with data engineers, analysts, and product teams to translate ambiguous business problems into measurable outcomes.\n\nOUR IDEAL CANDIDATE WILL HAVE:\n\u2022 2 to 4 years of experience applying data science, machine learning, or AI techniques in real world business settings.\n\u2022 Strong programming skills in Python, proficiency in SQL for large scale data manipulation.\n\u2022 Familiarity with frameworks such as scikit-learn, XGBoost etc.\n\u2022 Understanding of LLM architectures, embeddings, vector search, and RAG pipelines.\n\u2022 Experience working on cloud platforms.\n\u2022 Strong analytical, storytelling, and communication skills to translate technical insights into actionable recommendations.\n\u2022 A mindset of curiosity, ownership, and collaboration, with an eagerness to work on open-ended problems.\n\u2022 Experience operationalizing AI & ML models in a production setting.\n\nSnowflake is growing fast, and we\u2019re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.\n\nHow do you want to make your impact?\n\nFor jobs located in the United States, please visit the job posting on the Snowflake Careers Site for salary and benefits information: careers.snowflake.com",
    "url": "https://builtin.com/job/enterprise-data-analyst/7508278?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "TechVerito Software Solutions - Senior Data Scientist - Machine Learning/Artificial Intelligence (Pune)",
    "company": "TechVerito",
    "location": "Pune",
    "salary": "",
    "description": "Description :\nAbout the Role\nWe are looking for a Senior Data Scientist to lead the development and deployment of machine learning models that drive key business decisions.\nYou will translate complex business problems into actionable ML solutions, from experimentation to production.\nKey Responsibilities :\n- Lead end-to-end development of Machine Learning models for areas such as prediction, classification, and recommendation.\n- Design, implement, and validate models using rigorous statistical methods and ML best practices.\n- Develop robust ETL/ELT pipelines to ensure high-quality data for model training and inference.\n- Collaborate with Data Engineering and DevOps teams to productionize models and monitor their performance in a live setting.\n- Communicate complex analytical insights and model outcomes to technical and non-technical stakeholders.\n- Research and apply cutting-edge techniques in the fields of AI, Deep Learning, and NLP.\nTechnical Skills Required :\n- Languages: Expert proficiency in Python (NumPy, Pandas, SciPy, Scikit-learn).\n- ML/DL Frameworks: Hands-on experience with TensorFlow or PyTorch.\n- Big Data: Experience with SQL and distributed processing frameworks like Spark (PySpark).\n- Cloud & MLOps: Familiarity with deploying and managing models on cloud platforms (AWS SageMaker, Azure ML, or GCP AI Platform).\nKnowledge of MLOps tools (e., MLflow, Kubeflow) is highly desirable.\n- Statistics: Strong foundation in statistics, probability, and experimental design (A/B testing).\nQualifications :\n- Master's or Ph. in Computer Science, Statistics, Mathematics, or a related quantitative field.\n- 4+ years of hands-on experience in a Data Scientist role, with a focus on building and deploying ML models\n\n(ref:hirist.tech)",
    "url": "https://in.jobrapido.com/jobpreview/8149968057129762816?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Industry Consultant - Manufacturing + Data Science",
    "company": "Khoobi Consulting",
    "location": "IN",
    "salary": "",
    "description": "Responsibility:\n\n- Help customers identify opportunities of monetizing their data assets to drive growth and profitability.\n\n- Understand customer's engineering, supply chain and production planning requirements and design digital solutions for customers that have AI and AI-Agents embedded in them.\n\n- Act as a bridge between customer business stakeholders and development teams comprising of Data Scientists and Solution Architects.\n\n- Publish Whitepapers on topics covering application of AI to solve domain specific issues and drive growth in the industry.\n\nEssential Skills:\n\n- Ability to manage senior customer stakeholders.\n\n- Ability to help customers understand how Industry 4.0 practices can be applied in their environment.\n\n- Ability to lead requirement gathering and solutioning workshops with customers.\n\n- Ability to understand the latest development in AI research and relate them to areas where they can be applied.\n\nExperience:\n\n- Overall 15 20 years.\n\nDomain:\n\n- Minimum 10 years in Manufacturing (Production Planning, Maintenance, Automation, Control Systems, Supply Chain).\n\n- Preferred Experience in Actual Automation and Control Systems experience preferred.\n\nTechnical: Minimum 5 years in Control Systems data, Digital Applications implementation.\n\nKnowledge:\n\n- Strong in applying Statistics knowledge.\n\n- Machine Learning / Deep Learning / LLM / Agents.\n\nQualifications.\n\n- Masters or Bachelor's degree in Computer Science, Engineering or related field.\n\nWorking Arrangements.\n\n- 100% work from office.",
    "url": "https://www.iimjobs.com/j/industry-consultant-manufacturing-data-science-1632852?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Science Instructor",
    "company": "Itvedant Education Pvt. Ltd.",
    "location": "Pune",
    "salary": "",
    "description": "Responsibilities:\n\n\u25cf Conducting classroom and online lectures on programming languages (Data Science, Python,\n\nData Analytics) and related technologies to students\n\n\u25cf Assigning and evaluating coursework, quizzes, and projects\n\n\u25cf Providing one-on-one assistance and mentoring to students as required\n\n\u25cf Ensuring that the course curriculum is up-to-date and relevant to industry standards\n\n\u25cf Collaborating with other trainers and course developers to develop new training materials\n\n\u25cf Maintaining accurate student records and progress reports\n\n\u25cf Creating a positive and engaging learning environment for students\n\n\u25cf Participating in faculty meetings, staff development programs, and other professional\n\ndevelopment activities as required\n\n\u25cf Staying up-to-date with the latest trends and developments and related technologies\n\nRequirements:\n\n\u25cf A Bachelor's or Master's degree in Computer Science or a related field\n\n\u25cf A minimum of 1 years of experience as a trainer\n\n\u25cf Excellent communication and interpersonal skills\n\n\u25cf Strong knowledge of Python, Machine Learning, Data Science, Data Analytics, Deep\n\nLearning, NLP and related technologies\n\n\u25cf Experience working with databases such as PostgreSQL and MySQL\n\n\u25cf A passion for teaching and helping students achieve their career goals\n\n\u25cf Ability to work independently as well as in a team environment",
    "url": "https://in.linkedin.com/jobs/view/data-science-instructor-at-itvedant-education-pvt-ltd-4320264933?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Business Sales Head- Data Science",
    "company": "Cinecraft",
    "location": "Pune",
    "salary": "",
    "description": "Position: Business Head \u2013 Data Science\n\nLocation: Pune, Maharashtra\nInstitute: Cinecraft Digital Academy\n\nAbout the Role:\nWe are seeking a dynamic and experienced Business Head \u2013 Data Science to lead our Data Science, AI, and Analytics division. The ideal candidate will drive business growth, oversee academic excellence, and build strong industry partnerships to strengthen our position as a leading digital education brand.\n\nKey Responsibilities:\n\nAchieve admission and revenue targets for Data Science & AI programs.\nLead academic planning, curriculum upgrades, and faculty management.\nCollaborate with marketing for lead generation and brand building.\nDevelop industry tie-ups for placements, projects, and internships.\nManage team performance and ensure smooth operations.\nStay updated with market trends and identify new course opportunities.\n\nRequirements:\n\nGraduate/Postgraduate in Data Science, Computer Science, or Business/ MBA.\n3+ years of experience in education management, EdTech, or training industry working towards admissions.\nStrong knowledge of Data Science, AI, and analytics ecosystem.\n\nExcellent leadership, communication, and business development skills.\n\nWhat We Offer:\nCompetitive salary with performance incentives.\nGrowth-driven, creative work environment.\nOpportunity to lead an expanding digital education brand.\n\nMore about this Business Sales Head- Data Science job\n\nCinecraft is aggressively hiring for the job profile of Business Sales Head- Data Science at Pune in Pawar Quarter (Hotel Raviraj) locality. Kindly go through the FAQs below to get all answers related to the given job.\n\n1. How much salary can I expect as a Business Sales Head- Data Science in Cinecraft in Pune?\n\nAns. You can expect a minimum salary of 40,000 INR and can go up to 60,000 INR. The salary offered will depend on your skills, experience and performance in the interview.\n\n2. What is the eligibility criteria to apply for Business Sales Head- Data Science in Cinecraft in Pune?\n\nAns. The candidate should have completed Graduate degree and people who have 3 to 31 years are eligible to apply for this job. You can apply for more jobs in Pune to get hired quickly.\n\n3. Is there any specific skill required for this job?\n\nAns. The candidate should have Good (Intermediate / Advanced) English skills and sound communication skills for this job.\n\n4. Who can apply for this job?\n\nAns. Only Male candidates can apply for this job.\n\n5. Is it a work from home job?\n\nAns. No, it\u2019s not a work from home job and can\u2019t be done online. You can explore and apply for other work from home jobs in Pune at apna.\n\n6. Are there any charges or deposits required while applying for the role or while joining?\n\nAns. No work-related deposit needs to be made during your employment with the company.\n\n7. How can I apply for this job?\n\nAns. Go to the apna app and apply for this job. Click on the apply button and call HR directly to schedule your interview.\n\n8. What is the last date to apply?\n\nAns. The last date to apply for this job is 12-Nov-2025.\n\nFor more details, download apna app and find Full Time jobs in Pune. Through apna, you can find jobs in 74 cities across India. Join NOW!",
    "url": "https://apna.co/job/pune/business-sales-head-data-science-879117150?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "AI ML Python data science trainer",
    "company": "myinternship.in",
    "location": "Pune",
    "salary": "",
    "description": "Looking for an experienced AI, ML, Data Science & Analytics Trainer to deliver engaging, hands-on sessions covering Python, Machine Learning, and Power BI.\nShould have strong practical knowledge, real-world project exposure, and passion for teaching.\nResponsible for curriculum delivery, student mentoring, and guiding on live projects.\n\nJob Type: Full-time\n\nWork Location: In person",
    "url": "https://www.glassdoor.co.in/job-listing/ai-ml-python-data-science-trainer-myinternship-in-JV_IC2856202_KO0,33_KE34,49.htm?jl=1009923636335&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "AIML (Data Scientist)",
    "company": "WOW Softech",
    "location": "Pune",
    "salary": "",
    "description": "Role & responsibilities\n\nData Scientist,\n\u2022 At least 4+ years of significant experience in data Science, developing video analytics/image processing software\n\u2022 Knowledge required on- ffmpeg, Deep Learning and Deep Stream SDK using Nvidia Jetson Nano\n\u2022 Demonstrated ability in troubleshooting and hardware/software trade-offs\n\nPreferred candidate profile",
    "url": "https://in.bebee.com/job/242610eeb2baec709223c052a199eb7e?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Data Scientist/Machine Learning Engineer Assistant vice president",
    "company": "Early Career",
    "location": "Pune",
    "salary": "",
    "description": "ML Solutions team within Markets OPS Technology is dedicated to developing solutions using Artificial Intelligence, Machine Learning and Generative AI. This team is a leader in creating new ideas, innovative technology solutions, and ground-breaking solutions for Markets Operations and Other Line of Businesses. We work closely with our clients and business partners to progress solutions from ideation to production by leveraging the entrepreneurial spirit and technological excellence.\n\nJob Description:\n\nThe ML Solutions team is seeking a Data Scientist/Machine Learning Engineer to drive the design, development, and deployment of innovative AI/ML and GenAI-based solutions. In this hands-on role, you will leverage your expertise to create a variety of AI models, guiding a team from initial concept to successful production. A key aspect involves mentoring team members and fostering their growth. You will collaborate closely with business partners and stakeholders, championing the adoption of these advanced technologies to enhance client experiences, deliver tangible value to our customers, and ensure adherence to regulatory requirements through cutting-edge technical solutions. This position offers a unique opportunity to shape the future of our AI initiatives and make a significant impact on the organization.\n\nKey Responsibilities:\n\u2022 Hands-On Execution and Delivery: Actively contribute to the development and delivery of AI solutions, driving innovation and excellence within the team. Take a hands-on approach to ensure AI models are successfully deployed into production environments, meeting high-quality standards and performance benchmarks.\n\u2022 Mentoring Young Talents: Mentoring team, guiding data analysts/ML engineers from concept to production. This involves fostering technical growth, providing project oversight, and ensuring adherence to best practices, ultimately building a high-performing and innovative team.\n\u2022 Quality Control: Ensure the quality and performance of generative AI models, conducting rigorous testing and evaluation.\n\u2022 Research and Development: Participate in research activities to explore and advance state-of-the-art generative AI techniques. Stay actively engaged in monitoring ongoing research efforts, keeping abreast of emerging trends, and ensuring that the Generative AI team remains at the forefront of the field.\n\u2022 Cross-Functional Collaboration: Collaborate effectively with various teams, including product managers, engineers, and data scientists, to integrate AI technologies into products and services.\n\nSkills & Qualifications:\n\u2022 8 to 13 years of Strong hands-on experience in Machine Learning, delivering complex solutions to production.\n\u2022 Experience with Generative AI technologies essential.\n\u2022 Understanding of concepts like supervised, unsupervised, clustering, embedding.\n\u2022 Knowledge of NLP, Name Entity Recognition, Computer Vision, Transformers, Large Language Models.\n\u2022 In-depth knowledge of deep learning and Generative AI frameworks such as, Langchain, Lang Graph, Crew AI or similar.\n\u2022 Experience with and other open-source frameworks/ libraries/ APIs like Hugging Face Transformers, Spacy, Pandas, scikit-learn, NumPy, OpenCV.\n\u2022 Experience in using Machine Learning/Deep Learning: XGBoost, LightGBM, TensorFlow, PyTorch, Keras.\n\u2022 Proficiency in Python Software Development, following Object-Oriented design patterns and best practices.\n\u2022 Strong background in mathematics: linear algebra, probability, statistics, and optimization.\n\u2022 Experience with evaluation, scoring with framework like ML Flow\n\u2022 Experience of Docker container and edited a Docker file, experience with K8s is a plus.\n\u2022 Experience with Postgres and Vector DBs a plus.\n\u2022 Excellent problem-solving skills and the ability to think creatively.\n\u2022 Strong communication and collaboration skills, with the ability to work effectively with cross-functional teams\n\u2022 Publications and contributions to the AI research community are a plus.\n\u2022 Master\u2019s degree/Ph. D. or equivalent experience in Computer Science, Data Science, Statistics, or a related field.\n\u2022 8-12 years of experience\n\nThis job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.\n\n------------------------------------------------------\n\nJob Family Group:\nTechnology\n\n------------------------------------------------------\n\nJob Family:\nApplications Development\n\n------------------------------------------------------\n\nTime Type:\nFull time\n\n------------------------------------------------------\n\nMost Relevant Skills\nPlease see the requirements listed above.\n\n------------------------------------------------------\n\nOther Relevant Skills\nData Science, Machine Learning.\n\n------------------------------------------------------\n\nCiti is an equal opportunity employer, and qualified candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other characteristic protected by law.\n\nIf you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.\n\nView Citi\u2019s EEO Policy Statement and the Know Your Rights poster.",
    "url": "https://jobs.citi.com/job/pune/data-scientist-machine-learning-engineer-assistant-vice-president/287/83901989456?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Search Engineer - Machine Learning/Artificial Intelligence",
    "company": "Talentxo",
    "location": "Pune",
    "salary": "",
    "description": "Salary 10 - 20 LPA Roles & Responsibilities :- The Primary focus of this role is to develop and manage applications involved with Search Systems. Maintain and upgrade search indices for large document repositories, as well as optimizing indexing/queries and supporting analytics. - He will be leading a Team of search engineers who build Tags, taxonomy, Thesaurus and ontology data models and standard to define and organize our customers search experience.- Drive and coordinate cross-functional projects with broad range of Loan, Insurance and investment products owners, engineers, designers and other groups that may include architecting new data solutions- Analyze website metrics and customer behaviour data to make intelligent decisions on optimizing our search model. Collaborate and consult directly with key stakeholders, technical teams and leadership on solutions for taxonomy and metadata that will positively impact the customers search experience- Expand and refine data retrieval techniques to use our extensive product catalog and improve customer data quality - This role is for machine learning and data-oriented product development (horizontal capability builds) but it will also require strong program management and execution skills. - Technical Interactions with vendor or partners in technical capacity for business/capability deliverables. - Develops proof of concept to prove or disprove validity of concept. - Work with cross functional team to integrate these models into larger solutions. - Works collaboratively in a multi-disciplinary team environment; Establishes and maintains professional networks with subject matter experts. - Responsible for artificial intelligence / machine learning technology and application analysis, understand latest industrial and academic developments in AI/ML. - Design competitive AI/ML services and user experience for next generation products and create prototypes for demonstration. Strong empowerment and self-drive is a must.Ideal Candidate :- PhD/MTech/BE/ BTech/MSc in CS or Math, Operation research, Statistics, Econometrics or in any quantitative field- 3+ years of industrial experience in Search, Information retrieval, NLP, Machine learning, predictive analytics solution development and deployment- Strong Problem-solving ability- Should have strong experience in anyone or more programming languages Python or JAVA. Experience in RESTful, Web Services,- Experience in using Python, R, SAS or any other statistical software (plus other open source libraries)- skills with Shell/Perl (or similar scripting language), Scala and Java- Experience with development tools like Eclipse, Git, Gradle, Jenkins, Jira, JFrog Artifactory etc.- Experience with web application server like Tomcat, Jetty, JBoss etc.- Strong understanding of OOP design patterns and industry best practices.- Fair knowledge of scripting and working in Linux environment- Good to have Experience of building Solutions with latest front-end technologies (JavaScript libraries like React or Angular, CSS3, HTML5).- Hands-on experience of API Integration single-sign -on and token-based authentication. Experience integrating with SQL and NoSQL databases (Cosmos DB, Cassandra, MongoDB)- Good understanding of DevOps pipeline like Azure Devops. Experience in Agile environment- Experience in any of the following area could be plus: Lucene based search engines (Elasticsearch, Solr)- Experience Container Orchestration technologies (Kubernetes), distributed systems, scalable data analytics technologies (Spark)- Experience in mentoring junior team members, and guiding them on machine learning, NLP, Computer Vision, Speech analytics and data modeling applications- Strong communication and data presentation skills- Skills with Relational Databases, Data warehouses, Structured & Unstructured data forms.- Publications /patents/presentation in recognized Machine Learning and Data Mining journals/conferences is preferred- Solid knowledge in deep learning algorithms and AI system design and architecture.- Strong hands-on nature (ability to self-code is a must).- Strong capability to work on server class (cloud machines) for data science capability builds- Strong IT & Business interactions capability- Strong team player with exceptional program management.Perks, Benefits & CultureOur people define our passion and our audacious, incredibly rewarding achievements. Bajaj Finance Limited is one of Indias most diversified Non-banking financial companies, and among Asias top 10 Large workplaces. If you have the drive to get ahead, we can help find you an opportunity at any of the 500+ locations were present in India. (ref:hirist.tech)",
    "url": "https://in.jooble.org/jdp/-7718339905405608865?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "AI/ML Platform Engineer",
    "company": "Johnson Controls International",
    "location": "Pune",
    "salary": "",
    "description": "Job Title: Senior Data Scientist \u2013 Data & Analytics\n\nJohnson Controls International (JCI) is seeking a Senior Data Scientist to join our innovative and impact-driven Data Science and Analytics team. This role is ideal for a seasoned expert with a deep understanding of machine learning, AI, and cloud data platforms, and a strong grasp of the latest advancements in Generative AI and Large Language Models (LLMs).\n\nAs a Senior Data Scientist, you will lead the development and deployment of scalable AI solutions\u2014including those powered by LLMs\u2014to accelerate digital transformation across our products, operations, and customer experiences. You'll play a critical role in shaping JCI\u2019s data science strategy, mentoring teams, and driving the use of AI to deliver measurable business value.\n\nHow you will do it\n\nAdvanced Analytics, LLMs & Modeling\n\u2022 Design and implement advanced machine learning models including deep learning, time-series forecasting, recommendation engines, and LLM-based solutions (e.g., GPT, LLaMA, Claude).\n\u2022 Develop use cases around enterprise search, document summarization, conversational AI, and automated knowledge retrieval using large language models.\n\u2022 Fine-tune or prompt-engineer foundation models (e.g., OpenAI, Azure OpenAI, Hugging Face) for domain-specific applications.\n\u2022 Evaluate and optimize LLM performance, latency, cost-effectiveness, and hallucination mitigation strategies for production use.\n\nData Strategy & Engineering Collaboration\n\u2022 Work closely with data and ML engineering teams to integrate LLM-powered applications into scalable, secure, and reliable pipelines.\n\u2022 Contribute to the development of retrieval-augmented generation (RAG) architectures using vector databases (e.g., FAISS, Azure Cognitive Search).\n\u2022 Support the deployment of models using MLOps principles, ensuring robust monitoring and lifecycle management.\n\nBusiness Impact & AI Strategy\n\u2022 Partner with cross-functional stakeholders to identify opportunities for applying LLMs and generative AI to solve complex business challenges.\n\u2022 Lead workshops or proofs-of-concept to demonstrate value of LLM use cases across business units.\n\u2022 Translate complex model outputs, including those from LLMs, into clear insights and decision support tools for non-technical audiences.\n\nThought Leadership & Mentorship\n\u2022 Act as an internal thought leader on AI and LLM innovation, keeping JCI at the forefront of industry advancements.\n\u2022 Mentor and upskill data science team members in advanced AI techniques, including transformer models and generative AI frameworks.\n\u2022 Contribute to strategic roadmaps for generative AI and model governance within the enterprise.\n\nQualifications & Experience\n\u2022 Education in Data Science, Artificial Intelligence, Computer Science, or related quantitative discipline.\n\u2022 5+ years of hands-on experience in data science, including at least 1\u20132 years working with LLMs or generative AI technologies.\n\u2022 Demonstrated success in deploying machine learning and NLP solutions at scale.\n\u2022 Proven experience with cloud AI platforms\u2014especially Azure OpenAI, Azure ML, Hugging Face, or AWS Bedrock.\n\nTechnical Expertise\n\u2022 Proficiency in Python and SQL, including libraries like Transformers (Hugging Face), LangChain, PyTorch, and TensorFlow.\n\u2022 Experience with prompt engineering, fine-tuning, and LLM orchestration tools.\n\u2022 Familiarity with data storage, retrieval systems, and vector databases.\n\u2022 Strong understanding of model evaluation techniques for generative AI, including factuality, relevance, and toxicity metrics.\n\nLeadership & Soft Skills\n\u2022 Strategic thinker with a strong ability to align AI initiatives to business goals.\n\u2022 Excellent communication and storytelling skills, especially in articulating the value of LLMs and advanced analytics.\n\u2022 Strong collaborator with a track record of influencing stakeholders across product, engineering, and executive teams.\n\nPreferred Qualifications\n\u2022 Experience with IoT, edge analytics, or smart building systems.\n\u2022 Familiarity with LLMOps, LangChain, Semantic Kernel, or similar orchestration frameworks.\n\u2022 Knowledge of data privacy and governance considerations specific to LLM usage in enterprise environments.",
    "url": "https://jobs.johnsoncontrols.com/job/WD30254347?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "AI Ml Engineer  Freshers",
    "company": "Agiliad",
    "location": "Pune",
    "salary": "",
    "description": "Required Skills:\n\u2022 Strong understanding of Machine Learning, Deep Learning, and Generative AI concepts.\n\u2022 Good knowledge of Python, TensorFlow, PyTorch, Keras, and Scikit-learn.\n\u2022 Understanding of Statistics, Linear Algebra, and Probability.\n\u2022 Familiarity with AI Ops tools, Docker, Git, and Azure is a plus.\n\u2022 Excellent problem-solving and analytical skills.\n\nEligibility Criteria:\n\u2022 Education: B.E/B.Tech/M.Tech/B.Sc/M.Sc in Computer Science, IT, AI/ML, or related fields.\n\u2022 Academic Performance: Minimum 80% or above in 10th, 12th, and Graduation.\n\u2022 Batch: 2024 / 2025 Pass-out.\n\u2022 Skill -Good Communication.",
    "url": "https://in.bebee.com/job/8cfee268fce41499651d7f3c4987aa05?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "\u25b7 (High Salary) Generative AI Engineer",
    "company": "Ascendion",
    "location": "Pune",
    "salary": "",
    "description": "Position Details :\n\nJob Title : GenAI Engineer\n\nExperience : 3+ years\n\nLocation Options : Pune\n\nSkills : Python, Langchain, Langgraph, Autogen\n\nOverview :\n\nWe are actively seeking highly skilled GenAI Engineers. The ideal candidates will bring hands-on experience in developing and deploying Generative AI (GenAI) solutions from MVP to production.\n\nKey Skills :\n\u2022 Python, Langchain, Langgraph, Autogen\n\u2022 Ai agents build (multi-Agent orchestration)\n\u2022 Build and orchestrate AI agents, including multi-agent systems using frameworks like LangChain, LangGraph, and AutoGen.\n\u2022 Collaborate with cross-functional teams to integrate agents with external tools (e.g., GitHub, web UIs). Worked on integrating tools with agent ex., GitHub, ui etc\n\u2022 Work in an agile environment to rapidly prototype and transition MVPs to production. Worked on mvp to production for genai solution\n\u2022 Support and optimize RAG (Retrieval-Augmented Generation) pipelines.\n\u2022 Contribute to prompt engineering strategies and scalable GenAI infrastructure. Experience on prompt engineering and rag setup and support\n\u2022 Leverage Databricks for model development, data preparation, and orchestration. Proficiency in Databricks for ML / AI workflows.",
    "url": "https://in.talent.com/view?id=aa56bd025e37&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Artificial Intelligence & Machine Learning Engineer",
    "company": "confidential",
    "location": "Pune",
    "salary": "",
    "description": "JOB DESCRIPTION\n\nJob Summary:\nAs a Machine Learning Engineer at Emerson, you will be responsible for developing, implementing, and optimizing machine learning models and systems. You will collaborate closely with data scientists, software engineers, and other collaborators to translate data insights into practical, scalable solutions\nDesign, build, and deploy machine learning models and algorithms to solve specific business problems. Optimize models for performance and scalability.\nWork with large data sets to preprocess, clean, and transform data for use in machine learning models. Develop and maintain data pipelines.\nMonitor and evaluate the performance of deployed models, making adjustments and improvements as needed to ensure accuracy and reliability.\nWork with multi-functional teams such as data scientists, analysts, and product managers to understand requirements and deliver machine learning solutions that meet business needs.\nKeep up with the latest research and trends in machine learning and artificial intelligence. Explore and implement new techniques and technologies to enhance model performance.\nDocument model development processes, code, and standard methodologies. Provide clear and comprehensive reports on model performance and metrics\nParticipate in regular Scrum events such as Sprint Planning, Sprint Review, and Sprint Retrospective\nInthisRole,YourResponsibilitiesWill b e:\nDesign, build, and deploy machine learning models and algorithms to solve specific business problems. Optimize models for performance and scalability.\nWork with large data sets to preprocess, clean, and transform data for use in machine learning models. Develop and maintain data pipelines.\nMonitor and evaluate the performance of deployed models, making adjustments and improvements as needed to ensure accuracy and reliability.\nWork with multi-functional teams such as data scientists, analysts, and product managers to understand requirements and deliver machine learning solutions that meet business needs.\nKeep up with the latest research and trends in machine learning and artificial intelligence. Explore and implement new techniques and technologies to enhance model performance.\nDocument model development processes, code, and standard methodologies. Provide clear and comprehensive reports on model performance and metrics\nParticipate in regular Scrum events such as Sprint Planning, Sprint Review, and Sprint Retrospective\nWhoYou Are:\n\nYou quickly and decisively act in constantly evolving, unexpected situations. You adjust communicationcontentandstyletomeettheneedsofdiversepartners.Youalwayskeeptheend in sight puts in extra effort to meet deadlines. You analyze multiple and diverse sources of informationtodefineproblemsaccuratelybeforemovingtosolutions.Youobservesituationaland group dynamics and select best-fit approach.\nForThisRole,YouWill Need:\nBachelor's degree in computer science, Data Science, Statistics, or a related field or a master's degree or higher is preferred.\nMore than 3 years of experience in machine learning engineering or a related role, with a strong track record of developing and deploying machine learning models.\nProficiency in programming languages such as Python or R. Experience with machine learning frameworks (e.g., Go, TensorFlow, PyTorch, scikit-learn).\nExperience with Azure Cognitive services\nExperience with data processing and manipulation tools and libraries (e.g., pandas, NumPy).\nStrong analytical and problem-solving skills, with the ability to handle complex and large-scale data sets.\nExperience with deploying machine learning models to production environments, including knowledge of containerization technologies (e.g., Docker or equivalent) and cloud platforms, Microsoft Azure is preferred\nExcellent verbal and written communication skills, with the ability to explain technical concepts to non-technical collaborators\nPreferredQualificationsthatSetYou Apart:\n\nPrior experience in engineering domain would be nice to have\nPrior experience in working with teams in Scaled Agile Framework (SAFe) is nice to have\nPossession of relevant certification/s in data science from reputed universities specializing in AI.\nFamiliarity with version control systems (e.g., Git) and CI/CD pipelines.\nUnderstanding of standard processes in software development and methodologies.",
    "url": "https://in.jooble.org/rjdp/-6265525461943023084?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Engineer-AI",
    "company": "Sakon",
    "location": "Pune",
    "salary": "",
    "description": "Role: AI Engineer \u2013 Agentic Systems & LLM Applications\n\nAbout the Role:\n\nWe\u2019re looking for a well-rounded, forward-thinking AI Engineer who can design, build, and deploy intelligent systems powered by LLMs, retrieval-augmented generation, and agentic orchestration frameworks. The ideal candidate not only knows how to build modular, reasoning-capable AI tools but can also distill ambiguous product requirements into practical, scalable AI-first solutions.\n\nYou\u2019ll work across the full stack: orchestrating agents, integrating retrieval systems, designing for structured outputs, and deploying models in local or cloud environments. Bonus points if you\u2019ve explored emerging multimodal or agent communication frameworks. Most importantly, you stay current with new AI research and are excited to apply it creatively in real-world settings.\n\nMust-Have Skills\n\n1. LLM Application Development\n\n\u2022 Strong experience with LLM APIs or open-source models (GPT-4, Claude, LLaMA, Mistral)\n\n\u2022 Comfortable with prompt design, structured reasoning patterns (e.g. ReAct, scratchpads), and output validation\n\n\u2022 Built or contributed to LLM-driven apps, assistants, or internal tools\n\n2. Agentic System Design\n\n\u2022 Experience with LangChain, CrewAI, or similar multi-agent orchestration libraries\n\n\u2022 Understands task chaining, tool delegation, memory/state handling, and agent coordination\n\n\u2022 Familiar with emerging design patterns like ReAct, Planner-Executor, and Reflexion\n\n3. Retrieval-Augmented Generation (RAG)\n\n\u2022 Proficient in designing RAG pipelines using vector stores (FAISS, Pinecone, Weaviate)\n\n\u2022 Knows how to retrieve, chunk, and inject relevant context to ground LLM output\n\n\u2022 Able to handle unstructured, semi-structured, and structured knowledge sources\n\n4. Structured Output & Tool Use\n\n\u2022 Experience generating structured outputs using Pydantic, JSON schemas, or custom formats\n\n\u2022 Familiar with tool calling, using LLMs to interact with APIs, calculators, databases, etc.\n\n\u2022 Comfortable validating and parsing outputs for downstream reliability\n\n5. Business & Product Thinking\n\n\u2022 Can translate high-level goals into AI-first system architectures\n\n\u2022 Understands tradeoffs like accuracy vs interpretability or autonomy vs human-in-the-loop\n\n\u2022 Collaborates well with product and design teams to scope and iterate on solutions\n\n6. Research Fluency & Emerging Technologies\n\n\u2022 Keeps up with current trends in LLM research, open-source models, and deployment tools\n\n\u2022 Familiarity with Model Context Protocol (MCP) or similar innovations is a plus\n\n\u2022 Reads new papers, explores tools (Hugging Face, Papers with Code), and experiments frequently\n\nGood to have:\n\n\u2022 Multimodal model experience (e.g., GPT-4V, LLaVA, OCR, visual grounding tasks)\n\n\u2022 Experience with local LLM deployment using tools like vLLM, Ollama, or quantized GGUF models\n\n\u2022 Exposure to fine-tuning or alignment techniques (LoRA, PEFT, RLHF)\n\n\u2022 Backend knowledge with FastAPI, Flask, LangServe\n\n\u2022 Prototyping in Streamlit, Gradio, or notebooks for quick internal demos\n\n\u2022 Cloud deployment familiarity (AWS, GCP, Azure)\n\n\u2022 Awareness of hallucination mitigation, evaluation, and monitoring techniques\n\nIf Interested, please share updated resume with anuradha.dhal@sakon.com",
    "url": "https://in.linkedin.com/jobs/view/engineer-ai-at-sakon-4319259790?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Data AI Engineering Senior Associate",
    "company": "MSCI",
    "location": "Pune",
    "salary": "",
    "description": "Your Team Responsibilities\n\nThe AI Engineering team at MSCI is seeking a Senior Associate to help build and scale our internal platform for deploying intelligent agents. This platform enables developers and non-technical teams to quickly build, test, and deploy agents that interact with internal APIs and data while respecting entitlements and data boundaries.\n\nYou will work in close collaboration with engineers across cloud infrastructure, ML ops, and security to ensure the agent platform is robust, flexible, and easy to use. This role requires a passion for platform usability, developer experience, and pragmatic engineering in cross-cloud (Azure + GCP) environments.\n\nYour Key Responsibilities\n\u2022 Implement and improve internal tooling and runtimes for deploying agent-based applications across MSCI teams.\n\u2022 Integrate entitlement and data-privacy policies into AI workflows using internal security and identity layers.\n\u2022 Develop reusable libraries and interfaces for agents to interact with MSCI services via MCP and additional integrations.\n\u2022 Collaborate with UX and internal client teams to build low-friction, high-compliance agent deployment pathways.\n\u2022 Contribute to observability, sandboxing, and monitoring capabilities for agent executions and workflows.\n\nYour skills and experience that will help you excel\n\u2022 Strong experience building platforms or tooling used by other engineers, ideally in agentic or ML-enabled systems.\n\u2022 Proficient in Python, Typescript, or Go, with experience deploying apps or services in Azure and/or GCP.\n\u2022 Understanding of prompt engineering, LLM orchestration tools (e.g., LangChain, google ADK), and multi-agent patterns.\n\u2022 Familiarity with RBAC, authentication standards (OAuth, SAML), and entitlements in enterprise systems.\n\u2022 Enthusiastic about developer productivity and the impact of well-designed internal platforms.\n\nAbout MSCI\n\nWhat we offer you\n\u2022 Transparent compensation schemes and comprehensive employee benefits, tailored to your location, ensuring your financial security, health, and overall wellbeing.\n\u2022 Flexible working arrangements, advanced technology, and collaborative workspaces.\n\u2022 A culture of high performance and innovation where we experiment with new ideas and take responsibility for achieving results.\n\u2022 A global network of talented colleagues, who inspire, support, and share their expertise to innovate and deliver for our clients.\n\u2022 Global Orientation program to kickstart your journey, followed by access to our Learning@MSCI platform, LinkedIn Learning Pro and tailored learning opportunities for ongoing skills development.\n\u2022 Multi-directional career paths that offer professional growth and development through new challenges, internal mobility and expanded roles.\n\u2022 We actively nurture an environment that builds a sense of inclusion belonging and connection, including eight Employee Resource Groups. All Abilities, Asian Support Network, Black Leadership Network, Climate Action Network, Hola! MSCI, Pride & Allies, Women in Tech, and Women\u2019s Leadership Forum.\n\nAt MSCI we are passionate about what we do, and we are inspired by our purpose \u2013 to power better investment decisions. You\u2019ll be part of an industry-leading network of creative, curious, and entrepreneurial pioneers. This is a space where you can challenge yourself, set new standards and perform beyond expectations for yourself, our clients, and our industry.\n\nMSCI is a leading provider of critical decision support tools and services for the global investment community. With over 50 years of expertise in research, data, and technology, we power better investment decisions by enabling clients to understand and analyze key drivers of risk and return and confidently build more effective portfolios. We create industry-leading research-enhanced solutions that clients use to gain insight into and improve transparency across the investment process.\n\nMSCI Inc. is an equal opportunity employer. It is the policy of the firm to ensure equal employment opportunity without discrimination or harassment on the basis of race, color, religion, creed, age, sex, gender, gender identity, sexual orientation, national origin, citizenship, disability, marital and civil partnership/union status, pregnancy (including unlawful discrimination on the basis of a legally protected parental leave), veteran status, or any other characteristic protected by law. MSCI is also committed to working with and providing reasonable accommodations to individuals with disabilities. If you are an individual with a disability and would like to request a reasonable accommodation for any part of the application process, please email Disability.Assistance@msci.com and indicate the specifics of the assistance needed. Please note, this e-mail is intended only for individuals who are requesting a reasonable workplace accommodation; it is not intended for other inquiries.\n\nTo all recruitment agencies\n\nMSCI does not accept unsolicited CVs/Resumes. Please do not forward CVs/Resumes to any MSCI employee, location, or website. MSCI is not responsible for any fees related to unsolicited CVs/Resumes.\n\nNote on recruitment scams\n\nWe are aware of recruitment scams where fraudsters impersonating MSCI personnel may try and elicit personal information from job seekers. Read our full note on careers.msci.com",
    "url": "https://talentcommunity.msci.com/event-13931/jobs/4056?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-27T00:00:00.000Z"
  },
  {
    "title": "ML Engineer II - Aws, Aws Cloud (Pune)",
    "company": "Peak Hire Solutions",
    "location": "Pune",
    "salary": "",
    "description": "Job Details\n\n- Job Title: ML Engineer II - Aws, Aws Cloud\n\n- Industry: Technology\n\n- Domain - Information technology (IT)\n\n- Experience Required: 6-12 years\n\n- Employment Type: Full Time\n\n- Job Location: Pune\n\n- CTC Range: Best in Industry\n\nJob Description:\n\nCore Responsibilities:\n\n? The MLE will design, build, test, and deploy scalable machine learning systems, optimizing model accuracy and efficiency\n\n? Model Development: Algorithms and architectures span traditional statistical methods to deep learning along with employing LLMs in up-to-date frameworks.\n\n? Data Preparation: Prepare, cleanse, and transform data for model training and evaluation.\n\n? Algorithm Implementation: Implement and optimize machine learning algorithms and statistical models.\n\n? System Integration: Integrate models into existing systems and workflows.\n\n? Model Deployment: Deploy models to production environments and monitor performance.\n\n? Collaboration: Work closely with data scientists, software engineers, and other stakeholders.\n\n? Continuous Improvement: Identify areas for improvement in model performance and systems.\n\nSkills:\n\n? Programming and Software Engineering: Knowledge of software engineering best practices (version control, testing, CI/CD).\n\n? Data Engineering: Ability to handle data pipelines, data cleaning, and feature engineering. Proficiency in SQL for data manipulation + Kafka, Chaossearch logs, etc for troubleshooting; Other tech touch points are ScyllaDB (like BigTable), OpenSearch, Neo4J graph\n\n? Model Deployment and Monitoring: MLOps Experience in deploying ML models to production environments.\n\n? Knowledge of model monitoring and performance evaluation.\n\nRequired experience:\n\n? Amazon SageMaker: Deep understanding of SageMaker's capabilities for building, training, and deploying ML models; understanding of the Sagemaker pipeline with ability to analyze gaps and recommend/implement improvements\n\n? AWS Cloud Infrastructure: Familiarity with S3, EC2, Lambda and using these services in\n\nML workflows\n\n? AWS data: Redshift, Glue\n\n? Containerization and Orchestration: Understanding of Docker and Kubernetes, and their implementation within AWS (EKS, ECS)\n\nSkills: Aws, Aws Cloud, Amazon Redshift, Eks\n\nMust-Haves\n\nAws, Aws Cloud, Amazon Redshift, Eks\n\nNP: Immediate \u2013 30 Days\n\nSkills:- Amazon Web Services (AWS), AWS CloudFormation, Amazon Redshift, Elastic Search, ECS, Docker, Kubernetes, Machine Learning (ML), MLOps, Neo4J, SQL, Algorithms, Architecture, Statistical Modeling, Large Language Models (LLM) and Deep Learning",
    "url": "https://in.jobrapido.com/jobpreview/6078549723050934272?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "AI Solutions Lead",
    "company": "Syngenta",
    "location": "Pune",
    "salary": "",
    "description": "The AI Solutions Lead will be responsible for:\n\u2022 Architectural Leadership: Leading the design and architecture of AI solutions, ensuring scalability, maintainability, and optimal performance.\n\u2022 Technical Guidance: Collaborating with development teams to understand requirements and provide expert architectural guidance and support.\n\u2022 Business Alignment: Working closely with Product and Business stakeholders to understand their needs and ensure the AI platform effectively meets user requirements.\n\u2022 Cross-functional Collaboration: Partnering with cross-functional stakeholders to translate complex business requirements into robust technical solutions.\n\u2022 Solution Definition: Defining clear implementation approaches, algorithms, and code structures for AI solutions.\n\u2022 Successful Solution Delivery: Taking ultimate accountability for the successful end-to-end delivery of AI solutions, ensuring they are implemented, deployed, and operationalized effectively, meet defined business objectives, adhere to architectural designs and quality standards, and are delivered within project timelines.\n\u2022 Technology Scouting: Staying abreast of the latest trends and emerging technologies in the AI space, evaluating their potential impact, and recommending their introduction into Syngenta's ecosystem.\n\u2022 Experience Architecture: Defining, prototyping, and recommending technology solutions, detailing implementation designs, and identifying interfaces for integration with other products.\n\nCompany Description\n\nJoin Syngenta Group, a leader in agricultural innovation where technology meets purpose. As digital pioneers in AgTech, we're integrating AI across our value chain from smart breeding to precision agriculture. Our global team of 56,000 professionals is transforming sustainable farming worldwide. At Syngenta IT & Digital, your expertise will directly impact food security and shape the future of agriculture through cutting-edge technology.\n\nQualifications\n\u2022 Education:\n\u2022 Degree in Computer Science, AI, ML, Data Science, Engineering, or a related field.\n\u2022 Experience:\n\u2022 4+ years of progressive experience in designing, architecting, and leading the end-to-end delivery of complex AI/ML solutions in a cloud environment.\n\u2022 Demonstrated expertise in AI/ML solution architecture, including model development, deployment, MLOps (Machine Learning Operations), and scalable data pipelines.\n\u2022 Proven experience with major cloud platforms (e.g., AWS, Azure, GCP) and their AI/ML services, specifically in building and operationalizing AI solutions.\n\u2022 Strong understanding of SQL and NoSQL databases, and experience with data warehousing/data lake concepts relevant to AI/ML workloads.\n\u2022 Experience with SAP fundamentals and SAP Joule, or similar enterprise resource planning (ERP) systems, particularly concerning data integration for AI solutions.\n\u2022 Track record of successfully leading technical teams or projects, demonstrating strong project delivery capabilities.\n\u2022 Skills:\n\u2022 Deep technical expertise in AI/ML concepts, algorithms, and frameworks.\n\u2022 Proficiency in programming languages commonly used in AI/ML (e.g., Python, R, Java) for development, prototyping, and integration.\n\u2022 Strong architectural design skills for building scalable, robust, and maintainable AI systems that meet performance and security requirements.\n\u2022 Excellent analytical, critical thinking, and complex problem-solving abilities, with a proven capacity to translate complex business challenges into effective AI solutions.\n\u2022 Exceptional communication, presentation, and stakeholder management skills, with the ability to articulate complex technical concepts clearly to diverse audiences (technical and non-technical).\n\u2022 Ability to lead, mentor, and collaborate effectively within cross-functional and agile teams.\n\u2022 Demonstrated ability to prototype, evaluate, and recommend new technologies and innovative AI solutions, aligning with strategic business objectives.\n\nCritical success factors & key challenges\n\u2022 Solution Design Excellence: Demonstrating strong solution design, logical thinking, and reasoning skills.\n\u2022 Prototyping & Evaluation: Ability to deliver Proofs of Concept (POCs) and Minimum Viable Products (MVPs), and conduct technology evaluations using design thinking practices.\n\u2022 Strategic Prioritization: Orchestrating efforts to prioritize business initiatives across complex and evolving change agendas.\n\u2022 Stakeholder Management: Excellent communication and stakeholder management skills, including the ability to explain complex technical information to non-technical audiences.\n\u2022 Problem Solving & Decision Making: Strong capabilities in problem-solving and decision-making.\n\u2022 Team Leadership: Proven teamwork, team management, and leadership skills.\n\nAdditional Information\n\nWe are a leading, science-based agriculture company, empowering farmers to meet the demands of modern agriculture. Using cutting-edge innovation, we help farmers to grow resilient, healthy crops that can feed a growing global population, while promoting sustainable farming practices that protect and enhance our planet. Headquartered in Switzerland, we are a global agritech leader with more than 30,000 employees across over 90 countries.\n\nhttps://www.syngenta.com/company",
    "url": "https://jobs.syngenta.com/job/ai-solutions-lead-in-in-pune-jid-15234?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Sr Data Scientist",
    "company": "Birlasoft Limited",
    "location": "Pune",
    "salary": "",
    "description": "Area(s) of responsibility\n\nData Scientist experience (8 to 10) - 5B\n\n5 years of relevant work experience as a data scientist\n\nExperience designing and building statistical forecasting models.\n\nExperience in Python, AWS Cloud Services SageMaker,Comprehend, Amazon Bedrock for generative AI and Open AI\n\nExperience designing and building machine learning models.\n\nLead the end-to-end development of AI/ML solutions, from problem definition to production deployment.\n\nStrong programming skills in Python and experience with libraries like TensorFlow, PyTorch, Scikit-learn.\n\nMinimum 2 years of experience in Azure Cloud using Natural Language API\n\nExperience designing and building statistical forecasting models.\n\nExperience in Ingesting data from API and Databases\n\nExperience designing and building machine learning models.\n\nHands-on experience with LLMs and GenAI frameworks\n\nExperience in Django, Flask web frameworks\n\nExperience designing and building optimization models., including expertise with statistical data analysis\n\nMandatory Skillset: Python, AWS Cloud Services SageMaker, Comprehend, Amazon Bedrock for generative AI and Open AI",
    "url": "https://jobs.birlasoft.com/job/Pune-Sr-Data-Scientist-INDI/45605844/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Senior Data Scientist (Artificial Intelligence Machine Learning)",
    "company": "FIS Global",
    "location": "Pune",
    "salary": "",
    "description": "Position Type :\n\nFull time\n\nType Of Hire :\n\nExperienced (relevant combo of work and education)\n\nEducation Desired :\n\nBachelor of Engineering\n\nTravel Percentage :\n\n1 - 5%\n\nSenior Data Scientist (Artificial Intelligence Machine Learning)\n\nAre you curious, motivated, and forward-thinking? At FIS you\u2019ll have the opportunity to work on some of the most challenging and relevant issues in financial services and technology. Our talented people empower us, and we believe in being part of a team that is open, collaborative, entrepreneurial, passionate and above all fun.\n\nAbout the role:\n\u2022 We are looking for a talented and passionate Data Scientist willing to challenge themself and produce best in class AI enabled solution\n\u2022 You will be required to use the concepts of AIML, GenAI, LLMs, Sentiment analysis, etc.\n\u2022 The role requires creating correlation between different data points and do predictive, preventive analysis.\n\nAbout the Team :\n\nTeam provide solutions and services that help our clients grow, compete, and optimize their business. Our AIOPS team is creating AIML solution targeted to reduce the Enterprise MTTR through our world class product\n\nWhat you will be doing:\n\u2022 Employ machine learning and statistical modeling to create and enhance data driven products.\n\u2022 Analyze and extract insights from internal and external data.\n\u2022 Work with Big Data and transform complex datasets into more usable formats.\n\u2022 Work with a variety of data science tools and programming languages such as SAS, Python, R, Scala, SQL. Work independently and collaborate with other groups to solve complex problems.\n\u2022 Create and present analyses to internal and external partners and clients.\n\u2022 Will be working in 2 Pm to 11 Pm IST Shifts\n\nWhat you bring:\n\u2022 4 to 6 Years of machine learning, artificial intelligence, statistical modeling, data visualization, and data analysis\n\u2022 Proficient in data science tools and programming languages such as SAS, Python, R, Scala, SQL\n\u2022 Relevant degree in Artificial Intelligence Machine Learning\n\u2022 Experience or knowledge of cloud-based technology\n\u2022 Knowledge of financial services industry\n\nWhat we offer you:\n\u2022 A range of benefits designed to help support your lifestyle and wellbeing.\n\u2022 A multi-faceted job with a broad spectrum of responsibilities\n\u2022 A modern international work environment and a dedicated and innovative team\n\u2022 A broad range of professional education and personal development possibilities \u2013 FIS is your final career step.\n\nPrivacy Statement\n\nFIS is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how FIS protects personal information online, please see the Online Privacy Notice.\n\nSourcing Model\n\nRecruitment at FIS works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. FIS does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company.\n\n#pridepass",
    "url": "https://www.glassdoor.co.in/job-listing/senior-data-scientist-artificial-intelligence-machine-learning-fis-global-JV_IC2856202_KO0,62_KE63,73.htm?jl=1009714190836&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Machine Learning Engineer (MLE) \u2013 Python | DS | DE | ETL | Azure | Databricks",
    "company": "Apptware",
    "location": "Pune",
    "salary": "",
    "description": "Job description\n\nPosition: Machine Learning Engineer (MLE) \u2013 Python | DS | DE | ETL | Azure | Databricks\n\n\ud83d\udd39 Experience: 4\u20138 years\n\n\ud83d\udd39 Location: Pune / Bangalore\n\n\ud83d\udd39 Employment Type: Full-time\n\nJob Description:\n\nWe are seeking an experienced Machine Learning Engineer (MLE) with strong expertise in Python, Data Science (DS), Data Engineering (DE), ETL, and Azure Databricks. The ideal candidate will design, build, and deploy scalable ML solutions while collaborating with data and engineering teams to solve complex business challenges.\n\nKey Responsibilities:\n\u2022 Design and implement end-to-end ML pipelines using Databricks and Azure.\n\u2022 Develop, train, and deploy machine learning models for various business use cases.\n\u2022 Perform data preprocessing, feature engineering, and model optimization on large datasets.\n\u2022 Integrate ML models with production systems and ensure performance monitoring.\n\u2022 Collaborate with cross-functional teams to understand business needs and deliver effective ML solutions.\n\u2022 Stay updated with the latest trends in ML, DL, and AI frameworks.\n\nRequired Skills:\n\u2022 Python (Advanced) \u2013 Must\n\u2022 Data Science (DS), Data Engineering (DE), and ETL \u2013 Must\n\u2022 Machine Learning (ML) \u2013 Must\n\u2022 Deep Learning (Basic Understanding) \u2013 Good to have\n\u2022 Natural Language Processing (NLP) \u2013 Basic Understanding\n\u2022 Computer Vision \u2013 Basic Understanding\n\u2022 Python for Image Processing \u2013 Basic Understanding\n\u2022 ML Frameworks (TensorFlow / PyTorch / Scikit-learn) \u2013 Must\n\u2022 Azure Cloud \u2013 Must\n\u2022 Databricks \u2013 Must\n\nGood to Have:\n\u2022 Experience with Agile Methodology\n\u2022 Exposure to MLOps and CI/CD pipelines\n\u2022 Familiarity with data visualization tools like Power BI or Tableau\n\nAdditional Details:\n\u2022 Immediate joiners preferred\n\u2022 Candidates with up to 30 days\u2019 notice period can be considered\n\nApply Here: https://forms.gle/PNgXBb3QJh57Uqd79",
    "url": "https://in.linkedin.com/jobs/view/machine-learning-engineer-mle-%E2%80%93-python-ds-de-etl-azure-databricks-at-apptware-4331708651?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Enterprise Data Analyst",
    "company": "Snowflake",
    "location": "Pune",
    "salary": "",
    "description": "Snowflake is about empowering enterprises to achieve their full potential \u2014 and people too. With a culture that\u2019s all in on impact, innovation, and collaboration, Snowflake is the sweet spot for building big, moving fast, and taking technology \u2014 and careers \u2014 to the next level.\n\nSnowflake is seeking a Data Scientist to join our expanding Enterprise AI & ML team. This role involves working on diverse AI/ML and data science initiatives, utilizing Snowflake's Data Cloud and Cortex AI. The successful candidate will design and develop scalable data science and machine learning solutions, build interactive AI applications, and collaborate on operationalizing intelligent systems to enhance data-driven decision-making throughout the company. This position focuses on applying data science, AI & ML skill sets to various domain specific business data problems across Snowflake.\n\nON THE DATA SCIENCE & ANALYTICS TEAM AT SNOWFLAKE, YOU WILL:\n\u2022 Design, prototype, and deploy data science and AI solutions.\n\u2022 Conduct end to end experimentation, including data exploration, feature engineering, model development, and validation.\n\u2022 Build and maintain Streamlit applications to visualize models, showcase insights, and enable business stakeholders to interact with AI driven solutions.\n\u2022 Develop and optimize LLM based applications, workflows, and operations; with a focus on retrieval, generation, semantic understanding and fine-tuning.\n\u2022 Partner cross functionally with data engineers, analysts, and product teams to translate ambiguous business problems into measurable outcomes.\n\nOUR IDEAL CANDIDATE WILL HAVE:\n\u2022 2 to 4 years of experience applying data science, machine learning, or AI techniques in real world business settings.\n\u2022 Strong programming skills in Python, proficiency in SQL for large scale data manipulation.\n\u2022 Familiarity with frameworks such as scikit-learn, XGBoost etc.\n\u2022 Understanding of LLM architectures, embeddings, vector search, and RAG pipelines.\n\u2022 Experience working on cloud platforms.\n\u2022 Strong analytical, storytelling, and communication skills to translate technical insights into actionable recommendations.\n\u2022 A mindset of curiosity, ownership, and collaboration, with an eagerness to work on open-ended problems.\n\u2022 Experience operationalizing AI & ML models in a production setting.\n\nSnowflake is growing fast, and we\u2019re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.\n\nHow do you want to make your impact?\n\nFor jobs located in the United States, please visit the job posting on the Snowflake Careers Site for salary and benefits information: careers.snowflake.com",
    "url": "https://builtin.com/job/enterprise-data-analyst/7508278?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "TechVerito Software Solutions - Senior Data Scientist - Machine Learning/Artificial Intelligence (Pune)",
    "company": "TechVerito",
    "location": "Pune",
    "salary": "",
    "description": "Description :\nAbout the Role\nWe are looking for a Senior Data Scientist to lead the development and deployment of machine learning models that drive key business decisions.\nYou will translate complex business problems into actionable ML solutions, from experimentation to production.\nKey Responsibilities :\n- Lead end-to-end development of Machine Learning models for areas such as prediction, classification, and recommendation.\n- Design, implement, and validate models using rigorous statistical methods and ML best practices.\n- Develop robust ETL/ELT pipelines to ensure high-quality data for model training and inference.\n- Collaborate with Data Engineering and DevOps teams to productionize models and monitor their performance in a live setting.\n- Communicate complex analytical insights and model outcomes to technical and non-technical stakeholders.\n- Research and apply cutting-edge techniques in the fields of AI, Deep Learning, and NLP.\nTechnical Skills Required :\n- Languages: Expert proficiency in Python (NumPy, Pandas, SciPy, Scikit-learn).\n- ML/DL Frameworks: Hands-on experience with TensorFlow or PyTorch.\n- Big Data: Experience with SQL and distributed processing frameworks like Spark (PySpark).\n- Cloud & MLOps: Familiarity with deploying and managing models on cloud platforms (AWS SageMaker, Azure ML, or GCP AI Platform).\nKnowledge of MLOps tools (e., MLflow, Kubeflow) is highly desirable.\n- Statistics: Strong foundation in statistics, probability, and experimental design (A/B testing).\nQualifications :\n- Master's or Ph. in Computer Science, Statistics, Mathematics, or a related quantitative field.\n- 4+ years of hands-on experience in a Data Scientist role, with a focus on building and deploying ML models\n\n(ref:hirist.tech)",
    "url": "https://in.jobrapido.com/jobpreview/8149968057129762816?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Industry Consultant - Manufacturing + Data Science",
    "company": "Khoobi Consulting",
    "location": "IN",
    "salary": "",
    "description": "Responsibility:\n\n- Help customers identify opportunities of monetizing their data assets to drive growth and profitability.\n\n- Understand customer's engineering, supply chain and production planning requirements and design digital solutions for customers that have AI and AI-Agents embedded in them.\n\n- Act as a bridge between customer business stakeholders and development teams comprising of Data Scientists and Solution Architects.\n\n- Publish Whitepapers on topics covering application of AI to solve domain specific issues and drive growth in the industry.\n\nEssential Skills:\n\n- Ability to manage senior customer stakeholders.\n\n- Ability to help customers understand how Industry 4.0 practices can be applied in their environment.\n\n- Ability to lead requirement gathering and solutioning workshops with customers.\n\n- Ability to understand the latest development in AI research and relate them to areas where they can be applied.\n\nExperience:\n\n- Overall 15 20 years.\n\nDomain:\n\n- Minimum 10 years in Manufacturing (Production Planning, Maintenance, Automation, Control Systems, Supply Chain).\n\n- Preferred Experience in Actual Automation and Control Systems experience preferred.\n\nTechnical: Minimum 5 years in Control Systems data, Digital Applications implementation.\n\nKnowledge:\n\n- Strong in applying Statistics knowledge.\n\n- Machine Learning / Deep Learning / LLM / Agents.\n\nQualifications.\n\n- Masters or Bachelor's degree in Computer Science, Engineering or related field.\n\nWorking Arrangements.\n\n- 100% work from office.",
    "url": "https://www.iimjobs.com/j/industry-consultant-manufacturing-data-science-1632852?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Science Instructor",
    "company": "Itvedant Education Pvt. Ltd.",
    "location": "Pune",
    "salary": "",
    "description": "Responsibilities:\n\n\u25cf Conducting classroom and online lectures on programming languages (Data Science, Python,\n\nData Analytics) and related technologies to students\n\n\u25cf Assigning and evaluating coursework, quizzes, and projects\n\n\u25cf Providing one-on-one assistance and mentoring to students as required\n\n\u25cf Ensuring that the course curriculum is up-to-date and relevant to industry standards\n\n\u25cf Collaborating with other trainers and course developers to develop new training materials\n\n\u25cf Maintaining accurate student records and progress reports\n\n\u25cf Creating a positive and engaging learning environment for students\n\n\u25cf Participating in faculty meetings, staff development programs, and other professional\n\ndevelopment activities as required\n\n\u25cf Staying up-to-date with the latest trends and developments and related technologies\n\nRequirements:\n\n\u25cf A Bachelor's or Master's degree in Computer Science or a related field\n\n\u25cf A minimum of 1 years of experience as a trainer\n\n\u25cf Excellent communication and interpersonal skills\n\n\u25cf Strong knowledge of Python, Machine Learning, Data Science, Data Analytics, Deep\n\nLearning, NLP and related technologies\n\n\u25cf Experience working with databases such as PostgreSQL and MySQL\n\n\u25cf A passion for teaching and helping students achieve their career goals\n\n\u25cf Ability to work independently as well as in a team environment",
    "url": "https://in.linkedin.com/jobs/view/data-science-instructor-at-itvedant-education-pvt-ltd-4320264933?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Business Sales Head- Data Science",
    "company": "Cinecraft",
    "location": "Pune",
    "salary": "",
    "description": "Position: Business Head \u2013 Data Science\n\nLocation: Pune, Maharashtra\nInstitute: Cinecraft Digital Academy\n\nAbout the Role:\nWe are seeking a dynamic and experienced Business Head \u2013 Data Science to lead our Data Science, AI, and Analytics division. The ideal candidate will drive business growth, oversee academic excellence, and build strong industry partnerships to strengthen our position as a leading digital education brand.\n\nKey Responsibilities:\n\nAchieve admission and revenue targets for Data Science & AI programs.\nLead academic planning, curriculum upgrades, and faculty management.\nCollaborate with marketing for lead generation and brand building.\nDevelop industry tie-ups for placements, projects, and internships.\nManage team performance and ensure smooth operations.\nStay updated with market trends and identify new course opportunities.\n\nRequirements:\n\nGraduate/Postgraduate in Data Science, Computer Science, or Business/ MBA.\n3+ years of experience in education management, EdTech, or training industry working towards admissions.\nStrong knowledge of Data Science, AI, and analytics ecosystem.\n\nExcellent leadership, communication, and business development skills.\n\nWhat We Offer:\nCompetitive salary with performance incentives.\nGrowth-driven, creative work environment.\nOpportunity to lead an expanding digital education brand.\n\nMore about this Business Sales Head- Data Science job\n\nCinecraft is aggressively hiring for the job profile of Business Sales Head- Data Science at Pune in Pawar Quarter (Hotel Raviraj) locality. Kindly go through the FAQs below to get all answers related to the given job.\n\n1. How much salary can I expect as a Business Sales Head- Data Science in Cinecraft in Pune?\n\nAns. You can expect a minimum salary of 40,000 INR and can go up to 60,000 INR. The salary offered will depend on your skills, experience and performance in the interview.\n\n2. What is the eligibility criteria to apply for Business Sales Head- Data Science in Cinecraft in Pune?\n\nAns. The candidate should have completed Graduate degree and people who have 3 to 31 years are eligible to apply for this job. You can apply for more jobs in Pune to get hired quickly.\n\n3. Is there any specific skill required for this job?\n\nAns. The candidate should have Good (Intermediate / Advanced) English skills and sound communication skills for this job.\n\n4. Who can apply for this job?\n\nAns. Only Male candidates can apply for this job.\n\n5. Is it a work from home job?\n\nAns. No, it\u2019s not a work from home job and can\u2019t be done online. You can explore and apply for other work from home jobs in Pune at apna.\n\n6. Are there any charges or deposits required while applying for the role or while joining?\n\nAns. No work-related deposit needs to be made during your employment with the company.\n\n7. How can I apply for this job?\n\nAns. Go to the apna app and apply for this job. Click on the apply button and call HR directly to schedule your interview.\n\n8. What is the last date to apply?\n\nAns. The last date to apply for this job is 12-Nov-2025.\n\nFor more details, download apna app and find Full Time jobs in Pune. Through apna, you can find jobs in 74 cities across India. Join NOW!",
    "url": "https://apna.co/job/pune/business-sales-head-data-science-879117150?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "AI ML Python data science trainer",
    "company": "myinternship.in",
    "location": "Pune",
    "salary": "",
    "description": "Looking for an experienced AI, ML, Data Science & Analytics Trainer to deliver engaging, hands-on sessions covering Python, Machine Learning, and Power BI.\nShould have strong practical knowledge, real-world project exposure, and passion for teaching.\nResponsible for curriculum delivery, student mentoring, and guiding on live projects.\n\nJob Type: Full-time\n\nWork Location: In person",
    "url": "https://www.glassdoor.co.in/job-listing/ai-ml-python-data-science-trainer-myinternship-in-JV_IC2856202_KO0,33_KE34,49.htm?jl=1009923636335&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "AIML (Data Scientist)",
    "company": "WOW Softech",
    "location": "Pune",
    "salary": "",
    "description": "Role & responsibilities\n\nData Scientist,\n\u2022 At least 4+ years of significant experience in data Science, developing video analytics/image processing software\n\u2022 Knowledge required on- ffmpeg, Deep Learning and Deep Stream SDK using Nvidia Jetson Nano\n\u2022 Demonstrated ability in troubleshooting and hardware/software trade-offs\n\nPreferred candidate profile",
    "url": "https://in.bebee.com/job/242610eeb2baec709223c052a199eb7e?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Machine Learning Engineer (MLE) \u2013 Python | DS | DE | ETL | Azure | Databricks",
    "company": "Apptware",
    "location": "Pune",
    "salary": "",
    "description": "Job description\n\nPosition: Machine Learning Engineer (MLE) \u2013 Python | DS | DE | ETL | Azure | Databricks\n\n\ud83d\udd39 Experience: 4\u20138 years\n\n\ud83d\udd39 Location: Pune / Bangalore\n\n\ud83d\udd39 Employment Type: Full-time\n\nJob Description:\n\nWe are seeking an experienced Machine Learning Engineer (MLE) with strong expertise in Python, Data Science (DS), Data Engineering (DE), ETL, and Azure Databricks. The ideal candidate will design, build, and deploy scalable ML solutions while collaborating with data and engineering teams to solve complex business challenges.\n\nKey Responsibilities:\n\u2022 Design and implement end-to-end ML pipelines using Databricks and Azure.\n\u2022 Develop, train, and deploy machine learning models for various business use cases.\n\u2022 Perform data preprocessing, feature engineering, and model optimization on large datasets.\n\u2022 Integrate ML models with production systems and ensure performance monitoring.\n\u2022 Collaborate with cross-functional teams to understand business needs and deliver effective ML solutions.\n\u2022 Stay updated with the latest trends in ML, DL, and AI frameworks.\n\nRequired Skills:\n\u2022 Python (Advanced) \u2013 Must\n\u2022 Data Science (DS), Data Engineering (DE), and ETL \u2013 Must\n\u2022 Machine Learning (ML) \u2013 Must\n\u2022 Deep Learning (Basic Understanding) \u2013 Good to have\n\u2022 Natural Language Processing (NLP) \u2013 Basic Understanding\n\u2022 Computer Vision \u2013 Basic Understanding\n\u2022 Python for Image Processing \u2013 Basic Understanding\n\u2022 ML Frameworks (TensorFlow / PyTorch / Scikit-learn) \u2013 Must\n\u2022 Azure Cloud \u2013 Must\n\u2022 Databricks \u2013 Must\n\nGood to Have:\n\u2022 Experience with Agile Methodology\n\u2022 Exposure to MLOps and CI/CD pipelines\n\u2022 Familiarity with data visualization tools like Power BI or Tableau\n\nAdditional Details:\n\u2022 Immediate joiners preferred\n\u2022 Candidates with up to 30 days\u2019 notice period can be considered\n\nApply Here: https://forms.gle/PNgXBb3QJh57Uqd79",
    "url": "https://in.linkedin.com/jobs/view/machine-learning-engineer-mle-%E2%80%93-python-ds-de-etl-azure-databricks-at-apptware-4331708651?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "AI/ML Engineer-Automotive",
    "company": "Quest Global",
    "location": "Pune",
    "salary": "",
    "description": "Job Requirements\n\nWe are looking for an experienced AI/ML Engineer to design, develop and deploy machine learning algorithms on embedded platforms for the next generation automotive infotainment systems. This engineer will work on Android / Linux based applications that will process various sensor data and external input at real-time to predict various vehicle conditions and adjust vehicle operations accordingly.\n\nRoles & Responsibilities\n\u2022 Design, train, and optimize AI/ML models for real-time, edge-based deployment.\n\u2022 Work with multi-modal data sources (audio, vision, sensor, telematics) to build robust AI systems.\n\u2022 Develop end-to-end pipelines for data preprocessing, model training, evaluation, and deployment.\n\u2022 Implement algorithms optimized for embedded and resource-constrained platforms\n\u2022 Validate AI models with real-world automotive sensor datasets\n\u2022 Perform model optimization (quantization, pruning) for deployment on embedded SoCs\n\u2022 Collaborate with system architects, Application developers, and automotive domain experts to ensure end-to-end functionality\n\u2022 Stay up to date with AI/ML advancements and automotive industry trends\n\nWork Experience\n\nRequired Skills (Technical Competency):\n\u2022 4\u20135 years of proven development experience in AI/ML for embedded device\n\u2022 Strong expertise in deep learning frameworks (TensorFlow, PyTorch, ONNX).\n\u2022 Practical experience with edge/embedded AI (NVIDIA Jetson, Qualcomm, ARM).\n\u2022 Proficiency in NLP / Conversational AI / Speech interfaces ( ASR, TTS )\n\u2022 Solid programming skills in Python and C++/Java for optimization and integration.\n\u2022 Solid understanding of application development in embedded Linux / Android\n\u2022 Familiarity with automotive standards, protocols such as CAN\n\u2022 Good communication skills and great team spirit\n\nDesired Skills\n\u2022 Experience working with embedded Linux, Automotive Android\n\u2022 Knowledge of vehicle data interfaces (CAN, OBD-II, sensors).\n\u2022 Exposure to MLOps pipelines and cloud platforms (AWS/GCP/Azure).",
    "url": "https://in.linkedin.com/jobs/view/ai-ml-engineer-automotive-at-quest-global-4319585096?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "ML Engineer (CB35FT RM 3693)",
    "company": "Source-right",
    "location": "Pune",
    "salary": "",
    "description": "Position: ML Engineer (CB35FT RM 3693)\n\nWork mode : Work From Office\n\nKey Responsibilities\n\nDesign, develop, and maintain data pipelines for large-scale structured and unstructured\n\ndatasets\n\nApply ML/DL techniques for:\n\nCustomer segmentation\n\nAnomaly detection\n\nSales forecasting and pattern analysis\n\nRecommendation engines\n\nFine-tune and deploy machine learning models in production using best practices\n\nDesign, prompt, and integrate LLM-based modules for tasks like summarization, Q&A, and\n\ncode generation\n\nWork on multi-modal LLM tasks involving text, image (CV), and speech (ASR/TTS)\n\nDevelop and expose ML APIs using FastAPI/Docker for integration with other systems\n\nMonitor model performance and retrain/update models as required\n\nCollaborate with frontend/backend developers, data teams, and product managers\n\nRequired Skills & Experience\n\n3\u20135 years of hands-on experience in ML/Data Science/Data Engineering roles\n\nMin 2 years hands on experience in Microsoft SQL (T-SQL) Coding, SPOC, Complex SQL Joins,\n\nData Modelling\n\nProficient in Python, including libraries like pandas, scikit-learn, PyTorch or TensorFlow\n\nExperience in deploying ML models using FastAPI, Docker, and CI/CD pipelines\n\nSolid understanding of data preprocessing, ETL, and feature engineering\n\nExperience with deep learning and LLMs (e.g., OpenAI, HuggingFace, LLaMA, etc.)\n\nPractical experience with prompt engineering and LLM fine-tuning\n\nFamiliarity with multi-modal learning, Computer Vision (e.g., OpenCV, YOLO, CLIP), and Speech\n\nAI (e.g., Whisper, TTS engines)\n\nStrong understanding of ML lifecycle: training, evaluation, monitoring, deployment\n\nExperience with cloud platforms (Azure) is a plus\n\nAbility to write clean, modular, production-grade code\n\u2022 ******************************************************************************************************************************************\n\nJob Category: Others\n\nJob Type: Full Time\n\nJob Location: Pune\n\nExperience: 3 - 5 years\n\nNotice period: 0-30 days",
    "url": "https://www.glassdoor.co.in/job-listing/ml-engineer-cb35ft-rm-3693-source-right-JV_IC2856202_KO0,26_KE27,39.htm?jl=1009926843012&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "Python Data Scientist / ML Engineer \u2013 Remote/Hybrid | AI, ML, Deep Learning | Only 4+ Years of Experience",
    "company": "Remotohire",
    "location": "Pune",
    "salary": "",
    "description": "Company: RemotoHire\n\nWork Mode: Remote / Hybrid\n\nExperience: 4\u20137 years\n\nAbout the Role:\n\nWe are hiring Python Data Scientists & ML Engineers to design and deploy intelligent systems, from predictive analytics to generative AI. You\u2019ll work with global clients on real-world AI/ML problems.\n\nKey Responsibilities:\n\u2022 Build ML models using scikit-learn, TensorFlow, PyTorch.\n\u2022 Work on NLP, Computer Vision, Generative AI, LLMs (GPT, LangChain).\n\u2022 Deploy ML pipelines on AWS SageMaker, Azure ML, GCP Vertex AI.\n\u2022 Handle data preprocessing, feature engineering, big data (Spark, Hadoop).\n\u2022 Optimize models for performance and scalability.\n\nRequired Skills:\n\u2022 Strong in Python, Pandas, NumPy, Matplotlib, Jupyter.\n\u2022 ML frameworks: scikit-learn, TensorFlow, PyTorch.\n\u2022 Cloud ML services: AWS, Azure, GCP.\n\u2022 Knowledge of MLOps, CI/CD for ML pipelines.\n\u2022 Bonus: Experience with AI Agents, RAG pipelines, and vector databases.\n\n\ud83d\udc49 Apply Now: https://www.oxcytech.com/developer-application\n\n\ud83d\udccc Note: While applying, please select \u201cPython Data Science / Machine Learning / AI\u201d from the Main dropdown.",
    "url": "https://in.linkedin.com/jobs/view/python-data-scientist-ml-engineer-%E2%80%93-remote-hybrid-ai-ml-deep-learning-only-4%2B-years-of-experience-at-remotohire-4331723103?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Immediate Start! Generative AI Engineer (Pune)",
    "company": "Synechron",
    "location": "Pune",
    "salary": "",
    "description": "Greetings,\n\nWe have immediate opportunity for AI/ML Engineer \u2013 7 to 10 years\n\nSynechron\u2013 Pune, Hinjewadi\n\nJob Role: AI/ML Engineer\n\nJob Location: Pune, Hinjewadi\n\nAbout Company:\n\nAt Synechron, we believe in the power of digital to transform businesses for the better. Our global consulting firm combines creativity and innovative technology to deliver industry-leading digital solutions. Synechron's progressive technologies and optimization strategies span end-to-end Artificial Intelligence, Consulting, Digital, Cloud & DevOps, Data, and Software Engineering, servicing an array of noteworthy financial services and technology firms. Through research and development initiatives in our FinLabs we develop solutions for modernization, from Artificial Intelligence and Blockchain to Data Science models, Digital Underwriting, mobile-first applications and more. Over the last 20+ years, our company has been honoured with multiple employer awards, recognizing our commitment to our talented teams. With top clients to boast about, Synechron has a global workforce of 14,700+, and has 48 offices in 19 countries within key global markets. For more information on the company, please visit our website or LinkedIn community.\n\nDiversity, Equity, and Inclusion\n\nDiversity & Inclusion are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and an affirmative-action employer. Our Diversity, Equity, and Inclusion (DEI) initiative 'Same Difference' is committed to fostering an inclusive culture \u2013 promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We encourage applicants from across diverse backgrounds, race, ethnicities, religion, age, marital status, gender, sexual orientations, or disabilities to apply. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs, and more.\n\nAll employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant's gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.\n\nJob Description:\n\nWe are seeking a highly skilled AI/ML and GenAI Engineer for around 8-10 yrs with proven experience in designing, developing, and deploying sophisticated AI and NLP solutions. The ideal candidate will have hands-on expertise with large language models (LLMs), foundation models (FMs), and generative AI (GenAI). You will work on building end-to-end AI applications from scratch, transforming monolithic systems into scalable microservices, and integrating with cloud-based AI platforms like Azure, Amazon Bedrock, Gemini, and others.\n\nKey Responsibilities:\n\n- Design, develop, and optimize NLP models, including Large Language Models (LLMs) and Foundation Models (FMs).\n- Lead large data processing pipelines for training, fine-tuning, and deploying models on big data platforms.\n- Architect, build, and maintain scalable AI solutions incorporating MLOps best practices.\n- Transition legacy monolithic architectures into microservices-based systems for improved scalability and maintainability.\n- Build end-to-end AI applications from scratch, including model training, deployment, and integration.\n- Implement and optimize Retrieval-Augmented Generation (RAG) processes for enhanced contextual understanding.\n- Conduct thorough testing, validation, and debugging of AI/ML applications and pipelines.\n- Integrate AI solutions with cloud platforms such as Azure, Amazon Bedrock, Google Gemini, and other emerging frameworks.\n- Develop and maintain flexible, production-ready solutions supporting real-time and batch processing.\n- Collaborate with cross-functional teams to embed AI capabilities into customer-facing products and enterprise solutions.\n\nQualifications & Skills:\n\n- Proven experience in NLP, including transformer-based models, LLMs, and FMs.\n- Understanding of AI/MLOps workflows, CI/CD pipelines, model deployment, and monitoring.\n- Strong background in transforming monolithic architectures into microservices.\n- Experience with building AI applications from scratch, including model training and integrating with GenAI LLMs, tuning, and testing.\n- Expertise in testing/debugging AI applications, pipelines, and data workflows.\n- Practical knowledge of Retrieval-Augmented Generation (RAG) techniques.\n- Familiarity with GenAI, prompt engineering, and interaction with cloud AI platforms like Azure AI, Amazon Bedrock, Google Gemini.\n- Experience with integrating multiple LLM models and APIs for seamless application workflows.\n- Strong programming skills in Python and various AI coding libraries and frameworks.\n- Knowledge of containerization (Docker, Kubernetes) and cloud deployment.\n- Excellent problem-solving, debugging, and communication skills.\n\nQUALIFICATION:\n\nBachelor's or Master's degree in Computer Science, Engineering, or a related field\n\nIf you find this this prospect interesting kindly share your updated profile on bansi.hindocha@synechron.com\n\nWith below details (Mandatory)\n\nTotal Experience\n\nExperience in AI/ML-\n\nCurrent CTC-\n\nExpected CTC-\n\nNotice period-\n\nCurrent Location-\n\nReady to relocate to Pune-\n\nIf you had gone through any interviews in Synechron before? If Yes when\n\nRegards,\n\nBansi Hindocha\n\nbansi.hindocha@synechron.com",
    "url": "https://in.jobrapido.com/jobpreview/7637519772283830272?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "ML Engineer-AI Engineer-Machine Learning",
    "company": "EXL Talent Acquisition Team",
    "location": "Pune",
    "salary": "",
    "description": "We are seeking a skilled MLFlow 3 Engineer to join our Data & AI Engineering team. The ideal candidate will have hands-on experience in managing the end-to-end lifecycle of machine learning models using MLFlow 3.x, along with expertise in Python, Databricks, PySpark, and Azure. The role is a cusp between ML Engineering and MLOPs. You will work closely with data scientists, ML engineers, and DevOps teams to operationalize ML workflows, ensuring scalability, reliability, and compliance.",
    "url": "https://fa-ewjt-saasfaprod1.fa.ocs.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_2/job/5968/?source=jdpreferred.comutm_medium&utm_source=google&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "DevOps Engineer (with AI/ML) - 41778",
    "company": "Fission Labs",
    "location": "Pune",
    "salary": "",
    "description": "Role: DevOps Engineer (With AI/ML)\n\nExperience: 5+ years\n\nLocation: Hyderabad\n\nFission Labs, headquartered in Sunnyvale, with offices in Dallas & Hyderabad, Fission Labs is a leading software development company, specializing in crafting flexible, agile, and scalable solutions that propel businesses forward. With a comprehensive range of services, including product development, cloud engineering, big data analytics, QA, DevOps consulting, and AI/ML solutions, we empower clients to achieve sustainable digital transformation that aligns seamlessly with their business goals.\n\nWhat are we looking for!\n\nWe are seeking an experienced Senior Infrastructure Mgmt. Engineer with expertise in Azure and AWS, coupled with a strong background in AI/ML deployments. The ideal candidate will have a proven track record in designing, implementing, and maintaining scalable and secure cloud infrastructure on Azure and AWS platforms. Experience with GCP is a plus. The primary responsibility will be to lead the DevOps initiatives and ensure compliance with industry standards and regulations.\n\nResponsibilities\n\nLinux Expertise:\n\u2022 Possess in-depth knowledge of Linux operating systems, including CentOS, Ubuntu, and Red Hat, with expertise in shell scripting, package management, and system administration.\n\u2022 Configure and optimize Linux-based servers for performance, security, and resource utilization, including kernel tuning, file system management, and network configuration.\n\nCloud Expertise (AWS/Azure)\n\u2022 Demonstrate hands-on experience with a wide range of AWS and Azure services, including but not limited to EC2, S3, Lambda, RDS, Azure VMs, Azure Blob Storage, Azure Functions, etc.\n\u2022 Architect cloud solutions leveraging best practices and services offered by AWS and Azure, optimizing for scalability, reliability, and cost-effectiveness.\n\u2022 Implement and manage hybrid cloud environments, facilitating seamless integration and interoperability between AWS and Azure services.\n\nInfrastructure As Code (IAC)\n\u2022 Develop and maintain Infrastructure as Code (IAC) templates using tools such as Terraform or AWS CloudFormation, defining infrastructure components as code for automated provisioning and configuration.\n\u2022 Establish version control practices for IAC templates, ensuring traceability, auditability, and reproducibility of infrastructure changes.\n\nAI/ML Infrastructure Mgmt\n\u2022 Experience setting up cloud infrastructure stack, databases, service endpoints, GPU as well as CPU resource scaling, optimization etc.\n\u2022 Should have worked AIOps/MLOP\n\u2022 Should have worked on deploying AI/ML Apps using Docker and Kubernetes\n\u2022 Should have worked on scaling, high availability and reliability tasks for AI application\n\u2022 Should have worked on deploying and maintaining GPU clusters for AI/ML training and inference\n\nQualifications\n\u2022 6+ years of experience in Infrastructure Mgmt. roles, with a focus on cloud platforms (Azure and AWS Preferred).\n\u2022 Hands-on experience with operations (DevSecOps) principles and best practices.\n\u2022 Proficiency in scripting languages such as Python, PowerShell, or Bash.\n\u2022 Excellent communication and collaboration skills.\n\u2022 Certifications such as AWS Solution Architect Associate, AWS Cloud Practitioner, Azure DevOps Engineer Expert, Azure Administrator\n\u2022 Certified Kubernetes Administrator or relevant industry certifications are a plus.\n\nYou would enjoy\n\u2022 Opportunity to work on impactful technical challenges with global reach.\n\u2022 Vast opportunities for self-development, including online university access and knowledge sharing opportunities.\n\u2022 Sponsored Tech Talks & Hackathons to foster innovation and learning.\n\u2022 Generous benefits packages including health insurance, retirement benefits, flexible work hours, and more.\n\u2022 Supportive work environment with forums to explore passions beyond work.\n\nThis role presents a unique opportunity to contribute to the future of impactful business solutions while advancing your career in a collaborative and innovative environment.",
    "url": "https://in.linkedin.com/jobs/view/devops-engineer-with-ai-ml-41778-at-fission-labs-4333145831?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "[Immediate Start] Generative AI Engineer",
    "company": "Vsynergize AI",
    "location": "Pune",
    "salary": "",
    "description": "We are looking for a talented and driven AI Engineer with a strong foundation in Python,\n\nNatural Language Processing, and experience working with Large Language Models (LLMs).\n\nThis is an exciting opportunity to be at the forefront of AI development, working on real-world\n\nproblems involving cutting-edge technologies such as prompt engineering, cloud-based\n\ndeployments, and conversational AI.\n\nKey Responsibilities :\n\u2022 Design, build, and optimize AI models, particularly those leveraging LLMs.\n\u2022 Engineer prompts for effective interaction with foundational models (OpenAI, Claude,\n\netc.).\n\u2022 Develop and integrate APIs for scalable AI-powered solutions.\n\u2022 Deploy backend services and AI models on cloud platforms (AWS, GCP, Azure).\n\u2022 Work on NLP tasks such as text classification, summarization, semantic search, etc.\n\u2022 Collaborate with cross-functional teams to understand business needs and translate\n\nthem into AI solutions.\n\u2022 Ensure model and code quality through testing, performance evaluation, and\n\ndocumentation.\n\u2022 Continuously explore new advancements in AI and contribute to improving internal tools\n\nand workflows.\n\nRequired Skills & Experience :\n\u2022 2+ years of experience in software development with a focus on AI / ML.\n\u2022 Strong proficiency in Python.\n\u2022 Knowledge of frameworks like LangChain, RAG, or vector databases (e.g., FAISS,\n\nPinecone).\n\u2022 Hands-on experience with LLMs, prompt engineering, and NLP techniques.\n\u2022 Familiarity with API development and third-party API integrations.\n\u2022 Experience working with cloud platforms (AWS, Google Cloud, Azure).\n\u2022 Understanding of backend services and deployment best practices.\n\u2022 Solid knowledge of data modeling, with a focus on language data.\n\u2022 Strong problem-solving skills and critical thinking.\n\u2022 Excellent communication and collaboration abilities.\n\nNice to Have\n\u2022 Experience with MLOps tools and practices.\n\u2022 Model deployment and lifecycle management.\n\u2022 Experience building conversational AI tools (chatbots, voice bots, virtual assistants).\n\nWhy Join Us?\n\u2022 Work on innovative AI solutions with real-world impact.\n\u2022 Opportunity to learn and grow in a collaborative, fast-paced environment.\n\u2022 Flexible work culture and supportive team.",
    "url": "https://in.talent.com/view?id=b9d8ee149c5c&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "AI/ML Platform Engineer",
    "company": "Johnson Controls",
    "location": "Pimpri-Chinchwad",
    "salary": "",
    "description": "Job Title: Senior Data Scientist \u2013 Data & Analytics\n\nJohnson Controls International (JCI) is seeking a Senior Data Scientist to join our innovative and impact-driven Data Science and Analytics team. This role is ideal for a seasoned expert with a deep understanding of machine learning, AI, and cloud data platforms, and a strong grasp of the latest advancements in Generative AI and Large Language Models (LLMs).\n\nAs a Senior Data Scientist, you will lead the development and deployment of scalable AI solutions\u2014including those powered by LLMs\u2014to accelerate digital transformation across our products, operations, and customer experiences. You'll play a critical role in shaping JCI\u2019s data science strategy, mentoring teams, and driving the use of AI to deliver measurable business value.\n\nHow You Will Do It\n\nAdvanced Analytics, LLMs & Modeling\n\u2022 Design and implement advanced machine learning models including deep learning, time-series forecasting, recommendation engines, and LLM-based solutions (e.g., GPT, LLaMA, Claude).\n\u2022 Develop use cases around enterprise search, document summarization, conversational AI, and automated knowledge retrieval using large language models.\n\u2022 Fine-tune or prompt-engineer foundation models (e.g., OpenAI, Azure OpenAI, Hugging Face) for domain-specific applications.\n\u2022 Evaluate and optimize LLM performance, latency, cost-effectiveness, and hallucination mitigation strategies for production use.\n\nData Strategy & Engineering Collaboration\n\u2022 Work closely with data and ML engineering teams to integrate LLM-powered applications into scalable, secure, and reliable pipelines.\n\u2022 Contribute to the development of retrieval-augmented generation (RAG) architectures using vector databases (e.g., FAISS, Azure Cognitive Search).\n\u2022 Support the deployment of models using MLOps principles, ensuring robust monitoring and lifecycle management.\n\nBusiness Impact & AI Strategy\n\u2022 Partner with cross-functional stakeholders to identify opportunities for applying LLMs and generative AI to solve complex business challenges.\n\u2022 Lead workshops or proofs-of-concept to demonstrate value of LLM use cases across business units.\n\u2022 Translate complex model outputs, including those from LLMs, into clear insights and decision support tools for non-technical audiences.\n\nThought Leadership & Mentorship\n\u2022 Act as an internal thought leader on AI and LLM innovation, keeping JCI at the forefront of industry advancements.\n\u2022 Mentor and upskill data science team members in advanced AI techniques, including transformer models and generative AI frameworks.\n\u2022 Contribute to strategic roadmaps for generative AI and model governance within the enterprise.\n\nQualifications & Experience\n\u2022 Education in Data Science, Artificial Intelligence, Computer Science, or related quantitative discipline.\n\u2022 5+ years of hands-on experience in data science, including at least 1\u20132 years working with LLMs or generative AI technologies.\n\u2022 Demonstrated success in deploying machine learning and NLP solutions at scale.\n\u2022 Proven experience with cloud AI platforms\u2014especially Azure OpenAI, Azure ML, Hugging Face, or AWS Bedrock.\n\nTechnical Expertise\n\u2022 Proficiency in Python and SQL, including libraries like Transformers (Hugging Face), LangChain, PyTorch, and TensorFlow.\n\u2022 Experience with prompt engineering, fine-tuning, and LLM orchestration tools.\n\u2022 Familiarity with data storage, retrieval systems, and vector databases.\n\u2022 Strong understanding of model evaluation techniques for generative AI, including factuality, relevance, and toxicity metrics.\n\nLeadership & Soft Skills\n\u2022 Strategic thinker with a strong ability to align AI initiatives to business goals.\n\u2022 Excellent communication and storytelling skills, especially in articulating the value of LLMs and advanced analytics.\n\u2022 Strong collaborator with a track record of influencing stakeholders across product, engineering, and executive teams.\n\nPreferred Qualifications\n\u2022 Experience with IoT, edge analytics, or smart building systems.\n\u2022 Familiarity with LLMOps, LangChain, Semantic Kernel, or similar orchestration frameworks.\n\u2022 Knowledge of data privacy and governance considerations specific to LLM usage in enterprise environments.",
    "url": "https://in.linkedin.com/jobs/view/ai-ml-platform-engineer-at-johnson-controls-4324739939?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Ai/ Ml Engineer Pune",
    "company": "Sava Healthcare",
    "location": "Pune",
    "salary": "",
    "description": "Key Responsibilities:\nDesign, build, and deploy AI/ML models for real-world business and manufacturing problems (e.g., predictive maintenance, process optimization, document automation, etc.).\nDevelop end-to-end AI web applications (backend + frontend) using frameworks like Flask, FastAPI, or Django for backend and React, Angular, or Vue for frontend.\nImplement and maintain data pipelines for model training and prediction.\nIntegrate trained models into scalable and user-friendly web interfaces.\nHost, monitor, and maintain AI applications on cloud or on-premise web servers (AWS, Azure, Google Cloud, or companys internal servers).\nCollaborate with IT, QA, and process teams to identify automation and AI opportunities.\nEnsure application security, reliability, and performance optimization.\nDocument model architecture, APIs, and deployment procedures.\n\nRequired Skills & Qualifications:\nBachelor\u2019s or Master\u2019s degree in Computer Science, Data Science, Artificial Intelligence, or related field.\nProven experience in AI/ML development and deployment.\nRobust programming skills in Python (TensorFlow, PyTorch, scikit-learn, OpenCV, etc.).\nProficiency in web frameworks (Flask, Django, FastAPI) and frontend technologies (HTML, CSS, JavaScript, React/Angular preferred).\nExperience in model deployment (Docker, REST API, Flask/FastAPI endpoints).\nFamiliarity with cloud platforms (AWS, Azure, or Google Cloud) and web hosting environments.\nKnowledge of database systems (MySQL, PostgreSQL, MongoDB).\nUnderstanding of version control (Git/GitHub) and CI/CD pipelines.\nRobust analytical thinking, problem-solving, and communication skills.",
    "url": "https://in.jobrapido.com/jobpreview/1449940021648818176?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (Python/ GenAI/ AgenticAI)",
    "company": "Wolters Kluwer",
    "location": "Pune",
    "salary": "",
    "description": "Key Responsibilities\n\nActive Learner with Enthusiasm for Problem-Solving\n\nContinuously learn and apply new AI/ML techniques, including Generative AI, Agentic AI deep learning, and other emerging technologies. Demonstrate a passion for solving complex business challenges and experimenting with novel approaches to improve model performance.\n\nQuick Prototyping & Experimentation\n\nDevelop rapid prototypes to test new AI/GenAI/ML approaches and solutions for business problems. Implement proof-of-concept models quickly, enabling fast experimentation and iteration to assess feasibility before scaling to full development.\n\nSupport AI Product Development & Iteration\n\nCollaborate with lead/ senior data scientists and cross-functional teams to support the design, development, and deployment of AI-driven products. Contribute to the creation of prototypes and refine models based on business needs and feedback.\n\nModel Development and Optimization\n\nDesign, develop, and test machine learning, deep learning, and generative AI models, focusing on performance, scalability, and business relevance. Continuously refine and optimize models based on real-world results and metrics.\n\nData Preparation & Collaboration\n\nAssist in defining data requirements and support data engineers in building data pipelines. Clean and preprocess datasets, ensuring data quality and preparing it for use in machine learning applications. Collaborate closely with engineers to integrate models into production systems.\n\nResearch Support and Knowledge Sharing\n\nStay informed about the latest trends and research in AI/GenAI/ML and generative models, applying this knowledge to current projects. Actively participate in team discussions, contribute to the evaluation of new techniques, and share insights with peers to foster a collaborative learning environment.\n\nEssential Skills\n\u2022 Good knowledge of Python programming language, data engineering and data science ecosystem in Python.\n\u2022 Hands on experience in Generative AI, Agentic AI, LLM and Advance RAG techniques.\n\u2022 Hands on experience in developing and supporting Machine Learning solutions.\n\u2022 Hands on experience in developing Natural Language Processing (NLP) solutions\n\u2022 Hands on experience on SQL ecosystem\n\u2022 Hands on experience on Solr framework with Python\n\u2022 Experience of working on Linux and shell scripting\n\u2022 Basic statistical modelling knowledge\n\u2022 Strong Computer Science fundamentals are must. (Data structures, Algorithms, OS, Databases).\n\u2022 Good communication and organizational skills with significant attention to detail\n\u2022 Experience partnering with cross-functional teams of domain experts, engineers, data scientists, and production support teams.\n\u2022 Strong attention to detail with excellent problem-solving skills.\n\u2022 Desire and ability to thrive in a distributed technical environment while working on multiple projects simultaneously.\n\u2022 Passionate about latest technology trends with a strong desire for innovation.\n\u2022 Self-motivated, self-managing and able to work independently.\n\nEducation And Experience\n\u2022 Bachelor's degree (B.E/ B Tech. computer science, engineering, statistics/mathematics or a related field) from a four-year college or university, or equivalent, master\u2019s a plus.\n\u2022 Total at least 1 years of experience working on enterprise AI products\n\u2022 Experience in supporting software products or applications in the AI ML domain.\n\u2022 The above statements are intended to describe the general nature and level of work being performed by most people assigned to this job. They are not intended to be an exhaustive list of all duties and responsibilities and requirements.\n\nApplicants may be required to appear onsite at a Wolters Kluwer office as part of the recruitment process.",
    "url": "https://in.linkedin.com/jobs/view/data-scientist-python-genai-agenticai-at-wolters-kluwer-4319872554?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Scientist",
    "company": "Snowflake",
    "location": "Pune",
    "salary": "",
    "description": "Snowflake is about empowering enterprises to achieve their full potential \u2014 and people too. With a culture that\u2019s all in on impact, innovation, and collaboration, Snowflake is the sweet spot for building big, moving fast, and taking technology \u2014 and careers \u2014 to the next level.\n\nSnowflake is seeking a Data Scientist to join our expanding Enterprise AI & ML team. This role involves working on diverse AI/ML and data science initiatives, utilizing Snowflake's Data Cloud and Cortex AI. The successful candidate will design and develop scalable data science and machine learning solutions, build interactive AI applications, and collaborate on operationalizing intelligent systems to enhance data-driven decision-making throughout the company. This position focuses on applying data science, AI & ML skill sets to various domain specific business data problems across Snowflake.\n\nON THE ENTERPRISE AI & ML TEAM AT SNOWFLAKE, YOU WILL:\n\u2022 Design, prototype, and deploy data science and AI solutions.\n\u2022 Conduct end to end experimentation, including data exploration, feature engineering, model development, and validation.\n\u2022 Build and maintain Streamlit applications to visualize models, showcase insights, and enable business stakeholders to interact with AI driven solutions.\n\u2022 Develop and optimize LLM based applications, workflows, and operations; with a focus on retrieval, generation, semantic understanding and fine-tuning.\n\u2022 Partner cross functionally with data engineers, analysts, and product teams to translate ambiguous business problems into measurable outcomes.\n\nOUR IDEAL CANDIDATE WILL HAVE:\n\u2022 2 to 4 years of experience applying data science, machine learning, or AI techniques in real world business settings.\n\u2022 Strong programming skills in Python, proficiency in SQL for large scale data manipulation.\n\u2022 Familiarity with frameworks such as scikit-learn, XGBoost etc.\n\u2022 Understanding of LLM architectures, embeddings, vector search, and RAG pipelines.\n\u2022 Experience working on cloud platforms.\n\u2022 Strong analytical, storytelling, and communication skills to translate technical insights into actionable recommendations.\n\u2022 A mindset of curiosity, ownership, and collaboration, with an eagerness to work on open-ended problems.\n\u2022 Experience operationalizing AI & ML models in a production setting.\n\nSnowflake is growing fast, and we\u2019re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.\n\nHow do you want to make your impact?\n\nFor jobs located in the United States, please visit the job posting on the Snowflake Careers Site for salary and benefits information: careers.snowflake.com",
    "url": "https://careers.snowflake.com/us/en/job/SNCOUSE5563EEBE22F4F83ABADA6BD2B014860EXTERNALENUSF7C857F3DD284045B0C758E492307EC3/Data-Scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "\u25b7 (15h Left) Manager, Data Science (Media / Market Research)",
    "company": "NielsenIQ",
    "location": "Pune",
    "salary": "",
    "description": "As a Data Science Manager you will have following key accountabilities :\n\nTeam Leadership : Build and lead a high-performing team of 6-8 Data Scientists and Machine Learning Engineers in our Pune hub. Foster a collaborative and inclusive team culture that encourages innovation and continuous learning.\n\nTechnical Communication : Explain Data Science principles, concepts, algorithms, and approaches in simple terms to diverse audiences, including non-technical stakeholders.\n\nBusiness Understanding : Utilize your solid business understanding to align with stakeholders, discuss requirements and feasibility, and manage expectations effectively. Ensure clear communication and understanding of project goals and outcomes.\n\nEducational Background :\n\nPhD or Master\u2019s degree in Computer Science, Engineering, Statistics, Mathematics, or a related field, with min 8+ years of experience as a Data Scientist.\n\nLeadership Experience :\n\nProven experience as a people manager and / or mentor, with a track record of developing and leading high-performing teams.\n\nLeadership Experience :\n\nProven experience as a people manager and / or mentor, with a track record of developing and leading high-performing teams\n\nCommunication Skills :\n\u2022 Ability to effectively communicate complex methodologies and technologies to both technical and non-technical audiences.\n\u2022 Strong problem-solving skills and an independent working style.\n\nTechnical Expertise :\n\u2022 Strong statistical and machine learning modeling skills, including statistical tests, classification, predictive modeling, handling of missing data, and sampling / weighting techniques.\n\u2022 Solid in analytical programming languages such as Python or R, along with their respective ecosystems.\n\u2022 Hands-on experience implementing these models in production systems.\n\u2022 Proficient in software development skills, including unit testing, CI / CD, and version control with Git, along with familiarity with computer science and engineering fundamentals such as data structures, software design principles, and testing strategies.\n\nPreferred qualifications\n\u2022 Experience in the Media industry\n\u2022 Experience working with cloud-based data services (AWS, Azure, or GCP)\n\u2022 Experience with Optimization techniques such as : linear programming, integer programming, genetic algorithms, constrained optimization is a plus",
    "url": "https://in.talent.com/view?id=9ec995376b19&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Data Scientist  People Data Analytics & Insights",
    "company": "Syngenta",
    "location": "Pune",
    "salary": "",
    "description": "We are seeking a highly analytical and business-focused Data Scientist to join our People Analytics & Insights team. In this role, you will leverage advanced analytics, machine learning, and statistical modeling to uncover insights from workforce data, supporting strategic talent decisions across the organization. You will partner closely with HR, Talent Management, and business leaders to deliver data-driven solutions that enhance employee experience, improve workforce planning, and inform diversity, equity, and inclusion (DEI) strategies.\n\nKey Responsibilities:\n\u2022 Analyze large and complex HR datasets (e.g., engagement, attrition, performance, compensation, hiring) to uncover trends, patterns, and opportunities for business impact.\n\u2022 Build predictive and prescriptive models (e.g., attrition risk, career pathing, workforce segmentation) to support data-informed people strategies.\n\u2022 Translate business problems into analytical questions and communicate findings in clear, actionable terms to non-technical audiences.\n\u2022 Develop visualizations, dashboards, and storytelling tools to enhance insight delivery (e.g., in Tableau, Power BI, Workday Discovery Boards).\n\u2022 Partner with HR stakeholders to identify KPIs, define success metrics, and improve people-related decision-making through data.\n\u2022 Design and implement surveys, experiments (A/B testing), and causal inference models to evaluate the impact of HR programs and initiatives.\n\u2022 Ensure ethical data use and compliance with privacy and governance standards.\n\u2022 Stay current on industry best practices in people analytics, data science, and AI/ML in HR.\n\nCompany Description\n\nAt the Syngenta Group, our 56,000 people across more than 90 countries strive every day to transform agriculture through tailor-made solutions for the benefit of farmers, society and our planet \u2013 making us the world's most local agricultural technology and innovation partner.\n\nWebsite address - https://www.syngentagroup.com/\n\nLI page - https://www.linkedin.com/company/syngentagroup/posts/?feedView=all\n\nQualifications\n\u2022 Bachelor\u2019s or Master\u2019s degree in Data Science, Statistics, Computer Science, Industrial/Organizational Psychology, Economics, or a related field.\n\u2022 3\u20135+ years of experience in data science, analytics, or a similar role, ideally within HR or workforce analytics.\n\u2022 Proficiency in Python or R for statistical analysis and modeling.\n\u2022 Strong SQL skills for data extraction and manipulation.\n\u2022 Experience with data visualization tools (e.g., Tableau, Power BI, Workday Discovery Boards).\n\u2022 Solid understanding of machine learning algorithms, statistical modeling, and hypothesis testing.\n\u2022 Excellent communication skills, with the ability to explain complex analytical concepts to HR and business audiences.\n\u2022 Familiarity with Workday, SAP SuccessFactors, or other HRIS platforms is a plus.\n\nPreferred Skills:\n\u2022 Experience with natural language processing (NLP) on employee feedback or engagement data.\n\u2022 Knowledge of DEI analytics and workforce diversity measurement.\n\u2022 Exposure to cloud-based data platforms (e.g., AWS, GCP, Azure).\n\u2022 Understanding of HR functional areas like talent acquisition, performance management, and learning & development.\n\nKey Competencies:\n\u2022 Analytical Thinking & Problem Solving\n\u2022 Business Acumen & Strategic Mindset\n\u2022 Data Storytelling & Visualization\n\u2022 Collaboration & Stakeholder Management\n\u2022 Data Ethics & Privacy Awareness\n\nAdditional Information\n\nWL: 4A\n\nNote: Syngenta is an Equal Opportunity Employer and does not discriminate in recruitment, hiring, training, promotion or any other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, gender identity, marital or veteran status, disability, or any other legally protected status\n\nFollow us on: Twitter & LinkedIn\n\nhttps://twitter.com/SyngentaAPAC\n\nhttps://www.linkedin.com/company/syngenta/",
    "url": "https://jobs.syngenta.com/job/data-scientist-people-data-analytics-and-insights-in-in-pune-jid-14917?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Lead Data Scientist+ Instructor",
    "company": "Uplers",
    "location": "Pune",
    "salary": "",
    "description": "Experience: 7.00 + years\n\nSalary: Confidential (based on experience)\n\nShift: (GMT+05:30) Asia/Kolkata (IST)\n\nOpportunity Type: Office (Pune)\n\nPlacement Type: Full time Permanent Position\n\n(*Note: This is a requirement for one of Uplers' client - Newton School)\n\nWhat do you need for this opportunity?\n\nMust have skills required:\n\nMachine Learning, NLP, Computer Vision, Statistics, pandas, NumPy, Python\n\nNewton School is Looking for:\n\nAbout Newton:\n\nNewton School of Technology (NST) is a new-age institution redefining technical education in India. Founded by IIT alumni, NST offers a 4-year B.Tech in Computer Science and AI, focused on hands-on learning and deep industry integration. Within two years, over 93% of students have secured paid internships with companies like Razorpay, SarvamAI, and DRDO, along with global exposure through tech treks to Singapore and Silicon Valley. Led by a distinguished faculty comprising ICPC World Finalists and ex-professionals from ISRO, Microsoft, MakeMyTrip, and several other leading tech organisations, NST is building a scalable, high-impact model that produces industry-ready talent for the world\u2019s most advanced technology roles.\n\nAbout the Role:\n\nWe are currently looking for a Data Scientist + Instructor\u2013 AI/ML to join our Computer Science Department. This role is ideal for professionals with substantial industry experience professionals who are passionate about Artificial Intelligence and Machine Learning, and committed to shaping the next generation of tech talent. The position combines hands-on technical expertise with academic responsibilities, including designing and delivering course content, conducting practical lab sessions, and mentoring students in core Data Science and AI/ML concepts. The ideal candidate will also collaborate with academic leaders and industry partners to ensure curriculum relevance, integrate real-world problem-solving, and drive strong learning outcomes.\n\nKey Responsibilities:\n\u2022 Teach Applied AI/ML: Design and deliver practical, project-based courses in AI/ML(Python for ML, Statistics, ML Algorithms, Deep Learning, NLP, CV, ML Ops, GenAI).\n\u2022 Develop Industry-Relevant Curriculum: Help design and update the AI/ML curriculum to reflect current industry tools, techniques, and best practices, incorporating your professional experience and case studies.\n\u2022 Mentor Student Projects: Guide students through hands-on AI/ML projects, providing technical direction, code reviews, and feedback based on industry standards.\n\u2022 Guide & Mentor Students: Advise students on developing practical skills, understanding career paths in AI/ML, and preparing for internships and job placements.\n\u2022 Stay Current: Bring the latest AI/ML research, tools, and industry trends into the classroom.\n\u2022 Collaborate: Work closely with other expert faculty and staff to create a unified and effective learning experience.\n\u2022 Assess Practical Skills: Design and evaluate assignments, projects, and assessments focused on real-world applications.\n\nQualifications and Requirements:\n\u2022 Bachelor\u2019s or Master\u2019s degree in Computer Science, Engineering, Data Science, AI/ML, or related field. (PhD is valued but not mandatory.)\n\u2022 7+ years of direct, hands-on professional experience in the tech industry as an AI/ML Engineer, Data Scientist, Research Scientist, or similar role involving AI/ML development and deployment.\n\u2022 Proven Industry Track Record: Demonstrated experience in building, training, and deploying machine learning models (including deep learning) for real-world problems.\n\u2022 Deep AI/ML Understanding: Strong grasp of core ML algorithms (classical & deep learning \u2013 CNNs, RNNs, Transformers), model evaluation, statistics, and awareness of current research/industry trends.\n\u2022 Passion for Teaching/Mentoring: Ability to explain complex concepts clearly and guide others. Prior mentoring, corporate training, technical workshops, or project supervision experience is highly relevant.\n\nRequired Skills:\n\u2022 Technical: Expert-level Python programming.\n\u2022 Proficiency with data science libraries (Pandas, NumPy, Scikit-learn).\n\u2022 Hands-on experience with ML/DL frameworks (TensorFlow, PyTorch).\n\u2022 Strong SQL and data handling skills.\n\u2022 Understanding of ML Ops practices and tools (Git, Docker, AWS/GCP/Azure).\n\u2022 Knowledge of key AI areas (NLP, Computer Vision, Generative AI/LLMs).\n\u2022 Soft Skills: Strong communication, mentoring ability, collaboration, and a genuine passion for education.\n\nGood-to-Have:\n\u2022 Prior teaching experience at the undergraduate or graduate level.\n\u2022 Familiarity with modern teaching methodologies and academic\n\nHow to apply for this opportunity?\n\u2022 Step 1: Click On Apply! And Register or Login on our portal.\n\u2022 Step 2: Complete the Screening Form & Upload updated Resume\n\u2022 Step 3: Increase your chances to get shortlisted & meet the client for the Interview!\n\nAbout Uplers:\n\nOur goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement.\n\n(Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well).\n\nSo, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you!",
    "url": "https://in.linkedin.com/jobs/view/lead-data-scientist%2B-instructor-at-uplers-4333996105?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T12:00:00.000Z"
  },
  {
    "title": "Data Scientist AI ML Developer",
    "company": "Princenton software services pvt ltd",
    "location": "Pune",
    "salary": "",
    "description": "In this Role, Your Responsibilities Will Be:\n\n\u00b7 Develop, train and deploy machine learning, deep learning AI models for a variety of business use cases such as classification, prediction, recommendation, NLP and Image Processing.\n\n\u00b7 Design and implement end-to-end ML workflows from data ingestion and preprocessing to model deployment and monitoring.\n\n\u00b7 Collect, clean, and preprocess structured and unstructured data from multiple sources using industry-standard techniques such as normalization, feature engineering, dimensionality reduction, and optimization.\n\n\u00b7 Perform exploratory data analysis (EDA) to identify patterns, correlations, and actionable insights.\n\n\u00b7 Apply advanced knowledge of machine learning algorithms including regression, classification, clustering, decision trees, ensemble methods, and neural networks.\n\n\u00b7 Use Azure ML Studio, TensorFlow, PyTorch, and other ML frameworks to implement and optimize model architectures.\n\n\u00b7 Perform hyperparameter tuning, cross-validation, and performance evaluation using industry-standard metrics to ensure model robustness and accuracy.\n\n\u00b7 Integrate models and services into business applications through RESTful APIs developed using FastAPI, Flask or Django.\n\n\u00b7 Build and maintain scalable and reusable ML components and pipelines using Azure ML Studio, Kubeflow, and MLflow.\n\n\u00b7 Enforce and integrate AI guardrails: bias mitigation, security practices, explainability, compliance with ethical and regulatory standards.\n\n\u00b7 Deploy models in production using Docker and Kubernetes, ensuring scalability, high availability, and fault tolerance.\n\n\u00b7 Utilize Azure AI services and infrastructure for development, training, inferencing, and model lifecycle management.\n\n\u00b7 Support and collaborate on the integration of large language models (LLMs), embeddings, vector databases, and RAG techniques where applicable.\n\n\u00b7 Monitor deployed models for drift, performance degradation, and data quality issues, and implement retraining workflows as needed.\n\n\u00b7 Collaborate with cross-functional teams including software engineers, product managers, business analysts, and architects to define and deliver AI-driven solutions.\n\n\u00b7 Communicate complex ML concepts, model outputs, and technical findings clearly to both technical and non-technical stakeholders.\n\n\u00b7 Stay current with the latest research, trends, and advancements in AI/ML and evaluate new tools and frameworks for potential adoption.\n\n\u00b7 Maintain comprehensive documentation of data pipelines, model architectures, training configurations, deployment steps, and experiment results.\n\n\u00b7 Drive innovation through experimentation, rapid prototyping, and the development of future-ready AI components and best practices.\n\n\u00b7 Write modular, maintainable, and production-ready code in Python with proper documentation and version control.\n\n\u00b7 Contribute to building reusable components and ML accelerators.\n\nQualifications:\n\u2022 Bachelor's or Master's degree in Computer Science, Data Science, Machine Learning, Statistics, Mathematics, or a related field over 7+ years.\n\u2022 Proven experience as a Data Scientist, ML Developer, or in a similar role.\n\n\u00b7 Strong command of Python and ML libraries (e.g., Azure ML Studio, scikit-learn, TensorFlow, PyTorch, XGBoost).\n\u2022 Data Engineering: Experience with ETL/ELT pipelines, data ingestion, transformation, and orchestration (Airflow, Dataflow, Composer).\n\u2022 ML Model Development: Strong grasp of statistical modelling, supervised/unsupervised learning, time-series forecasting, and NLP.\n\n\u00b7 Proficiency in Python\n\u2022 Strong knowledge of machine learning algorithms, frameworks (e.g., TensorFlow, PyTorch, scikit-learn), and statistical analysis techniques.\n\u2022 Proficiency in programming languages such as Python, R, or SQL.\n\u2022 Experience with data preprocessing, feature engineering, and model evaluation techniques.\n\u2022 MLOps & Deployment: Hands-on experience with CI/CD pipelines, model monitoring, and version control.\n\u2022 Familiarity with cloud platforms (e.g., Azure (Primarily), AWS and deployment tools.\n\u2022 Knowledge of DevOps platform.\n\u2022 Excellent problem-solving skills and attention to detail.\n\u2022 Strong communication and collaboration skills, with the ability to work effectively in a team environment.\n\nPreferred Qualifications:\n\u2022 Proficiency in Python, with libraries like pandas, NumPy, scikit-learn, spacy, NLTK and Tensor Flow, Pytorch\n\u2022 Knowledge of natural language processing (NLP) and custom/computer, YoLo vision techniques.\n\u2022 Experience with Graph ML, reinforcement learning, or causal inference modeling.\n\u2022 Familiarity with marketing analytics, attribution modelling, and A/B testing methodologies.\n\u2022 Working knowledge of BI tools for integrating ML insights into dashboards.\n\n\u00b7 Hands on MLOps experience, with an appreciation of the end-to-end CI/CD process\n\u2022 Familiarity with DevOps practices and CI/CD pipelines.\n\u2022 Experience with big data technologies (e.g., Hadoop, Spark) is added advantage\n\nJob Type: Full-time\n\nPay: \u20b9489,656.78 - \u20b91,757,284.43 per year\n\nWork Location: In person",
    "url": "https://www.glassdoor.co.in/job-listing/data-scientist-ai-ml-developer-princenton-software-services-pvt-ltd-JV_IC2856202_KO0,30_KE31,67.htm?jl=1009928106836&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Sr. Data Scientist / Machine Learning Engineer",
    "company": "TeamPlus",
    "location": "Pune",
    "salary": "",
    "description": "Strong programming skills in Python and SQL.\n\nDeep knowledge of data science and machine learning\n\nlibraries such as Pandas, Scikit-learn,\n\nTensorFlow, and PyTorch.\n\nProven experience in building, training, and deploying\n\nmachine learning models into production\n\nsystems.\n\nHands-on experience with big data technologies (Hadoop,\n\nSpark).\n\nStrong working knowledge of AWS cloud services (S3, EC2,\n\nEMR, Lambda, SageMaker, etc.).\n\nExperience working with Databricks and Airflow for data\n\nworkflow management.\n\nExcellent problem-solving skills and the ability to work in\n\ncollaborative, fast-paced environments.\n\nPreferred Qualifications:\n\nExperience with MLOps practices and CI/CD for model\n\ndeployment.\n\nFamiliarity with data versioning tools (e.g., DVC, MLflow).\n\nStrong understanding of data engineering concepts and\n\ndistributed computing.",
    "url": "https://www.teamplusindia.in/job/teamplus-remote-sr-data-scientist-machine-learning-engineer/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T10:00:00.000Z"
  },
  {
    "title": "(29 / 10 / 2025) Data Scientist",
    "company": "Tata Consultancy Services",
    "location": "Pune",
    "salary": "",
    "description": "Dear Candidate,\n\nGreetings from TATA Consultancy Services!!\n\nPosition- Data Scientist-Python\n\nExperience-4 to 8 years\n\nLocation- Chennai, Pune, Mumbai\n\nNotice Period- 0 to 60 days / Serving Notice Period\n\nKey Responsibilities :\n\u2022 Understand business process / business problems and device Machine Learning solutions to optimize business processes wherever possible.\n\u2022 Experience using statistical computer languages (Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\n\u2022 Formulating machine learning solutions to business metrics, designing features from the data available from many large data sources, training, evaluating, and deploying models in production\n\u2022 Developing high-performance algorithms for precision targeting, testing and implementing these algorithms in scalable, production-ready code; Interacting with other teams to define interfaces and understanding and resolving dependencies.\n\u2022 Developing coding in high-level languages such as R, Python, Java\n\u2022 Experience working with and creating data architectures.\n\u2022 Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages / drawbacks.\n\u2022 Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.\n\nNote : Note-Candidates who have previously worked at TCS not eligible to apply.\n\nOnly relevant experience candidates can apply.",
    "url": "https://in.talent.com/view?id=d99f903fffd8&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Senior Data Scientist (Artificial Intelligence Machine Learning)",
    "company": "FIS Global",
    "location": "Pune",
    "salary": "",
    "description": "Position Type :\nFull time\n\nType Of Hire :\nExperienced (relevant combo of work and education)\n\nEducation Desired :\nBachelor of Engineering\n\nTravel Percentage :\n1 - 5%\n\nSenior Data Scientist (Artificial Intelligence Machine Learning)\n\nAre you curious, motivated, and forward-thinking? At FIS you\u2019ll have the opportunity to work on some of the most challenging and relevant issues in financial services and technology. Our talented people empower us, and we believe in being part of a team that is open, collaborative, entrepreneurial, passionate and above all fun.\n\nAbout the role:\n\u2022 We are looking for a talented and passionate Data Scientist willing to challenge themself and produce best in class AI enabled solution\n\u2022 You will be required to use the concepts of AIML, GenAI, LLMs, Sentiment analysis, etc.\n\u2022 The role requires creating correlation between different data points and do predictive, preventive analysis.\n\nAbout the Team :\n\nTeam provide solutions and services that help our clients grow, compete, and optimize their business. Our AIOPS team is creating AIML solution targeted to reduce the Enterprise MTTR through our world class product\n\nWhat you will be doing:\n\u2022 Employ machine learning and statistical modeling to create and enhance data driven products.\n\u2022 Analyze and extract insights from internal and external data.\n\u2022 Work with Big Data and transform complex datasets into more usable formats.\n\u2022 Work with a variety of data science tools and programming languages such as SAS, Python, R, Scala, SQL. Work independently and collaborate with other groups to solve complex problems.\n\u2022 Create and present analyses to internal and external partners and clients.\n\u2022 Will be working in 2 Pm to 11 Pm IST Shifts\n\nWhat you bring:\n\u2022 4 to 6 Years of machine learning, artificial intelligence, statistical modeling, data visualization, and data analysis\n\u2022 Proficient in data science tools and programming languages such as SAS, Python, R, Scala, SQL\n\u2022 Relevant degree in Artificial Intelligence Machine Learning\n\u2022 Experience or knowledge of cloud-based technology\n\u2022 Knowledge of financial services industry\n\nWhat we offer you:\n\u2022 A range of benefits designed to help support your lifestyle and wellbeing.\n\u2022 A multi-faceted job with a broad spectrum of responsibilities\n\u2022 A modern international work environment and a dedicated and innovative team\n\u2022 A broad range of professional education and personal development possibilities \u2013 FIS is your final career step.\n\nPrivacy Statement\n\nFIS is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how FIS protects personal information online, please see the Online Privacy Notice.\n\nSourcing Model\n\nRecruitment at FIS works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. FIS does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company.\n\n#pridepass",
    "url": "https://careers.fisglobal.com/us/en/job/FIGLUSJR0296204EXTERNAL/Senior-Data-Scientist-Artificial-Intelligence-Machine-Learning?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (Lead / Associate Architect) - 42146",
    "company": "Fission Labs",
    "location": "Pune",
    "salary": "",
    "description": "Role: Data Scientist (Lead / Associate Architect)\n\nExperience: 8+ years\n\nLocation: Hyderabad / Pune\n\nFission Labs, headquartered in Sunnyvale, with offices in Dallas & Hyderabad, Fission Labs is a leading software development company, specializing in crafting flexible, agile, and scalable solutions that propel businesses forward. With a comprehensive range of services, including product development, cloud engineering, big data analytics, QA, DevOps consulting, and AI/ML solutions, we empower clients to achieve sustainable digital transformation that aligns seamlessly with their business goals.\n\nWhat are we looking for!\n\nAs a Data Science professional at Fission Labs, you will be part of a high-impact team that designs and develops data-driven solutions for complex business challenges. You\u2019ll work on end-to-end AI and ML systems \u2014 from data exploration and model development to large-scale deployment and optimization in cloud environments.\n\nResponsibilities\n\u2022 Design and architect complex Generative AI solutions using AWS technologies.\n\u2022 Develop advanced AI architectures incorporating state-of-the-art GenAI technologies.\n\u2022 Create and implement Retrieval Augmented Generation (RAG) and GraphRAG solutions.\n\u2022 Architect scalable AI systems using AWS Bedrock and SageMaker.\n\u2022 Design and implement agentic AI systems with advanced reasoning capabilities.\n\u2022 Develop custom AI solutions leveraging vector databases and advanced machine learning techniques.\n\u2022 Evaluate and integrate emerging GenAI technologies and methodologies.\n\nTechnical Expertise Requirements\n\nGenerative AI Technologies\n\nExpert-level Understanding Of\n\u2022 Retrieval Augmented Generation (RAG)\n\u2022 GraphRAG methodologies\n\u2022 LoRA (Low-Rank Adaptation) techniques\n\u2022 Vector Database architectures\n\u2022 Agentic AI design principles\n\nAWS AI Services\n\nComprehensive Expertise In\n\u2022 AWS Bedrock\n\u2022 Amazon SageMaker\n\u2022 AWS AI/ML services ecosystem\n\u2022 Cloud-native AI solution design\n\nTechnical Skills\n\nAdvanced Python programming for AI/ML applications\n\nDeep Understanding Of\n\u2022 Large Language Models (LLMs)\n\u2022 Machine Learning architectures\n\u2022 Preferred Qualifications\n\u2022 AI model fine-tuning techniques\n\u2022 Prompt engineering\n\u2022 AI system design and integration\n\nCore Competencies\n\u2022 Advanced AI solution architecture\n\u2022 Machine learning model optimization\n\u2022 Cloud-native AI system design\n\u2022 Performance tuning of GenAI solutions\n\u2022 Enterprise AI strategy development\n\nTechnical Stack\n\u2022 Programming Languages: Python (required)\n\u2022 Cloud Platform: AWS\n\nAI Technologies\n\u2022 Bedrock\n\u2022 SageMaker\n\u2022 Vector Databases\n\nMachine Learning Frameworks\n\u2022 PyTorch\n\u2022 TensorFlow\n\u2022 Hugging Face\n\nAI Integration Tools\n\u2022 LangChain o LlamaIndex\n\nYou would enjoy\n\u2022 Opportunity to work on impactful technical challenges with global reach.\n\u2022 Vast opportunities for self-development, including online university access and knowledge sharing opportunities.\n\u2022 Sponsored Tech Talks & Hackathons to foster innovation and learning.\n\u2022 Generous benefits packages including health insurance, retirement benefits, flexible work hours, and more.\n\u2022 Supportive work environment with forums to explore passions beyond work.",
    "url": "https://in.linkedin.com/jobs/view/data-scientist-lead-associate-architect-42146-at-fission-labs-4333036595?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (Python/ GenAI/ AgenticAI)",
    "company": "Wolters Kluwer",
    "location": "Pune",
    "salary": "",
    "description": "Key Responsibilities\n\nActive Learner with Enthusiasm for Problem-Solving\n\nContinuously learn and apply new AI/ML techniques, including Generative AI, Agentic AI deep learning, and other emerging technologies. Demonstrate a passion for solving complex business challenges and experimenting with novel approaches to improve model performance.\n\nQuick Prototyping & Experimentation\n\nDevelop rapid prototypes to test new AI/GenAI/ML approaches and solutions for business problems. Implement proof-of-concept models quickly, enabling fast experimentation and iteration to assess feasibility before scaling to full development.\n\nSupport AI Product Development & Iteration\n\nCollaborate with lead/ senior data scientists and cross-functional teams to support the design, development, and deployment of AI-driven products. Contribute to the creation of prototypes and refine models based on business needs and feedback.\n\nModel Development and Optimization\n\nDesign, develop, and test machine learning, deep learning, and generative AI models, focusing on performance, scalability, and business relevance. Continuously refine and optimize models based on real-world results and metrics.\n\nData Preparation & Collaboration\n\nAssist in defining data requirements and support data engineers in building data pipelines. Clean and preprocess datasets, ensuring data quality and preparing it for use in machine learning applications. Collaborate closely with engineers to integrate models into production systems.\n\nResearch Support and Knowledge Sharing\n\nStay informed about the latest trends and research in AI/GenAI/ML and generative models, applying this knowledge to current projects. Actively participate in team discussions, contribute to the evaluation of new techniques, and share insights with peers to foster a collaborative learning environment.\n\nEssential Skills\n\u2022 Good knowledge of Python programming language, data engineering and data science ecosystem in Python.\n\u2022 Hands on experience in Generative AI, Agentic AI, LLM and Advance RAG techniques.\n\u2022 Hands on experience in developing and supporting Machine Learning solutions.\n\u2022 Hands on experience in developing Natural Language Processing (NLP) solutions\n\u2022 Hands on experience on SQL ecosystem\n\u2022 Hands on experience on Solr framework with Python\n\u2022 Experience of working on Linux and shell scripting\n\u2022 Basic statistical modelling knowledge\n\u2022 Strong Computer Science fundamentals are must. (Data structures, Algorithms, OS, Databases).\n\u2022 Good communication and organizational skills with significant attention to detail\n\u2022 Experience partnering with cross-functional teams of domain experts, engineers, data scientists, and production support teams.\n\u2022 Strong attention to detail with excellent problem-solving skills.\n\u2022 Desire and ability to thrive in a distributed technical environment while working on multiple projects simultaneously.\n\u2022 Passionate about latest technology trends with a strong desire for innovation.\n\u2022 Self-motivated, self-managing and able to work independently.\n\nEducation And Experience\n\u2022 Bachelor's degree (B.E/ B Tech. computer science, engineering, statistics/mathematics or a related field) from a four-year college or university, or equivalent, master\u2019s a plus.\n\u2022 Total at least 1 years of experience working on enterprise AI products\n\u2022 Experience in supporting software products or applications in the AI ML domain.\n\u2022 The above statements are intended to describe the general nature and level of work being performed by most people assigned to this job. They are not intended to be an exhaustive list of all duties and responsibilities and requirements.\n\nApplicants may be required to appear onsite at a Wolters Kluwer office as part of the recruitment process.",
    "url": "https://in.linkedin.com/jobs/view/data-scientist-python-genai-agenticai-at-wolters-kluwer-4319872554?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Scientist AI ML Developer",
    "company": "Princenton software services pvt ltd",
    "location": "Pune",
    "salary": "",
    "description": "In this Role, Your Responsibilities Will Be:\n\n\u00b7 Develop, train and deploy machine learning, deep learning AI models for a variety of business use cases such as classification, prediction, recommendation, NLP and Image Processing.\n\n\u00b7 Design and implement end-to-end ML workflows from data ingestion and preprocessing to model deployment and monitoring.\n\n\u00b7 Collect, clean, and preprocess structured and unstructured data from multiple sources using industry-standard techniques such as normalization, feature engineering, dimensionality reduction, and optimization.\n\n\u00b7 Perform exploratory data analysis (EDA) to identify patterns, correlations, and actionable insights.\n\n\u00b7 Apply advanced knowledge of machine learning algorithms including regression, classification, clustering, decision trees, ensemble methods, and neural networks.\n\n\u00b7 Use Azure ML Studio, TensorFlow, PyTorch, and other ML frameworks to implement and optimize model architectures.\n\n\u00b7 Perform hyperparameter tuning, cross-validation, and performance evaluation using industry-standard metrics to ensure model robustness and accuracy.\n\n\u00b7 Integrate models and services into business applications through RESTful APIs developed using FastAPI, Flask or Django.\n\n\u00b7 Build and maintain scalable and reusable ML components and pipelines using Azure ML Studio, Kubeflow, and MLflow.\n\n\u00b7 Enforce and integrate AI guardrails: bias mitigation, security practices, explainability, compliance with ethical and regulatory standards.\n\n\u00b7 Deploy models in production using Docker and Kubernetes, ensuring scalability, high availability, and fault tolerance.\n\n\u00b7 Utilize Azure AI services and infrastructure for development, training, inferencing, and model lifecycle management.\n\n\u00b7 Support and collaborate on the integration of large language models (LLMs), embeddings, vector databases, and RAG techniques where applicable.\n\n\u00b7 Monitor deployed models for drift, performance degradation, and data quality issues, and implement retraining workflows as needed.\n\n\u00b7 Collaborate with cross-functional teams including software engineers, product managers, business analysts, and architects to define and deliver AI-driven solutions.\n\n\u00b7 Communicate complex ML concepts, model outputs, and technical findings clearly to both technical and non-technical stakeholders.\n\n\u00b7 Stay current with the latest research, trends, and advancements in AI/ML and evaluate new tools and frameworks for potential adoption.\n\n\u00b7 Maintain comprehensive documentation of data pipelines, model architectures, training configurations, deployment steps, and experiment results.\n\n\u00b7 Drive innovation through experimentation, rapid prototyping, and the development of future-ready AI components and best practices.\n\n\u00b7 Write modular, maintainable, and production-ready code in Python with proper documentation and version control.\n\n\u00b7 Contribute to building reusable components and ML accelerators.\n\nQualifications:\n\u2022 Bachelor's or Master's degree in Computer Science, Data Science, Machine Learning, Statistics, Mathematics, or a related field over 7+ years.\n\u2022 Proven experience as a Data Scientist, ML Developer, or in a similar role.\n\n\u00b7 Strong command of Python and ML libraries (e.g., Azure ML Studio, scikit-learn, TensorFlow, PyTorch, XGBoost).\n\u2022 Data Engineering: Experience with ETL/ELT pipelines, data ingestion, transformation, and orchestration (Airflow, Dataflow, Composer).\n\u2022 ML Model Development: Strong grasp of statistical modelling, supervised/unsupervised learning, time-series forecasting, and NLP.\n\n\u00b7 Proficiency in Python\n\u2022 Strong knowledge of machine learning algorithms, frameworks (e.g., TensorFlow, PyTorch, scikit-learn), and statistical analysis techniques.\n\u2022 Proficiency in programming languages such as Python, R, or SQL.\n\u2022 Experience with data preprocessing, feature engineering, and model evaluation techniques.\n\u2022 MLOps & Deployment: Hands-on experience with CI/CD pipelines, model monitoring, and version control.\n\u2022 Familiarity with cloud platforms (e.g., Azure (Primarily), AWS and deployment tools.\n\u2022 Knowledge of DevOps platform.\n\u2022 Excellent problem-solving skills and attention to detail.\n\u2022 Strong communication and collaboration skills, with the ability to work effectively in a team environment.\n\nPreferred Qualifications:\n\u2022 Proficiency in Python, with libraries like pandas, NumPy, scikit-learn, spacy, NLTK and Tensor Flow, Pytorch\n\u2022 Knowledge of natural language processing (NLP) and custom/computer, YoLo vision techniques.\n\u2022 Experience with Graph ML, reinforcement learning, or causal inference modeling.\n\u2022 Familiarity with marketing analytics, attribution modelling, and A/B testing methodologies.\n\u2022 Working knowledge of BI tools for integrating ML insights into dashboards.\n\n\u00b7 Hands on MLOps experience, with an appreciation of the end-to-end CI/CD process\n\u2022 Familiarity with DevOps practices and CI/CD pipelines.\n\u2022 Experience with big data technologies (e.g., Hadoop, Spark) is added advantage\n\nJob Type: Full-time\n\nPay: \u20b9489,656.78 - \u20b91,757,284.43 per year\n\nWork Location: In person",
    "url": "https://www.glassdoor.com/job-listing/data-scientist-ai-ml-developer-princenton-software-services-pvt-ltd-JV_IC2856202_KO0,30_KE31,67.htm?jl=1009928106836&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Data Scientist",
    "company": "Snowflake",
    "location": "Pune",
    "salary": "",
    "description": "Snowflake is about empowering enterprises to achieve their full potential \u2014 and people too. With a culture that\u2019s all in on impact, innovation, and collaboration, Snowflake is the sweet spot for building big, moving fast, and taking technology \u2014 and careers \u2014 to the next level.\n\nSnowflake is seeking a Data Scientist to join our expanding Enterprise AI & ML team. This role involves working on diverse AI/ML and data science initiatives, utilizing Snowflake's Data Cloud and Cortex AI. The successful candidate will design and develop scalable data science and machine learning solutions, build interactive AI applications, and collaborate on operationalizing intelligent systems to enhance data-driven decision-making throughout the company. This position focuses on applying data science, AI & ML skill sets to various domain specific business data problems across Snowflake.\n\nON THE ENTERPRISE AI & ML TEAM AT SNOWFLAKE, YOU WILL:\n\u2022 Design, prototype, and deploy data science and AI solutions.\n\u2022 Conduct end to end experimentation, including data exploration, feature engineering, model development, and validation.\n\u2022 Build and maintain Streamlit applications to visualize models, showcase insights, and enable business stakeholders to interact with AI driven solutions.\n\u2022 Develop and optimize LLM based applications, workflows, and operations; with a focus on retrieval, generation, semantic understanding and fine-tuning.\n\u2022 Partner cross functionally with data engineers, analysts, and product teams to translate ambiguous business problems into measurable outcomes.\n\nOUR IDEAL CANDIDATE WILL HAVE:\n\u2022 2 to 4 years of experience applying data science, machine learning, or AI techniques in real world business settings.\n\u2022 Strong programming skills in Python, proficiency in SQL for large scale data manipulation.\n\u2022 Familiarity with frameworks such as scikit-learn, XGBoost etc.\n\u2022 Understanding of LLM architectures, embeddings, vector search, and RAG pipelines.\n\u2022 Experience working on cloud platforms.\n\u2022 Strong analytical, storytelling, and communication skills to translate technical insights into actionable recommendations.\n\u2022 A mindset of curiosity, ownership, and collaboration, with an eagerness to work on open-ended problems.\n\u2022 Experience operationalizing AI & ML models in a production setting.\n\nSnowflake is growing fast, and we\u2019re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.\n\nHow do you want to make your impact?\n\nFor jobs located in the United States, please visit the job posting on the Snowflake Careers Site for salary and benefits information: careers.snowflake.com",
    "url": "https://careers.snowflake.com/us/en/job/SNCOUSE5563EEBE22F4F83ABADA6BD2B014860EXTERNALENUSF7C857F3DD284045B0C758E492307EC3/Data-Scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "\u25b7 (15h Left) Manager, Data Science (Media / Market Research)",
    "company": "NielsenIQ",
    "location": "Pune",
    "salary": "",
    "description": "As a Data Science Manager you will have following key accountabilities :\n\nTeam Leadership : Build and lead a high-performing team of 6-8 Data Scientists and Machine Learning Engineers in our Pune hub. Foster a collaborative and inclusive team culture that encourages innovation and continuous learning.\n\nTechnical Communication : Explain Data Science principles, concepts, algorithms, and approaches in simple terms to diverse audiences, including non-technical stakeholders.\n\nBusiness Understanding : Utilize your solid business understanding to align with stakeholders, discuss requirements and feasibility, and manage expectations effectively. Ensure clear communication and understanding of project goals and outcomes.\n\nEducational Background :\n\nPhD or Master\u2019s degree in Computer Science, Engineering, Statistics, Mathematics, or a related field, with min 8+ years of experience as a Data Scientist.\n\nLeadership Experience :\n\nProven experience as a people manager and / or mentor, with a track record of developing and leading high-performing teams.\n\nLeadership Experience :\n\nProven experience as a people manager and / or mentor, with a track record of developing and leading high-performing teams\n\nCommunication Skills :\n\u2022 Ability to effectively communicate complex methodologies and technologies to both technical and non-technical audiences.\n\u2022 Strong problem-solving skills and an independent working style.\n\nTechnical Expertise :\n\u2022 Strong statistical and machine learning modeling skills, including statistical tests, classification, predictive modeling, handling of missing data, and sampling / weighting techniques.\n\u2022 Solid in analytical programming languages such as Python or R, along with their respective ecosystems.\n\u2022 Hands-on experience implementing these models in production systems.\n\u2022 Proficient in software development skills, including unit testing, CI / CD, and version control with Git, along with familiarity with computer science and engineering fundamentals such as data structures, software design principles, and testing strategies.\n\nPreferred qualifications\n\u2022 Experience in the Media industry\n\u2022 Experience working with cloud-based data services (AWS, Azure, or GCP)\n\u2022 Experience with Optimization techniques such as : linear programming, integer programming, genetic algorithms, constrained optimization is a plus",
    "url": "https://in.talent.com/view?id=9ec995376b19&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Data Scientist  People Data Analytics & Insights",
    "company": "Syngenta",
    "location": "Pune",
    "salary": "",
    "description": "We are seeking a highly analytical and business-focused Data Scientist to join our People Analytics & Insights team. In this role, you will leverage advanced analytics, machine learning, and statistical modeling to uncover insights from workforce data, supporting strategic talent decisions across the organization. You will partner closely with HR, Talent Management, and business leaders to deliver data-driven solutions that enhance employee experience, improve workforce planning, and inform diversity, equity, and inclusion (DEI) strategies.\n\nKey Responsibilities:\n\u2022 Analyze large and complex HR datasets (e.g., engagement, attrition, performance, compensation, hiring) to uncover trends, patterns, and opportunities for business impact.\n\u2022 Build predictive and prescriptive models (e.g., attrition risk, career pathing, workforce segmentation) to support data-informed people strategies.\n\u2022 Translate business problems into analytical questions and communicate findings in clear, actionable terms to non-technical audiences.\n\u2022 Develop visualizations, dashboards, and storytelling tools to enhance insight delivery (e.g., in Tableau, Power BI, Workday Discovery Boards).\n\u2022 Partner with HR stakeholders to identify KPIs, define success metrics, and improve people-related decision-making through data.\n\u2022 Design and implement surveys, experiments (A/B testing), and causal inference models to evaluate the impact of HR programs and initiatives.\n\u2022 Ensure ethical data use and compliance with privacy and governance standards.\n\u2022 Stay current on industry best practices in people analytics, data science, and AI/ML in HR.\n\nCompany Description\n\nAt the Syngenta Group, our 56,000 people across more than 90 countries strive every day to transform agriculture through tailor-made solutions for the benefit of farmers, society and our planet \u2013 making us the world's most local agricultural technology and innovation partner.\n\nWebsite address - https://www.syngentagroup.com/\n\nLI page - https://www.linkedin.com/company/syngentagroup/posts/?feedView=all\n\nQualifications\n\u2022 Bachelor\u2019s or Master\u2019s degree in Data Science, Statistics, Computer Science, Industrial/Organizational Psychology, Economics, or a related field.\n\u2022 3\u20135+ years of experience in data science, analytics, or a similar role, ideally within HR or workforce analytics.\n\u2022 Proficiency in Python or R for statistical analysis and modeling.\n\u2022 Strong SQL skills for data extraction and manipulation.\n\u2022 Experience with data visualization tools (e.g., Tableau, Power BI, Workday Discovery Boards).\n\u2022 Solid understanding of machine learning algorithms, statistical modeling, and hypothesis testing.\n\u2022 Excellent communication skills, with the ability to explain complex analytical concepts to HR and business audiences.\n\u2022 Familiarity with Workday, SAP SuccessFactors, or other HRIS platforms is a plus.\n\nPreferred Skills:\n\u2022 Experience with natural language processing (NLP) on employee feedback or engagement data.\n\u2022 Knowledge of DEI analytics and workforce diversity measurement.\n\u2022 Exposure to cloud-based data platforms (e.g., AWS, GCP, Azure).\n\u2022 Understanding of HR functional areas like talent acquisition, performance management, and learning & development.\n\nKey Competencies:\n\u2022 Analytical Thinking & Problem Solving\n\u2022 Business Acumen & Strategic Mindset\n\u2022 Data Storytelling & Visualization\n\u2022 Collaboration & Stakeholder Management\n\u2022 Data Ethics & Privacy Awareness\n\nAdditional Information\n\nWL: 4A\n\nNote: Syngenta is an Equal Opportunity Employer and does not discriminate in recruitment, hiring, training, promotion or any other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, gender identity, marital or veteran status, disability, or any other legally protected status\n\nFollow us on: Twitter & LinkedIn\n\nhttps://twitter.com/SyngentaAPAC\n\nhttps://www.linkedin.com/company/syngenta/",
    "url": "https://jobs.syngenta.com/job/data-scientist-people-data-analytics-and-insights-in-in-pune-jid-14917?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Lead Data Scientist+ Instructor",
    "company": "Uplers",
    "location": "Pune",
    "salary": "",
    "description": "Experience: 7.00 + years\n\nSalary: Confidential (based on experience)\n\nShift: (GMT+05:30) Asia/Kolkata (IST)\n\nOpportunity Type: Office (Pune)\n\nPlacement Type: Full time Permanent Position\n\n(*Note: This is a requirement for one of Uplers' client - Newton School)\n\nWhat do you need for this opportunity?\n\nMust have skills required:\n\nMachine Learning, NLP, Computer Vision, Statistics, pandas, NumPy, Python\n\nNewton School is Looking for:\n\nAbout Newton:\n\nNewton School of Technology (NST) is a new-age institution redefining technical education in India. Founded by IIT alumni, NST offers a 4-year B.Tech in Computer Science and AI, focused on hands-on learning and deep industry integration. Within two years, over 93% of students have secured paid internships with companies like Razorpay, SarvamAI, and DRDO, along with global exposure through tech treks to Singapore and Silicon Valley. Led by a distinguished faculty comprising ICPC World Finalists and ex-professionals from ISRO, Microsoft, MakeMyTrip, and several other leading tech organisations, NST is building a scalable, high-impact model that produces industry-ready talent for the world\u2019s most advanced technology roles.\n\nAbout the Role:\n\nWe are currently looking for a Data Scientist + Instructor\u2013 AI/ML to join our Computer Science Department. This role is ideal for professionals with substantial industry experience professionals who are passionate about Artificial Intelligence and Machine Learning, and committed to shaping the next generation of tech talent. The position combines hands-on technical expertise with academic responsibilities, including designing and delivering course content, conducting practical lab sessions, and mentoring students in core Data Science and AI/ML concepts. The ideal candidate will also collaborate with academic leaders and industry partners to ensure curriculum relevance, integrate real-world problem-solving, and drive strong learning outcomes.\n\nKey Responsibilities:\n\u2022 Teach Applied AI/ML: Design and deliver practical, project-based courses in AI/ML(Python for ML, Statistics, ML Algorithms, Deep Learning, NLP, CV, ML Ops, GenAI).\n\u2022 Develop Industry-Relevant Curriculum: Help design and update the AI/ML curriculum to reflect current industry tools, techniques, and best practices, incorporating your professional experience and case studies.\n\u2022 Mentor Student Projects: Guide students through hands-on AI/ML projects, providing technical direction, code reviews, and feedback based on industry standards.\n\u2022 Guide & Mentor Students: Advise students on developing practical skills, understanding career paths in AI/ML, and preparing for internships and job placements.\n\u2022 Stay Current: Bring the latest AI/ML research, tools, and industry trends into the classroom.\n\u2022 Collaborate: Work closely with other expert faculty and staff to create a unified and effective learning experience.\n\u2022 Assess Practical Skills: Design and evaluate assignments, projects, and assessments focused on real-world applications.\n\nQualifications and Requirements:\n\u2022 Bachelor\u2019s or Master\u2019s degree in Computer Science, Engineering, Data Science, AI/ML, or related field. (PhD is valued but not mandatory.)\n\u2022 7+ years of direct, hands-on professional experience in the tech industry as an AI/ML Engineer, Data Scientist, Research Scientist, or similar role involving AI/ML development and deployment.\n\u2022 Proven Industry Track Record: Demonstrated experience in building, training, and deploying machine learning models (including deep learning) for real-world problems.\n\u2022 Deep AI/ML Understanding: Strong grasp of core ML algorithms (classical & deep learning \u2013 CNNs, RNNs, Transformers), model evaluation, statistics, and awareness of current research/industry trends.\n\u2022 Passion for Teaching/Mentoring: Ability to explain complex concepts clearly and guide others. Prior mentoring, corporate training, technical workshops, or project supervision experience is highly relevant.\n\nRequired Skills:\n\u2022 Technical: Expert-level Python programming.\n\u2022 Proficiency with data science libraries (Pandas, NumPy, Scikit-learn).\n\u2022 Hands-on experience with ML/DL frameworks (TensorFlow, PyTorch).\n\u2022 Strong SQL and data handling skills.\n\u2022 Understanding of ML Ops practices and tools (Git, Docker, AWS/GCP/Azure).\n\u2022 Knowledge of key AI areas (NLP, Computer Vision, Generative AI/LLMs).\n\u2022 Soft Skills: Strong communication, mentoring ability, collaboration, and a genuine passion for education.\n\nGood-to-Have:\n\u2022 Prior teaching experience at the undergraduate or graduate level.\n\u2022 Familiarity with modern teaching methodologies and academic\n\nHow to apply for this opportunity?\n\u2022 Step 1: Click On Apply! And Register or Login on our portal.\n\u2022 Step 2: Complete the Screening Form & Upload updated Resume\n\u2022 Step 3: Increase your chances to get shortlisted & meet the client for the Interview!\n\nAbout Uplers:\n\nOur goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement.\n\n(Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well).\n\nSo, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you!",
    "url": "https://in.linkedin.com/jobs/view/lead-data-scientist%2B-instructor-at-uplers-4333996105?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T12:00:00.000Z"
  },
  {
    "title": "Sr. Data Scientist / Machine Learning Engineer",
    "company": "TeamPlus",
    "location": "Pune",
    "salary": "",
    "description": "Strong programming skills in Python and SQL.\n\nDeep knowledge of data science and machine learning\n\nlibraries such as Pandas, Scikit-learn,\n\nTensorFlow, and PyTorch.\n\nProven experience in building, training, and deploying\n\nmachine learning models into production\n\nsystems.\n\nHands-on experience with big data technologies (Hadoop,\n\nSpark).\n\nStrong working knowledge of AWS cloud services (S3, EC2,\n\nEMR, Lambda, SageMaker, etc.).\n\nExperience working with Databricks and Airflow for data\n\nworkflow management.\n\nExcellent problem-solving skills and the ability to work in\n\ncollaborative, fast-paced environments.\n\nPreferred Qualifications:\n\nExperience with MLOps practices and CI/CD for model\n\ndeployment.\n\nFamiliarity with data versioning tools (e.g., DVC, MLflow).\n\nStrong understanding of data engineering concepts and\n\ndistributed computing.",
    "url": "https://www.teamplusindia.in/job/teamplus-remote-sr-data-scientist-machine-learning-engineer/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T10:00:00.000Z"
  },
  {
    "title": "(29 / 10 / 2025) Data Scientist",
    "company": "Tata Consultancy Services",
    "location": "Pune",
    "salary": "",
    "description": "Dear Candidate,\n\nGreetings from TATA Consultancy Services!!\n\nPosition- Data Scientist-Python\n\nExperience-4 to 8 years\n\nLocation- Chennai, Pune, Mumbai\n\nNotice Period- 0 to 60 days / Serving Notice Period\n\nKey Responsibilities :\n\u2022 Understand business process / business problems and device Machine Learning solutions to optimize business processes wherever possible.\n\u2022 Experience using statistical computer languages (Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\n\u2022 Formulating machine learning solutions to business metrics, designing features from the data available from many large data sources, training, evaluating, and deploying models in production\n\u2022 Developing high-performance algorithms for precision targeting, testing and implementing these algorithms in scalable, production-ready code; Interacting with other teams to define interfaces and understanding and resolving dependencies.\n\u2022 Developing coding in high-level languages such as R, Python, Java\n\u2022 Experience working with and creating data architectures.\n\u2022 Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages / drawbacks.\n\u2022 Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.\n\nNote : Note-Candidates who have previously worked at TCS not eligible to apply.\n\nOnly relevant experience candidates can apply.",
    "url": "https://in.talent.com/view?id=d99f903fffd8&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Senior Data Scientist (Artificial Intelligence Machine Learning)",
    "company": "FIS Global",
    "location": "Pune",
    "salary": "",
    "description": "Position Type :\nFull time\n\nType Of Hire :\nExperienced (relevant combo of work and education)\n\nEducation Desired :\nBachelor of Engineering\n\nTravel Percentage :\n1 - 5%\n\nSenior Data Scientist (Artificial Intelligence Machine Learning)\n\nAre you curious, motivated, and forward-thinking? At FIS you\u2019ll have the opportunity to work on some of the most challenging and relevant issues in financial services and technology. Our talented people empower us, and we believe in being part of a team that is open, collaborative, entrepreneurial, passionate and above all fun.\n\nAbout the role:\n\u2022 We are looking for a talented and passionate Data Scientist willing to challenge themself and produce best in class AI enabled solution\n\u2022 You will be required to use the concepts of AIML, GenAI, LLMs, Sentiment analysis, etc.\n\u2022 The role requires creating correlation between different data points and do predictive, preventive analysis.\n\nAbout the Team :\n\nTeam provide solutions and services that help our clients grow, compete, and optimize their business. Our AIOPS team is creating AIML solution targeted to reduce the Enterprise MTTR through our world class product\n\nWhat you will be doing:\n\u2022 Employ machine learning and statistical modeling to create and enhance data driven products.\n\u2022 Analyze and extract insights from internal and external data.\n\u2022 Work with Big Data and transform complex datasets into more usable formats.\n\u2022 Work with a variety of data science tools and programming languages such as SAS, Python, R, Scala, SQL. Work independently and collaborate with other groups to solve complex problems.\n\u2022 Create and present analyses to internal and external partners and clients.\n\u2022 Will be working in 2 Pm to 11 Pm IST Shifts\n\nWhat you bring:\n\u2022 4 to 6 Years of machine learning, artificial intelligence, statistical modeling, data visualization, and data analysis\n\u2022 Proficient in data science tools and programming languages such as SAS, Python, R, Scala, SQL\n\u2022 Relevant degree in Artificial Intelligence Machine Learning\n\u2022 Experience or knowledge of cloud-based technology\n\u2022 Knowledge of financial services industry\n\nWhat we offer you:\n\u2022 A range of benefits designed to help support your lifestyle and wellbeing.\n\u2022 A multi-faceted job with a broad spectrum of responsibilities\n\u2022 A modern international work environment and a dedicated and innovative team\n\u2022 A broad range of professional education and personal development possibilities \u2013 FIS is your final career step.\n\nPrivacy Statement\n\nFIS is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how FIS protects personal information online, please see the Online Privacy Notice.\n\nSourcing Model\n\nRecruitment at FIS works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. FIS does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company.\n\n#pridepass",
    "url": "https://careers.fisglobal.com/us/en/job/FIGLUSJR0296204EXTERNAL/Senior-Data-Scientist-Artificial-Intelligence-Machine-Learning?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (Lead / Associate Architect) - 42146",
    "company": "Fission Labs",
    "location": "Pune",
    "salary": "",
    "description": "Role: Data Scientist (Lead / Associate Architect)\n\nExperience: 8+ years\n\nLocation: Hyderabad / Pune\n\nFission Labs, headquartered in Sunnyvale, with offices in Dallas & Hyderabad, Fission Labs is a leading software development company, specializing in crafting flexible, agile, and scalable solutions that propel businesses forward. With a comprehensive range of services, including product development, cloud engineering, big data analytics, QA, DevOps consulting, and AI/ML solutions, we empower clients to achieve sustainable digital transformation that aligns seamlessly with their business goals.\n\nWhat are we looking for!\n\nAs a Data Science professional at Fission Labs, you will be part of a high-impact team that designs and develops data-driven solutions for complex business challenges. You\u2019ll work on end-to-end AI and ML systems \u2014 from data exploration and model development to large-scale deployment and optimization in cloud environments.\n\nResponsibilities\n\u2022 Design and architect complex Generative AI solutions using AWS technologies.\n\u2022 Develop advanced AI architectures incorporating state-of-the-art GenAI technologies.\n\u2022 Create and implement Retrieval Augmented Generation (RAG) and GraphRAG solutions.\n\u2022 Architect scalable AI systems using AWS Bedrock and SageMaker.\n\u2022 Design and implement agentic AI systems with advanced reasoning capabilities.\n\u2022 Develop custom AI solutions leveraging vector databases and advanced machine learning techniques.\n\u2022 Evaluate and integrate emerging GenAI technologies and methodologies.\n\nTechnical Expertise Requirements\n\nGenerative AI Technologies\n\nExpert-level Understanding Of\n\u2022 Retrieval Augmented Generation (RAG)\n\u2022 GraphRAG methodologies\n\u2022 LoRA (Low-Rank Adaptation) techniques\n\u2022 Vector Database architectures\n\u2022 Agentic AI design principles\n\nAWS AI Services\n\nComprehensive Expertise In\n\u2022 AWS Bedrock\n\u2022 Amazon SageMaker\n\u2022 AWS AI/ML services ecosystem\n\u2022 Cloud-native AI solution design\n\nTechnical Skills\n\nAdvanced Python programming for AI/ML applications\n\nDeep Understanding Of\n\u2022 Large Language Models (LLMs)\n\u2022 Machine Learning architectures\n\u2022 Preferred Qualifications\n\u2022 AI model fine-tuning techniques\n\u2022 Prompt engineering\n\u2022 AI system design and integration\n\nCore Competencies\n\u2022 Advanced AI solution architecture\n\u2022 Machine learning model optimization\n\u2022 Cloud-native AI system design\n\u2022 Performance tuning of GenAI solutions\n\u2022 Enterprise AI strategy development\n\nTechnical Stack\n\u2022 Programming Languages: Python (required)\n\u2022 Cloud Platform: AWS\n\nAI Technologies\n\u2022 Bedrock\n\u2022 SageMaker\n\u2022 Vector Databases\n\nMachine Learning Frameworks\n\u2022 PyTorch\n\u2022 TensorFlow\n\u2022 Hugging Face\n\nAI Integration Tools\n\u2022 LangChain o LlamaIndex\n\nYou would enjoy\n\u2022 Opportunity to work on impactful technical challenges with global reach.\n\u2022 Vast opportunities for self-development, including online university access and knowledge sharing opportunities.\n\u2022 Sponsored Tech Talks & Hackathons to foster innovation and learning.\n\u2022 Generous benefits packages including health insurance, retirement benefits, flexible work hours, and more.\n\u2022 Supportive work environment with forums to explore passions beyond work.",
    "url": "https://in.linkedin.com/jobs/view/data-scientist-lead-associate-architect-42146-at-fission-labs-4333036595?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Sr Data Scientist",
    "company": "Birlasoft Limited",
    "location": "Pune",
    "salary": "",
    "description": "Area(s) of responsibility\n\nData Scientist experience (8 to 10) - 5B\n\n5 years of relevant work experience as a data scientist\n\nExperience designing and building statistical forecasting models.\n\nExperience in Python, AWS Cloud Services SageMaker,Comprehend, Amazon Bedrock for generative AI and Open AI\n\nExperience designing and building machine learning models.\n\nLead the end-to-end development of AI/ML solutions, from problem definition to production deployment.\n\nStrong programming skills in Python and experience with libraries like TensorFlow, PyTorch, Scikit-learn.\n\nMinimum 2 years of experience in Azure Cloud using Natural Language API\n\nExperience designing and building statistical forecasting models.\n\nExperience in Ingesting data from API and Databases\n\nExperience designing and building machine learning models.\n\nHands-on experience with LLMs and GenAI frameworks\n\nExperience in Django, Flask web frameworks\n\nExperience designing and building optimization models., including expertise with statistical data analysis\n\nMandatory Skillset: Python, AWS Cloud Services SageMaker, Comprehend, Amazon Bedrock for generative AI and Open AI",
    "url": "https://jobs.birlasoft.com/job/Pune-Sr-Data-Scientist-INDI/45605844/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Senior Data Scientist (Artificial Intelligence Machine Learning)",
    "company": "FIS Global",
    "location": "Pune",
    "salary": "",
    "description": "Position Type :\n\nFull time\n\nType Of Hire :\n\nExperienced (relevant combo of work and education)\n\nEducation Desired :\n\nBachelor of Engineering\n\nTravel Percentage :\n\n1 - 5%\n\nSenior Data Scientist (Artificial Intelligence Machine Learning)\n\nAre you curious, motivated, and forward-thinking? At FIS you\u2019ll have the opportunity to work on some of the most challenging and relevant issues in financial services and technology. Our talented people empower us, and we believe in being part of a team that is open, collaborative, entrepreneurial, passionate and above all fun.\n\nAbout the role:\n\u2022 We are looking for a talented and passionate Data Scientist willing to challenge themself and produce best in class AI enabled solution\n\u2022 You will be required to use the concepts of AIML, GenAI, LLMs, Sentiment analysis, etc.\n\u2022 The role requires creating correlation between different data points and do predictive, preventive analysis.\n\nAbout the Team :\n\nTeam provide solutions and services that help our clients grow, compete, and optimize their business. Our AIOPS team is creating AIML solution targeted to reduce the Enterprise MTTR through our world class product\n\nWhat you will be doing:\n\u2022 Employ machine learning and statistical modeling to create and enhance data driven products.\n\u2022 Analyze and extract insights from internal and external data.\n\u2022 Work with Big Data and transform complex datasets into more usable formats.\n\u2022 Work with a variety of data science tools and programming languages such as SAS, Python, R, Scala, SQL. Work independently and collaborate with other groups to solve complex problems.\n\u2022 Create and present analyses to internal and external partners and clients.\n\u2022 Will be working in 2 Pm to 11 Pm IST Shifts\n\nWhat you bring:\n\u2022 4 to 6 Years of machine learning, artificial intelligence, statistical modeling, data visualization, and data analysis\n\u2022 Proficient in data science tools and programming languages such as SAS, Python, R, Scala, SQL\n\u2022 Relevant degree in Artificial Intelligence Machine Learning\n\u2022 Experience or knowledge of cloud-based technology\n\u2022 Knowledge of financial services industry\n\nWhat we offer you:\n\u2022 A range of benefits designed to help support your lifestyle and wellbeing.\n\u2022 A multi-faceted job with a broad spectrum of responsibilities\n\u2022 A modern international work environment and a dedicated and innovative team\n\u2022 A broad range of professional education and personal development possibilities \u2013 FIS is your final career step.\n\nPrivacy Statement\n\nFIS is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how FIS protects personal information online, please see the Online Privacy Notice.\n\nSourcing Model\n\nRecruitment at FIS works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. FIS does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company.\n\n#pridepass",
    "url": "https://www.glassdoor.co.in/job-listing/senior-data-scientist-artificial-intelligence-machine-learning-fis-global-JV_IC2856202_KO0,62_KE63,73.htm?jl=1009714190836&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Data Scientist- Gen AI (3-5 years exp only)",
    "company": "confidential",
    "location": "Pune",
    "salary": "",
    "description": "As a Data Scientist, you'll play a crucial role in supporting data-driven projects, performing routine data analysis tasks, and assisting with model development and testing. Your role involves contributing to various stages of the data science lifecycle and providing insights that help shape business strategies. This position is suited for those with a foundational understanding of data science and are eager to deepen their expertise.\n\nResponsibilities:\n\u2022 Contribute to more advanced data collection and preprocessing efforts.\n\u2022 Assist in developing and testing machine learning models.\n\u2022 Perform descriptive data analysis and provide preliminary insights.\n\u2022 Create visualizations and reports to support data findings.\n\u2022 Manage and maintain data repositories efficiently.\n\u2022 Support senior data scientists in feature creation and selection.\n\u2022 Participate in collaborative projects with cross-functional teams.\n\u2022 Help automate data processing tasks using scripts.\n\u2022 Contribute to model validation and performance testing.\n\u2022 Stay informed about emerging data science tools and methodologies.\n\nSkills:\n\u2022 Advanced Data Cleaning: Enhanced preprocessing and data wrangling techniques.\n\u2022 Intermediate Python: Proficiency in Python for data science tasks.\n\u2022 SQL: More advanced SQL querying skills.\n\u2022 Data Visualization: Ability to create meaningful visualizations using tools like Tableau or Matplotlib.\n\u2022 Machine Learning Basics: Understanding of basic machine learning concepts and algorithms.\n\u2022 Statistical Analysis: Intermediate statistical methods and their applications.\n\u2022 Communication: Articulating data insights clearly to non-technical stakeholders.\n\u2022 Problem-Solving: Effective in identifying data-related issues and providing solutions.\n\nApplicants may be required to appear onsite at a Wolters Kluwer office as part of the recruitment process.",
    "url": "https://in.jooble.org/jdp/-5701870864767254657?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "WFH Machine Learning Jobs in Pune",
    "company": "Turing.com",
    "location": "Pune",
    "salary": "",
    "description": "We, at Turing, are looking for experienced ML engineers who will design and develop machine learning and deep learning systems, machine learning tests and implement Ml algorithms to help in creating AI solutions. Apply for machine learning jobs in Pune and get a chance to work closely with global software engineers, AI/ML enthusiasts and gain unique experiences.",
    "url": "https://www.turing.com/jobs/machine-learning-jobs-in-pune?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Python & ML Intern (Data Science Track)",
    "company": "Skillfied Mentor Jobs",
    "location": "Pune",
    "salary": "",
    "description": "Python & ML Intern (Data Science Track)\n\nLocation: Remote / Virtual\n\nInternship Type: Unpaid (Stipend available for top performers)\n\nSchedule: Flexible duration & working hours\n\nAbout the Internship\n\nKickstart your journey into Data Science & Machine Learning with this internship crafted for students and fresh graduates. Gain hands-on experience in Python, ML algorithms, and data-driven solutions, while working on real-world projects under the guidance of expert mentors.\n\nWhat You'll Learn:\n\nHands-on projects in\nPython, Machine Learning & Data Science\n\nData preprocessing, visualization & model building\n\nReal-world applications of ML in different industries\n\nWhy Join Us?\n\nWork on\nlive projects\nguided by expert mentors\n\nBuild a\nstrong portfolio\nfor your career in Data Science\n\nEarn an\nISO Certified Internship Certificate\n\nEligibility:\n\nStudents & freshers passionate about\nPython, ML & Data Science\n\nBasic knowledge of Python/Maths/Statistics will be a plus\n\nApplication Deadline: 5th September 2025\n\nKickstart your career in\nData Science & Machine Learning\nwith our ISO Certified Internship",
    "url": "https://www.recruit.net/job/python-ml-data-science-track-jobs/A1A1222481411831?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "DeepTek.ai - Senior Data Scientist - Python / Deep Learning",
    "company": "DeepTek Medical Imaging Pvt Ltd",
    "location": "Pune",
    "salary": "",
    "description": "Description :\n\nKey Responsibilities :\n\u2022 Lead the design, development, and optimization of deep learning models for medical image analysis, including tasks like segmentation, classification, object detection.\n\u2022 Provide technical leadership and mentorship to junior data scientists and engineers, fostering best practices in research methodology, coding standards, and documentation.\n\u2022 Perform advanced error analysis, bias assessment, and domain generalization studies to ensure robustness across diverse populations and imaging devices.\n\u2022 Guide data storage, preprocessing and annotation strategies, collaborating with clinical experts to ensure data quality and clinical validity.\n\u2022 Collaborate cross-functionally with radiologists, regulatory teams, and product stakeholders to align AI development with clinical requirements and compliance standards.\n\nExperience :\n\u2022 3+ years Data Science / Machine Learning experience\n\nRequired Skills :\n\u2022 Strong programming skills in Python and familiarity with data science and image processing libraries (e.g.,\n\nNumPy, pandas, scikit-learn, OpenCV, PIL).\n\u2022 Strong fundamental knowledge of machine learning, computer vision and image processing.\n\u2022 Hands-on experience with deep learning frameworks like Keras or PyTorch.\n\u2022 Demonstrated experience with both CNNs and transformer-based architectures (e.g., ViT, Swin) for segmentation, detection, and classification tasks.\n\u2022 Strong background with model evaluation and error analysis.\n\u2022 Ability to bridge data science with engineering tasks, ensuring smooth integration of AI models into production workflows.\n\u2022 Hands-on experience with model optimization techniques (e.g distillation, ONNX conversion) for efficient inference.\n\u2022 Hands-on experience with containerization tools like Docker.\n\nDesired Skills :\n\u2022 Familiarity with healthcare / radiology datasets, DICOM standards, and PACS integration.\n\u2022 Experience with domain adaptation, and robustness strategies for cross-site / cross-device generalization.\n\u2022 Experience with scalable backend development for AI applications\n\nQualification :\n\u2022 Bachelors or Masters degree in Computer Science, Data Science, Machine Learning, Statistics, or a related field.\n\n(ref : hirist.tech)",
    "url": "https://in.talent.com/view?id=4a965bcff8b2&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Associate Data Science Engineer",
    "company": "Cognologix",
    "location": "Pune",
    "salary": "",
    "description": "Associate Data Science Engineer\nWe are seeking an experienced Data Science Engineer with 1+ years of experience implementing AI/ML solutions. The role focuses on developing AI applications and developing cloud-native solutions.\n\nYou will work on:\nWe are looking for a self-driven Data Science Professional to be a member of our Data & AI Practice. We help many of our clients in building advanced analytics solutions (from traditional ML to deep learning, Computer Vision, Gen AI & Automation). You will work on some of the cutting-edge AI technologies to build meaningful products & solutions.\nJob Location: Pune\n\nWhat you will do (Responsibilities):\n\u2022 Perform high-level work both independently and collaboratively as a project member.\n\u2022 Collaborate with Product Management team, elicit AI/ML use case specific requirements, explore and evaluate approaches\n\u2022 Develop Computer Vision, NLP, Deep Learning, multi-modal Gen AI based application features & demos according to the requirements and needs.\n\u2022 Explore new tools, technologies, frameworks in ML, DL, CV, Gen AI technologies and experiments.\n\nWhat you bring (Skills):\n\u2022 1+ years of end-to-end project lifecycle experience (Analysis, Design, Development, Testing, Deployment & Monitoring) in building AI application\n\u2022 Sound knowledge in Linear Algebra, Statistics, Probability\n\u2022 Strong Knowledge & Experience in Python and Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK etc.\n\u2022 Experience with machine learning, deep learning, and/or NLP/NLG frameworks (like Keras, TensorFlow or PyTorch etc.), HuggingFace Transformers and libraries (like scikit-learn, spacy, CoreNLP etc.)\n\u2022 Sound Knowledge of deep learning models for computer vision tasks.\n\u2022 Understanding of image processing, Object detection frameworks and image classification areas\n\u2022 Sound Knowledge in Generative AI /LLM\u2019s models, frameworks, tools & technologies.\n\u2022 Experience in Prompt Engineering & Langchain / LlamaIndex.\n\u2022 Excellent analytical, problem solving and communication skills\n\nGreat if you know (Skills):\n\u2022 Experience in Vector search, RAG frameworks, Function Calling, Agentic Frameworks\n\u2022 Exposure to Cloud-based services such as AWS (Preferred), Azure or GCP\n\u2022 Experience with async programming and RESTful APIs (FastAPI)\n\u2022 Sound understanding of CI-CD, Containerization & Orchestration\n\u2022 Experience with Scrum and/or other Agile development processes\n\u2022 Exposure to MlOps, LLMOps \u2013 model and experiment versioning, hyper parameter tuning, model deployment and monitoring aspects\n\u2022 Sound understanding of data visualization aspects\n\nAdvantage Cognologix:\n\u2022 A higher degree of autonomy, startup culture & small teams\n\u2022 Opportunities to become an expert in emerging technologies\n\u2022 Remote working options for the right maturity level\n\u2022 Competitive salary & family benefits\n\u2022 Performance based career advancement\n\nAbout Cognologix:\nCognologix helps companies disrupt by reimagining their business models and innovate like a Startup. We are at the forefront of digital disruption and take a business-first approach to help meet our client\u2019s strategic goals.\nWe are a Data focused organization helping our clients to deliver their next generation of products in the most efficient, modern, and cloud-native way.",
    "url": "https://careers.cognologix.com/jobs/I51tD9YU1xzC/associate-data-science-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T05:00:00.000Z"
  },
  {
    "title": "Lead Data Scientist Gen Ai High Salary Pune",
    "company": "Yash Technologies",
    "location": "Pune",
    "salary": "",
    "description": "Job Overview:\n\nLocations- Indore/Pune/Hyderabad/Bangalore\n\nWe are looking for a AI/ML Developer to join our team of researchers, data scientists, and developers. You will work on cutting-edge AI solutions across industries such as commerce, agriculture, insurance, financial markets, and procurement. Your role involves developing and optimizing machine learning and generative AI models to solve real-world challenges.\n\nKey Responsibilities:\n\n\u2022 Develop and optimize ML, NLP, Deep Learning, and Generative AI models.\n\n\u2022 Research and implement state-of-the-art algorithms for supervised and unsupervised learning.\n\n\u2022 Work with large-scale datasets in distributed environments.\n\n\u2022 Understand business processes to select and apply the best ML approaches.\n\n\u2022 Ensure scalability and performance of ML solutions.\n\n\u2022 Collaborate with cross-functional teams, including product owners, designers, and developers.\n\n\u2022 Solve complex data integration and deployment challenges.\n\n\u2022 Communicate results effectively using data visualization.\n\n\u2022 Work in global teams across different time zones.\n\nRequired Skills & Experience:\n\n\u2022 Robust experience in Machine Learning, Deep Learning, NLP, and Generative AI.\n\n\u2022 Hands-on expertise in frameworks like TensorFlow, PyTorch, or Hugging Face Transformers.\n\n\u2022 Experience with LLMs (Large Language Models), model fine-tuning, and prompt engineering.\n\n\u2022 Proficiency in Python, R, or Scala for ML development.\n\n\u2022 Knowledge of cloud-based ML platforms (AWS, Azure, GCP).\n\n\u2022 Experience with big data processing (Spark, Hadoop, or Dask).\n\n\u2022 Ability to scale ML models from prototypes to production.\n\n\u2022 Solid analytical and problem-solving skills.\n\nIf you\u2019re passionate about pushing the boundaries of ML and GenAI, we\u2019d love to hear from you!",
    "url": "https://in.jobrapido.com/jobpreview/4714194881201831936?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "DATA SCIENCE POWER BI INTERNSHIP PUNE",
    "company": "confidential",
    "location": "Pune",
    "salary": "",
    "description": "Maxgen Technologies Pvt ltd is an it company based in pune .We are offering data science internship with power bi program to engineering and diploma candidates..\n\nBenefit we are offering\n\nenjoying work environment .\n\nsmooth shift timing.\n\nlive project in internship.\n\nlong time or short time internship.\n\nhybrid mode internship.\n\nvisit us\n\ncontact us View phone number on foundit.in, View phone number on foundit.in,View phone number on foundit.in ,View phone number on foundit.in,\n\naddress 6th Floor, Konark Icon, 601, above Maruti Suzuki, Magarpatta, Pune, Maharashtra",
    "url": "https://in.jooble.org/jdp/1298935089934152488?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Enterprise Data Analyst",
    "company": "Snowflake",
    "location": "Pune",
    "salary": "",
    "description": "Snowflake is about empowering enterprises to achieve their full potential \u2014 and people too. With a culture that\u2019s all in on impact, innovation, and collaboration, Snowflake is the sweet spot for building big, moving fast, and taking technology \u2014 and careers \u2014 to the next level.\n\nSnowflake is seeking a Data Scientist to join our expanding Enterprise AI & ML team. This role involves working on diverse AI/ML and data science initiatives, utilizing Snowflake's Data Cloud and Cortex AI. The successful candidate will design and develop scalable data science and machine learning solutions, build interactive AI applications, and collaborate on operationalizing intelligent systems to enhance data-driven decision-making throughout the company. This position focuses on applying data science, AI & ML skill sets to various domain specific business data problems across Snowflake.\n\nON THE DATA SCIENCE & ANALYTICS TEAM AT SNOWFLAKE, YOU WILL:\n\u2022 Design, prototype, and deploy data science and AI solutions.\n\u2022 Conduct end to end experimentation, including data exploration, feature engineering, model development, and validation.\n\u2022 Build and maintain Streamlit applications to visualize models, showcase insights, and enable business stakeholders to interact with AI driven solutions.\n\u2022 Develop and optimize LLM based applications, workflows, and operations; with a focus on retrieval, generation, semantic understanding and fine-tuning.\n\u2022 Partner cross functionally with data engineers, analysts, and product teams to translate ambiguous business problems into measurable outcomes.\n\nOUR IDEAL CANDIDATE WILL HAVE:\n\u2022 2 to 4 years of experience applying data science, machine learning, or AI techniques in real world business settings.\n\u2022 Strong programming skills in Python, proficiency in SQL for large scale data manipulation.\n\u2022 Familiarity with frameworks such as scikit-learn, XGBoost etc.\n\u2022 Understanding of LLM architectures, embeddings, vector search, and RAG pipelines.\n\u2022 Experience working on cloud platforms.\n\u2022 Strong analytical, storytelling, and communication skills to translate technical insights into actionable recommendations.\n\u2022 A mindset of curiosity, ownership, and collaboration, with an eagerness to work on open-ended problems.\n\u2022 Experience operationalizing AI & ML models in a production setting.\n\nSnowflake is growing fast, and we\u2019re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.\n\nHow do you want to make your impact?\n\nFor jobs located in the United States, please visit the job posting on the Snowflake Careers Site for salary and benefits information: careers.snowflake.com",
    "url": "https://builtin.com/job/enterprise-data-analyst/7508278?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Senior Data Scientist (Artificial Intelligence Machine Learning)",
    "company": "FIS Global",
    "location": "Pune",
    "salary": "",
    "description": "Position Type :\n\nFull time\n\nType Of Hire :\n\nExperienced (relevant combo of work and education)\n\nEducation Desired :\n\nBachelor of Engineering\n\nTravel Percentage :\n\n1 - 5%\n\nSenior Data Scientist (Artificial Intelligence Machine Learning)\n\nAre you curious, motivated, and forward-thinking? At FIS you\u2019ll have the opportunity to work on some of the most challenging and relevant issues in financial services and technology. Our talented people empower us, and we believe in being part of a team that is open, collaborative, entrepreneurial, passionate and above all fun.\n\nAbout the role:\n\u2022 We are looking for a talented and passionate Data Scientist willing to challenge themself and produce best in class AI enabled solution\n\u2022 You will be required to use the concepts of AIML, GenAI, LLMs, Sentiment analysis, etc.\n\u2022 The role requires creating correlation between different data points and do predictive, preventive analysis.\n\nAbout the Team :\n\nTeam provide solutions and services that help our clients grow, compete, and optimize their business. Our AIOPS team is creating AIML solution targeted to reduce the Enterprise MTTR through our world class product\n\nWhat you will be doing:\n\u2022 Employ machine learning and statistical modeling to create and enhance data driven products.\n\u2022 Analyze and extract insights from internal and external data.\n\u2022 Work with Big Data and transform complex datasets into more usable formats.\n\u2022 Work with a variety of data science tools and programming languages such as SAS, Python, R, Scala, SQL. Work independently and collaborate with other groups to solve complex problems.\n\u2022 Create and present analyses to internal and external partners and clients.\n\u2022 Will be working in 2 Pm to 11 Pm IST Shifts\n\nWhat you bring:\n\u2022 4 to 6 Years of machine learning, artificial intelligence, statistical modeling, data visualization, and data analysis\n\u2022 Proficient in data science tools and programming languages such as SAS, Python, R, Scala, SQL\n\u2022 Relevant degree in Artificial Intelligence Machine Learning\n\u2022 Experience or knowledge of cloud-based technology\n\u2022 Knowledge of financial services industry\n\nWhat we offer you:\n\u2022 A range of benefits designed to help support your lifestyle and wellbeing.\n\u2022 A multi-faceted job with a broad spectrum of responsibilities\n\u2022 A modern international work environment and a dedicated and innovative team\n\u2022 A broad range of professional education and personal development possibilities \u2013 FIS is your final career step.\n\nPrivacy Statement\n\nFIS is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how FIS protects personal information online, please see the Online Privacy Notice.\n\nSourcing Model\n\nRecruitment at FIS works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. FIS does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company.\n\n#pridepass",
    "url": "https://www.glassdoor.co.in/job-listing/senior-data-scientist-artificial-intelligence-machine-learning-fis-global-JV_IC2856202_KO0,62_KE63,73.htm?jl=1009714190836&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "WFH Machine Learning Jobs in Pune",
    "company": "Turing.com",
    "location": "Pune",
    "salary": "",
    "description": "We, at Turing, are looking for experienced ML engineers who will design and develop machine learning and deep learning systems, machine learning tests and implement Ml algorithms to help in creating AI solutions. Apply for machine learning jobs in Pune and get a chance to work closely with global software engineers, AI/ML enthusiasts and gain unique experiences.",
    "url": "https://www.turing.com/jobs/machine-learning-jobs-in-pune?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Data Scientist- Gen AI (3-5 years exp only)",
    "company": "confidential",
    "location": "Pune",
    "salary": "",
    "description": "As a Data Scientist, you'll play a crucial role in supporting data-driven projects, performing routine data analysis tasks, and assisting with model development and testing. Your role involves contributing to various stages of the data science lifecycle and providing insights that help shape business strategies. This position is suited for those with a foundational understanding of data science and are eager to deepen their expertise.\n\nResponsibilities:\n\u2022 Contribute to more advanced data collection and preprocessing efforts.\n\u2022 Assist in developing and testing machine learning models.\n\u2022 Perform descriptive data analysis and provide preliminary insights.\n\u2022 Create visualizations and reports to support data findings.\n\u2022 Manage and maintain data repositories efficiently.\n\u2022 Support senior data scientists in feature creation and selection.\n\u2022 Participate in collaborative projects with cross-functional teams.\n\u2022 Help automate data processing tasks using scripts.\n\u2022 Contribute to model validation and performance testing.\n\u2022 Stay informed about emerging data science tools and methodologies.\n\nSkills:\n\u2022 Advanced Data Cleaning: Enhanced preprocessing and data wrangling techniques.\n\u2022 Intermediate Python: Proficiency in Python for data science tasks.\n\u2022 SQL: More advanced SQL querying skills.\n\u2022 Data Visualization: Ability to create meaningful visualizations using tools like Tableau or Matplotlib.\n\u2022 Machine Learning Basics: Understanding of basic machine learning concepts and algorithms.\n\u2022 Statistical Analysis: Intermediate statistical methods and their applications.\n\u2022 Communication: Articulating data insights clearly to non-technical stakeholders.\n\u2022 Problem-Solving: Effective in identifying data-related issues and providing solutions.\n\nApplicants may be required to appear onsite at a Wolters Kluwer office as part of the recruitment process.",
    "url": "https://in.jooble.org/jdp/-5701870864767254657?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "Lead Data Scientist Gen Ai High Salary Pune",
    "company": "Yash Technologies",
    "location": "Pune",
    "salary": "",
    "description": "Job Overview:\n\nLocations- Indore/Pune/Hyderabad/Bangalore\n\nWe are looking for a AI/ML Developer to join our team of researchers, data scientists, and developers. You will work on cutting-edge AI solutions across industries such as commerce, agriculture, insurance, financial markets, and procurement. Your role involves developing and optimizing machine learning and generative AI models to solve real-world challenges.\n\nKey Responsibilities:\n\n\u2022 Develop and optimize ML, NLP, Deep Learning, and Generative AI models.\n\n\u2022 Research and implement state-of-the-art algorithms for supervised and unsupervised learning.\n\n\u2022 Work with large-scale datasets in distributed environments.\n\n\u2022 Understand business processes to select and apply the best ML approaches.\n\n\u2022 Ensure scalability and performance of ML solutions.\n\n\u2022 Collaborate with cross-functional teams, including product owners, designers, and developers.\n\n\u2022 Solve complex data integration and deployment challenges.\n\n\u2022 Communicate results effectively using data visualization.\n\n\u2022 Work in global teams across different time zones.\n\nRequired Skills & Experience:\n\n\u2022 Robust experience in Machine Learning, Deep Learning, NLP, and Generative AI.\n\n\u2022 Hands-on expertise in frameworks like TensorFlow, PyTorch, or Hugging Face Transformers.\n\n\u2022 Experience with LLMs (Large Language Models), model fine-tuning, and prompt engineering.\n\n\u2022 Proficiency in Python, R, or Scala for ML development.\n\n\u2022 Knowledge of cloud-based ML platforms (AWS, Azure, GCP).\n\n\u2022 Experience with big data processing (Spark, Hadoop, or Dask).\n\n\u2022 Ability to scale ML models from prototypes to production.\n\n\u2022 Solid analytical and problem-solving skills.\n\nIf you\u2019re passionate about pushing the boundaries of ML and GenAI, we\u2019d love to hear from you!",
    "url": "https://in.jobrapido.com/jobpreview/4714194881201831936?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "DeepTek.ai - Senior Data Scientist - Python / Deep Learning",
    "company": "DeepTek Medical Imaging Pvt Ltd",
    "location": "Pune",
    "salary": "",
    "description": "Description :\n\nKey Responsibilities :\n\u2022 Lead the design, development, and optimization of deep learning models for medical image analysis, including tasks like segmentation, classification, object detection.\n\u2022 Provide technical leadership and mentorship to junior data scientists and engineers, fostering best practices in research methodology, coding standards, and documentation.\n\u2022 Perform advanced error analysis, bias assessment, and domain generalization studies to ensure robustness across diverse populations and imaging devices.\n\u2022 Guide data storage, preprocessing and annotation strategies, collaborating with clinical experts to ensure data quality and clinical validity.\n\u2022 Collaborate cross-functionally with radiologists, regulatory teams, and product stakeholders to align AI development with clinical requirements and compliance standards.\n\nExperience :\n\u2022 3+ years Data Science / Machine Learning experience\n\nRequired Skills :\n\u2022 Strong programming skills in Python and familiarity with data science and image processing libraries (e.g.,\n\nNumPy, pandas, scikit-learn, OpenCV, PIL).\n\u2022 Strong fundamental knowledge of machine learning, computer vision and image processing.\n\u2022 Hands-on experience with deep learning frameworks like Keras or PyTorch.\n\u2022 Demonstrated experience with both CNNs and transformer-based architectures (e.g., ViT, Swin) for segmentation, detection, and classification tasks.\n\u2022 Strong background with model evaluation and error analysis.\n\u2022 Ability to bridge data science with engineering tasks, ensuring smooth integration of AI models into production workflows.\n\u2022 Hands-on experience with model optimization techniques (e.g distillation, ONNX conversion) for efficient inference.\n\u2022 Hands-on experience with containerization tools like Docker.\n\nDesired Skills :\n\u2022 Familiarity with healthcare / radiology datasets, DICOM standards, and PACS integration.\n\u2022 Experience with domain adaptation, and robustness strategies for cross-site / cross-device generalization.\n\u2022 Experience with scalable backend development for AI applications\n\nQualification :\n\u2022 Bachelors or Masters degree in Computer Science, Data Science, Machine Learning, Statistics, or a related field.\n\n(ref : hirist.tech)",
    "url": "https://in.talent.com/view?id=4a965bcff8b2&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Python & ML Intern (Data Science Track)",
    "company": "Skillfied Mentor Jobs",
    "location": "Pune",
    "salary": "",
    "description": "Python & ML Intern (Data Science Track)\n\nLocation: Remote / Virtual\n\nInternship Type: Unpaid (Stipend available for top performers)\n\nSchedule: Flexible duration & working hours\n\nAbout the Internship\n\nKickstart your journey into Data Science & Machine Learning with this internship crafted for students and fresh graduates. Gain hands-on experience in Python, ML algorithms, and data-driven solutions, while working on real-world projects under the guidance of expert mentors.\n\nWhat You'll Learn:\n\nHands-on projects in\nPython, Machine Learning & Data Science\n\nData preprocessing, visualization & model building\n\nReal-world applications of ML in different industries\n\nWhy Join Us?\n\nWork on\nlive projects\nguided by expert mentors\n\nBuild a\nstrong portfolio\nfor your career in Data Science\n\nEarn an\nISO Certified Internship Certificate\n\nEligibility:\n\nStudents & freshers passionate about\nPython, ML & Data Science\n\nBasic knowledge of Python/Maths/Statistics will be a plus\n\nApplication Deadline: 5th September 2025\n\nKickstart your career in\nData Science & Machine Learning\nwith our ISO Certified Internship",
    "url": "https://www.recruit.net/job/python-ml-data-science-track-jobs/A1A1222481411831?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Associate Data Science Engineer",
    "company": "Cognologix",
    "location": "Pune",
    "salary": "",
    "description": "Associate Data Science Engineer\nWe are seeking an experienced Data Science Engineer with 1+ years of experience implementing AI/ML solutions. The role focuses on developing AI applications and developing cloud-native solutions.\n\nYou will work on:\nWe are looking for a self-driven Data Science Professional to be a member of our Data & AI Practice. We help many of our clients in building advanced analytics solutions (from traditional ML to deep learning, Computer Vision, Gen AI & Automation). You will work on some of the cutting-edge AI technologies to build meaningful products & solutions.\nJob Location: Pune\n\nWhat you will do (Responsibilities):\n\u2022 Perform high-level work both independently and collaboratively as a project member.\n\u2022 Collaborate with Product Management team, elicit AI/ML use case specific requirements, explore and evaluate approaches\n\u2022 Develop Computer Vision, NLP, Deep Learning, multi-modal Gen AI based application features & demos according to the requirements and needs.\n\u2022 Explore new tools, technologies, frameworks in ML, DL, CV, Gen AI technologies and experiments.\n\nWhat you bring (Skills):\n\u2022 1+ years of end-to-end project lifecycle experience (Analysis, Design, Development, Testing, Deployment & Monitoring) in building AI application\n\u2022 Sound knowledge in Linear Algebra, Statistics, Probability\n\u2022 Strong Knowledge & Experience in Python and Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK etc.\n\u2022 Experience with machine learning, deep learning, and/or NLP/NLG frameworks (like Keras, TensorFlow or PyTorch etc.), HuggingFace Transformers and libraries (like scikit-learn, spacy, CoreNLP etc.)\n\u2022 Sound Knowledge of deep learning models for computer vision tasks.\n\u2022 Understanding of image processing, Object detection frameworks and image classification areas\n\u2022 Sound Knowledge in Generative AI /LLM\u2019s models, frameworks, tools & technologies.\n\u2022 Experience in Prompt Engineering & Langchain / LlamaIndex.\n\u2022 Excellent analytical, problem solving and communication skills\n\nGreat if you know (Skills):\n\u2022 Experience in Vector search, RAG frameworks, Function Calling, Agentic Frameworks\n\u2022 Exposure to Cloud-based services such as AWS (Preferred), Azure or GCP\n\u2022 Experience with async programming and RESTful APIs (FastAPI)\n\u2022 Sound understanding of CI-CD, Containerization & Orchestration\n\u2022 Experience with Scrum and/or other Agile development processes\n\u2022 Exposure to MlOps, LLMOps \u2013 model and experiment versioning, hyper parameter tuning, model deployment and monitoring aspects\n\u2022 Sound understanding of data visualization aspects\n\nAdvantage Cognologix:\n\u2022 A higher degree of autonomy, startup culture & small teams\n\u2022 Opportunities to become an expert in emerging technologies\n\u2022 Remote working options for the right maturity level\n\u2022 Competitive salary & family benefits\n\u2022 Performance based career advancement\n\nAbout Cognologix:\nCognologix helps companies disrupt by reimagining their business models and innovate like a Startup. We are at the forefront of digital disruption and take a business-first approach to help meet our client\u2019s strategic goals.\nWe are a Data focused organization helping our clients to deliver their next generation of products in the most efficient, modern, and cloud-native way.",
    "url": "https://careers.cognologix.com/jobs/I51tD9YU1xzC/associate-data-science-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T05:00:00.000Z"
  },
  {
    "title": "Data Scientist (AI_ML & Analytics) (Pune)",
    "company": "Quloi",
    "location": "Pune",
    "salary": "",
    "description": "Work with Product to shape requirements and easy solution flows including light UI with DevOps on data compute, deployments, partner with Frontend Backend to integrate models into our MERN + GraphQL platform. done ML solution to production.",
    "url": "https://in.jobrapido.com/jobpreview/2846817867691720704?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "DATA SCIENCE POWER BI INTERNSHIP PUNE",
    "company": "confidential",
    "location": "Pune",
    "salary": "",
    "description": "Maxgen Technologies Pvt ltd is an it company based in pune .We are offering data science internship with power bi program to engineering and diploma candidates..\n\nBenefit we are offering\n\nenjoying work environment .\n\nsmooth shift timing.\n\nlive project in internship.\n\nlong time or short time internship.\n\nhybrid mode internship.\n\nvisit us\n\ncontact us View phone number on foundit.in, View phone number on foundit.in,View phone number on foundit.in ,View phone number on foundit.in,\n\naddress 6th Floor, Konark Icon, 601, above Maruti Suzuki, Magarpatta, Pune, Maharashtra",
    "url": "https://in.jooble.org/jdp/1298935089934152488?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Enterprise Data Analyst",
    "company": "Snowflake",
    "location": "Pune",
    "salary": "",
    "description": "Snowflake is about empowering enterprises to achieve their full potential \u2014 and people too. With a culture that\u2019s all in on impact, innovation, and collaboration, Snowflake is the sweet spot for building big, moving fast, and taking technology \u2014 and careers \u2014 to the next level.\n\nSnowflake is seeking a Data Scientist to join our expanding Enterprise AI & ML team. This role involves working on diverse AI/ML and data science initiatives, utilizing Snowflake's Data Cloud and Cortex AI. The successful candidate will design and develop scalable data science and machine learning solutions, build interactive AI applications, and collaborate on operationalizing intelligent systems to enhance data-driven decision-making throughout the company. This position focuses on applying data science, AI & ML skill sets to various domain specific business data problems across Snowflake.\n\nON THE DATA SCIENCE & ANALYTICS TEAM AT SNOWFLAKE, YOU WILL:\n\u2022 Design, prototype, and deploy data science and AI solutions.\n\u2022 Conduct end to end experimentation, including data exploration, feature engineering, model development, and validation.\n\u2022 Build and maintain Streamlit applications to visualize models, showcase insights, and enable business stakeholders to interact with AI driven solutions.\n\u2022 Develop and optimize LLM based applications, workflows, and operations; with a focus on retrieval, generation, semantic understanding and fine-tuning.\n\u2022 Partner cross functionally with data engineers, analysts, and product teams to translate ambiguous business problems into measurable outcomes.\n\nOUR IDEAL CANDIDATE WILL HAVE:\n\u2022 2 to 4 years of experience applying data science, machine learning, or AI techniques in real world business settings.\n\u2022 Strong programming skills in Python, proficiency in SQL for large scale data manipulation.\n\u2022 Familiarity with frameworks such as scikit-learn, XGBoost etc.\n\u2022 Understanding of LLM architectures, embeddings, vector search, and RAG pipelines.\n\u2022 Experience working on cloud platforms.\n\u2022 Strong analytical, storytelling, and communication skills to translate technical insights into actionable recommendations.\n\u2022 A mindset of curiosity, ownership, and collaboration, with an eagerness to work on open-ended problems.\n\u2022 Experience operationalizing AI & ML models in a production setting.\n\nSnowflake is growing fast, and we\u2019re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.\n\nHow do you want to make your impact?\n\nFor jobs located in the United States, please visit the job posting on the Snowflake Careers Site for salary and benefits information: careers.snowflake.com",
    "url": "https://builtin.com/job/enterprise-data-analyst/7508278?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Data Scientist- Gen AI (3-5 years exp only)",
    "company": "confidential",
    "location": "Pune",
    "salary": "",
    "description": "As a Data Scientist, you'll play a crucial role in supporting data-driven projects, performing routine data analysis tasks, and assisting with model development and testing. Your role involves contributing to various stages of the data science lifecycle and providing insights that help shape business strategies. This position is suited for those with a foundational understanding of data science and are eager to deepen their expertise.\n\nResponsibilities:\n\u2022 Contribute to more advanced data collection and preprocessing efforts.\n\u2022 Assist in developing and testing machine learning models.\n\u2022 Perform descriptive data analysis and provide preliminary insights.\n\u2022 Create visualizations and reports to support data findings.\n\u2022 Manage and maintain data repositories efficiently.\n\u2022 Support senior data scientists in feature creation and selection.\n\u2022 Participate in collaborative projects with cross-functional teams.\n\u2022 Help automate data processing tasks using scripts.\n\u2022 Contribute to model validation and performance testing.\n\u2022 Stay informed about emerging data science tools and methodologies.\n\nSkills:\n\u2022 Advanced Data Cleaning: Enhanced preprocessing and data wrangling techniques.\n\u2022 Intermediate Python: Proficiency in Python for data science tasks.\n\u2022 SQL: More advanced SQL querying skills.\n\u2022 Data Visualization: Ability to create meaningful visualizations using tools like Tableau or Matplotlib.\n\u2022 Machine Learning Basics: Understanding of basic machine learning concepts and algorithms.\n\u2022 Statistical Analysis: Intermediate statistical methods and their applications.\n\u2022 Communication: Articulating data insights clearly to non-technical stakeholders.\n\u2022 Problem-Solving: Effective in identifying data-related issues and providing solutions.\n\nApplicants may be required to appear onsite at a Wolters Kluwer office as part of the recruitment process.",
    "url": "https://in.jooble.org/jdp/-5701870864767254657?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "Lead Data Scientist Gen Ai High Salary Pune",
    "company": "Yash Technologies",
    "location": "Pune",
    "salary": "",
    "description": "Job Overview:\n\nLocations- Indore/Pune/Hyderabad/Bangalore\n\nWe are looking for a AI/ML Developer to join our team of researchers, data scientists, and developers. You will work on cutting-edge AI solutions across industries such as commerce, agriculture, insurance, financial markets, and procurement. Your role involves developing and optimizing machine learning and generative AI models to solve real-world challenges.\n\nKey Responsibilities:\n\n\u2022 Develop and optimize ML, NLP, Deep Learning, and Generative AI models.\n\n\u2022 Research and implement state-of-the-art algorithms for supervised and unsupervised learning.\n\n\u2022 Work with large-scale datasets in distributed environments.\n\n\u2022 Understand business processes to select and apply the best ML approaches.\n\n\u2022 Ensure scalability and performance of ML solutions.\n\n\u2022 Collaborate with cross-functional teams, including product owners, designers, and developers.\n\n\u2022 Solve complex data integration and deployment challenges.\n\n\u2022 Communicate results effectively using data visualization.\n\n\u2022 Work in global teams across different time zones.\n\nRequired Skills & Experience:\n\n\u2022 Robust experience in Machine Learning, Deep Learning, NLP, and Generative AI.\n\n\u2022 Hands-on expertise in frameworks like TensorFlow, PyTorch, or Hugging Face Transformers.\n\n\u2022 Experience with LLMs (Large Language Models), model fine-tuning, and prompt engineering.\n\n\u2022 Proficiency in Python, R, or Scala for ML development.\n\n\u2022 Knowledge of cloud-based ML platforms (AWS, Azure, GCP).\n\n\u2022 Experience with big data processing (Spark, Hadoop, or Dask).\n\n\u2022 Ability to scale ML models from prototypes to production.\n\n\u2022 Solid analytical and problem-solving skills.\n\nIf you\u2019re passionate about pushing the boundaries of ML and GenAI, we\u2019d love to hear from you!",
    "url": "https://in.jobrapido.com/jobpreview/4714194881201831936?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "WFH Machine Learning Jobs in Pune",
    "company": "Turing.com",
    "location": "Pune",
    "salary": "",
    "description": "We, at Turing, are looking for experienced ML engineers who will design and develop machine learning and deep learning systems, machine learning tests and implement Ml algorithms to help in creating AI solutions. Apply for machine learning jobs in Pune and get a chance to work closely with global software engineers, AI/ML enthusiasts and gain unique experiences.",
    "url": "https://www.turing.com/jobs/machine-learning-jobs-in-pune?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Senior Data Scientist (Artificial Intelligence Machine Learning)",
    "company": "FIS Global",
    "location": "Pune",
    "salary": "",
    "description": "Position Type :\n\nFull time\n\nType Of Hire :\n\nExperienced (relevant combo of work and education)\n\nEducation Desired :\n\nBachelor of Engineering\n\nTravel Percentage :\n\n1 - 5%\n\nSenior Data Scientist (Artificial Intelligence Machine Learning)\n\nAre you curious, motivated, and forward-thinking? At FIS you\u2019ll have the opportunity to work on some of the most challenging and relevant issues in financial services and technology. Our talented people empower us, and we believe in being part of a team that is open, collaborative, entrepreneurial, passionate and above all fun.\n\nAbout the role:\n\u2022 We are looking for a talented and passionate Data Scientist willing to challenge themself and produce best in class AI enabled solution\n\u2022 You will be required to use the concepts of AIML, GenAI, LLMs, Sentiment analysis, etc.\n\u2022 The role requires creating correlation between different data points and do predictive, preventive analysis.\n\nAbout the Team :\n\nTeam provide solutions and services that help our clients grow, compete, and optimize their business. Our AIOPS team is creating AIML solution targeted to reduce the Enterprise MTTR through our world class product\n\nWhat you will be doing:\n\u2022 Employ machine learning and statistical modeling to create and enhance data driven products.\n\u2022 Analyze and extract insights from internal and external data.\n\u2022 Work with Big Data and transform complex datasets into more usable formats.\n\u2022 Work with a variety of data science tools and programming languages such as SAS, Python, R, Scala, SQL. Work independently and collaborate with other groups to solve complex problems.\n\u2022 Create and present analyses to internal and external partners and clients.\n\u2022 Will be working in 2 Pm to 11 Pm IST Shifts\n\nWhat you bring:\n\u2022 4 to 6 Years of machine learning, artificial intelligence, statistical modeling, data visualization, and data analysis\n\u2022 Proficient in data science tools and programming languages such as SAS, Python, R, Scala, SQL\n\u2022 Relevant degree in Artificial Intelligence Machine Learning\n\u2022 Experience or knowledge of cloud-based technology\n\u2022 Knowledge of financial services industry\n\nWhat we offer you:\n\u2022 A range of benefits designed to help support your lifestyle and wellbeing.\n\u2022 A multi-faceted job with a broad spectrum of responsibilities\n\u2022 A modern international work environment and a dedicated and innovative team\n\u2022 A broad range of professional education and personal development possibilities \u2013 FIS is your final career step.\n\nPrivacy Statement\n\nFIS is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how FIS protects personal information online, please see the Online Privacy Notice.\n\nSourcing Model\n\nRecruitment at FIS works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. FIS does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company.\n\n#pridepass",
    "url": "https://www.glassdoor.co.in/job-listing/senior-data-scientist-artificial-intelligence-machine-learning-fis-global-JV_IC2856202_KO0,62_KE63,73.htm?jl=1009714190836&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Associate Data Science Engineer",
    "company": "Cognologix",
    "location": "Pune",
    "salary": "",
    "description": "Associate Data Science Engineer\nWe are seeking an experienced Data Science Engineer with 1+ years of experience implementing AI/ML solutions. The role focuses on developing AI applications and developing cloud-native solutions.\n\nYou will work on:\nWe are looking for a self-driven Data Science Professional to be a member of our Data & AI Practice. We help many of our clients in building advanced analytics solutions (from traditional ML to deep learning, Computer Vision, Gen AI & Automation). You will work on some of the cutting-edge AI technologies to build meaningful products & solutions.\nJob Location: Pune\n\nWhat you will do (Responsibilities):\n\u2022 Perform high-level work both independently and collaboratively as a project member.\n\u2022 Collaborate with Product Management team, elicit AI/ML use case specific requirements, explore and evaluate approaches\n\u2022 Develop Computer Vision, NLP, Deep Learning, multi-modal Gen AI based application features & demos according to the requirements and needs.\n\u2022 Explore new tools, technologies, frameworks in ML, DL, CV, Gen AI technologies and experiments.\n\nWhat you bring (Skills):\n\u2022 1+ years of end-to-end project lifecycle experience (Analysis, Design, Development, Testing, Deployment & Monitoring) in building AI application\n\u2022 Sound knowledge in Linear Algebra, Statistics, Probability\n\u2022 Strong Knowledge & Experience in Python and Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK etc.\n\u2022 Experience with machine learning, deep learning, and/or NLP/NLG frameworks (like Keras, TensorFlow or PyTorch etc.), HuggingFace Transformers and libraries (like scikit-learn, spacy, CoreNLP etc.)\n\u2022 Sound Knowledge of deep learning models for computer vision tasks.\n\u2022 Understanding of image processing, Object detection frameworks and image classification areas\n\u2022 Sound Knowledge in Generative AI /LLM\u2019s models, frameworks, tools & technologies.\n\u2022 Experience in Prompt Engineering & Langchain / LlamaIndex.\n\u2022 Excellent analytical, problem solving and communication skills\n\nGreat if you know (Skills):\n\u2022 Experience in Vector search, RAG frameworks, Function Calling, Agentic Frameworks\n\u2022 Exposure to Cloud-based services such as AWS (Preferred), Azure or GCP\n\u2022 Experience with async programming and RESTful APIs (FastAPI)\n\u2022 Sound understanding of CI-CD, Containerization & Orchestration\n\u2022 Experience with Scrum and/or other Agile development processes\n\u2022 Exposure to MlOps, LLMOps \u2013 model and experiment versioning, hyper parameter tuning, model deployment and monitoring aspects\n\u2022 Sound understanding of data visualization aspects\n\nAdvantage Cognologix:\n\u2022 A higher degree of autonomy, startup culture & small teams\n\u2022 Opportunities to become an expert in emerging technologies\n\u2022 Remote working options for the right maturity level\n\u2022 Competitive salary & family benefits\n\u2022 Performance based career advancement\n\nAbout Cognologix:\nCognologix helps companies disrupt by reimagining their business models and innovate like a Startup. We are at the forefront of digital disruption and take a business-first approach to help meet our client\u2019s strategic goals.\nWe are a Data focused organization helping our clients to deliver their next generation of products in the most efficient, modern, and cloud-native way.",
    "url": "https://careers.cognologix.com/jobs/I51tD9YU1xzC/associate-data-science-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T05:00:00.000Z"
  },
  {
    "title": "Python & ML Intern (Data Science Track)",
    "company": "Skillfied Mentor Jobs",
    "location": "Pune",
    "salary": "",
    "description": "Python & ML Intern (Data Science Track)\n\nLocation: Remote / Virtual\n\nInternship Type: Unpaid (Stipend available for top performers)\n\nSchedule: Flexible duration & working hours\n\nAbout the Internship\n\nKickstart your journey into Data Science & Machine Learning with this internship crafted for students and fresh graduates. Gain hands-on experience in Python, ML algorithms, and data-driven solutions, while working on real-world projects under the guidance of expert mentors.\n\nWhat You'll Learn:\n\nHands-on projects in\nPython, Machine Learning & Data Science\n\nData preprocessing, visualization & model building\n\nReal-world applications of ML in different industries\n\nWhy Join Us?\n\nWork on\nlive projects\nguided by expert mentors\n\nBuild a\nstrong portfolio\nfor your career in Data Science\n\nEarn an\nISO Certified Internship Certificate\n\nEligibility:\n\nStudents & freshers passionate about\nPython, ML & Data Science\n\nBasic knowledge of Python/Maths/Statistics will be a plus\n\nApplication Deadline: 5th September 2025\n\nKickstart your career in\nData Science & Machine Learning\nwith our ISO Certified Internship",
    "url": "https://www.recruit.net/job/python-ml-data-science-track-jobs/A1A1222481411831?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "DATA SCIENCE POWER BI INTERNSHIP PUNE",
    "company": "confidential",
    "location": "Pune",
    "salary": "",
    "description": "Maxgen Technologies Pvt ltd is an it company based in pune .We are offering data science internship with power bi program to engineering and diploma candidates..\n\nBenefit we are offering\n\nenjoying work environment .\n\nsmooth shift timing.\n\nlive project in internship.\n\nlong time or short time internship.\n\nhybrid mode internship.\n\nvisit us\n\ncontact us View phone number on foundit.in, View phone number on foundit.in,View phone number on foundit.in ,View phone number on foundit.in,\n\naddress 6th Floor, Konark Icon, 601, above Maruti Suzuki, Magarpatta, Pune, Maharashtra",
    "url": "https://in.jooble.org/jdp/1298935089934152488?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (AI_ML & Analytics) (Pune)",
    "company": "Quloi",
    "location": "Pune",
    "salary": "",
    "description": "Work with Product to shape requirements and easy solution flows including light UI with DevOps on data compute, deployments, partner with Frontend Backend to integrate models into our MERN + GraphQL platform. done ML solution to production.",
    "url": "https://in.jobrapido.com/jobpreview/2846817867691720704?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "DeepTek.ai - Senior Data Scientist - Python / Deep Learning",
    "company": "DeepTek Medical Imaging Pvt Ltd",
    "location": "Pune",
    "salary": "",
    "description": "Description :\n\nKey Responsibilities :\n\u2022 Lead the design, development, and optimization of deep learning models for medical image analysis, including tasks like segmentation, classification, object detection.\n\u2022 Provide technical leadership and mentorship to junior data scientists and engineers, fostering best practices in research methodology, coding standards, and documentation.\n\u2022 Perform advanced error analysis, bias assessment, and domain generalization studies to ensure robustness across diverse populations and imaging devices.\n\u2022 Guide data storage, preprocessing and annotation strategies, collaborating with clinical experts to ensure data quality and clinical validity.\n\u2022 Collaborate cross-functionally with radiologists, regulatory teams, and product stakeholders to align AI development with clinical requirements and compliance standards.\n\nExperience :\n\u2022 3+ years Data Science / Machine Learning experience\n\nRequired Skills :\n\u2022 Strong programming skills in Python and familiarity with data science and image processing libraries (e.g.,\n\nNumPy, pandas, scikit-learn, OpenCV, PIL).\n\u2022 Strong fundamental knowledge of machine learning, computer vision and image processing.\n\u2022 Hands-on experience with deep learning frameworks like Keras or PyTorch.\n\u2022 Demonstrated experience with both CNNs and transformer-based architectures (e.g., ViT, Swin) for segmentation, detection, and classification tasks.\n\u2022 Strong background with model evaluation and error analysis.\n\u2022 Ability to bridge data science with engineering tasks, ensuring smooth integration of AI models into production workflows.\n\u2022 Hands-on experience with model optimization techniques (e.g distillation, ONNX conversion) for efficient inference.\n\u2022 Hands-on experience with containerization tools like Docker.\n\nDesired Skills :\n\u2022 Familiarity with healthcare / radiology datasets, DICOM standards, and PACS integration.\n\u2022 Experience with domain adaptation, and robustness strategies for cross-site / cross-device generalization.\n\u2022 Experience with scalable backend development for AI applications\n\nQualification :\n\u2022 Bachelors or Masters degree in Computer Science, Data Science, Machine Learning, Statistics, or a related field.\n\n(ref : hirist.tech)",
    "url": "https://in.talent.com/view?id=4a965bcff8b2&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Urgent Search! Senior Data Scientist Pune",
    "company": "Elevarae",
    "location": "Pune",
    "salary": "",
    "description": "We\u2019re Hiring \u2013 Data Science Offshore Leads (Life Sciences | PI \u2013 Oil & Energy)\n\nElevarae is hiring two experienced Data Science Offshore Leads for our client, a global technology leader driving innovation across industries. These are immediate requirements for hybrid roles based in Pune \u2014 ideal for professionals ready to join immediately or within a short notice period.\nLocation: Pune (Hybrid)\nExperience: 8\u201312 years\nEducation: Bachelor\u2019s and Master\u2019s in Engineering/Technology\nJoin: Immediate to Early Joiners\n\nOpen Positions:\n\nData Science Offshore Lead \u2013 Life Sciences Domain\n\nData Science Offshore Lead \u2013 PI, Oil & Energy Domain\n\nKey Responsibilities\nLead and execute multiple Tier-1 client projects involving advanced Data Science techniques (AI, ML, GenAI).\nManage the complete Data Science lifecycle \u2014 from problem comprehension and analytical solution development to deployment and post-delivery support.\nAct as the primary client contact for discussions, presentations, and requirement gathering.\nGuide cross-functional teams and ensure technical excellence and business alignment.\nCollaborate with domain experts, business stakeholders, and engineering teams to deliver high-impact analytical solutions.\n\nEssential Skills (Must Have)\nDeep expertise in AI/ML/GenAI algorithms, methodologies, and end-to-end lifecycle including MLOps and post-deployment model support.\nRobust comprehension of complex business problems in Life Sciences or Oil & Energy domains.\nExceptional articulation and communication skills to bridge technical and business perspectives.\nAdvanced analytical and problem-solving ability for actionable insights and strategic outcomes.\n\nAdditional Skills (Valuable to Have)\nExposure to cloud platforms (AWS / Azure / GCP), DevOps, and deployment frameworks.\nExperience leading agile teams and using agile methodology.\nFamiliarity with data visualization tools (Tableau, Power BI).\nUnderstanding of data engineering principles and big data ecosystems.\n\nIf you\u2019re an experienced Data Science skilled looking to make an impact in complex, high-visibility projects \u2014 we\u2019d love to hear from you.\nHiring #DataScience #AI #ML #GenAI #LifeSciences #OilAndEnergy #Elevarae #DataScienceJobs #HybridWork #ImmediateJoiners #PuneJobs",
    "url": "https://in.jobrapido.com/jobpreview/5956365943658512384?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Data Science Mentor / Faculty",
    "company": "Greamio Technologies Pvt. Ltd",
    "location": "Pune",
    "salary": "",
    "description": "Call: 9225586827 (Mon to Sat / 11 am - 6 pm)\n\nCompany Name: Greamio Technologies Private Limited\n\nJob Title: Data Science Trainer\n\nLocation: Pune\n\nSalary: \u20b920,000 - \u20b930,000\n\nEmployment Type: Full-Time\n\nJob Description:\n\nWe are looking for a highly motivated and skilled Data Science Trainer to join our team. The ideal candidate will have a passion for teaching and a deep understanding of data science concepts, tools, and methodologies. The trainer will be responsible for delivering high-quality training to students, helping them build a solid foundation in data science, and guiding them through practical projects.\n\nKey Responsibilities:\n\u2022 Deliver engaging and interactive training sessions on various data science topics, including statistics, machine learning, data visualization, and programming (Python).\n\u2022 Design and develop course materials, assignments, quizzes, and hands-on projects.\n\u2022 Mentor and guide students through practical exercises and real-world applications.\n\u2022 Provide timely feedback and support to students on their progress and performance.\n\u2022 Stay up-to-date with the latest trends and advancements in data science and incorporate them into the curriculum.\n\u2022 Conduct assessments and evaluations to measure the effectiveness of the training program.\n\u2022 Adapt teaching methods and materials to meet the diverse needs of learners in both online and classroom settings.\n\nRequirements:\n\u2022 Bachelor's or Master's degree in Computer Science, Statistics, or a related field.\n\u2022 Proven experience as a Data Science Trainer or similar role.\n\u2022 Proficiency in programming languages such as Python, C, and SQL.\n\u2022 Strong knowledge of data science tools and platforms (e.g., Jupyter, TensorFlow, Pandas, NumPy, Scikit-learn).\n\u2022 Excellent communication and presentation skills.\n\u2022 Ability to explain complex concepts in a simple and clear manner.\n\u2022 Experience in mentoring or teaching is preferred.\n\u2022 Certifications in data science or related fields are a plus.\n\nPreferred Skills:\n\u2022 \u00b7 Hands-on experience with data analytics, machine learning models, and big data tools.\n\u2022 \u00b7 Familiarity with cloud platforms (AWS, Google Cloud, Azure) for data science projects.\n\u2022 \u00b7 Ability to design project-based learning experiences for students.\n\nJob Types: Full-time, Part-time, Permanent, Freelance\n\nPay: \u20b920,000.00 - \u20b935,000.00 per month\n\nWork Location: In person",
    "url": "https://www.simplyhired.co.in/job/OGz9kM7VP71souZayRLVyJSVmjuB859UGT9xjMwSBZi08BEMNl-Nsw?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Senior Analyst, Big Data Analytics & Engineering",
    "company": "Mastercard",
    "location": "Pune",
    "salary": "",
    "description": "Our Purpose\n\nMastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we\u2019re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.\n\nTitle and Summary\n\nSenior Analyst, Big Data Analytics & Engineering\n\nAbout Mastercard\nMastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.\nOur decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.\n\nPosition Overview:\n\nThe candidate for this position will focus on Data Unification across different data assets, enabling a single unified view of data from multiple sources and support the development of new innovative data driven products, services and actionable insights that will help business to take decisions.\n\nExperience with LLMs or generative AI for automation to build data pipelines & AI - Enhanced Data Processing.\n\nThe Role:\nWe are seeking a Senior Analyst, Data Unification & Analytics who will:\n\n\u2022 Perform data ingestion, aggregation, processing to drive and enable relevant insights from available data sets.\n\u2022 Partner with various teams (i.e., Product Manager, Data Science, Platform Strategy, Technology) on data needs/requirements in order to deliver data solutions that generate business value.\n\u2022 Manipulate and analyze complex, high-volume, high-dimensionality data from varying sources using a variety of tools and data analysis techniques.\n\u2022 Identify innovative ideas and deliver proof of concepts, prototypes to deliver against the existing and future needs and propose new products, services and enhancements.\n\u2022 Integrate new data assets which increase the value proposition for our customers and enhance our existing solutions and services.\n\u2022 Analyse large volumes of transaction and product data to generate insights and actionable recommendations to drive business growth\n\u2022 Collect and synthesize feedback from clients, development, product and sales teams for new solutions or product enhancements.\n\u2022 Apply knowledge of metrics, measurements, and benchmarking to complex and demanding solutions.\n\nAll about You\n\u2022 Good understanding of Python \u2013 Pandas, Numpy, PySpark and Impala.\n\u2022 Experience in doing data analysis and extraction on Hadoop.\n\u2022 Experience with Enterprise Business Intelligence Platform/Data platform.\n\u2022 Strong SQL and higher-level programming languages with solid knowledge of data mining, machine learning algorithms and tools\n\u2022 Experience with data integration tools \u2013 ETL/ELT tools (i.e. Apache NiFi, Azure Data Factory, Pentaho, Talend)\n\u2022 Experience with Graph Database is a plus.\n\u2022 Experience in hands-on data modeling, programming, querying, data mining and report development using large volumes of granular data to deliver business intelligence and custom reporting solutions.\n\u2022 Exposure to collecting and/or working with data including standardizing, summarizing, offering initial observations and highlighting inconsistencies.\n\u2022 Strong understanding of the application of analytical methods and data visualization to support business decisions.\n\u2022 Ability to understand complex operational systems and analytics/business intelligence tools for the delivery of information products and analytical offerings to a large, global user base.\n\u2022 Able to work in a fast-paced, deadline-driven environment as part of a team and as an individual contributor\n\u2022 Ability to easily move between business, analytical, and technical teams and articulate solution requirements for each group\n\nCorporate Security Responsibility\n\nAll activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:\n\u2022 Abide by Mastercard\u2019s security policies and practices;\n\u2022 Ensure the confidentiality and integrity of the information being accessed;\n\u2022 Report any suspected information security violation or breach, and\n\u2022 Complete all periodic mandatory security trainings in accordance with Mastercard\u2019s guidelines.",
    "url": "https://careers.mastercard.com/us/en/job/R-262901/Senior-Analyst-Big-Data-Analytics-Engineering?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Data Scientist-Artificial Intelligence",
    "company": "IBM",
    "location": "Pune",
    "salary": "",
    "description": "Introduction\n\nIn this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology.\n\nYour Role And Responsibilities\n\u2022 As an Associate Data Scientist at IBM, you will work to solve business problems using leading edge and open-source tools such as Python, R, and TensorFlow, combined with IBM tools and our AI application suites. You will prepare, analyze, and understand data to deliver insight, predict emerging trends, and provide recommendations to stakeholders.\n\u2022 In your role, you may be responsible for:\n\u2022 Implementing and validating predictive and prescriptive models and creating and maintaining statistical models with a focus on big data & incorporating machine learning. techniques in your projects\n\u2022 Writing programs to cleanse and integrate data in an efficient and reusable manner\n\u2022 Working in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors\n\u2022 Communicating with internal and external clients to understand and define business needs and appropriate modelling techniques to provide analytical solutions.\n\u2022 Evaluating modelling results and communicating the results to technical and non-technical audiences.\n\nPreferred Education\n\nMaster's Degree\n\nRequired Technical And Professional Expertise\n\u2022 Proof of Concept (POC) Development: Develop POCs to validate and showcase the feasibility and effectiveness of the proposed AI solutions.\n\u2022 Collaborate with development teams to implement and iterate on POCs, ensuring alignment with customer requirements and expectations.\n\u2022 Help in showcasing the ability of Gen AI code assistant to refactor/rewrite and document code from one language to another, particularly COBOL to JAVA through rapid prototypes/ PoC\n\u2022 Document solution architectures, design decisions, implementation details, and lessons learned.\n\u2022 Create technical documentation, white papers, and best practice guides.\n\nPreferred Technical And Professional Experience\n\u2022 Strong programming skills, with proficiency in Python and experience with AI frameworks such as TensorFlow, PyTorch, Keras or Hugging Face.\n\u2022 Understanding in the usage of libraries such as SciKit Learn, Pandas, Matplotlib, etc. Familiarity with cloud platforms\n\u2022 Experience and working knowledge in COBOL & JAVA would be preferred.",
    "url": "https://www.foundit.in/job/data-scientist-artificial-intelligence-ibm-pune-37616817?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Blucognition- Data Scientist (Risk Strategy)",
    "company": "Nexthire",
    "location": "Pune",
    "salary": "",
    "description": "Role: Data Scientist / Risk Strategy\nExperience: 3+ Years\nLocation: Remote\nSkills Required: SQL, Python, R, Databricks, Credit Risk Strategy building, Credit Risk Solutions\n\nAbout bluCognition:\n\nBluCognition is an AI/ML based company specializing in risk analytics, data conversion and data enrichment capabilities. Founded some very named senior professionals from the financial services industry, the company is headquartered in the US, with the delivery centre based in Pune.\n\nWe build all our solutions while leveraging the latest technology stack in AI, ML and NLP combined with decades of experience in risk management at some of the largest financial services firms in the world. Our clients are some of the biggest and the most progressive names in the financial services industry.\n\nWe are entering a significant growth phase and are looking for individuals with entrepreneurial mindset who wants us to join in this exciting journey.\n\nPosition: Data Scientist (Risk strategy, SME)\nAbout the role\nAs Data Scientist in the credit risk strategy team, you will leverage your creative and critical thinking skills\nto develop best-in-class risk management strategies that have a meaningful impact on the client's\nbusiness. These strategies will support the client's credit and fraud risk, customer experience, marketing\nverticals and beyond.\nHaving you aboard will enable us to stay aligned with market trends by improving the turnaround time\nfor developing and implementing risk strategies, allowing for quicker iterations and broader coverage in\naddressing business challenges through scientific methods. The core KPIs for this position include\nadditional revenue generated and costs saved from releases. This role also supports compliance,\ndocumentation, and knowledge sharing in risk strategies.\nWhat you'll do\nDevelop, validate and deploy risk management strategies using a combination of sophisticated data analytics and domain expertise\nExtract and explore data, validate data integrity, perform ad hoc analysis, evaluate new data sources for usage in strategy development\nMaintain robust documentation of approach and techniques used; including objectives, assumptions, performance, weaknesses, and limitations\nBe ready to adapt to new tools/libraries/technologies/platforms\nActively partner with engineers to validate & deploy scalable solutions\nCollaborate to gather insight from partners across the organization\nFurther develop expertise in data science and engineering through self-study, project exposure and guidance of senior team members\nWhat you'll bring\nDegree in a quantitative field (e.g., computer science, data science, engineering, economics, mathematics, etc.). Advanced degree preferred\n3+ years of Data Science experience\n2+ years in financial services\nExperience building and implementing risk strategies in production\nDeep understanding of segmentation techniques such as decision trees\nExperience in banking sector with exposure to risk management analytics\nProficient with Python\nProficient with SQL\nPractical experience using Spark is a plus\nUnderstanding of statistical modeling techniques is a plus\nTechnical understanding of algorithm complexity, probability & statistics\nSelf-driven with an aptitude for independent research & problem-solving\nAbility to multi-task in a fast-paced environment is essential",
    "url": "https://www.recruit.net/job/blucognition-data-scientist-risk-strategy-jobs/ED604CCD08826865?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "\u25b7 Urgent Data Scientist Pune",
    "company": "Terragig",
    "location": "Pune",
    "salary": "",
    "description": "We are looking for Data Science off-shore Lead \u2013 Life Sciences Domain\n\nLocation - Pune\n\nJob Type - Fulltime\n\nnotice period - 45 days\n\nExperience - 6+ Years\n\nRequired Skills:\n\nData Science , AI, ML, GenAI, MLOps , Life Sciences Domain\n\nRoles and responsibilities\nLead data science efforts (AI, ML, GenAI, analytical formulation) for multiple client engagements in Life Sciences domain.\nManage end-to-end Data Science project lifecycle from problem comprehension, analytical solution development to final delivery.\nAct as primary point of contact for client interactions, presentations, and requirement elicitation.\nGuide teams on advanced data science techniques ensuring alignment with business objectives.\nCollaborate cross-functionally with domain experts, business stakeholders, and technical teams to deliver robust analytical solutions.\nExpert knowledge of data science algorithms, methodologies, and end-to-end lifecycle (AI/ML/GenAI), MLOps and post deployment service of AI models\nSolid comprehension of complex Life Sciences problems\nExceptional articulation skills to communicate technical concepts clearly to both technical and business stakeholders.\nAdvanced analytical skills for strategic problem-solving and actionable insight generation.",
    "url": "https://in.jobrapido.com/jobpreview/8900853684796129280?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Data Science Offshore Lead (Life Sciences)",
    "company": "ProLegion",
    "location": "Pune",
    "salary": "",
    "description": "Job Title: Data Science Offshore Lead (Life Sciences)\n\nLocation: Pune, Maharashtra, India\n\nDuration: Contractual\n\nRoles and Responsibilities\n\u2022 Lead and manage offshore data science projects specifically in the life sciences sector, ensuring alignment with overall business goals.\n\u2022 Coordinate with cross-functional teams to ensure the seamless execution of data-driven initiatives, providing leadership and direction as needed.\n\u2022 Develop and implement robust data science models and algorithms to address key business questions within life sciences.\n\u2022 Facilitate communication between onshore and offshore teams to ensure project objectives are met effectively and efficiently.\n\u2022 Maintain a comprehensive understanding of the latest advancements in data science and machine learning, applying cutting-edge approaches as appropriate to ongoing projects.\n\u2022 Ensure continuous quality improvement and risk management across all project phases, delivering high-quality outputs on time and within budget.\n\u2022 Conduct regular progress reviews with stakeholders, addressing any issues or concerns promptly and effectively.\n\nRequired Qualifications\n\u2022 Proven experience in leading data science teams, preferably within the life sciences sector, showcasing successful project delivery and team management.\n\u2022 Strong knowledge and practical experience in applying data science and machine learning techniques to real-world problems.\n\u2022 Advanced degree in a relevant field such as Data Science, Computer Science, or Life Sciences with a solid foundation in quantitative and analytical skills.\n\u2022 Demonstrated project management skills with the ability to oversee multiple projects simultaneously, managing resources and timelines effectively.\n\u2022 Excellent communication and interpersonal skills, with the capability to liaise effectively with diverse teams and stakeholders across global locations.\n\u2022 Strong problem-solving and decision-making skills, able to translate complex data insights into actionable strategies.\n\u2022 Proficiency in programming languages commonly used in data science, such as Python or R, and experience with data visualisation tools.\n\nKey Responsibilities\n\u2022 Lead offshore data science operations in Pune, Maharashtra, India, ensuring the delivery of high-quality analytical solutions to the life sciences industry.\n\u2022 Partner with global stakeholders to define project scopes, objectives, and success metrics, aligning them with strategic priorities.\n\u2022 Foster a collaborative and innovative work environment, championing best practices and continuous improvement in data science methodologies.\n\u2022 Mentor and develop talent within the team, providing guidance, feedback, and career development opportunities to junior team members.\n\u2022 Identify opportunities for growth and expansion of data science capabilities within life sciences projects, advocating for investment in new tools and technologies.\n\u2022 Ensure regulatory compliance and ethical standards are met in all analytical processes and project deliveries.\n\u2022 Drive the adoption of automated, efficient workflows, enhancing the analytical capabilities and performance across all offshore operations.",
    "url": "https://in.linkedin.com/jobs/view/data-science-offshore-lead-life-sciences-at-prolegion-4333352948?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Scientist/Machine Learning Engineer Assistant vice president",
    "company": "Early Career",
    "location": "Pune",
    "salary": "",
    "description": "ML Solutions team within Markets OPS Technology is dedicated to developing solutions using Artificial Intelligence, Machine Learning and Generative AI. This team is a leader in creating new ideas, innovative technology solutions, and ground-breaking solutions for Markets Operations and Other Line of Businesses. We work closely with our clients and business partners to progress solutions from ideation to production by leveraging the entrepreneurial spirit and technological excellence.\n\nJob Description:\n\nThe ML Solutions team is seeking a Data Scientist/Machine Learning Engineer to drive the design, development, and deployment of innovative AI/ML and GenAI-based solutions. In this hands-on role, you will leverage your expertise to create a variety of AI models, guiding a team from initial concept to successful production. A key aspect involves mentoring team members and fostering their growth. You will collaborate closely with business partners and stakeholders, championing the adoption of these advanced technologies to enhance client experiences, deliver tangible value to our customers, and ensure adherence to regulatory requirements through cutting-edge technical solutions. This position offers a unique opportunity to shape the future of our AI initiatives and make a significant impact on the organization.\n\nKey Responsibilities:\n\u2022 Hands-On Execution and Delivery: Actively contribute to the development and delivery of AI solutions, driving innovation and excellence within the team. Take a hands-on approach to ensure AI models are successfully deployed into production environments, meeting high-quality standards and performance benchmarks.\n\u2022 Mentoring Young Talents: Mentoring team, guiding data analysts/ML engineers from concept to production. This involves fostering technical growth, providing project oversight, and ensuring adherence to best practices, ultimately building a high-performing and innovative team.\n\u2022 Quality Control: Ensure the quality and performance of generative AI models, conducting rigorous testing and evaluation.\n\u2022 Research and Development: Participate in research activities to explore and advance state-of-the-art generative AI techniques. Stay actively engaged in monitoring ongoing research efforts, keeping abreast of emerging trends, and ensuring that the Generative AI team remains at the forefront of the field.\n\u2022 Cross-Functional Collaboration: Collaborate effectively with various teams, including product managers, engineers, and data scientists, to integrate AI technologies into products and services.\n\nSkills & Qualifications:\n\u2022 8 to 13 years of Strong hands-on experience in Machine Learning, delivering complex solutions to production.\n\u2022 Experience with Generative AI technologies essential.\n\u2022 Understanding of concepts like supervised, unsupervised, clustering, embedding.\n\u2022 Knowledge of NLP, Name Entity Recognition, Computer Vision, Transformers, Large Language Models.\n\u2022 In-depth knowledge of deep learning and Generative AI frameworks such as, Langchain, Lang Graph, Crew AI or similar.\n\u2022 Experience with and other open-source frameworks/ libraries/ APIs like Hugging Face Transformers, Spacy, Pandas, scikit-learn, NumPy, OpenCV.\n\u2022 Experience in using Machine Learning/Deep Learning: XGBoost, LightGBM, TensorFlow, PyTorch, Keras.\n\u2022 Proficiency in Python Software Development, following Object-Oriented design patterns and best practices.\n\u2022 Strong background in mathematics: linear algebra, probability, statistics, and optimization.\n\u2022 Experience with evaluation, scoring with framework like ML Flow\n\u2022 Experience of Docker container and edited a Docker file, experience with K8s is a plus.\n\u2022 Experience with Postgres and Vector DBs a plus.\n\u2022 Excellent problem-solving skills and the ability to think creatively.\n\u2022 Strong communication and collaboration skills, with the ability to work effectively with cross-functional teams\n\u2022 Publications and contributions to the AI research community are a plus.\n\u2022 Master\u2019s degree/Ph. D. or equivalent experience in Computer Science, Data Science, Statistics, or a related field.\n\u2022 8-12 years of experience\n\nThis job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.\n\n------------------------------------------------------\n\nJob Family Group:\nTechnology\n\n------------------------------------------------------\n\nJob Family:\nApplications Development\n\n------------------------------------------------------\n\nTime Type:\nFull time\n\n------------------------------------------------------\n\nMost Relevant Skills\nPlease see the requirements listed above.\n\n------------------------------------------------------\n\nOther Relevant Skills\nData Science, Machine Learning.\n\n------------------------------------------------------\n\nCiti is an equal opportunity employer, and qualified candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other characteristic protected by law.\n\nIf you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.\n\nView Citi\u2019s EEO Policy Statement and the Know Your Rights poster.",
    "url": "https://jobs.citi.com/job/pune/data-scientist-machine-learning-engineer-assistant-vice-president/287/83901989456?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Urgent Search : Data Scientist",
    "company": "ARKRAY, Inc.",
    "location": "Pune",
    "salary": "",
    "description": "Job title : Data Scientist (Full time)\n\nReport to : Data Science Manager in Pune\n\nJob Responsibilities\n\u2022 Solve Time series 1D (continuous glucose monitoring), RNA sequencing, and Computer vision (mainly medical images) problems\n\u2022 Solve challenging problems using scalable 1D signal processing, machine learning, and deep learning approaches.\n\u2022 In charge of developing state-of-the-art machine learning / deep learning algorithms for medical datasets\n\u2022 Communicate highly technical results and methods concisely and clearly\n\u2022 Collaborate with researchers in Japan to understand requirement as well request data.\n\nRequirement\n\u2022 Master / Ph.D. in relevant field from tier-1 colleges\n\u2022 CGPA greater than 8.0\n\u2022 1~2 years of experience with programming language / s Python or C++, Pandas\n\u2022 1~2 years of experience of working with deep learning framework, i.e. Pytorch or Tensorflow\n\u2022 Well acquainted with classical time series problems-algorithms, NLP, Computer vision etc.\n\u2022 Demonstrated experience with machine learning / deep learning models.\n\u2022 Candidates should be able to read and implement research papers from top conferences.\n\u2022 Develop IP (patents) and publish papers.\n\u2022 Proficiency in Windows, Linux, dockers, PPT, and Git commands are highly required.\n\nPreferred Skills\n\u2022 Experience working with time-series, text, and sequential datasets in real world settings.\n\u2022 Proven track record of research or industry experience on Time series problems, NLP, tabular datasets.\n\u2022 Well acquainted with machine learning libraries such as pandas, scikit-learn etc.\n\u2022 Experience programming in Azure or GCP or other cloud service.\n\u2022 Publications in top-tier conferences will be a plus.\n\nLocation\n\nPune, India\n\nAWIFS office (Co-working space)\n\nElpro City Square Mall, MG Rd, Chinchwad Gaon, Chinchwad, Pimpri-Chinchwad, Pune, Maharashtra 41103",
    "url": "https://in.talent.com/view?id=410aaffbc203&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "DATA SCIENCE POWER BI INTERNSHIP PUNE",
    "company": "confidential",
    "location": "Pune",
    "salary": "",
    "description": "Maxgen Technologies Pvt ltd is an it company based in pune .We are offering data science internship with power bi program to engineering and diploma candidates..\n\nBenefit we are offering\n\nenjoying work environment .\n\nsmooth shift timing.\n\nlive project in internship.\n\nlong time or short time internship.\n\nhybrid mode internship.\n\nvisit us\n\ncontact us View phone number on foundit.in, View phone number on foundit.in,View phone number on foundit.in ,View phone number on foundit.in,\n\naddress 6th Floor, Konark Icon, 601, above Maruti Suzuki, Magarpatta, Pune, Maharashtra",
    "url": "https://in.jooble.org/jdp/1298935089934152488?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (Python/ GenAI/ AgenticAI)",
    "company": "Wolters Kluwer",
    "location": "Pune",
    "salary": "",
    "description": "Key Responsibilities\n\nActive Learner with Enthusiasm for Problem-Solving\n\nContinuously learn and apply new AI/ML techniques, including Generative AI, Agentic AI deep learning, and other emerging technologies. Demonstrate a passion for solving complex business challenges and experimenting with novel approaches to improve model performance.\n\nQuick Prototyping & Experimentation\n\nDevelop rapid prototypes to test new AI/GenAI/ML approaches and solutions for business problems. Implement proof-of-concept models quickly, enabling fast experimentation and iteration to assess feasibility before scaling to full development.\n\nSupport AI Product Development & Iteration\n\nCollaborate with lead/ senior data scientists and cross-functional teams to support the design, development, and deployment of AI-driven products. Contribute to the creation of prototypes and refine models based on business needs and feedback.\n\nModel Development and Optimization\n\nDesign, develop, and test machine learning, deep learning, and generative AI models, focusing on performance, scalability, and business relevance. Continuously refine and optimize models based on real-world results and metrics.\n\nData Preparation & Collaboration\n\nAssist in defining data requirements and support data engineers in building data pipelines. Clean and preprocess datasets, ensuring data quality and preparing it for use in machine learning applications. Collaborate closely with engineers to integrate models into production systems.\n\nResearch Support and Knowledge Sharing\n\nStay informed about the latest trends and research in AI/GenAI/ML and generative models, applying this knowledge to current projects. Actively participate in team discussions, contribute to the evaluation of new techniques, and share insights with peers to foster a collaborative learning environment.\n\nEssential Skills\n\u2022 Good knowledge of Python programming language, data engineering and data science ecosystem in Python.\n\u2022 Hands on experience in Generative AI, Agentic AI, LLM and Advance RAG techniques.\n\u2022 Hands on experience in developing and supporting Machine Learning solutions.\n\u2022 Hands on experience in developing Natural Language Processing (NLP) solutions\n\u2022 Hands on experience on SQL ecosystem\n\u2022 Hands on experience on Solr framework with Python\n\u2022 Experience of working on Linux and shell scripting\n\u2022 Basic statistical modelling knowledge\n\u2022 Strong Computer Science fundamentals are must. (Data structures, Algorithms, OS, Databases).\n\u2022 Good communication and organizational skills with significant attention to detail\n\u2022 Experience partnering with cross-functional teams of domain experts, engineers, data scientists, and production support teams.\n\u2022 Strong attention to detail with excellent problem-solving skills.\n\u2022 Desire and ability to thrive in a distributed technical environment while working on multiple projects simultaneously.\n\u2022 Passionate about latest technology trends with a strong desire for innovation.\n\u2022 Self-motivated, self-managing and able to work independently.\n\nEducation And Experience\n\u2022 Bachelor's degree (B.E/ B Tech. computer science, engineering, statistics/mathematics or a related field) from a four-year college or university, or equivalent, master\u2019s a plus.\n\u2022 Total at least 1 years of experience working on enterprise AI products\n\u2022 Experience in supporting software products or applications in the AI ML domain.\n\u2022 The above statements are intended to describe the general nature and level of work being performed by most people assigned to this job. They are not intended to be an exhaustive list of all duties and responsibilities and requirements.\n\nApplicants may be required to appear onsite at a Wolters Kluwer office as part of the recruitment process.",
    "url": "https://in.linkedin.com/jobs/view/data-scientist-python-genai-agenticai-at-wolters-kluwer-4319872554?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Scientist",
    "company": "Snowflake",
    "location": "Pune",
    "salary": "",
    "description": "Snowflake is about empowering enterprises to achieve their full potential \u2014 and people too. With a culture that\u2019s all in on impact, innovation, and collaboration, Snowflake is the sweet spot for building big, moving fast, and taking technology \u2014 and careers \u2014 to the next level.\n\nSnowflake is seeking a Data Scientist to join our expanding Enterprise AI & ML team. This role involves working on diverse AI/ML and data science initiatives, utilizing Snowflake's Data Cloud and Cortex AI. The successful candidate will design and develop scalable data science and machine learning solutions, build interactive AI applications, and collaborate on operationalizing intelligent systems to enhance data-driven decision-making throughout the company. This position focuses on applying data science, AI & ML skill sets to various domain specific business data problems across Snowflake.\n\nON THE ENTERPRISE AI & ML TEAM AT SNOWFLAKE, YOU WILL:\n\u2022 Design, prototype, and deploy data science and AI solutions.\n\u2022 Conduct end to end experimentation, including data exploration, feature engineering, model development, and validation.\n\u2022 Build and maintain Streamlit applications to visualize models, showcase insights, and enable business stakeholders to interact with AI driven solutions.\n\u2022 Develop and optimize LLM based applications, workflows, and operations; with a focus on retrieval, generation, semantic understanding and fine-tuning.\n\u2022 Partner cross functionally with data engineers, analysts, and product teams to translate ambiguous business problems into measurable outcomes.\n\nOUR IDEAL CANDIDATE WILL HAVE:\n\u2022 2 to 4 years of experience applying data science, machine learning, or AI techniques in real world business settings.\n\u2022 Strong programming skills in Python, proficiency in SQL for large scale data manipulation.\n\u2022 Familiarity with frameworks such as scikit-learn, XGBoost etc.\n\u2022 Understanding of LLM architectures, embeddings, vector search, and RAG pipelines.\n\u2022 Experience working on cloud platforms.\n\u2022 Strong analytical, storytelling, and communication skills to translate technical insights into actionable recommendations.\n\u2022 A mindset of curiosity, ownership, and collaboration, with an eagerness to work on open-ended problems.\n\u2022 Experience operationalizing AI & ML models in a production setting.\n\nSnowflake is growing fast, and we\u2019re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.\n\nHow do you want to make your impact?\n\nFor jobs located in the United States, please visit the job posting on the Snowflake Careers Site for salary and benefits information: careers.snowflake.com",
    "url": "https://careers.snowflake.com/us/en/job/SNCOUSE5563EEBE22F4F83ABADA6BD2B014860EXTERNALENUSF7C857F3DD284045B0C758E492307EC3/Data-Scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "\u25b7 (15h Left) Manager, Data Science (Media / Market Research)",
    "company": "NielsenIQ",
    "location": "Pune",
    "salary": "",
    "description": "As a Data Science Manager you will have following key accountabilities :\n\nTeam Leadership : Build and lead a high-performing team of 6-8 Data Scientists and Machine Learning Engineers in our Pune hub. Foster a collaborative and inclusive team culture that encourages innovation and continuous learning.\n\nTechnical Communication : Explain Data Science principles, concepts, algorithms, and approaches in simple terms to diverse audiences, including non-technical stakeholders.\n\nBusiness Understanding : Utilize your solid business understanding to align with stakeholders, discuss requirements and feasibility, and manage expectations effectively. Ensure clear communication and understanding of project goals and outcomes.\n\nEducational Background :\n\nPhD or Master\u2019s degree in Computer Science, Engineering, Statistics, Mathematics, or a related field, with min 8+ years of experience as a Data Scientist.\n\nLeadership Experience :\n\nProven experience as a people manager and / or mentor, with a track record of developing and leading high-performing teams.\n\nLeadership Experience :\n\nProven experience as a people manager and / or mentor, with a track record of developing and leading high-performing teams\n\nCommunication Skills :\n\u2022 Ability to effectively communicate complex methodologies and technologies to both technical and non-technical audiences.\n\u2022 Strong problem-solving skills and an independent working style.\n\nTechnical Expertise :\n\u2022 Strong statistical and machine learning modeling skills, including statistical tests, classification, predictive modeling, handling of missing data, and sampling / weighting techniques.\n\u2022 Solid in analytical programming languages such as Python or R, along with their respective ecosystems.\n\u2022 Hands-on experience implementing these models in production systems.\n\u2022 Proficient in software development skills, including unit testing, CI / CD, and version control with Git, along with familiarity with computer science and engineering fundamentals such as data structures, software design principles, and testing strategies.\n\nPreferred qualifications\n\u2022 Experience in the Media industry\n\u2022 Experience working with cloud-based data services (AWS, Azure, or GCP)\n\u2022 Experience with Optimization techniques such as : linear programming, integer programming, genetic algorithms, constrained optimization is a plus",
    "url": "https://in.talent.com/view?id=9ec995376b19&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Data Scientist  People Data Analytics & Insights",
    "company": "Syngenta",
    "location": "Pune",
    "salary": "",
    "description": "We are seeking a highly analytical and business-focused Data Scientist to join our People Analytics & Insights team. In this role, you will leverage advanced analytics, machine learning, and statistical modeling to uncover insights from workforce data, supporting strategic talent decisions across the organization. You will partner closely with HR, Talent Management, and business leaders to deliver data-driven solutions that enhance employee experience, improve workforce planning, and inform diversity, equity, and inclusion (DEI) strategies.\n\nKey Responsibilities:\n\u2022 Analyze large and complex HR datasets (e.g., engagement, attrition, performance, compensation, hiring) to uncover trends, patterns, and opportunities for business impact.\n\u2022 Build predictive and prescriptive models (e.g., attrition risk, career pathing, workforce segmentation) to support data-informed people strategies.\n\u2022 Translate business problems into analytical questions and communicate findings in clear, actionable terms to non-technical audiences.\n\u2022 Develop visualizations, dashboards, and storytelling tools to enhance insight delivery (e.g., in Tableau, Power BI, Workday Discovery Boards).\n\u2022 Partner with HR stakeholders to identify KPIs, define success metrics, and improve people-related decision-making through data.\n\u2022 Design and implement surveys, experiments (A/B testing), and causal inference models to evaluate the impact of HR programs and initiatives.\n\u2022 Ensure ethical data use and compliance with privacy and governance standards.\n\u2022 Stay current on industry best practices in people analytics, data science, and AI/ML in HR.\n\nCompany Description\n\nAt the Syngenta Group, our 56,000 people across more than 90 countries strive every day to transform agriculture through tailor-made solutions for the benefit of farmers, society and our planet \u2013 making us the world's most local agricultural technology and innovation partner.\n\nWebsite address - https://www.syngentagroup.com/\n\nLI page - https://www.linkedin.com/company/syngentagroup/posts/?feedView=all\n\nQualifications\n\u2022 Bachelor\u2019s or Master\u2019s degree in Data Science, Statistics, Computer Science, Industrial/Organizational Psychology, Economics, or a related field.\n\u2022 3\u20135+ years of experience in data science, analytics, or a similar role, ideally within HR or workforce analytics.\n\u2022 Proficiency in Python or R for statistical analysis and modeling.\n\u2022 Strong SQL skills for data extraction and manipulation.\n\u2022 Experience with data visualization tools (e.g., Tableau, Power BI, Workday Discovery Boards).\n\u2022 Solid understanding of machine learning algorithms, statistical modeling, and hypothesis testing.\n\u2022 Excellent communication skills, with the ability to explain complex analytical concepts to HR and business audiences.\n\u2022 Familiarity with Workday, SAP SuccessFactors, or other HRIS platforms is a plus.\n\nPreferred Skills:\n\u2022 Experience with natural language processing (NLP) on employee feedback or engagement data.\n\u2022 Knowledge of DEI analytics and workforce diversity measurement.\n\u2022 Exposure to cloud-based data platforms (e.g., AWS, GCP, Azure).\n\u2022 Understanding of HR functional areas like talent acquisition, performance management, and learning & development.\n\nKey Competencies:\n\u2022 Analytical Thinking & Problem Solving\n\u2022 Business Acumen & Strategic Mindset\n\u2022 Data Storytelling & Visualization\n\u2022 Collaboration & Stakeholder Management\n\u2022 Data Ethics & Privacy Awareness\n\nAdditional Information\n\nWL: 4A\n\nNote: Syngenta is an Equal Opportunity Employer and does not discriminate in recruitment, hiring, training, promotion or any other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, gender identity, marital or veteran status, disability, or any other legally protected status\n\nFollow us on: Twitter & LinkedIn\n\nhttps://twitter.com/SyngentaAPAC\n\nhttps://www.linkedin.com/company/syngenta/",
    "url": "https://jobs.syngenta.com/job/data-scientist-people-data-analytics-and-insights-in-in-pune-jid-14917?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Lead Data Scientist+ Instructor",
    "company": "Uplers",
    "location": "Pune",
    "salary": "",
    "description": "Experience: 7.00 + years\n\nSalary: Confidential (based on experience)\n\nShift: (GMT+05:30) Asia/Kolkata (IST)\n\nOpportunity Type: Office (Pune)\n\nPlacement Type: Full time Permanent Position\n\n(*Note: This is a requirement for one of Uplers' client - Newton School)\n\nWhat do you need for this opportunity?\n\nMust have skills required:\n\nMachine Learning, NLP, Computer Vision, Statistics, pandas, NumPy, Python\n\nNewton School is Looking for:\n\nAbout Newton:\n\nNewton School of Technology (NST) is a new-age institution redefining technical education in India. Founded by IIT alumni, NST offers a 4-year B.Tech in Computer Science and AI, focused on hands-on learning and deep industry integration. Within two years, over 93% of students have secured paid internships with companies like Razorpay, SarvamAI, and DRDO, along with global exposure through tech treks to Singapore and Silicon Valley. Led by a distinguished faculty comprising ICPC World Finalists and ex-professionals from ISRO, Microsoft, MakeMyTrip, and several other leading tech organisations, NST is building a scalable, high-impact model that produces industry-ready talent for the world\u2019s most advanced technology roles.\n\nAbout the Role:\n\nWe are currently looking for a Data Scientist + Instructor\u2013 AI/ML to join our Computer Science Department. This role is ideal for professionals with substantial industry experience professionals who are passionate about Artificial Intelligence and Machine Learning, and committed to shaping the next generation of tech talent. The position combines hands-on technical expertise with academic responsibilities, including designing and delivering course content, conducting practical lab sessions, and mentoring students in core Data Science and AI/ML concepts. The ideal candidate will also collaborate with academic leaders and industry partners to ensure curriculum relevance, integrate real-world problem-solving, and drive strong learning outcomes.\n\nKey Responsibilities:\n\u2022 Teach Applied AI/ML: Design and deliver practical, project-based courses in AI/ML(Python for ML, Statistics, ML Algorithms, Deep Learning, NLP, CV, ML Ops, GenAI).\n\u2022 Develop Industry-Relevant Curriculum: Help design and update the AI/ML curriculum to reflect current industry tools, techniques, and best practices, incorporating your professional experience and case studies.\n\u2022 Mentor Student Projects: Guide students through hands-on AI/ML projects, providing technical direction, code reviews, and feedback based on industry standards.\n\u2022 Guide & Mentor Students: Advise students on developing practical skills, understanding career paths in AI/ML, and preparing for internships and job placements.\n\u2022 Stay Current: Bring the latest AI/ML research, tools, and industry trends into the classroom.\n\u2022 Collaborate: Work closely with other expert faculty and staff to create a unified and effective learning experience.\n\u2022 Assess Practical Skills: Design and evaluate assignments, projects, and assessments focused on real-world applications.\n\nQualifications and Requirements:\n\u2022 Bachelor\u2019s or Master\u2019s degree in Computer Science, Engineering, Data Science, AI/ML, or related field. (PhD is valued but not mandatory.)\n\u2022 7+ years of direct, hands-on professional experience in the tech industry as an AI/ML Engineer, Data Scientist, Research Scientist, or similar role involving AI/ML development and deployment.\n\u2022 Proven Industry Track Record: Demonstrated experience in building, training, and deploying machine learning models (including deep learning) for real-world problems.\n\u2022 Deep AI/ML Understanding: Strong grasp of core ML algorithms (classical & deep learning \u2013 CNNs, RNNs, Transformers), model evaluation, statistics, and awareness of current research/industry trends.\n\u2022 Passion for Teaching/Mentoring: Ability to explain complex concepts clearly and guide others. Prior mentoring, corporate training, technical workshops, or project supervision experience is highly relevant.\n\nRequired Skills:\n\u2022 Technical: Expert-level Python programming.\n\u2022 Proficiency with data science libraries (Pandas, NumPy, Scikit-learn).\n\u2022 Hands-on experience with ML/DL frameworks (TensorFlow, PyTorch).\n\u2022 Strong SQL and data handling skills.\n\u2022 Understanding of ML Ops practices and tools (Git, Docker, AWS/GCP/Azure).\n\u2022 Knowledge of key AI areas (NLP, Computer Vision, Generative AI/LLMs).\n\u2022 Soft Skills: Strong communication, mentoring ability, collaboration, and a genuine passion for education.\n\nGood-to-Have:\n\u2022 Prior teaching experience at the undergraduate or graduate level.\n\u2022 Familiarity with modern teaching methodologies and academic\n\nHow to apply for this opportunity?\n\u2022 Step 1: Click On Apply! And Register or Login on our portal.\n\u2022 Step 2: Complete the Screening Form & Upload updated Resume\n\u2022 Step 3: Increase your chances to get shortlisted & meet the client for the Interview!\n\nAbout Uplers:\n\nOur goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement.\n\n(Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well).\n\nSo, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you!",
    "url": "https://in.linkedin.com/jobs/view/lead-data-scientist%2B-instructor-at-uplers-4333996105?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T12:00:00.000Z"
  },
  {
    "title": "Data Scientist AI ML Developer",
    "company": "Princenton software services pvt ltd",
    "location": "Pune",
    "salary": "",
    "description": "In this Role, Your Responsibilities Will Be:\n\n\u00b7 Develop, train and deploy machine learning, deep learning AI models for a variety of business use cases such as classification, prediction, recommendation, NLP and Image Processing.\n\n\u00b7 Design and implement end-to-end ML workflows from data ingestion and preprocessing to model deployment and monitoring.\n\n\u00b7 Collect, clean, and preprocess structured and unstructured data from multiple sources using industry-standard techniques such as normalization, feature engineering, dimensionality reduction, and optimization.\n\n\u00b7 Perform exploratory data analysis (EDA) to identify patterns, correlations, and actionable insights.\n\n\u00b7 Apply advanced knowledge of machine learning algorithms including regression, classification, clustering, decision trees, ensemble methods, and neural networks.\n\n\u00b7 Use Azure ML Studio, TensorFlow, PyTorch, and other ML frameworks to implement and optimize model architectures.\n\n\u00b7 Perform hyperparameter tuning, cross-validation, and performance evaluation using industry-standard metrics to ensure model robustness and accuracy.\n\n\u00b7 Integrate models and services into business applications through RESTful APIs developed using FastAPI, Flask or Django.\n\n\u00b7 Build and maintain scalable and reusable ML components and pipelines using Azure ML Studio, Kubeflow, and MLflow.\n\n\u00b7 Enforce and integrate AI guardrails: bias mitigation, security practices, explainability, compliance with ethical and regulatory standards.\n\n\u00b7 Deploy models in production using Docker and Kubernetes, ensuring scalability, high availability, and fault tolerance.\n\n\u00b7 Utilize Azure AI services and infrastructure for development, training, inferencing, and model lifecycle management.\n\n\u00b7 Support and collaborate on the integration of large language models (LLMs), embeddings, vector databases, and RAG techniques where applicable.\n\n\u00b7 Monitor deployed models for drift, performance degradation, and data quality issues, and implement retraining workflows as needed.\n\n\u00b7 Collaborate with cross-functional teams including software engineers, product managers, business analysts, and architects to define and deliver AI-driven solutions.\n\n\u00b7 Communicate complex ML concepts, model outputs, and technical findings clearly to both technical and non-technical stakeholders.\n\n\u00b7 Stay current with the latest research, trends, and advancements in AI/ML and evaluate new tools and frameworks for potential adoption.\n\n\u00b7 Maintain comprehensive documentation of data pipelines, model architectures, training configurations, deployment steps, and experiment results.\n\n\u00b7 Drive innovation through experimentation, rapid prototyping, and the development of future-ready AI components and best practices.\n\n\u00b7 Write modular, maintainable, and production-ready code in Python with proper documentation and version control.\n\n\u00b7 Contribute to building reusable components and ML accelerators.\n\nQualifications:\n\u2022 Bachelor's or Master's degree in Computer Science, Data Science, Machine Learning, Statistics, Mathematics, or a related field over 7+ years.\n\u2022 Proven experience as a Data Scientist, ML Developer, or in a similar role.\n\n\u00b7 Strong command of Python and ML libraries (e.g., Azure ML Studio, scikit-learn, TensorFlow, PyTorch, XGBoost).\n\u2022 Data Engineering: Experience with ETL/ELT pipelines, data ingestion, transformation, and orchestration (Airflow, Dataflow, Composer).\n\u2022 ML Model Development: Strong grasp of statistical modelling, supervised/unsupervised learning, time-series forecasting, and NLP.\n\n\u00b7 Proficiency in Python\n\u2022 Strong knowledge of machine learning algorithms, frameworks (e.g., TensorFlow, PyTorch, scikit-learn), and statistical analysis techniques.\n\u2022 Proficiency in programming languages such as Python, R, or SQL.\n\u2022 Experience with data preprocessing, feature engineering, and model evaluation techniques.\n\u2022 MLOps & Deployment: Hands-on experience with CI/CD pipelines, model monitoring, and version control.\n\u2022 Familiarity with cloud platforms (e.g., Azure (Primarily), AWS and deployment tools.\n\u2022 Knowledge of DevOps platform.\n\u2022 Excellent problem-solving skills and attention to detail.\n\u2022 Strong communication and collaboration skills, with the ability to work effectively in a team environment.\n\nPreferred Qualifications:\n\u2022 Proficiency in Python, with libraries like pandas, NumPy, scikit-learn, spacy, NLTK and Tensor Flow, Pytorch\n\u2022 Knowledge of natural language processing (NLP) and custom/computer, YoLo vision techniques.\n\u2022 Experience with Graph ML, reinforcement learning, or causal inference modeling.\n\u2022 Familiarity with marketing analytics, attribution modelling, and A/B testing methodologies.\n\u2022 Working knowledge of BI tools for integrating ML insights into dashboards.\n\n\u00b7 Hands on MLOps experience, with an appreciation of the end-to-end CI/CD process\n\u2022 Familiarity with DevOps practices and CI/CD pipelines.\n\u2022 Experience with big data technologies (e.g., Hadoop, Spark) is added advantage\n\nJob Type: Full-time\n\nPay: \u20b9489,656.78 - \u20b91,757,284.43 per year\n\nWork Location: In person",
    "url": "https://www.glassdoor.co.in/job-listing/data-scientist-ai-ml-developer-princenton-software-services-pvt-ltd-JV_IC2856202_KO0,30_KE31,67.htm?jl=1009928106836&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Sr. Data Scientist / Machine Learning Engineer",
    "company": "TeamPlus",
    "location": "Pune",
    "salary": "",
    "description": "Strong programming skills in Python and SQL.\n\nDeep knowledge of data science and machine learning\n\nlibraries such as Pandas, Scikit-learn,\n\nTensorFlow, and PyTorch.\n\nProven experience in building, training, and deploying\n\nmachine learning models into production\n\nsystems.\n\nHands-on experience with big data technologies (Hadoop,\n\nSpark).\n\nStrong working knowledge of AWS cloud services (S3, EC2,\n\nEMR, Lambda, SageMaker, etc.).\n\nExperience working with Databricks and Airflow for data\n\nworkflow management.\n\nExcellent problem-solving skills and the ability to work in\n\ncollaborative, fast-paced environments.\n\nPreferred Qualifications:\n\nExperience with MLOps practices and CI/CD for model\n\ndeployment.\n\nFamiliarity with data versioning tools (e.g., DVC, MLflow).\n\nStrong understanding of data engineering concepts and\n\ndistributed computing.",
    "url": "https://www.teamplusindia.in/job/teamplus-remote-sr-data-scientist-machine-learning-engineer/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T10:00:00.000Z"
  },
  {
    "title": "(29 / 10 / 2025) Data Scientist",
    "company": "Tata Consultancy Services",
    "location": "Pune",
    "salary": "",
    "description": "Dear Candidate,\n\nGreetings from TATA Consultancy Services!!\n\nPosition- Data Scientist-Python\n\nExperience-4 to 8 years\n\nLocation- Chennai, Pune, Mumbai\n\nNotice Period- 0 to 60 days / Serving Notice Period\n\nKey Responsibilities :\n\u2022 Understand business process / business problems and device Machine Learning solutions to optimize business processes wherever possible.\n\u2022 Experience using statistical computer languages (Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\n\u2022 Formulating machine learning solutions to business metrics, designing features from the data available from many large data sources, training, evaluating, and deploying models in production\n\u2022 Developing high-performance algorithms for precision targeting, testing and implementing these algorithms in scalable, production-ready code; Interacting with other teams to define interfaces and understanding and resolving dependencies.\n\u2022 Developing coding in high-level languages such as R, Python, Java\n\u2022 Experience working with and creating data architectures.\n\u2022 Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages / drawbacks.\n\u2022 Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.\n\nNote : Note-Candidates who have previously worked at TCS not eligible to apply.\n\nOnly relevant experience candidates can apply.",
    "url": "https://in.talent.com/view?id=d99f903fffd8&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Senior Data Scientist (Artificial Intelligence Machine Learning)",
    "company": "FIS Global",
    "location": "Pune",
    "salary": "",
    "description": "Position Type :\nFull time\n\nType Of Hire :\nExperienced (relevant combo of work and education)\n\nEducation Desired :\nBachelor of Engineering\n\nTravel Percentage :\n1 - 5%\n\nSenior Data Scientist (Artificial Intelligence Machine Learning)\n\nAre you curious, motivated, and forward-thinking? At FIS you\u2019ll have the opportunity to work on some of the most challenging and relevant issues in financial services and technology. Our talented people empower us, and we believe in being part of a team that is open, collaborative, entrepreneurial, passionate and above all fun.\n\nAbout the role:\n\u2022 We are looking for a talented and passionate Data Scientist willing to challenge themself and produce best in class AI enabled solution\n\u2022 You will be required to use the concepts of AIML, GenAI, LLMs, Sentiment analysis, etc.\n\u2022 The role requires creating correlation between different data points and do predictive, preventive analysis.\n\nAbout the Team :\n\nTeam provide solutions and services that help our clients grow, compete, and optimize their business. Our AIOPS team is creating AIML solution targeted to reduce the Enterprise MTTR through our world class product\n\nWhat you will be doing:\n\u2022 Employ machine learning and statistical modeling to create and enhance data driven products.\n\u2022 Analyze and extract insights from internal and external data.\n\u2022 Work with Big Data and transform complex datasets into more usable formats.\n\u2022 Work with a variety of data science tools and programming languages such as SAS, Python, R, Scala, SQL. Work independently and collaborate with other groups to solve complex problems.\n\u2022 Create and present analyses to internal and external partners and clients.\n\u2022 Will be working in 2 Pm to 11 Pm IST Shifts\n\nWhat you bring:\n\u2022 4 to 6 Years of machine learning, artificial intelligence, statistical modeling, data visualization, and data analysis\n\u2022 Proficient in data science tools and programming languages such as SAS, Python, R, Scala, SQL\n\u2022 Relevant degree in Artificial Intelligence Machine Learning\n\u2022 Experience or knowledge of cloud-based technology\n\u2022 Knowledge of financial services industry\n\nWhat we offer you:\n\u2022 A range of benefits designed to help support your lifestyle and wellbeing.\n\u2022 A multi-faceted job with a broad spectrum of responsibilities\n\u2022 A modern international work environment and a dedicated and innovative team\n\u2022 A broad range of professional education and personal development possibilities \u2013 FIS is your final career step.\n\nPrivacy Statement\n\nFIS is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how FIS protects personal information online, please see the Online Privacy Notice.\n\nSourcing Model\n\nRecruitment at FIS works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. FIS does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company.\n\n#pridepass",
    "url": "https://careers.fisglobal.com/us/en/job/FIGLUSJR0296204EXTERNAL/Senior-Data-Scientist-Artificial-Intelligence-Machine-Learning?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (Lead / Associate Architect) - 42146",
    "company": "Fission Labs",
    "location": "Pune",
    "salary": "",
    "description": "Role: Data Scientist (Lead / Associate Architect)\n\nExperience: 8+ years\n\nLocation: Hyderabad / Pune\n\nFission Labs, headquartered in Sunnyvale, with offices in Dallas & Hyderabad, Fission Labs is a leading software development company, specializing in crafting flexible, agile, and scalable solutions that propel businesses forward. With a comprehensive range of services, including product development, cloud engineering, big data analytics, QA, DevOps consulting, and AI/ML solutions, we empower clients to achieve sustainable digital transformation that aligns seamlessly with their business goals.\n\nWhat are we looking for!\n\nAs a Data Science professional at Fission Labs, you will be part of a high-impact team that designs and develops data-driven solutions for complex business challenges. You\u2019ll work on end-to-end AI and ML systems \u2014 from data exploration and model development to large-scale deployment and optimization in cloud environments.\n\nResponsibilities\n\u2022 Design and architect complex Generative AI solutions using AWS technologies.\n\u2022 Develop advanced AI architectures incorporating state-of-the-art GenAI technologies.\n\u2022 Create and implement Retrieval Augmented Generation (RAG) and GraphRAG solutions.\n\u2022 Architect scalable AI systems using AWS Bedrock and SageMaker.\n\u2022 Design and implement agentic AI systems with advanced reasoning capabilities.\n\u2022 Develop custom AI solutions leveraging vector databases and advanced machine learning techniques.\n\u2022 Evaluate and integrate emerging GenAI technologies and methodologies.\n\nTechnical Expertise Requirements\n\nGenerative AI Technologies\n\nExpert-level Understanding Of\n\u2022 Retrieval Augmented Generation (RAG)\n\u2022 GraphRAG methodologies\n\u2022 LoRA (Low-Rank Adaptation) techniques\n\u2022 Vector Database architectures\n\u2022 Agentic AI design principles\n\nAWS AI Services\n\nComprehensive Expertise In\n\u2022 AWS Bedrock\n\u2022 Amazon SageMaker\n\u2022 AWS AI/ML services ecosystem\n\u2022 Cloud-native AI solution design\n\nTechnical Skills\n\nAdvanced Python programming for AI/ML applications\n\nDeep Understanding Of\n\u2022 Large Language Models (LLMs)\n\u2022 Machine Learning architectures\n\u2022 Preferred Qualifications\n\u2022 AI model fine-tuning techniques\n\u2022 Prompt engineering\n\u2022 AI system design and integration\n\nCore Competencies\n\u2022 Advanced AI solution architecture\n\u2022 Machine learning model optimization\n\u2022 Cloud-native AI system design\n\u2022 Performance tuning of GenAI solutions\n\u2022 Enterprise AI strategy development\n\nTechnical Stack\n\u2022 Programming Languages: Python (required)\n\u2022 Cloud Platform: AWS\n\nAI Technologies\n\u2022 Bedrock\n\u2022 SageMaker\n\u2022 Vector Databases\n\nMachine Learning Frameworks\n\u2022 PyTorch\n\u2022 TensorFlow\n\u2022 Hugging Face\n\nAI Integration Tools\n\u2022 LangChain o LlamaIndex\n\nYou would enjoy\n\u2022 Opportunity to work on impactful technical challenges with global reach.\n\u2022 Vast opportunities for self-development, including online university access and knowledge sharing opportunities.\n\u2022 Sponsored Tech Talks & Hackathons to foster innovation and learning.\n\u2022 Generous benefits packages including health insurance, retirement benefits, flexible work hours, and more.\n\u2022 Supportive work environment with forums to explore passions beyond work.",
    "url": "https://in.linkedin.com/jobs/view/data-scientist-lead-associate-architect-42146-at-fission-labs-4333036595?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Sr Data Scientist",
    "company": "Birlasoft Limited",
    "location": "Pune",
    "salary": "",
    "description": "Area(s) of responsibility\n\nData Scientist experience (8 to 10) - 5B\n\n5 years of relevant work experience as a data scientist\n\nExperience designing and building statistical forecasting models.\n\nExperience in Python, AWS Cloud Services SageMaker,Comprehend, Amazon Bedrock for generative AI and Open AI\n\nExperience designing and building machine learning models.\n\nLead the end-to-end development of AI/ML solutions, from problem definition to production deployment.\n\nStrong programming skills in Python and experience with libraries like TensorFlow, PyTorch, Scikit-learn.\n\nMinimum 2 years of experience in Azure Cloud using Natural Language API\n\nExperience designing and building statistical forecasting models.\n\nExperience in Ingesting data from API and Databases\n\nExperience designing and building machine learning models.\n\nHands-on experience with LLMs and GenAI frameworks\n\nExperience in Django, Flask web frameworks\n\nExperience designing and building optimization models., including expertise with statistical data analysis\n\nMandatory Skillset: Python, AWS Cloud Services SageMaker, Comprehend, Amazon Bedrock for generative AI and Open AI",
    "url": "https://jobs.birlasoft.com/job/Pune-Sr-Data-Scientist-INDI/45605844/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Data Scientist- Gen AI (3-5 years exp only)",
    "company": "confidential",
    "location": "Pune",
    "salary": "",
    "description": "As a Data Scientist, you'll play a crucial role in supporting data-driven projects, performing routine data analysis tasks, and assisting with model development and testing. Your role involves contributing to various stages of the data science lifecycle and providing insights that help shape business strategies. This position is suited for those with a foundational understanding of data science and are eager to deepen their expertise.\n\nResponsibilities:\n\u2022 Contribute to more advanced data collection and preprocessing efforts.\n\u2022 Assist in developing and testing machine learning models.\n\u2022 Perform descriptive data analysis and provide preliminary insights.\n\u2022 Create visualizations and reports to support data findings.\n\u2022 Manage and maintain data repositories efficiently.\n\u2022 Support senior data scientists in feature creation and selection.\n\u2022 Participate in collaborative projects with cross-functional teams.\n\u2022 Help automate data processing tasks using scripts.\n\u2022 Contribute to model validation and performance testing.\n\u2022 Stay informed about emerging data science tools and methodologies.\n\nSkills:\n\u2022 Advanced Data Cleaning: Enhanced preprocessing and data wrangling techniques.\n\u2022 Intermediate Python: Proficiency in Python for data science tasks.\n\u2022 SQL: More advanced SQL querying skills.\n\u2022 Data Visualization: Ability to create meaningful visualizations using tools like Tableau or Matplotlib.\n\u2022 Machine Learning Basics: Understanding of basic machine learning concepts and algorithms.\n\u2022 Statistical Analysis: Intermediate statistical methods and their applications.\n\u2022 Communication: Articulating data insights clearly to non-technical stakeholders.\n\u2022 Problem-Solving: Effective in identifying data-related issues and providing solutions.\n\nApplicants may be required to appear onsite at a Wolters Kluwer office as part of the recruitment process.",
    "url": "https://in.jooble.org/jdp/-5701870864767254657?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "WFH Machine Learning Jobs in Pune",
    "company": "Turing.com",
    "location": "Pune",
    "salary": "",
    "description": "We, at Turing, are looking for experienced ML engineers who will design and develop machine learning and deep learning systems, machine learning tests and implement Ml algorithms to help in creating AI solutions. Apply for machine learning jobs in Pune and get a chance to work closely with global software engineers, AI/ML enthusiasts and gain unique experiences.",
    "url": "https://www.turing.com/jobs/machine-learning-jobs-in-pune?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "DeepTek.ai - Senior Data Scientist - Python / Deep Learning",
    "company": "DeepTek Medical Imaging Pvt Ltd",
    "location": "Pune",
    "salary": "",
    "description": "Description :\n\nKey Responsibilities :\n\u2022 Lead the design, development, and optimization of deep learning models for medical image analysis, including tasks like segmentation, classification, object detection.\n\u2022 Provide technical leadership and mentorship to junior data scientists and engineers, fostering best practices in research methodology, coding standards, and documentation.\n\u2022 Perform advanced error analysis, bias assessment, and domain generalization studies to ensure robustness across diverse populations and imaging devices.\n\u2022 Guide data storage, preprocessing and annotation strategies, collaborating with clinical experts to ensure data quality and clinical validity.\n\u2022 Collaborate cross-functionally with radiologists, regulatory teams, and product stakeholders to align AI development with clinical requirements and compliance standards.\n\nExperience :\n\u2022 3+ years Data Science / Machine Learning experience\n\nRequired Skills :\n\u2022 Strong programming skills in Python and familiarity with data science and image processing libraries (e.g.,\n\nNumPy, pandas, scikit-learn, OpenCV, PIL).\n\u2022 Strong fundamental knowledge of machine learning, computer vision and image processing.\n\u2022 Hands-on experience with deep learning frameworks like Keras or PyTorch.\n\u2022 Demonstrated experience with both CNNs and transformer-based architectures (e.g., ViT, Swin) for segmentation, detection, and classification tasks.\n\u2022 Strong background with model evaluation and error analysis.\n\u2022 Ability to bridge data science with engineering tasks, ensuring smooth integration of AI models into production workflows.\n\u2022 Hands-on experience with model optimization techniques (e.g distillation, ONNX conversion) for efficient inference.\n\u2022 Hands-on experience with containerization tools like Docker.\n\nDesired Skills :\n\u2022 Familiarity with healthcare / radiology datasets, DICOM standards, and PACS integration.\n\u2022 Experience with domain adaptation, and robustness strategies for cross-site / cross-device generalization.\n\u2022 Experience with scalable backend development for AI applications\n\nQualification :\n\u2022 Bachelors or Masters degree in Computer Science, Data Science, Machine Learning, Statistics, or a related field.\n\n(ref : hirist.tech)",
    "url": "https://in.talent.com/view?id=4a965bcff8b2&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Python & ML Intern (Data Science Track)",
    "company": "Skillfied Mentor Jobs",
    "location": "Pune",
    "salary": "",
    "description": "Python & ML Intern (Data Science Track)\n\nLocation: Remote / Virtual\n\nInternship Type: Unpaid (Stipend available for top performers)\n\nSchedule: Flexible duration & working hours\n\nAbout the Internship\n\nKickstart your journey into Data Science & Machine Learning with this internship crafted for students and fresh graduates. Gain hands-on experience in Python, ML algorithms, and data-driven solutions, while working on real-world projects under the guidance of expert mentors.\n\nWhat You'll Learn:\n\nHands-on projects in\nPython, Machine Learning & Data Science\n\nData preprocessing, visualization & model building\n\nReal-world applications of ML in different industries\n\nWhy Join Us?\n\nWork on\nlive projects\nguided by expert mentors\n\nBuild a\nstrong portfolio\nfor your career in Data Science\n\nEarn an\nISO Certified Internship Certificate\n\nEligibility:\n\nStudents & freshers passionate about\nPython, ML & Data Science\n\nBasic knowledge of Python/Maths/Statistics will be a plus\n\nApplication Deadline: 5th September 2025\n\nKickstart your career in\nData Science & Machine Learning\nwith our ISO Certified Internship",
    "url": "https://www.recruit.net/job/python-ml-data-science-track-jobs/A1A1222481411831?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Associate Data Science Engineer",
    "company": "Cognologix",
    "location": "Pune",
    "salary": "",
    "description": "Associate Data Science Engineer\nWe are seeking an experienced Data Science Engineer with 1+ years of experience implementing AI/ML solutions. The role focuses on developing AI applications and developing cloud-native solutions.\n\nYou will work on:\nWe are looking for a self-driven Data Science Professional to be a member of our Data & AI Practice. We help many of our clients in building advanced analytics solutions (from traditional ML to deep learning, Computer Vision, Gen AI & Automation). You will work on some of the cutting-edge AI technologies to build meaningful products & solutions.\nJob Location: Pune\n\nWhat you will do (Responsibilities):\n\u2022 Perform high-level work both independently and collaboratively as a project member.\n\u2022 Collaborate with Product Management team, elicit AI/ML use case specific requirements, explore and evaluate approaches\n\u2022 Develop Computer Vision, NLP, Deep Learning, multi-modal Gen AI based application features & demos according to the requirements and needs.\n\u2022 Explore new tools, technologies, frameworks in ML, DL, CV, Gen AI technologies and experiments.\n\nWhat you bring (Skills):\n\u2022 1+ years of end-to-end project lifecycle experience (Analysis, Design, Development, Testing, Deployment & Monitoring) in building AI application\n\u2022 Sound knowledge in Linear Algebra, Statistics, Probability\n\u2022 Strong Knowledge & Experience in Python and Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK etc.\n\u2022 Experience with machine learning, deep learning, and/or NLP/NLG frameworks (like Keras, TensorFlow or PyTorch etc.), HuggingFace Transformers and libraries (like scikit-learn, spacy, CoreNLP etc.)\n\u2022 Sound Knowledge of deep learning models for computer vision tasks.\n\u2022 Understanding of image processing, Object detection frameworks and image classification areas\n\u2022 Sound Knowledge in Generative AI /LLM\u2019s models, frameworks, tools & technologies.\n\u2022 Experience in Prompt Engineering & Langchain / LlamaIndex.\n\u2022 Excellent analytical, problem solving and communication skills\n\nGreat if you know (Skills):\n\u2022 Experience in Vector search, RAG frameworks, Function Calling, Agentic Frameworks\n\u2022 Exposure to Cloud-based services such as AWS (Preferred), Azure or GCP\n\u2022 Experience with async programming and RESTful APIs (FastAPI)\n\u2022 Sound understanding of CI-CD, Containerization & Orchestration\n\u2022 Experience with Scrum and/or other Agile development processes\n\u2022 Exposure to MlOps, LLMOps \u2013 model and experiment versioning, hyper parameter tuning, model deployment and monitoring aspects\n\u2022 Sound understanding of data visualization aspects\n\nAdvantage Cognologix:\n\u2022 A higher degree of autonomy, startup culture & small teams\n\u2022 Opportunities to become an expert in emerging technologies\n\u2022 Remote working options for the right maturity level\n\u2022 Competitive salary & family benefits\n\u2022 Performance based career advancement\n\nAbout Cognologix:\nCognologix helps companies disrupt by reimagining their business models and innovate like a Startup. We are at the forefront of digital disruption and take a business-first approach to help meet our client\u2019s strategic goals.\nWe are a Data focused organization helping our clients to deliver their next generation of products in the most efficient, modern, and cloud-native way.",
    "url": "https://careers.cognologix.com/jobs/I51tD9YU1xzC/associate-data-science-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T05:00:00.000Z"
  },
  {
    "title": "Senior Data Scientist (Artificial Intelligence Machine Learning)",
    "company": "FIS Global",
    "location": "Pune",
    "salary": "",
    "description": "Position Type :\n\nFull time\n\nType Of Hire :\n\nExperienced (relevant combo of work and education)\n\nEducation Desired :\n\nBachelor of Engineering\n\nTravel Percentage :\n\n1 - 5%\n\nSenior Data Scientist (Artificial Intelligence Machine Learning)\n\nAre you curious, motivated, and forward-thinking? At FIS you\u2019ll have the opportunity to work on some of the most challenging and relevant issues in financial services and technology. Our talented people empower us, and we believe in being part of a team that is open, collaborative, entrepreneurial, passionate and above all fun.\n\nAbout the role:\n\u2022 We are looking for a talented and passionate Data Scientist willing to challenge themself and produce best in class AI enabled solution\n\u2022 You will be required to use the concepts of AIML, GenAI, LLMs, Sentiment analysis, etc.\n\u2022 The role requires creating correlation between different data points and do predictive, preventive analysis.\n\nAbout the Team :\n\nTeam provide solutions and services that help our clients grow, compete, and optimize their business. Our AIOPS team is creating AIML solution targeted to reduce the Enterprise MTTR through our world class product\n\nWhat you will be doing:\n\u2022 Employ machine learning and statistical modeling to create and enhance data driven products.\n\u2022 Analyze and extract insights from internal and external data.\n\u2022 Work with Big Data and transform complex datasets into more usable formats.\n\u2022 Work with a variety of data science tools and programming languages such as SAS, Python, R, Scala, SQL. Work independently and collaborate with other groups to solve complex problems.\n\u2022 Create and present analyses to internal and external partners and clients.\n\u2022 Will be working in 2 Pm to 11 Pm IST Shifts\n\nWhat you bring:\n\u2022 4 to 6 Years of machine learning, artificial intelligence, statistical modeling, data visualization, and data analysis\n\u2022 Proficient in data science tools and programming languages such as SAS, Python, R, Scala, SQL\n\u2022 Relevant degree in Artificial Intelligence Machine Learning\n\u2022 Experience or knowledge of cloud-based technology\n\u2022 Knowledge of financial services industry\n\nWhat we offer you:\n\u2022 A range of benefits designed to help support your lifestyle and wellbeing.\n\u2022 A multi-faceted job with a broad spectrum of responsibilities\n\u2022 A modern international work environment and a dedicated and innovative team\n\u2022 A broad range of professional education and personal development possibilities \u2013 FIS is your final career step.\n\nPrivacy Statement\n\nFIS is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how FIS protects personal information online, please see the Online Privacy Notice.\n\nSourcing Model\n\nRecruitment at FIS works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. FIS does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company.\n\n#pridepass",
    "url": "https://www.glassdoor.co.in/job-listing/senior-data-scientist-artificial-intelligence-machine-learning-fis-global-JV_IC2856202_KO0,62_KE63,73.htm?jl=1009714190836&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Lead Data Scientist Gen Ai High Salary Pune",
    "company": "Yash Technologies",
    "location": "Pune",
    "salary": "",
    "description": "Job Overview:\n\nLocations- Indore/Pune/Hyderabad/Bangalore\n\nWe are looking for a AI/ML Developer to join our team of researchers, data scientists, and developers. You will work on cutting-edge AI solutions across industries such as commerce, agriculture, insurance, financial markets, and procurement. Your role involves developing and optimizing machine learning and generative AI models to solve real-world challenges.\n\nKey Responsibilities:\n\n\u2022 Develop and optimize ML, NLP, Deep Learning, and Generative AI models.\n\n\u2022 Research and implement state-of-the-art algorithms for supervised and unsupervised learning.\n\n\u2022 Work with large-scale datasets in distributed environments.\n\n\u2022 Understand business processes to select and apply the best ML approaches.\n\n\u2022 Ensure scalability and performance of ML solutions.\n\n\u2022 Collaborate with cross-functional teams, including product owners, designers, and developers.\n\n\u2022 Solve complex data integration and deployment challenges.\n\n\u2022 Communicate results effectively using data visualization.\n\n\u2022 Work in global teams across different time zones.\n\nRequired Skills & Experience:\n\n\u2022 Robust experience in Machine Learning, Deep Learning, NLP, and Generative AI.\n\n\u2022 Hands-on expertise in frameworks like TensorFlow, PyTorch, or Hugging Face Transformers.\n\n\u2022 Experience with LLMs (Large Language Models), model fine-tuning, and prompt engineering.\n\n\u2022 Proficiency in Python, R, or Scala for ML development.\n\n\u2022 Knowledge of cloud-based ML platforms (AWS, Azure, GCP).\n\n\u2022 Experience with big data processing (Spark, Hadoop, or Dask).\n\n\u2022 Ability to scale ML models from prototypes to production.\n\n\u2022 Solid analytical and problem-solving skills.\n\nIf you\u2019re passionate about pushing the boundaries of ML and GenAI, we\u2019d love to hear from you!",
    "url": "https://in.jobrapido.com/jobpreview/4714194881201831936?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "DATA SCIENCE POWER BI INTERNSHIP PUNE",
    "company": "confidential",
    "location": "Pune",
    "salary": "",
    "description": "Maxgen Technologies Pvt ltd is an it company based in pune .We are offering data science internship with power bi program to engineering and diploma candidates..\n\nBenefit we are offering\n\nenjoying work environment .\n\nsmooth shift timing.\n\nlive project in internship.\n\nlong time or short time internship.\n\nhybrid mode internship.\n\nvisit us\n\ncontact us View phone number on foundit.in, View phone number on foundit.in,View phone number on foundit.in ,View phone number on foundit.in,\n\naddress 6th Floor, Konark Icon, 601, above Maruti Suzuki, Magarpatta, Pune, Maharashtra",
    "url": "https://in.jooble.org/jdp/1298935089934152488?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Enterprise Data Analyst",
    "company": "Snowflake",
    "location": "Pune",
    "salary": "",
    "description": "Snowflake is about empowering enterprises to achieve their full potential \u2014 and people too. With a culture that\u2019s all in on impact, innovation, and collaboration, Snowflake is the sweet spot for building big, moving fast, and taking technology \u2014 and careers \u2014 to the next level.\n\nSnowflake is seeking a Data Scientist to join our expanding Enterprise AI & ML team. This role involves working on diverse AI/ML and data science initiatives, utilizing Snowflake's Data Cloud and Cortex AI. The successful candidate will design and develop scalable data science and machine learning solutions, build interactive AI applications, and collaborate on operationalizing intelligent systems to enhance data-driven decision-making throughout the company. This position focuses on applying data science, AI & ML skill sets to various domain specific business data problems across Snowflake.\n\nON THE DATA SCIENCE & ANALYTICS TEAM AT SNOWFLAKE, YOU WILL:\n\u2022 Design, prototype, and deploy data science and AI solutions.\n\u2022 Conduct end to end experimentation, including data exploration, feature engineering, model development, and validation.\n\u2022 Build and maintain Streamlit applications to visualize models, showcase insights, and enable business stakeholders to interact with AI driven solutions.\n\u2022 Develop and optimize LLM based applications, workflows, and operations; with a focus on retrieval, generation, semantic understanding and fine-tuning.\n\u2022 Partner cross functionally with data engineers, analysts, and product teams to translate ambiguous business problems into measurable outcomes.\n\nOUR IDEAL CANDIDATE WILL HAVE:\n\u2022 2 to 4 years of experience applying data science, machine learning, or AI techniques in real world business settings.\n\u2022 Strong programming skills in Python, proficiency in SQL for large scale data manipulation.\n\u2022 Familiarity with frameworks such as scikit-learn, XGBoost etc.\n\u2022 Understanding of LLM architectures, embeddings, vector search, and RAG pipelines.\n\u2022 Experience working on cloud platforms.\n\u2022 Strong analytical, storytelling, and communication skills to translate technical insights into actionable recommendations.\n\u2022 A mindset of curiosity, ownership, and collaboration, with an eagerness to work on open-ended problems.\n\u2022 Experience operationalizing AI & ML models in a production setting.\n\nSnowflake is growing fast, and we\u2019re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.\n\nHow do you want to make your impact?\n\nFor jobs located in the United States, please visit the job posting on the Snowflake Careers Site for salary and benefits information: careers.snowflake.com",
    "url": "https://builtin.com/job/enterprise-data-analyst/7508278?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "House Keeping Staff",
    "company": "Four Season Hospitality Services Prop Vijay Shrirang Kasurde",
    "location": "Phursungi",
    "salary": "",
    "description": "We are looking for a House Keeping Staff to join our team at Four Season Hospitality Services Prop Vijay Shrirang Kasurde to maintain cleanliness and hygiene in assigned areas. The role includes using appropriate cleaning methods, handling chemicals safely, and ensuring a sanitized environment. The position offers an in-hand salary of \u20b913000 - \u20b915000.\n\nKey Responsibilities:\n\u2022 Clean and sanitize designated areas, including floors, furniture, and fixtures.\n\u2022 Restock supplies like toiletries, towels, and cleaning products.\n\u2022 Use and maintain cleaning equipment and tools effectively.\n\u2022 Apply cleaning chemicals safely as per guidelines.\n\u2022 Report damages, maintenance issues, or safety hazards to the concerned department.\n\nJob Requirements:\n\nThe minimum qualification for this role is below 10th and 0 - 1 years of experience. Expert knowledge of cleaning chemicals, equipment, and safety procedures is essential. The role requires candidates with time management skills, attention to detail, and physical stamina to perform tasks efficiently.\n\u2022 It is a Full Time Housekeeping job for candidates with 0 - 1 years of experience.\n\nMore about this House Keeping Staff job\nPlease go through the FAQs to get all answers related to the given House Keeping Staff job\n\u2022 What is the eligibility criteria to apply for this House Keeping Staff job?\nAns: The candidate should be All Education levels and above with 0 - 1 years of experience of experience\n\u2022 How much salary can I expect for this job role?\nAns: You can expect a salary of \u20b913000 - \u20b915000 per month that depends on your interview. It's a Full Time job in Pune.\n\u2022 How many working days are there for this House Keeping Staff job?\nAns: This House Keeping Staff job will have 6 working days.\n\u2022 Are there any charges applicable while applying or joining this House Keeping Staff job?\nAns: No, there is no fee applicable for applying this House Keeping Staff job and during the employment with the company, i.e., Four Season Hospitality Services Prop Vijay Shrirang Kasurde.\n\u2022 Is it a work from home job?\nAns: No, it\u2019s not a work from home job and can't be done online.\n\u2022 How many openings are there for this House Keeping Staff role?\nAns: There is an immediate opening of 1 House Keeping Staff at Four Season Hospitality Services Prop Vijay Shrirang Kasurde\n\u2022 Who can apply for this job?\nAns: Both Male and Female candidates can apply for this Housekeeping job.\n\u2022 What are the timings of this House Keeping Staff job?\nAns: This House Keeping Staff job has 09:00 AM - 06:00 PM timing.\n\nCandidates can call HR for more info.",
    "url": "https://www.jobhai.com/housekeeping-house-keeping-staff-job-in-four-season-hospitality-services-prop-vijay-shrirang-kasurde-phursungi-pune-0-to-1-years-1761802204-6751746-jid?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Housekeeping Hotel Services Associate",
    "company": "beBeeCustomer",
    "location": "Pune",
    "salary": "",
    "description": "Hotel Housekeeping Associate Job Description\n\nDeliver exceptional customer service by providing consistent and professional housekeeping services.\n\nKey requirements include relevant education in Hospitality or Tourism management, at least 2 years of hotel operations experience, strong customer service communication interpersonal skills. Additional responsibilities may involve room cleaning laundry tasks to maintain cleanliness standards.\n\nMain Responsibilities:\n\u2022 Clean guest rooms according bathrooms ensuring highest quality standards.\n\u2022 Maintain cleanliness throughout the hotel including corridors public areas.\n\u2022 Assist with linen laundry tasks as required.\n\u2022 Support housekeeping team members during peak periods.\n\nRequirements:\n\u2022 Degree in Hospitality Tourism Management\n\u2022 At least 2 years hotel operations experience\n\u2022 Excellent customer service communication interpersonal skills\n\nBenefits:\n\u2022 Opportunity to work in a fast-paced environment\n\u2022 Chance to develop skills customer service\n\u2022 Competitive salary package benefits\n\nHow to Apply:\n\nTo apply for this role please submit your application through our website. We look forward to hearing from you.",
    "url": "https://in.bebee.com/job/042b7f939055d64b3b83cfce0b27dcb6?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "\u25b7 Only 24h Left : Python Developer",
    "company": "Wissen Technology",
    "location": "Pune",
    "salary": "",
    "description": "\u2022 Python (4+ years) : Strong expertise in data workflows and automation.\n\u2022 Spark (PySpark) : Hands-on experience with large-scale data processing.\n\u2022 Pandas : For detailed data analysis and validation.\n\u2022 Delta Lake : Managing structured and semi-structured datasets at scale.\n\u2022 SQL : Querying and performing operations on Delta tables.\n\u2022 Kubernetes (K8s) : Container orchestration and deployment.\n\u2022 Azure cloud : Compute and storage services.\n\u2022 Testing frameworks : Proven experience in unit, integration, and system-level testing.\n\nGood to have skillsets\n\u2022 Experience with climate, ESG, or large-scale data domains.\n\u2022 Strong understanding of data standards and governance practices.\n\u2022 Advanced SQL and optimization experience for large datasets.",
    "url": "https://in.talent.com/view?id=fbf46b62a391&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-03T23:00:00.000Z"
  },
  {
    "title": "\u25b7 3 Days Left! Contractual - Python- Django Developer (Pune)",
    "company": "Sagacity Softwares Private Limited",
    "location": "Pune",
    "salary": "",
    "description": "Contract Duration : 6 months\n\nLocation : Pune(onsite)\n\nExperience : 5-7 years\n\nStart Date : Immediate\n\nKey Responsibilities :\n\nDesign, develop, and maintain scalable Python-based applications and services.\n\nWrite clean, efficient, and reusable code following best practices.\n\nCollaborate with cross-functional teams including QA, DevOps, and product managers.\n\nDebug and resolve software defects and technical issues.\n\nParticipate in code reviews and contribute to continuous improvement processes.\n\nEnsure application performance, security, and scalability.\n\nRequired Skills(Mandatory) :\n\nStrong proficiency in Python 3.x\n\nTest Driven Development(TDD)\n\nUnit Testing\n\nOpenAPI / Swagger Documentation\n\nMulti-tenant application\n\nSAML Authentication\n\nHands-on experience with frameworks like Django (Flask or FastAPI \u2013 Optional)\n\nExperience with RESTful API development and integration.\n\nGood understanding of object-oriented programming (OOP).\n\nFamiliarity with SQL / NoSQL databases (e.g., PostgreSQL, MySQL, MongoDB).\n\nCelery with Redis for Message Broker\n\nKnowledge of version control systems like Git.\n\nExposure to Docker and basic knowledge of CI / CD pipelines is a plus.\n\nPreferred Skills :\n\nExperience with cloud platforms such as AWS or Azure.\n\nUnderstanding of Agile methodologies.\n\nExperience with data processing libraries (e.g., Pandas, NumPy) is a plus.\n\nPrior experience working with automotive or manufacturing clients is an advantage.",
    "url": "https://in.talent.com/view?id=6a59cc47bb07&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-03T23:00:00.000Z"
  },
  {
    "title": "\u25b7 Only 24h Left! Python Developer",
    "company": "Cavista Technologies",
    "location": "Pune",
    "salary": "",
    "description": "At Cavista, our mission is to empower organizations with the world\u2019s best technology solutions. We ensure the highest level of client satisfaction through a global network of innovation, and our software solutions are custom-built to accommodate your domain and requirements. Through world-class consultation, innovative IT solutions and personalized client services, Cavista increases operational efficiency for organizations of all sizes.\n\nCavista is searching for great talent. We are an open, agile environment, where transparent conversation ignites collaboration with a team of great thinkers. Everyone freely contributes, ideas override egos, and the best idea always wins. We embrace new technologies and pride ourselves on sustainable and quality code. In our world, opportunity paired with imagination is limitless and we build what others can only hope to dream. We build the best because we hire only the best! We\u2019ve created an atmosphere allowing you to produce your best work, by catering to the creative.\n\nWho we are looking for\n\nAn exceptional Engineer driven by creating groundbreaking technology to innovate the healthcare value chain. We are at the forefront of digital reinvention of healthcare, helping clients reimagine how advanced technology aids in the delivery of care in the home to patients and operational effectiveness to enterprises. This is an opportunity to join a dynamic team, using deep learning, neuro-linguistic programming (NLP), computer vision, chatbots, and robotics to help us improve various business outcomes and drive innovation.\n\nWe seek problem-solvers to thrive in our environment by making a lasting impact on care model innovations, and digital transformation as we develop technology to make lives better.\n\nWhat you will experience\u2026\n\u2022 A fast-paced, collaborative team-oriented environment that encourages every one to bring their authentic self to work every day.\n\u2022 Professional development for career growth and advancement\n\nWho we are...\n\nWe do business differently, by empowering our team to create fresh ideas which impact lives everywhere. We don\u2019t just dream it; we bring life- changing technology to healthcare impacting the way people work, learn and grow their business. Our edge does not come from our technology, it comes from our people. We work as one team with a common goal to create shared success benefiting everyone.\n\nWhat you will do\u2026\n\u2022 Work on functional design, process design (including scenario design, flow mapping), prototyping, testing, training, and defining support procedures, in collaboration with a diverse solutions delivery team\n\u2022 Support our Solutions Delivery team in conducting assessments of the AI (Artificial Intelligence) and automation market and competitor landscape\n\u2022 Collaborate with stakeholders and project teams supporting process, research and development to meet the needs of our AI strategy\n\u2022 Possess a deep understanding of our business and collaborate with teams on how integrating AI capabilities can help lead to solutions\n\u2022 Contribute to cross-functional teams in identifying and prioritizing key areas of our industry where AI solutions can drive significant business benefit\n\u2022 Analyze and explain AI and machine learning (ML) solutions while setting and maintaining high ethical standards\n\u2022 Knowledgeable of a broad range of technology, strategy, and policy and issues associated with AI in healthcare\n\nWhat you bring\u2026\n\u2022 Bachelor's or master's degree in computer science or related field\n\u2022 Required 2-5 years of Experience in Python\n\u2022 Experience with cloud environments\n\u2022 Experience applying AI to practical and comprehensive technology solutions\n\u2022 Experience with ML, deep learning, R, TensorFlow, Python, NLP,\n\u2022 Knowledge of basic algorithms, object-oriented and functional design principles, and best-practice patterns\n\u2022 Experience in REST API development, NoSQL database design, and RDBMS design and optimizations\n\u2022 Experience with innovation accelerators is a plus\n\u2022 Desire and ability to work effectively in an entrepreneurial and dynamic environment",
    "url": "https://in.talent.com/view?id=9849df2f8163&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "Urgent! Sr Python Developer",
    "company": "ACL Digital",
    "location": "Pune",
    "salary": "",
    "description": "Position : Sr Python Developer\n\nExp : 3-5 yrs\n\nLocation : Baner, Pune\n\nMandatory Skills Set : Python Development, Rest API, Linux\n\nJD :\n\n1. Python2.x and 3.x development experience mandatory.\n\n2. Having experience on designing REST API's\n\n3. Experience working with databases, preferably with knowledge of SQL.\n\n4. Hands on knowledge on AWS services.\n\n5. Hands-on on any of the distributions (Linux, CentOS, RedHat, Ubuntu or similar distro).\n\n6. Designing solutions for cloud \u2013 serverless frameworks and microservices",
    "url": "https://in.talent.com/view?id=a8bf46ecbf97&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "15h Left : Python Developer (5 years / FinTech)",
    "company": "PeopleGene",
    "location": "Pune",
    "salary": "",
    "description": "Responsibilities :\n\u2022 Own engineering design, implementation, and delivery of products and features\n\u2022 Improve the scalability and robustness of our backend systems and data pipelines\n\u2022 Collaborate with a cross-functional team of engineers, product managers, and UX\n\ndesigners to develop, test and launch new features\n\u2022 Build, maintain, and scale software development processes and infrastructure\n\nGood to have :\n\u2022 B. Tech / B. Engg in Computer Science or Information Technology from a reputed university\n\u2022 Prior 5 years of experience in building and designing SaaS products\n\u2022 Strong knowledge of OOP and Data Structures & Algorithms\n\u2022 Strong hands-on experience working with Django, Python, SQL, and database optimization\n\u2022 Passion for working on Big Data, Machine Learning, and Statistical problems\n\u2022 Has knowledge / basic experience in React, Redux, Javascript, HTML, CSS",
    "url": "https://in.talent.com/view?id=fc9b2dbf5180&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Python Developer, Pune, India Office",
    "company": "Valtitude",
    "location": "Pune",
    "salary": "",
    "description": "Job Description:\n\nWe are looking for a highly skilled Python Developer with strong expertise in Python, JavaScript, and modern web technologies to design, build, and optimize large-scale cloud-based applications. The ideal candidate will be hands-on with both front-end and back-end development, have experience in Azure services, and be proficient in building scalable APIs and data-driven systems.\n\nKey Responsibilities:\n\n1) Design, develop, and deploy scalable, secure, and high-performing web applications on Azure.\n\n2) Build and maintain front-end applications using modern JavaScript frameworks (React, Angular, or ).\n\n3) Develop back-end services and RESTful APIs primarily in Python.\n\n4) Optimize relational databases (SQL) to ensure efficiency, scalability, and reliability\n\n5) Implement CI/CD pipelines and automate deployments using Azure DevOps.\n\n6) Apply security best practices across applications, APIs, and infrastructure layers.\n\n7) Monitor, troubleshoot, and optimize applications using Azure Monitor, Application Insights, and Log Analytics.\n\n8) Work with ARM templates and infrastructure-as-code for resource management.\n\n9) Conduct end-to-end testing for functionality, usability, security, and performance.\n\n10) Analyze, process, and visualize data using Power BI, Excel, Power Query, or Python.\n\n11) Collaborate with cross-functional teams to define requirements, architect solutions, and deliver robust products.\n\n12) Create and maintain clear technical documentation and provide root cause analysis for production issues.\n\nRequirements/Qualifications:\n\n1) Bachelor's degree in computer science, Information Systems, Industrial Engineering, or a related field.\n\n2) Minimum 2 years of hands-on experience in in full-stack development, data analysis, or demand planning.\n\n3) Strong proficiency in Python (backend development, APIs, data processing).\n\n4) Solid experience with JavaScript, HTML, CSS, and at least one modern JS framework (React, Angular, Vue).\n\n5) Hands-on experience with SQL databases (query writing, optimization, performance tuning).\n\n6) Experience in Azure cloud services, DevOps, and CI/CD pipelines.\n\n7) Familiarity with API integration and data security best practices.\n\n8) Proficiency with Power BI and Excel for data analysis and reporting.\n\n9) Strong problem-solving, debugging, and analytical skills.\n\n10) Excellent communication and collaboration skills in a team environment.\n\nTo apply for this job, please email your resume to and add in the subject line Job Title and Job Code: Jcd-ASEP2105P",
    "url": "https://www.recruit.net/job/python-developer-pune-india-office-jobs/3D8C78659C922372?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Python Developer - Rest API + LLM | Pune | 8 to 12 Years",
    "company": "Capgemini",
    "location": "Pune",
    "salary": "",
    "description": "Job Description\n\nWe are seeking a highly skilled Python Developer with expertise in Artificial Intelligence, Retrieval-Augmented Generation (RAG) integration, and Model Context Protocol (MCP). The candidate will be responsible for developing scalable applications, building intelligent search and conversational systems, and enabling seamless interaction between enterprise systems and LLMs using RAG + MCP pipelines.\nWorks in the area of Software Engineering, which encompasses the development, maintenance and optimization of software solutions/applications.\n1. Applies scientific methods to analyse and solve software engineering problems.\n2. He/she is responsible for the development and application of software engineering practice and knowledge, in research, design, development and maintenance.\n3. His/her work requires the exercise of original thought and judgement and the ability to supervise the technical and administrative work of other software engineers.\n4. The software engineer builds skills and expertise of his/her software engineering discipline to reach standard software engineer skills expectations for the applicable role, as defined in Professional Communities.\n5. The software engineer collaborates and acts as team player with other software engineers and stakeholders.\n\nJob Description - Grade Specific\n\nKey Responsibilities:\n\u2022 Design, develop, and maintain applications in Python.\n\u2022 Implement RAG pipelines by integrating LLMs (OpenAI, Azure OpenAI, Hugging Face, LangChain, LlamaIndex, etc.) with enterprise and external data sources.\n\u2022 Develop MCP-based integrations to connect tools, APIs, and enterprise data systems with LLMs.\n\u2022 Build APIs and microservices for AI-powered search, summarization, and conversational AI.\n\u2022 Create document ingestion pipelines (PDFs, databases, SharePoint, etc.) and manage embeddings with vector databases (Pinecone, Weaviate, FAISS, Qdrant, Azure Cognitive Search, etc.).\n\u2022 Collaborate with AI engineers, architects, and data teams to ensure scalable deployment of RAG/MCP solutions.\n\u2022 Optimize application performance, security, and scalability for production-grade AI systems.\n\u2022 Stay updated with AI frameworks, MCP standards, and cloud AI services.\n\nRequired Skills & Experience:\n\u2022 Minimum of 8 years of IT experience with 1+ years of AI experience\n\u2022 Strong hands-on experience in Python.\n\u2022 Solid understanding of OOP, REST APIs, and microservices architecture.\n\u2022 Proven experience with LLM-based applications and RAG (Retrieval-Augmented Generation) integration.\n\u2022 Knowledge and practical implementation of Model Context Protocol (MCP) for AI tool orchestration.\n\u2022 Familiarity with vector databases (FAISS, Pinecone, Weaviate, Qdrant, Azure Cognitive Search).\n\u2022 Hands-on experience with LangChain, LlamaIndex, Hugging Face Transformers, or similar AI libraries.\n\u2022 Strong problem-solving and cross-functional collaboration skills.\n\nGood to Have Skills\n\nGood to Have:\n\u2022 Experience with containerization (Docker, Kubernetes).\n\u2022 Experience with cloud AI services (Azure, AWS, GCP) for deployment and scaling.\n\u2022 Exposure to SQL/NoSQL databases for structured and unstructured data.\n\u2022 Prior experience in chatbot development, enterprise search, or knowledge management systems.\n\u2022 Understanding of MLOps practices for AI model deployment and monitoring.",
    "url": "https://careers.capgemini.com/job/Pune-Python-Developer-Rest-API-%2B-LLM-Pune-8-to-12-Years/1262739701/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Python / GoLang Developer",
    "company": "Ciena",
    "location": "Pune",
    "salary": "",
    "description": "As the global leader in high-speed connectivity, Ciena is committed to a people-first approach. Our teams enjoy a culture focused on prioritizing a flexible work environment that empowers individual growth, well-being, and belonging. We\u2019re a technology company that leads with our humanity\u2014driving our business priorities alongside meaningful social, community, and societal impact.\n\nJoin Blue Planet, a division of Ciena, and be part of a team shaping the future of network automation. We are seeking highly motivated software engineers to create scalable, reliable, and innovative solutions for a large, distributed environment. If you are passionate about cutting-edge technologies and thrive in a collaborative, agile setting, this is your opportunity to make an impact.\n\nHow You Will Contribute\n\u2022 Design, develop, and maintain scalable microservices and tools, including integrations with Neo4j databases.\n\u2022 Implement innovative technologies, including CNOS and AI-based tools, to optimize platform services.\n\u2022 Build and enhance DevOps automation tools to deploy and manage microservices on Kubernetes.\n\u2022 Collaborate with design teams to support platform usage and deliver tailored customer solutions.\n\u2022 Contribute to all phases of the agile development lifecycle: planning, design, coding, testing, deployment, and documentation.\n\u2022 Troubleshoot and resolve customer-reported issues to ensure system reliability.\n\u2022 Continuously improve processes and systems for enhanced efficiency and performance.\n\nThe Must Haves\n\u2022 3 to 5 years of relevant experience.\n\u2022 Bachelor\u2019s or Master\u2019s Degree in Computer Science or equivalent experience.\n\u2022 Proficiency in programming languages such as Python or GoLang.\n\u2022 Knowledge of microservices and container-based technologies like Docker.\n\u2022 Familiarity with automated deployment, scaling, and management tools for containerized applications, such as Kubernetes (k8s).\n\u2022 Understanding of distributed, highly-available, horizontally scalable systems running at large scale.\n\u2022 Interest and ability to quickly learn and adapt to new languages and technologies.\n\u2022 Strong communication and interpersonal skills.\n\nNice To Haves\n\u2022 Foundational knowledge of Generative AI concepts and tools.\n\u2022 Experience with database technologies, including Neo4j and graph databases.\n\u2022 Good knowledge of OS and software security.\n\u2022 Familiarity with cloud environments such as AWS, Azure, Google Cloud, or OpenStack.\n\u2022 Excellent understanding of code versioning tools like Git.\n\u2022 Experience with distributed platforms and stream processing using Kafka or similar systems.\n\nNot ready to apply? Join our Talent Community to get relevant job alerts straight to your inbox.\n\nAt Ciena, we are committed to building and fostering an environment in which our employees feel respected, valued, and heard. Ciena values the diversity of its workforce and respects its employees as individuals. We do not tolerate any form of discrimination.\n\nCiena is an Equal Opportunity Employer, including disability and protected veteran status.\n\nIf contacted in relation to a job opportunity, please advise Ciena of any accommodation measures you may require.",
    "url": "https://in.linkedin.com/jobs/view/python-golang-developer-at-ciena-4332103167?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "[Only 24h Left] Sr Python Developer",
    "company": "ACL Digital",
    "location": "Pune",
    "salary": "",
    "description": "Position : Sr Python Developer\n\nExp : 3-5 yrs\n\nLocation : Baner, Pune\n\nMandatory Skills Set : Python Development, Rest API, Linux\n\nJD :\n\n1. Python2.x and 3.x development experience mandatory.\n\n2. Having experience on designing REST API's\n\n3. Experience working with databases, preferably with knowledge of SQL.\n\n4. Hands on knowledge on AWS services.\n\n5. Hands-on on any of the distributions (Linux, CentOS, RedHat, Ubuntu or similar distro).\n\n6. Designing solutions for cloud \u2013 serverless frameworks and microservices",
    "url": "https://in.talent.com/view?id=f000c018f3c8&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Lead Python Developer + Artificial intelligence_ Exp: 7+ Years",
    "company": "Atyeti Inc",
    "location": "Pune",
    "salary": "",
    "description": "Job Description :\n\nKey Responsibilities:\n\u2022 Design, develop, and maintain applications in Python.\n\u2022 Implement RAG pipelines by integrating LLMs (OpenAI, Azure OpenAI, Hugging Face, LangChain, LlamaIndex, etc.) with enterprise and external data sources.\n\u2022 Develop MCP-based integrations to connect tools, APIs, and enterprise data systems with LLMs.\n\u2022 Build APIs and microservices for AI-powered search, summarization, and conversational AI.\n\u2022 Create document ingestion pipelines (PDFs, databases, SharePoint, etc.) and manage embeddings with vector databases (Pinecone, Weaviate, FAISS, Qdrant, Azure Cognitive Search, etc.).\n\u2022 Collaborate with AI engineers, architects, and data teams to ensure scalable deployment of RAG/MCP solutions.\n\u2022 Optimize application performance, security, and scalability for production-grade AI systems.\n\u2022 Stay updated with AI frameworks, MCP standards, and cloud AI services.\n\nRequired Skills & Experience:\n\u2022 Minimum of 8 years of IT experience with 1+ years of AI experience\n\u2022 Strong hands-on experience in Python.\n\u2022 Solid understanding of OOP, REST APIs, and microservices architecture.\n\u2022 Proven experience with LLM-based applications and RAG (Retrieval-Augmented Generation) integration.\n\u2022 Knowledge and practical implementation of Model Context Protocol (MCP) for AI tool orchestration.\n\u2022 Familiarity with vector databases (FAISS, Pinecone, Weaviate, Qdrant, Azure Cognitive Search).\n\u2022 Hands-on experience with LangChain, LlamaIndex, Hugging Face Transformers, or similar AI libraries.\n\u2022 Strong problem-solving and cross-functional collaboration skills.\n\nGood to Have:\n\u2022 Experience with containerization (Docker, Kubernetes).\n\u2022 Experience with cloud AI services (Azure, AWS, GCP) for deployment and scaling.\n\u2022 Exposure to SQL/NoSQL databases for structured and unstructured data.\n\u2022 Prior experience in chatbot development, enterprise search, or knowledge management systems.\n\u2022 Understanding of MLOps practices for AI model deployment and monitoring.",
    "url": "https://in.linkedin.com/jobs/view/lead-python-developer-%2B-artificial-intelligence-exp-7%2B-years-at-atyeti-inc-4333527815?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Senior Python Developer - Embedded Linux Platform",
    "company": "Acclivis Technologies Pvt Ltd",
    "location": "Pune",
    "salary": "",
    "description": "Description\n\nJoin our cutting-edge automotive software team and work on next-generation embedded automation and CI/CD integration projects. We are looking for a passionate and experienced professional with strong expertise in Python and Yocto build systems.\n\nNotice Period : Immediate Joiner Preferred\n\nKey Responsibilities\n\u2022 Develop and maintain Python-based tools, scripts, and automation frameworks.\n\u2022 Manage and optimize Yocto build environments for embedded Linux platforms.\n\u2022 Implement and maintain CI/CD pipelines (Jenkins, GitLab CI, etc.)\n\u2022 Collaborate with cross-functional teams to integrate and deploy software efficiently.\n\u2022 Work within Linux-based environments using Bash scripting and Git version control.\n\nRequired Skills\n\u2022 Strong expertise in Python programming (tooling, automation, backend).\n\u2022 Hands-on experience with Yocto build system (mandatory).\n\u2022 Good understanding of CI/CD process and DevOps tools.\n\u2022 Proficiency with Linux, Bash scripting, Docker, and Git.\n\nGood To Have\n\u2022 Exposure to C/C++ or Embedded system integration.\n\u2022 Experience in Automotive or Functional Safety domains\n\n(ref:hirist.tech)",
    "url": "https://in.linkedin.com/jobs/view/senior-python-developer-embedded-linux-platform-at-acclivis-technologies-pvt-ltd-4333550063?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (Python/ GenAI/ AgenticAI)",
    "company": "Wolters Kluwer",
    "location": "Pune",
    "salary": "",
    "description": "Key Responsibilities\n\nActive Learner with Enthusiasm for Problem-Solving\n\nContinuously learn and apply new AI/ML techniques, including Generative AI, Agentic AI deep learning, and other emerging technologies. Demonstrate a passion for solving complex business challenges and experimenting with novel approaches to improve model performance.\n\nQuick Prototyping & Experimentation\n\nDevelop rapid prototypes to test new AI/GenAI/ML approaches and solutions for business problems. Implement proof-of-concept models quickly, enabling fast experimentation and iteration to assess feasibility before scaling to full development.\n\nSupport AI Product Development & Iteration\n\nCollaborate with lead/ senior data scientists and cross-functional teams to support the design, development, and deployment of AI-driven products. Contribute to the creation of prototypes and refine models based on business needs and feedback.\n\nModel Development and Optimization\n\nDesign, develop, and test machine learning, deep learning, and generative AI models, focusing on performance, scalability, and business relevance. Continuously refine and optimize models based on real-world results and metrics.\n\nData Preparation & Collaboration\n\nAssist in defining data requirements and support data engineers in building data pipelines. Clean and preprocess datasets, ensuring data quality and preparing it for use in machine learning applications. Collaborate closely with engineers to integrate models into production systems.\n\nResearch Support and Knowledge Sharing\n\nStay informed about the latest trends and research in AI/GenAI/ML and generative models, applying this knowledge to current projects. Actively participate in team discussions, contribute to the evaluation of new techniques, and share insights with peers to foster a collaborative learning environment.\n\nEssential Skills\n\u2022 Good knowledge of Python programming language, data engineering and data science ecosystem in Python.\n\u2022 Hands on experience in Generative AI, Agentic AI, LLM and Advance RAG techniques.\n\u2022 Hands on experience in developing and supporting Machine Learning solutions.\n\u2022 Hands on experience in developing Natural Language Processing (NLP) solutions\n\u2022 Hands on experience on SQL ecosystem\n\u2022 Hands on experience on Solr framework with Python\n\u2022 Experience of working on Linux and shell scripting\n\u2022 Basic statistical modelling knowledge\n\u2022 Strong Computer Science fundamentals are must. (Data structures, Algorithms, OS, Databases).\n\u2022 Good communication and organizational skills with significant attention to detail\n\u2022 Experience partnering with cross-functional teams of domain experts, engineers, data scientists, and production support teams.\n\u2022 Strong attention to detail with excellent problem-solving skills.\n\u2022 Desire and ability to thrive in a distributed technical environment while working on multiple projects simultaneously.\n\u2022 Passionate about latest technology trends with a strong desire for innovation.\n\u2022 Self-motivated, self-managing and able to work independently.\n\nEducation And Experience\n\u2022 Bachelor's degree (B.E/ B Tech. computer science, engineering, statistics/mathematics or a related field) from a four-year college or university, or equivalent, master\u2019s a plus.\n\u2022 Total at least 1 years of experience working on enterprise AI products\n\u2022 Experience in supporting software products or applications in the AI ML domain.\n\u2022 The above statements are intended to describe the general nature and level of work being performed by most people assigned to this job. They are not intended to be an exhaustive list of all duties and responsibilities and requirements.\n\nApplicants may be required to appear onsite at a Wolters Kluwer office as part of the recruitment process.",
    "url": "https://in.linkedin.com/jobs/view/data-scientist-python-genai-agenticai-at-wolters-kluwer-4319872554?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Intern \u2013 Python/Golang Developer (Blockchain Preferred)",
    "company": "ScopeX Fintech",
    "location": "Pune",
    "salary": "",
    "description": "We\u2019re looking for a Software Engineering Intern who\u2019s passionate about backend development, enjoys problem-solving, and loves to build things that scale.\n\nIf you\u2019re comfortable with Python or Golang, and have a curiosity for Blockchain, this is the perfect opportunity to work on exciting, real-world products.\n\nWhat You\u2019ll Do\n\u2022 Develop and maintain backend services using Python or Golang.\n\u2022 Collaborate with the team to design and implement RESTful APIs.\n\u2022 Write clean, efficient, and testable code.\n\u2022 Participate in debugging, optimization, and code reviews.\n\u2022 Work on live projects with mentorship from experienced engineers.\n\nWhat We\u2019re Looking For\n\u2022 Solid programming fundamentals and data structures knowledge.\n\u2022 Proficiency in Python or Golang.\n\u2022 Good understanding of APIs, Git, and databases.\n\u2022 Strong problem-solving and analytical mindset.\n\u2022 Excellent communication and willingness to learn.\n\nPreferred Skills\n\u2022 Blockchain experience preferred (smart contracts, Web3, token systems, or wallet integrations).\n\u2022 Familiarity with Django, FastAPI, or Gin frameworks.\n\u2022 Basic understanding of Docker, cloud deployments, or microservices.",
    "url": "https://wellfound.com/jobs/3537155-intern-python-golang-developer-blockchain-preferred?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Contractual - Python- Django Developer (Pune)",
    "company": "Sagacity Softwares Private Limited",
    "location": "Pune",
    "salary": "",
    "description": "Contract Duration: 6 months\n\nLocation: Pune(onsite)\n\nExperience: 5-7 years\n\nStart Date: Immediate\n\nKey Responsibilities:\n\nDesign, develop, and maintain scalable Python-based applications and services.\n\nWrite clean, efficient, and reusable code following best practices.\n\nCollaborate with cross-functional teams including QA, DevOps, and product managers.\n\nDebug and resolve software defects and technical issues.\n\nParticipate in code reviews and contribute to continuous improvement processes.\n\nEnsure application performance, security, and scalability.\n\nRequired Skills(Mandatory):\n\nStrong proficiency in Python 3.x\n\nTest Driven Development(TDD)\n\nUnit Testing\n\nOpenAPI/Swagger Documentation\n\nMulti-tenant application\n\nSAML Authentication\n\nHands-on experience with frameworks like Django (Flask or FastAPI \u2013 Optional)\n\nExperience with RESTful API development and integration.\n\nGood understanding of object-oriented programming (OOP).\n\nFamiliarity with SQL/NoSQL databases (e.g., PostgreSQL, MySQL, MongoDB).\n\nCelery with Redis for Message Broker\n\nKnowledge of version control systems like Git.\n\nExposure to Docker and basic knowledge of CI/CD pipelines is a plus.\n\nPreferred Skills:\n\nExperience with cloud platforms such as AWS or Azure.\n\nUnderstanding of Agile methodologies.\n\nExperience with data processing libraries (e.g., Pandas, NumPy) is a plus.\n\nPrior experience working with automotive or manufacturing clients is an advantage.",
    "url": "https://in.jooble.org/jdp/-9022331411785175512?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "Python Developer - (with SQL experience)",
    "company": "Wissen Technology",
    "location": "Pune",
    "salary": "",
    "description": "Python (4+ years) : Strong expertise in data workflows and automation.\n\nSpark (PySpark) : Hands-on experience with large-scale data processing.\n\nPandas : For detailed data analysis and validation.\n\nDelta Lake : Managing structured and semi-structured datasets at scale.\n\nSQL : Querying and performing operations on Delta tables.\n\nKubernetes (K8s) : Container orchestration and deployment.\n\nAzure cloud : Compute and storage services.\n\nTesting frameworks : Proven experience in unit, integration, and system-level testing.\n\nGood to have skillsets\n\nExperience with climate, ESG, or large-scale data domains .\n\nStrong understanding of data standards and governance practices .\n\nAdvanced SQL and optimization experience for large datasets.",
    "url": "https://in.jooble.org/rjdp/-7690808940003013664?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Technical Lead ( AI , Java & Python)",
    "company": "PTC",
    "location": "Pune",
    "salary": "",
    "description": "Our world is transforming, and PTC is leading the way.\u202fOur software brings the physical and digital worlds together, enabling companies to improve operations, create better products, and empower people in all aspects of their business.\n\nOur people make all the difference in our success. Today, we are a global team of nearly 7,000 and our main objective is to create opportunities for our team members to explore, learn, and grow \u2013 all while seeing their ideas come to life and celebrating the differences that make us who we are and the work we do possible.\n\nOur world is transforming, and PTC is leading the way.\u202fOur software brings the physical and digital worlds together, enabling companies to improve operations, create better products, and empower people in all aspects of their business.\n\nOur people make all the difference in our success. Today, we are a global team of nearly 7,000 and our main objective is to create opportunities for our team members to explore, learn, and grow \u2013 all while seeing their ideas come to life and celebrating the differences that make us who we are and the work we do possible.\n\nJob Overview:\n\nAs a Senior Software Engineer on AI team, you will be responsible for working independently on Central AI projects. You will collaborate with cross-functional teams to produce high-quality Software and contribute to larger team on projects as needed.\n\nRequired Skills:\n\u2022 Bachelor\u2019s Degree or higher in Computer Science or related disciplines.\n\u2022 5+ years of experience in building enterprise software applications with strong core programming skills using Object oriented programming (OOP), data structures, and design patterns.\n\u2022 Strong expertise in either Java or Python \u2014 must be proficient in one and have working exposure to the other.\n\u2022 Experience developing scalable backend services and RESTful APIs using Spring Boot or FastAPI, with exposure to microservices, asynchronous processing, and ML/AI integration\n\u2022 Proven experience implementing and maintaining CI/CD pipelines using Jenkins, GitHub Actions, GitLab CI, or Azure DevOps.\n\u2022 Proficiency with containerization (Docker) and orchestration (Kubernetes) for scalable deployment environments.\n\u2022 Understanding of infrastructure as code (IaC) tools such as Terraform, Helm, or Ansible.\n\u2022 Experience in build automation, artifact management, and release pipelines.\n\u2022 Familiarity with monitoring and logging solutions (Grafana, Prometheus, ELK Stack, CloudWatch).\n\u2022 Hands-on experience with Azure, including Azure App Services, Azure Kubernetes Service (AKS), Azure Functions, and Azure DevOps pipelines.\n\u2022 Exposure to cloud security, scalability, and cost optimization principles.\n\u2022 Familiarity with MLOps/AIOps/LLMOps tools\n\u2022 Familiarity with LangChain, Azure OpenAI, or OpenAI API for building intelligent applications and conversational AI systems.\n\u2022 Proficient in Git-based workflows (branching, merging, code reviews, pull requests).\n\u2022 Experience working in Agile/Scrum environments with cross-functional teams.Ability to mentor junior developers and contribute to architecture design discussions.\n\u2022 Strong communication skills and problem-solving mindset.\n\u2022 Ability to prioritize, organize and exhibit good time management skills.\n\u2022 Ability and willingness to innovate and learn new technologies quickly.\n\u2022 Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.\n\u2022 Require work related experience with Java, Eclipse, Unit Testing, Git\n\nJob Responsibilities:\n\u2022 Ability to deliver rapid iterations of software features\n\u2022 Develop innovative and scalable AI solutions for business problems.\n\u2022 Work with software development teams to implement common practices, components and frameworks for support rapid and scalable AI features.\n\u2022 Works collaboratively with other cross-functional teams to achieve goals.\n\u2022 Work on triaging issues reported by product teams\n\u2022 Work with publications team members to help document features for PTC help center.\n\u2022 Design, develop and execute all levels of software testing including unit, integration, performance, and system tests\n\u2022 Passionate about automation.\n\u2022 Additional, related duties as necessary\n\nNice-to- have Skills/Experience:\n\u2022 Prefer experience with Unix/Linux, Agile/Scrum, JIRA/Atlassian Tools\n\u2022 Value experience with relational DBs, Apache Libraries, Azure/Cloud, Distributed/Parallel Computing\n\u2022 CI/CD & DevOps best practices for AI-driven applications\n\u2022 Knowledge of data pipelines, ETL tools, or MLOps frameworks\n\u2022 Experience with API gateways, service mesh, and observability tools\n\u2022 Familiarity with security best practices, performance optimization, and automated testing.\n\nLife at PTC is about more than working with today\u2019s most cutting-edge technologies to transform the physical world. It\u2019s about showing up as you are and working alongside some of today\u2019s most talented industry leaders to transform the world around you.\n\nIf you share our passion for problem-solving through innovation, you\u2019ll likely become just as passionate about the PTC experience as we are. Are you ready to explore your next career move with us?\n\nLife at PTC is about more than working with today\u2019s most cutting-edge technologies to transform the physical world. It\u2019s about showing up as you are and working alongside some of today\u2019s most talented industry leaders to transform the world around you.\n\nIf you share our passion for problem-solving through innovation, you\u2019ll likely become just as passionate about the PTC experience as we are. Are you ready to explore your next career move with us?\n\nWe respect the privacy rights of individuals and are committed to handling Personal Information responsibly and in accordance with all applicable privacy and data protection laws. Review our Privacy Policy here.\"",
    "url": "https://in.linkedin.com/jobs/view/technical-lead-ai-java-python-at-ptc-4324702003?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "[3 Days Left] Contractual - Python- Django Developer (Pune)",
    "company": "Sagacity Softwares Private",
    "location": "Pune",
    "salary": "",
    "description": "Contract Duration: 6 months\n\nLocation: Pune(onsite)\n\nExperience: 5-7 years\n\nStart Date: Immediate\n\nKey Responsibilities:\n\nDesign, develop, and maintain scalable Python-based applications and services.\n\nWrite clean, efficient, and reusable code following best practices.\n\nCollaborate with cross-functional teams including QA, DevOps, and product managers.\n\nDebug and resolve software defects and technical issues.\n\nParticipate in code reviews and contribute to continuous improvement processes.\n\nEnsure application performance, security, and scalability.\n\nRequired Skills(Mandatory):\n\nRobust proficiency in Python 3.x\n\nTest Driven Development(TDD)\n\nUnit Testing\n\nOpenAPI/Swagger Documentation\n\nMulti-tenant application\n\nSAML Authentication\n\nHands-on experience with frameworks like Django (Flask or FastAPI \u2013 Optional)\n\nExperience with RESTful API development and integration.\n\nGood understanding of object-oriented programming (OOP).\n\nFamiliarity with SQL/NoSQL databases (e.g., PostgreSQL, MySQL, MongoDB).\n\nCelery with Redis for Message Broker\n\nKnowledge of version control systems like Git.\n\nExposure to Docker and basic knowledge of CI/CD pipelines is a plus.\n\nPreferred Skills:\n\nExperience with cloud platforms such as AWS or Azure.\n\nUnderstanding of Agile methodologies.\n\nExperience with data processing libraries (e.g., Pandas, NumPy) is a plus.\n\nPrior experience working with automotive or manufacturing clients is an advantage.",
    "url": "https://in.jobrapido.com/jobpreview/4427404040648785920?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Python Developer (GenAI/LLM) | 6\u201310 Years | Any  Location - Job ID: 8874",
    "company": "UST",
    "location": "Pune",
    "salary": "",
    "description": "Job Description\n\nThe role involves designing, developing, and integrating LLM-powered applications into enterprise systems. Key responsibilities include building REST/GraphQL APIs for seamless AI model integration, implementing prompt engineering techniques, evaluating LLM performance, and fine-tuning/customizing models for enterprise use cases.\n\nThe ideal candidate will have strong Python development expertise, hands-on experience with Large Language Models (LLMs), and proficiency in data preprocessing, embeddings, and prompt engineering.",
    "url": "https://in.bebee.com/job/277cc6e3be3c471efccfde8a62d92d4a?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "3 Days Left Python Developer",
    "company": "Tata Consultancy Services",
    "location": "Pune",
    "salary": "",
    "description": "Job Description\n\nThis role lays down the foundation for the entire project and requires experience in development using Python language script, SQL development, Agile, JIRA, Jenkins, and AWS deployment.\n\u2022 Develop code using Python.\n\u2022 Work with IT and Business stakeholders.\n\u2022 Gather requirements, design solutions, and implement CI/CD.\n\nRequirements:\n\u2022 BE/B.tech/MCA/M.Sc./MS degree with at least 3 years of relevant IT-experience.\n\u2022 Full-Time courses only.",
    "url": "https://in.bebee.com/job/65d826935c1365f605a111e85e29ea62?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Senior Software Engineer (Fullstack)",
    "company": "Zendesk Technologies Private Limited (India)",
    "location": "Pune",
    "salary": "",
    "description": "Job Description Note: This is a hybrid role, combining remote and on-site work, requiring 3 days in the office, and relocation to Pune. About Zendesk At Zendesk, our mission is simple yet powerful: to make customer experiences effortless. Every day, our products help thousands of businesses worldwide build deeper relationships with their customers through fast, reliable, and beautifully simple support experiences. We\u2019re taking that mission further with Action Builder \u2013 Zendesk\u2019s next-generation iPaaS solution. Action Builder empowers teams to connect apps, data, and AI-powered agents into seamless workflows that drive automation at scale. At the heart of Action Builder is our Connector SDK, built to make developing integrations faster, more reliable, and more scalable. To power this vision, we\u2019ve set up a dedicated engineering group, the Connector Lab, focused on defining connector bundles and rapidly delivering high-quality connectors across a wide range of third-party systems. Who you could be working with We\u2019re looking for a Senior Software Engineer to join the Connector Lab team in Pune. In this role, you\u2019ll go beyond writing code \u2014 you\u2019ll help define reusable patterns, guide the team on best practices, and ensure connectors are built for long-term scale, security, and maintainability. You\u2019ll collaborate closely with our SDK, platform, and product teams to build a system that enables rapid, reliable connector delivery at scale. You\u2019ll work with cutting-edge AI technologies to streamline and accelerate how we build and maintain connectors - making the process more efficient, intelligent, and scalable. This is a hands-on engineering role with opportunities to mentor, shape architecture, and influence strategy. What you\u2019ll get to do each day Design, build, and maintain third-party connectors using our Connector SDK. Define connector bundles, templates, and patterns to accelerate connector delivery. Lead technical design discussions and set best practices for connector architecture. Collaborate with SDK and platform teams to improve developer tooling, documentation, and workflows. Brainstorm and creatively apply AI technologies to make connector creation faster, smarter, and more reliable. Ensure integrations are scalable, secure, observable, and performant. Partner with Product to identify and prioritize the most impactful connectors for customers. Contribute to and enforce standards around testing, CI/CD, error handling, and observability. Mentor junior engineers and raise the technical bar across the team. What you bring to the role 7+ years of software development experience, ideally with a focus on integrations or API-driven systems. Strong JavaScript/TypeScript skills, with hands-on experience using SDKs and common libraries to build production-grade software. Familiarity with RESTful APIs, GraphQL, OAuth, and webhooks. Hands-on experience working with third-party APIs, solving common integration challenges (auth flows, rate limits, retries, schema drift). Strong systems design and architectural skills for scalable, reusable solutions. A strong product mindset \u2013 you build for reliability, maintainability, and customer impact. Excellent communication and collaboration skills, with experience mentoring or leading peers. Bonus points Experience contributing feedback to SDK or platform teams to improve developer tooling. Background in iPaaS, automation tools, or connector-heavy platforms. Contributions to open-source integration libraries or APIs. Why You\u2019ll Love Zendesk Work on high-impact projects at the core of Zendesk\u2019s automation strategy. Define patterns that will scale across hundreds of connectors. Be part of a mission-driven company with a global footprint and inclusive engineering culture. Flexible hybrid work from our Pune hub. Competitive compensation, benefits, and generous leave policies. Tech Stack Our code is written primarily in JavaScript / TypeScript. Our frontends use frameworks including React, Redux, React Testing Library, Cypress, Jest. Our servers live in AWS. Our applications/services are deployed via Spinnaker to Kubernetes. Our data is stored in Aurora/MySQL, DynamoDB, and S3. About Zendesk\u2019s Product Development Center of Excellence in Pune Zendesk is in the exciting stages of establishing a Product Development Center of Excellence in Pune. This center is being developed gradually to build and scale our operations with an amazing bunch of people. Our vision is to create a vibrant, innovative hub. As an early hire, you will have a unique opportunity to be a pivotal part of this journey. You\u2019ll play a key role in shaping the culture, processes, and success of our Pune site, contributing directly to the growth and maturity of our Product Development Center of Excellence. Your expertise and insights will help lay the foundation for a world-class development center, influencing the way we build and deliver products at Zendesk. EEO Statement Zendesk is an equal opportunity employer, and we\u2019re proud of our ongoing efforts to foster diversity & inclusion in the workplace. Individuals seeking employment at Zendesk are considered without regard to race, colour, religion, national origin, age, sex, gender, gender identity, gender expression, sexual orientation, marital status, medical condition, ancestry, physical or mental disability, military or veteran status, or any other characteristic protected by applicable law. By submitting your application, you agree that Zendesk may collect your personal data for recruiting, global organisation planning, and related purposes. Zendesk's Candidate Privacy Notice explains what personal information Zendesk may process, where Zendesk may process your personal information, its purposes for processing your personal information, and the rights you can exercise over Zendesk\u2019s use of your personal information. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. Please note that Zendesk can only hire candidates who are physically located and plan to work from Karnataka or Maharashtra. Please refer to the location posted on the requisition for where this role is based. Hybrid: In this role, our hybrid experience is designed at the team level to give you a rich onsite experience packed with connection, collaboration, learning, and celebration - while also giving you flexibility to work remotely for part of the week. This role must attend our local office for part of the week. The specific in-office schedule is to be determined by the hiring manager. The intelligent heart of customer experience Zendesk software was built to bring a sense of calm to the chaotic world of customer service. Today we power billions of conversations with brands you know and love. Zendesk believes in offering our people a fulfilling and inclusive experience. Our hybrid way of working, enables us to purposefully come together in person, at one of our many Zendesk offices around the world, to connect, collaborate and learn whilst also giving our people the flexibility to work remotely for part of the week. As part of our commitment to fairness and transparency, we inform all applicants that artificial intelligence (AI) or automated decision systems may be used to screen or evaluate applications for this position, in accordance with Company guidelines and applicable law. Zendesk is an equal opportunity employer, and we\u2019re proud of our ongoing efforts to foster global diversity, equity, & inclusion in the workplace. Individuals seeking employment and employees at Zendesk are considered without regard to race, color, religion, national origin, age, sex, gender, gender identity, gender expression, sexual orientation, marital status, medical condition, ancestry, disability, military or veteran status, or any other characteristic protected by applicable law. We are an AA/EEO/Veterans/Disabled employer. If you are based in the United States and would like more information about your EEO rights under the law, please click here. Zendesk endeavors to make reasonable accommodations for applicants with disabilities and disabled veterans pursuant to applicable federal and state law. If you are an individual with a disability and require a reasonable accommodation to submit this application, complete any pre-employment testing, or otherwise participate in the employee selection process, please send an e-mail to peopleandplaces@zendesk.com with your specific accommodation request. Zendesk is on a mission to simplify the complexity of business and make it easy for companies and customers to create connections. Our customer experience software unlocks the power of billions of interactions, enabling businesses to build rich, meaningful relationships with their customers. What\u2019s it like to work here? Our offices reflect the global cities we call home, and have spaces for collaboration, quiet, and events. With our hybrid approach, you\u2019ll experience flexibility and connection, collaboration, and learning with your team. We\u2019re aware of an increase in recruitment scams where individuals falsely claim to represent Zendesk. These scammers may ask for money or personal information by offering fake job opportunities through e-mail, text message or social media. Please verify the source of any job-related communications carefully. All official Zendesk communications are conducted through \"@zendesk.com\" email addresses. If you encounter suspicious messages, do not respond and report them to peopleandplaces@zendesk.com",
    "url": "https://zendesk.wd1.myworkdayjobs.com/fr-CA/zendesk/job/Senior-Software-Engineer--ROR---React-_R32610?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Associate Lead Software Engineer",
    "company": "Global Payments",
    "location": "Pune",
    "salary": "",
    "description": "Summary of This Role\n\nWorks throughout the software development life cycle and performs in a utility capacity to create, design, code, debug, maintain, test, implement and validate applications with a broad understanding of a variety of languages and architectures. Analyzes existing applications or formulate logic for new applications, procedures, flowcharting, coding and debugging programs. Maintains and utilizes application and programming documents in the development of code. Recommends changes in development, maintenance and system standards. Creates appropriate deliverables and develops application implementation plans throughout the life cycle in a flexible development environment.\n\nWhat Part Will You Play?\n\u2022 Develops basic to moderately complex code using front and / or back end programming languages within multiple platforms as needed in collaboration with business and technology teams for internal and external client software solutions. Designs, creates, and delivers routine to moderately complex program specifications for code development and support on multiple projects/issues with a wide understanding of the application / database to better align interactions and technologies.\n\u2022 Analyzes, modifies, and develops moderately complex code/unit testing in order to develop concise application documentation. Performs testing and validation requirements for moderately complex code changes. Performs corrective measures for moderately complex code deficiencies and escalates alternative proposals.\n\u2022 Participates in client facing meetings, joint venture discussions, vendor partnership teams to determine solution approaches.\n\u2022 Provides support to leadership for the design, development and enforcement of business / infrastructure application standards to include associated controls, procedures and monitoring to ensure compliance and accuracy of data. Applies a full understanding of procedures, methodology and application standards to include Payment Card Industry (PCI) security compliance.\n\u2022 Conducts and provides basic billable hours and resource estimates on initiatives, projects and issues.\n\u2022 Assists with on-the-job training and provides guidance to other software engineers.\n\nWhat Are We Looking For in This Role?\n\nMinimum Qualifications\n\u2022 BS in Computer Science, Information Technology, Business / Management Information Systems or related field\n\u2022 Typically minimum of 4 years - Professional Experience In Coding, Designing, Developing And Analyzing Data. Typically has an advanced knowledge and use of one or more front / back end languages / technologies and a moderate understanding of the other corresponding end language / technology from the following but not limited to; two or more modern programming languages used in the enterprise, experience working with various APIs, external Services, experience with both relational and NoSQL Databases.\n\nPreferred Qualifications\n\u2022 BS in Computer Science, Information Technology, Business / Management Information Systems or related field\n\u2022 6+ years professional Experience In Coding, Designing, Developing And Analyzing Data and experience with IBM Rational Tools\n\nWhat Are Our Desired Skills and Capabilities?\n\u2022 Skills / Knowledge - A seasoned, experienced professional with a full understanding of area of specialization; resolves a wide range of issues in creative ways. This job is the fully qualified, career-oriented, journey-level position.\n\u2022 Job Complexity - Works on problems of diverse scope where analysis of data requires evaluation of identifiable factors. Demonstrates good judgment in selecting methods and techniques for obtaining solutions. Networks with senior internal and external personnel in own area of expertise.\n\u2022 Supervision - Normally receives little instruction on day-to-day work, general instructions on new assignments.\n\nOperating Systems:\n\u2022 Linux distributions including one or more for the following: Ubuntu, CentOS/RHEL, Amazon Linux\n\u2022 Microsoft Windows\n\u2022 z/OS\n\u2022 Tandem/HP-Nonstop\n\nDatabase - Design, familiarity with DDL and DML for one or more of the following databases Oracle, MySQL, MS SQL Server, IMS, DB2, Hadoop\nBack-end technologies - Java, Python, .NET, Ruby, Mainframe COBOL, Mainframe Assembler\nFront-end technologies - HTML, JavaScript, jQuery, CICS\nWeb Frameworks \u2013 Web technologies like Node.js, React.js, Angular, Redux\nDevelopment Tools - Eclipse, Visual Studio, Webpack, Babel, Gulp\nMobile Development \u2013 iOS, Android\nMachine Learning \u2013 Python, R, Matlab, Tensorflow, DMTK",
    "url": "https://jobs.globalpayments.com/en/jobs/r0066730/associate-lead-software-engineer/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Software Engineer II - Java",
    "company": "Rapid7",
    "location": "Pune",
    "salary": "",
    "description": "About the Team\nOur Product and Engineering team works with our award-winning products to help us create a single experience to help customers assess risk, detect threats and automate their security programs at over 10,000 organizations. These teams use best-in-class technology, leading-edge research, and broad, strategic expertise to develop new products and features, and enhance existing features, in order to create value for customers across the world.\n\nThe stakes for creating a safer digital world are greater than ever. At Rapid7 we believe it\u2019s our responsibility to show up every day and give our best for our customers and the entire security community. Our global engineering teams are at the centre of this mission and are dedicated to building a complete suite of industry-leading products which provide a cohesive platform for our customers. Our range of solutions spans vulnerability management, detection, automation, cloud security, and penetration testing; in order to build these products our teams work with an array of technologies including Java, Python, AWS and Go, just to name a few.\n\nJoin our engineering team to help us build and innovate great products on our Insight platform using the latest technologies to make the world a safer digital space.\n\nAbout the Role\n\nThe Software Engineer is a part of our Product and Engineering team who are at the forefront of keeping our customers safe from attacks and breaches. In this role you will be focussed on helping our customers seamlessly manage their security solutions as effectively and efficiently as possible, and ensuring our products are delivering a secure experience. You will have the opportunity to further broaden your skills surrounded by a team of incredibly smart and experienced Engineers, whilst getting the opportunity to mentor others.\n\nIn this role, you will:\n\u2022 Build, maintain, and release our well architected services by writing correct and clean code consistently and following best practices and conventions. You will understand and make well-reasoned design decisions and tradeoffs in your areas of expertise\n\u2022 Take an active role in the design and planning of upcoming features, our engineers are first class stakeholders in all parts of the development process\n\u2022 When required, partner with internal teams such as UX and Product Management who work deeply with our product to ensure we are understanding our customers needs\n\u2022 Continue to develop a deep understanding of our products in order to support our customers\n\u2022 Work with Practice specific technologies\n\nThe skills you\u2019ll bring include:\n\u2022 3+ years experience in software development using Java. Experience using any of the following:\n\u2022 Java Microservices Architecture: Java Spring Boot\n\u2022 Dependency Management Tools such as Maven\n\u2022 Testing frameworks such as JUnit\n\u2022 CI/CS Integrations: Github Actions or Jenkins\n\u2022 Cloud Infrastructure such as AWS\n\u2022 Excited by technology, curious and eager to learn, with the ability to mentor more junior members of the team\n\u2022 The attitude and ability to thrive in a high-growth, evolving environment\n\u2022 Collaborative team player who has the ability to partner with others and drive toward solutions\n\u2022 Strong creative problem solving skills\n\u2022 Solid communicator with excellent written and verbal communications skills both within the team and cross functionally\n\u2022 Passionate about delighting customers, puts the customer needs at the forefront of all decision making\n\u2022 Excellent attention to detail\n\u2022 Demonstrable experience of delivering complex solutions to customers\n\nWe know that the best ideas and solutions come from multi-dimensional teams. That\u2019s because these teams reflect a variety of backgrounds and professional experiences. If you are excited about this role and feel your experience can make an impact, please don\u2019t be shy - apply today\n\nAbout Rapid7\n\nAt Rapid7, our vision is to create a secure digital world for our customers, our industry, and our communities. We do this by harnessing our collective expertise and passion to challenge what\u2019s possible and drive extraordinary impact. We\u2019re building a dynamic and collaborative workplace where new ideas are welcome.\n\nProtecting 11,000+ customers against bad actors and threats means we\u2019re continuing to push the envelope just like we\u2019 ve been doing for the past 20 years. If you \u2019re ready to solve some of the toughest challenges in cybersecurity, we\u2019re ready to help you take command of your career. Join us.",
    "url": "https://careers.rapid7.com/jobs/software-engineer-ii-java-pune-india-d413e7ac-82dc-432e-bb3f-35d249384342?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Embedded Software Engineer (C Language / Medical Devices)",
    "company": "Goken Nihon",
    "location": "Pune",
    "salary": "",
    "description": "Headquartered in Dublin, Ohio (USA) with Engineering Centers in Pune, India and Yokohama, Japan, Goken is a global Engineering Services and Product Development company founded in 2004. We partner with OEMs and suppliers across the mobility space, as well as clients in non-mobility industries, to deliver innovative solutions and accelerate product development.\n\nAt Goken, we embrace our motto of \u201cTime to Innovate\u201d by pushing boundaries, cultivating entrepreneurial thinking, and empowering individuals who thrive on tackling challenges, embrace fresh ideas, and are driven to create solutions that shape the future. This mindset fuels our mission and empowers our teams to solve complex problems, deliver measurable value, and move our clients and industries forward.\n\nOur Vision is to empower associates to drive innovation and lead meaningful change wherever it\u2019s needed, ensuring we stay ahead of the challenges and opportunities of tomorrow. Our Mission is to build trust that fosters greatness in our people, excellence in our clients, and positive impact in the communities we serve.\n\nGoken offers a competitive compensation structure and benefits that support professional growth and personal well-being. We also foster a culture built on high performance, collaboration, continuous improvement, and ongoing professional development.\n\nSummary\n\nYou will be responsible for the full software development lifecycle in a highly regulated medical device environment, from design through documentation, ensuring compliance with relevant industry standards to ensure the stability and drive the new feature development of embedded systems (STM32 / NORTi4 OS) for medical devices. You will be working onsite within our Embedded Systems Development team in Pune/Japan, focusing on high-quality, safety-critical firmware for medical applications.\n\nResponsibilities\n\n\u2003Software Design & Implementation\n\n\u2003\u2003\n\u2022 Translate design inputs and requirement/change specifications into concrete software designs (basic and detailed). \u2003\u2003\n\u2022 Implement firmware in C using environments such as IAR Embedded Workbench. \u2003\u2003\n\u2022 Maintain and optimize existing codebases for performance, memory efficiency, and reliability in real-time systems.\n\n\u2003Verification & Validation\n\n\u2003\u2003\n\u2022 Develop and execute comprehensive unit, integration, and system test plans. \u2003\u2003\n\u2022 Conduct detailed debugging and defect analysis on target hardware using IAR tools and similar environments.\n\n\u2003Documentation & Compliance\n\n\u2003\u2003\n\u2022 Prepare, revise, and maintain design specifications, test protocols, and verification records using Microsoft Word and Excel. \u2003\u2003\n\u2022 Ensure strict adherence to regulatory frameworks such as IEC 62304 and ISO 13485 for medical device software.\n\nQualifications\n\n\u2003\u2003\n\u2022 Minimum 3 years of professional embedded software development experience, ideally in medical devices or other regulated sectors (automotive, avionics, etc.). \u2003\u2003\n\u2022 Strong command of C language, including expertise in pointers, memory management, and data structures for constrained systems. \u2003\u2003\n\u2022 Hands-on proficiency in Git (commit, push, pull, merge, branch management). \u2003Japanese language: Business-level proficiency (JLPT N2 or above preferred) \u2003\u2003\n\u2022 Capable of daily technical discussions in Japanese \u2003\u2003\n\u2022 Able to read Japanese code comments and technical documentation \u2003\u2003\n\u2022 Able to author and revise technical documents in Japanese \u2003English language: Fluent for professional and technical communication.\n\n\u2003Good-to-Have Skills\n\n\u2003\u2003\n\u2022 Experience with STM32 microcontrollers (Arm Cortex-M) and IAR Embedded Workbench IDE. \u2003\u2003\n\u2022 Familiarity with NORTi v4 or other ITRON-specification RTOS (or equivalent RTOS kernel experience). \u2003\u2003\n\u2022 Working knowledge of IEC 62304 and/or ISO 13485 compliance frameworks. \u2003\u2003\n\u2022 Exposure to MISRA-C, code coverage tools, and automated testing environments.\n\n#GokenIndia\n\n#GokenNihon\n\nGoken is committed to fostering a respectful, inclusive, and engaging workplace across all global locations. We value diversity and provide equal opportunities for career growth and professional development, regardless of race, color, religion, national origin, sex, age, disability, veteran status, genetic information, sexual orientation, gender identity, marital status, or any other characteristic protected by law.",
    "url": "https://in.linkedin.com/jobs/view/embedded-software-engineer-c-language-medical-devices-at-goken-nihon-4337731395?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T12:00:00.000Z"
  },
  {
    "title": "Software Engineer-1",
    "company": "Mastercard",
    "location": "Pune",
    "salary": "",
    "description": "Mastercard is hiring for the role of Software Engineer-1!\n\nResponsibilities of the Candidate:\n\u2022 Own software delivery tasks (code development, test, deployment) at an application/software component level\n\u2022 Able to troubleshoot and refactor existing code for exceptional code quality.\n\u2022 Adopt new languages and architecture patterns needed for the work.\n\u2022 Participate and contribute to team\u2019s agile process and decisions.\n\u2022 Pull from backlog and deliver work after seeking guidance from experienced team members and in partnership with full scrum team.\n\u2022 Understands the big picture and end-to-end logical architecture of systems in ownership areas\n\u2022 Provide feedback and suggestions on areas to improve\n\u2022 Understands the use of Mastercard technology policies in everyday work\n\u2022 Demonstrate active learning and sharing of software practices via Guild/Engineering community initiatives\n\u2022 Influence the decisions made by the team.\n\u2022 Assist peers and less experienced members.\n\u2022 Influence the decisions made by the team.\n\u2022 Assist in technical documentation of APIs and services being delivered.\n\nRequirements:\n\u2022 Has ability to write secure code in three or more languages (e.g., Java, .NET, JavaScript, SQL)\n\u2022 Familiar with secure coding standards (e.g., OWASP, CWE, SEI CERT)\n\u2022 Infrastructure as code and cloud first software development knowledge experience preferred.\n\u2022 Understands and implements standard branching (e.g., Gitflow) and peer review practices\n\u2022 Apply tools (e.g., Sonar, Zally, Checkmarx ) and techniques to scan and measure code quality and anti-patterns as part of development activity\n\u2022 Understands and builds test code at unit level, service level, and integration level to ensure code and functional coverage\n\u2022 Understands the use of basic design patterns (e.g., factory, adaptor, singleton, composite, observer, strategy, inversion of control)\n\u2022 Understands requirement analysis being essential part of delivering value to our customers and partners and participate in elaboration, prioritization, and effort estimation\n\u2022 Understands agile and modern SDLC practices (Scrum/Kanban/Continuous Delivery/DevOps/Quality engineering) and the delivery situations they are used for\n\u2022 Understands the basic engineering principles used in building and running mission critical software capabilities (security, customer experience, testing, operability, simplification, service-oriented architecture)\n\u2022 Familiar with different application patterns to implement different types of business processes (e.g., APIs, event-driven-services, batch-services, web-applications, big data)\n\u2022 Understands Continuous Integration (CI) and Delivery (CD) concepts, and capabilities to support automation, pipelines, virtualization, and containerization\n\u2022 Has ability to write code (in languages such as Java, Python, Ruby, Bash, Perl, Groovy) to build automation tasks that are repeatable and efficient\n\u2022 Understands functional and non-functional testing types to elaborate and estimate test efforts",
    "url": "https://unstop.com/jobs/software-engineer-1-mastercard-1581849?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Only 24h Left! Software Engineer",
    "company": "LTIMindtree",
    "location": "Pune",
    "salary": "",
    "description": "Hi,\n\nKindly share your updated resume along with below details at Nikhil.Singh@LTIMindtree.com -\n\nCurrent location -\n\nPreferred location -\n\nCurrent CTC -\n\nExpected CTC -\n\nNotice period (LWD if serving / served) -\n\nYears of Experience in -\n\nTotal -\n\nAngular -\n\nJava -\n\nSpring boot -\n\nMicroservices -\n\nRole - Java full stack Developer\n\nExperience required 3 to 15 years\n\nLocation - Noida / Bangalore / Kolkata / Pune / Chennai / Mumbai\n\nThe Full Stack Engineer will be responsible for developing maintaining and deploying web applications using AngularJS Java and cloud technologies This position is ideal for someone who is experienced in developing web applications has the ability to work independently and is comfortable with both frontend and backend web development\n\nResponsibilities\n\u2022 Design develop and maintain web applications using Angular js Java and cloud technologies\n\u2022 Develop and maintain frontend web user interfaces and components\n\u2022 Create and maintain backend services for web applications\n\u2022 Develop and implement automated testing of web applications\n\u2022 Deploy applications to cloud\n\u2022 Develop and maintain CICD pipelines for web applications\n\u2022 Troubleshoot issues related to web application development\n\u2022 Provide technical assistance and guidance to other developers\n\u2022 Stay up to date with the latest technologies and best practices\n\u2022 Requirements\n\u2022 36 years of experience in web development using AngularJS Java and cloud technologies\n\u2022 Strong knowledge of web development principles and practices\n\u2022 Ability to work independently and as part of a team\n\u2022 Experience with developing automated testing\n\u2022 Excellent problem solving and communication skills\n\u2022 Knowledge of CICD pipelines\n\u2022 Ability to troubleshoot and debug web applications\n\u2022 Familiarity with database design and development",
    "url": "https://in.talent.com/view?id=f89fb52a3192&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Senior Consultant - Software Engineering",
    "company": "Principal Global Services",
    "location": "Pune",
    "salary": "",
    "description": "Responsibilities\n\nJob Purpose\n\nOwner of, and expert on large sections of our solutions. Consistently able to reduce the complexity of projects, services, and processes in order to get more done with less work. Consult with business partners and make recommendations on future technical trends/directions that encompass multiple systems and teams to meet business strategic initiatives.\n\nEssential Functions\n\nDescription\n\n% of Time Spent\n\nDelivery\n\u2022 Ownership & expertise on large sections of our solutions / multiple systems - Implementations & support\n\u2022 Building application/systems roadmap \u2013 mid to longer term (6-12 months)\n\u2022 Leverage enterprise level methodologies, tools, processes, technologies, design patterns in implementations and advance adoption within business unit\n\u2022 Lead Continuous Improvement practices within area of influence\n\u2022 Identify opportunities for business and technology Innovation aligned with HLIs\n\u2022 Bring automation first mindset to automate business processes\n\u2022 Collaborate with internal and external partners for implementing end to end solutions\n\n35%\n\nSolution Design & Implementation\n\u2022 Lead, design and communicate technical concepts to business stakeholders as well as communicate business objectives to the technical team and get buy-in.\n\u2022 Support broad architecture; design and implement large services, complex libraries or major pieces of infrastructure.\n\u2022 Quickly break down complex problems into potential solutions, knowns, and unknowns, in order to get to solid resolutions faster. Able to recognize and make trade-offs with respect to the whole system.\n\u2022 Capable of debugging the most complex problems that the team encounters.\n\u2022 Anticipate technical issues at the product level and make architectural and design decisions to avoid them\n\u2022 Practice/Implement Design thinking approach\n\n35%\n\nStrategy\n\u2022 Good understanding of business strategic initiatives; consistently influence decision-making at the business level\n\u2022 Be abreast with latest technology trends\n\n10%\n\nTalent Maturity\n\u2022 Grow the team's ability to own and design all software development layers of a solution, proactively nurture talent of the senior staff in the area\n\u2022 Multiply the effectiveness of others by facilitating cross-team work\n\u2022 Demonstrate engineering mindset and build it in teams\n\n15%\n\nOther\n\u2022 Contribution to CoPs (Community of Practice)\n\u2022 Networking for sharing and getting cross BU best practices\n\n5%\n\nQualifications\n\nQualifications\n\nEducation:\u202fGraduate \u2013 Bachelor\u2019s degree (any stream).\n\nExperience:\u202f11+ years of IT experience. Experience is not a constraint for the right candidate.\n\u2022 Proven experience as an IT professional. Ability to obtain certification(s) in an IT related field is a plus.\n\u2022 Basic knowledge of insurance and financial services products preferred. Knowledge of business unit applications preferred.\n\u2022 Advanced planning, organizational, problem-solving, analytical, decision-making and communication skills required.\n\u2022 Proficiency with database applications, knowledge of mainframe, distributed and/or web programming language, cloud, DevOps, modern engineering techniques\n\u2022 Strong leadership and presentation skills required. Must be able to maintain a high degree of accuracy and confidentiality.\n\u2022 Must have the desire to learn new technology and continuously grow.\n\u2022 Ability to work on cross-functional teams and collaborate with both It and non-IT partners. Some travel may be required, including overnight stays. May be required to provide on-call support.\n\nReporting Relationships\n\nThis job reports to: Program Manager\n\nDirect Reports: None",
    "url": "https://careers.principal.com/PH-talent/jobs/48549?lang=en-us&previousLocale=en-US&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Firmware Engineer",
    "company": "Philips",
    "location": "Pune",
    "salary": "",
    "description": "Job Title\nFirmware Engineer\n\nJob Description\n\nFirmware Engineer\n\nIn this role, you have the opportunity to make life better\n\nLooking at the challenges today the world is facing Philips\u2019 purpose has never been more relevant. So, whatever your role, if you share our passion for helping others, you\u2019ll be working towards creating a better and fairer future for all.\n\nThe Firmware Engineer will be responsible for the firmware / embedded software development of medical devices and associated equipment.\n\nYou are responsible for\n\u2022 Design and develop firmware for respiratory care medical equipment.\n\u2022 Create software requirements specifications, software architecture documents, and detailed software design documents based on electrical schematics of the embedded hardware platform.\n\u2022 Design and debug firmware for embedded processors, microcontrollers, digital signal processors, and other electronic components or circuits using C++ programming languages.\n\u2022 Design and debug multi-threaded firmware to run on various real-time operating systems.\n\u2022 Use test and measurement apparatus, including oscilloscopes, logic analyzers, communication protocol analyzers, and signal generators, to ensure that firmware functions per design requirements.\n\u2022 Manage relationships with software tools vendors, distributors, and subcontractors.\n\u2022 Manage the transition of products from the development stage to full-scale production and ensure that products are delivered to market on time and on budget.\n\u2022 Perform all these tasks under minimal supervision, and possess the ability to complete all phases of major projects\n\nTo succeed in this role, you\u2019ll need a customer-first attitude and the following\n\u2022 B.S. Electrical, Electronics or Computer Engineering required\n\u2022 4 - 9 years of related work experience\n\u2022 Expert level programming skills in C++ for real time environments.\n\u2022 Experience developing software in various RTOS environments (e.g. FreeRTOS, VxWorks, Yocto Linux).\n\u2022 Experience implementing highly optimized digital signal processing and pattern recognition algorithms.\n\u2022 Experience with linear algebra/matrix processing and associated software packages (MATLAB, etc.)\n\u2022 Experience estimating and planning software development projects.\n\u2022 Experience using test and measurement equipment, including oscilloscopes, logic analyzers, communication protocol analyzers, and signal generators.\n\u2022 Proficiency in Microsoft Office software suite, including Microsoft Visio.\n\u2022 Ability to demonstrate strong attention to accuracy and detail.\n\u2022 Ability to successfully manage multiple tasks.\n\nHow we work together\nWe believe that we are better together than apart. For our office-based teams, this means working in-person at least 3 days per week.\nOnsite roles require full-time presence in the company\u2019s facilities.\nField roles are most effectively done outside of the company\u2019s main facilities, generally at the customers\u2019 or suppliers\u2019 locations.\nIndicate if this role is an office/field/onsite role.\nAbout Philips\nWe are a health technology company. We built our entire company around the belief that every human matters, and we won't stop until everybody everywhere has access to the quality healthcare that we all deserve. Do the work of your life to help the lives of others.\n\u2022 Learn more about our business.\n\u2022 Discover our rich and exciting history.\n\u2022 Learn more about our purpose.\nIf you\u2019re interested in this role and have many, but not all, of the experiences needed, we encourage you to apply. You may still be the right candidate for this or other opportunities at Philips. Learn more about our culture of impact with care here.\n\n#connectedcare",
    "url": "https://www.careers.philips.com/global/en/job/565911/Firmware-Engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "Senior Software engineer-2",
    "company": "Mastercard",
    "location": "Pune",
    "salary": "",
    "description": "Our Purpose\n\nMastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we\u2019re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.\n\nTitle and Summary\n\nSenior Software engineer-2\n\nOverview:\n\nWho is Mastercard?We work to connect and power an inclusive, digital economy that benefits everyone, everywhere, by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships, and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team \u2013 one that makes better decisions, drives innovation, and delivers better business results.\nAbout the Role\n\nSoftware Engineers at Mastercard design and code payment applications, artificial intelligence, cloud, and machine learning platforms that provide mission-critical insights to many of the world\u2019s leading organizations and governments. As a Senior Software Engineer, you will deliver these products and solutions with speed and agility as part of a small team. This will involve developing high-performing, highly scalable software solutions and products for some of the world\u2019s top brands. Specific tasks vary depending on the project and the business unit that you join in.\nAll staff at Mastercard are expected to demonstrate 'Mastercard Way' cultural values every day - own it, simplify it, sense of urgency, thoughtful risk-taking, unlock potential, and be inclusive \u2013 with a relentless focus on our customers. As a Senior Software Engineer at Mastercard, you are expected to perform the following general responsibilities:\n\u2022 Actively participate in team prioritization discussions with Product/Business stakeholders\n\u2022 Estimate and own delivery tasks (design, dev, test, deployment, configuration, documentation) to meet the business requirements\n\u2022 Drive code/design/process trade-off discussions within their team when required\n\u2022 Perform demos/acceptance discussions in interacting with Product owners\n\u2022 Develop complete understanding of end-to-end technical architecture and dependency systems\n\u2022 Drive adoption of technology standards and opinionated frameworks, and review coding, test, and automation work of team members\n\u2022 Mentor and guide new and less-experienced team members\n\u2022 Identify opportunities to improve an overall process and trim waste; Share and seek knowledge within Guild/Program to drive reuse of patterns/libraries/practices and enhance productivity\n\nAll About You\n\nThe ideal candidate for this position should have/be:\n\u2022 Hold a bachelor\u2019s degree in Computer Science or equivalent experience. Cards and payments domain, experience in settlement, reporting and reconciliation\n\u2022 Hands-on experience on backend development - Java, SpringBoot, Devops, Oracle, Cloud native application design and deployment, automation testing\n\u2022 Deep knowledge of software development processes including agile processes\n\u2022 Involved and spearhead quality initiatives\n\u2022 Result oriented individual Automation experience and Code Quality\n\u2022 A team player with excellent verbal and written communication skills\n\u2022 Ability to guide people to implement the right solution\n\nCorporate Security Responsibility\n\nAll activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:\n\u2022 Abide by Mastercard\u2019s security policies and practices;\n\u2022 Ensure the confidentiality and integrity of the information being accessed;\n\u2022 Report any suspected information security violation or breach, and\n\u2022 Complete all periodic mandatory security trainings in accordance with Mastercard\u2019s guidelines.",
    "url": "https://careers.mastercard.com/us/en/job/R-263298/Senior-Software-engineer-2?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "Python Development - Internship",
    "company": "Fidel Softech Limited",
    "location": null,
    "salary": "",
    "description": "About the internship:\nSelected intern's day-to-day responsibilities include:\n\n- Collaborate with the development team to design, develop, and deploy Python-based solutions.\n\n- Write clean, efficient, and reusable code while adhering to best practices.\n\n-Conduct re\n\nsearch and analysis on the latest Python trends and emerging technologies.\n\n-Debug and troubleshoot software issues to ensure optimal functionality.\n\n-Assist in the integration of third-party APIs and libraries into existing projects.\n\n- Document technical processes and project details for knowledge sharing.\n\n-Actively engage in team discussions and brainstorming sessions. Selected intern's day-to-day responsibilities include:\n\nRequired Skills and Qualifications:\n\n-Currently pursuing or completing B.Tech/M.Tech/MCM/MCA in Computer Science, IT, or a related field.\n\n-Proficient in Python programming with a good understanding of data structures and algorithms.\n\n- Familiarity with Python frameworks such as Django, Flask, or FastAPI is a plus.\n\n-Knowledge of libraries/tools like NumPy, Pandas, or Matplotlib for data analysis.\n\n-Awareness of the latest trends in Python and its applications (e.g., AI/ML, Web Development, Data Science).\n\n-Strong problem-solving skills and a proactive approach to learning.\n\n-Good verbal and written communication skills.\n\nWho can apply:\n\nOnly those candidates can apply who:\n\u2022 are available for full time (in-office) internship\n\u2022 can start the internship between 31st Oct'25 and 5th Dec'25\n\u2022 are available for duration of 6 months\n\u2022 have relevant skills and interests\n\u2022 * Women wanting to start/restart their career can also apply.\n\u2022 are Computer Science Engineering students\n\nStipend:\nINR\u20b9 10,000 - 12,000 /month\n\nDeadline:\n2025-12-03 23:59:59\n\nOther perks:\nCertificate, 5 days a week, Free snacks & beverages\n\nSkills required:\nPython, Django, Machine Learning, Flask, NumPy, Pandas and Matplotlib\n\nOther Requirements:\n\n-Hands-on experience working on live Python projects.\n\n-Mentorship from experienced professionals.\n\n-Exposure to cutting-edge tools and technologies.\n\n-Opportunity to gain industry-relevant skills.\n\nAbout Company:\nFidel Softech Ltd. (formerly known as Fidel Softech Pvt. Ltd.) works with clients across diverse domains in the areas of technology implementation, localization services, consulting, and staffing services.\n\nFidel's unique expertise and USP lies in:\n\n1. Managing and executing Japanese geography projects\n\n2. Implementation and Operational support of ServiceNow, AutomationAnywhere\n\n3. Deep localization engineering as well as language expertise covering 60+ languages\n\n4. Specialized consulting & staffing services to support complex projects\n\n5. ISO9001, ISO27001 certified and strong awareness of quality, data security\n\n6. Exposure to global delivery models, agile and waterfall delivery methodologies",
    "url": "https://internshala.com/internship/detail/python-development-internship-in-pune-at-fidel-softech-limited1762185276?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "Senior Python Developer - Embedded Linux Platform",
    "company": "Acclivis Technologies Pvt Ltd",
    "location": null,
    "salary": "",
    "description": "Description\n\nJoin our cutting-edge automotive software team and work on next-generation embedded automation and CI/CD integration projects. We are looking for a passionate and experienced professional with strong expertise in Python and Yocto build systems.\n\nNotice Period : Immediate Joiner Preferred\n\nKey Responsibilities\n\u2022 Develop and maintain Python-based tools, scripts, and automation frameworks.\n\u2022 Manage and optimize Yocto build environments for embedded Linux platforms.\n\u2022 Implement and maintain CI/CD pipelines (Jenkins, GitLab CI, etc.)\n\u2022 Collaborate with cross-functional teams to integrate and deploy software efficiently.\n\u2022 Work within Linux-based environments using Bash scripting and Git version control.\n\nRequired Skills\n\u2022 Strong expertise in Python programming (tooling, automation, backend).\n\u2022 Hands-on experience with Yocto build system (mandatory).\n\u2022 Good understanding of CI/CD process and DevOps tools.\n\u2022 Proficiency with Linux, Bash scripting, Docker, and Git.\n\nGood To Have\n\u2022 Exposure to C/C++ or Embedded system integration.\n\u2022 Experience in Automotive or Functional Safety domains\n\n(ref:hirist.tech)",
    "url": "https://in.linkedin.com/jobs/view/senior-python-developer-embedded-linux-platform-at-acclivis-technologies-pvt-ltd-4333550063?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Data Scientist (Python/ GenAI/ AgenticAI)",
    "company": "Wolters Kluwer",
    "location": null,
    "salary": "",
    "description": "Key Responsibilities\n\nActive Learner with Enthusiasm for Problem-Solving\n\nContinuously learn and apply new AI/ML techniques, including Generative AI, Agentic AI deep learning, and other emerging technologies. Demonstrate a passion for solving complex business challenges and experimenting with novel approaches to improve model performance.\n\nQuick Prototyping & Experimentation\n\nDevelop rapid prototypes to test new AI/GenAI/ML approaches and solutions for business problems. Implement proof-of-concept models quickly, enabling fast experimentation and iteration to assess feasibility before scaling to full development.\n\nSupport AI Product Development & Iteration\n\nCollaborate with lead/ senior data scientists and cross-functional teams to support the design, development, and deployment of AI-driven products. Contribute to the creation of prototypes and refine models based on business needs and feedback.\n\nModel Development and Optimization\n\nDesign, develop, and test machine learning, deep learning, and generative AI models, focusing on performance, scalability, and business relevance. Continuously refine and optimize models based on real-world results and metrics.\n\nData Preparation & Collaboration\n\nAssist in defining data requirements and support data engineers in building data pipelines. Clean and preprocess datasets, ensuring data quality and preparing it for use in machine learning applications. Collaborate closely with engineers to integrate models into production systems.\n\nResearch Support and Knowledge Sharing\n\nStay informed about the latest trends and research in AI/GenAI/ML and generative models, applying this knowledge to current projects. Actively participate in team discussions, contribute to the evaluation of new techniques, and share insights with peers to foster a collaborative learning environment.\n\nEssential Skills\n\u2022 Good knowledge of Python programming language, data engineering and data science ecosystem in Python.\n\u2022 Hands on experience in Generative AI, Agentic AI, LLM and Advance RAG techniques.\n\u2022 Hands on experience in developing and supporting Machine Learning solutions.\n\u2022 Hands on experience in developing Natural Language Processing (NLP) solutions\n\u2022 Hands on experience on SQL ecosystem\n\u2022 Hands on experience on Solr framework with Python\n\u2022 Experience of working on Linux and shell scripting\n\u2022 Basic statistical modelling knowledge\n\u2022 Strong Computer Science fundamentals are must. (Data structures, Algorithms, OS, Databases).\n\u2022 Good communication and organizational skills with significant attention to detail\n\u2022 Experience partnering with cross-functional teams of domain experts, engineers, data scientists, and production support teams.\n\u2022 Strong attention to detail with excellent problem-solving skills.\n\u2022 Desire and ability to thrive in a distributed technical environment while working on multiple projects simultaneously.\n\u2022 Passionate about latest technology trends with a strong desire for innovation.\n\u2022 Self-motivated, self-managing and able to work independently.\n\nEducation And Experience\n\u2022 Bachelor's degree (B.E/ B Tech. computer science, engineering, statistics/mathematics or a related field) from a four-year college or university, or equivalent, master\u2019s a plus.\n\u2022 Total at least 1 years of experience working on enterprise AI products\n\u2022 Experience in supporting software products or applications in the AI ML domain.\n\u2022 The above statements are intended to describe the general nature and level of work being performed by most people assigned to this job. They are not intended to be an exhaustive list of all duties and responsibilities and requirements.\n\nApplicants may be required to appear onsite at a Wolters Kluwer office as part of the recruitment process.",
    "url": "https://in.linkedin.com/jobs/view/data-scientist-python-genai-agenticai-at-wolters-kluwer-4319872554?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Contractual - Python- Django Developer (Pune)",
    "company": "Sagacity Softwares Private Limited",
    "location": null,
    "salary": "",
    "description": "Contract Duration: 6 months\n\nLocation: Pune(onsite)\n\nExperience: 5-7 years\n\nStart Date: Immediate\n\nKey Responsibilities:\n\nDesign, develop, and maintain scalable Python-based applications and services.\n\nWrite clean, efficient, and reusable code following best practices.\n\nCollaborate with cross-functional teams including QA, DevOps, and product managers.\n\nDebug and resolve software defects and technical issues.\n\nParticipate in code reviews and contribute to continuous improvement processes.\n\nEnsure application performance, security, and scalability.\n\nRequired Skills(Mandatory):\n\nStrong proficiency in Python 3.x\n\nTest Driven Development(TDD)\n\nUnit Testing\n\nOpenAPI/Swagger Documentation\n\nMulti-tenant application\n\nSAML Authentication\n\nHands-on experience with frameworks like Django (Flask or FastAPI \u2013 Optional)\n\nExperience with RESTful API development and integration.\n\nGood understanding of object-oriented programming (OOP).\n\nFamiliarity with SQL/NoSQL databases (e.g., PostgreSQL, MySQL, MongoDB).\n\nCelery with Redis for Message Broker\n\nKnowledge of version control systems like Git.\n\nExposure to Docker and basic knowledge of CI/CD pipelines is a plus.\n\nPreferred Skills:\n\nExperience with cloud platforms such as AWS or Azure.\n\nUnderstanding of Agile methodologies.\n\nExperience with data processing libraries (e.g., Pandas, NumPy) is a plus.\n\nPrior experience working with automotive or manufacturing clients is an advantage.",
    "url": "https://in.jooble.org/jdp/-9022331411785175512?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "Intern \u2013 Python/Golang Developer (Blockchain Preferred)",
    "company": "ScopeX Fintech",
    "location": null,
    "salary": "",
    "description": "We\u2019re looking for a Software Engineering Intern who\u2019s passionate about backend development, enjoys problem-solving, and loves to build things that scale.\n\nIf you\u2019re comfortable with Python or Golang, and have a curiosity for Blockchain, this is the perfect opportunity to work on exciting, real-world products.\n\nWhat You\u2019ll Do\n\u2022 Develop and maintain backend services using Python or Golang.\n\u2022 Collaborate with the team to design and implement RESTful APIs.\n\u2022 Write clean, efficient, and testable code.\n\u2022 Participate in debugging, optimization, and code reviews.\n\u2022 Work on live projects with mentorship from experienced engineers.\n\nWhat We\u2019re Looking For\n\u2022 Solid programming fundamentals and data structures knowledge.\n\u2022 Proficiency in Python or Golang.\n\u2022 Good understanding of APIs, Git, and databases.\n\u2022 Strong problem-solving and analytical mindset.\n\u2022 Excellent communication and willingness to learn.\n\nPreferred Skills\n\u2022 Blockchain experience preferred (smart contracts, Web3, token systems, or wallet integrations).\n\u2022 Familiarity with Django, FastAPI, or Gin frameworks.\n\u2022 Basic understanding of Docker, cloud deployments, or microservices.",
    "url": "https://wellfound.com/jobs/3537155-intern-python-golang-developer-blockchain-preferred?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Python Developer - (with SQL experience)",
    "company": "Wissen Technology",
    "location": null,
    "salary": "",
    "description": "Python (4+ years) : Strong expertise in data workflows and automation.\n\nSpark (PySpark) : Hands-on experience with large-scale data processing.\n\nPandas : For detailed data analysis and validation.\n\nDelta Lake : Managing structured and semi-structured datasets at scale.\n\nSQL : Querying and performing operations on Delta tables.\n\nKubernetes (K8s) : Container orchestration and deployment.\n\nAzure cloud : Compute and storage services.\n\nTesting frameworks : Proven experience in unit, integration, and system-level testing.\n\nGood to have skillsets\n\nExperience with climate, ESG, or large-scale data domains .\n\nStrong understanding of data standards and governance practices .\n\nAdvanced SQL and optimization experience for large datasets.",
    "url": "https://in.jooble.org/rjdp/-7690808940003013664?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "3 Days Left Python Developer",
    "company": "Tata Consultancy Services",
    "location": null,
    "salary": "",
    "description": "Job Description\n\nThis role lays down the foundation for the entire project and requires experience in development using Python language script, SQL development, Agile, JIRA, Jenkins, and AWS deployment.\n\u2022 Develop code using Python.\n\u2022 Work with IT and Business stakeholders.\n\u2022 Gather requirements, design solutions, and implement CI/CD.\n\nRequirements:\n\u2022 BE/B.tech/MCA/M.Sc./MS degree with at least 3 years of relevant IT-experience.\n\u2022 Full-Time courses only.",
    "url": "https://in.bebee.com/job/65d826935c1365f605a111e85e29ea62?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Technical Lead ( AI , Java & Python)",
    "company": "PTC",
    "location": null,
    "salary": "",
    "description": "Our world is transforming, and PTC is leading the way.\u202fOur software brings the physical and digital worlds together, enabling companies to improve operations, create better products, and empower people in all aspects of their business.\n\nOur people make all the difference in our success. Today, we are a global team of nearly 7,000 and our main objective is to create opportunities for our team members to explore, learn, and grow \u2013 all while seeing their ideas come to life and celebrating the differences that make us who we are and the work we do possible.\n\nOur world is transforming, and PTC is leading the way.\u202fOur software brings the physical and digital worlds together, enabling companies to improve operations, create better products, and empower people in all aspects of their business.\n\nOur people make all the difference in our success. Today, we are a global team of nearly 7,000 and our main objective is to create opportunities for our team members to explore, learn, and grow \u2013 all while seeing their ideas come to life and celebrating the differences that make us who we are and the work we do possible.\n\nJob Overview:\n\nAs a Senior Software Engineer on AI team, you will be responsible for working independently on Central AI projects. You will collaborate with cross-functional teams to produce high-quality Software and contribute to larger team on projects as needed.\n\nRequired Skills:\n\u2022 Bachelor\u2019s Degree or higher in Computer Science or related disciplines.\n\u2022 5+ years of experience in building enterprise software applications with strong core programming skills using Object oriented programming (OOP), data structures, and design patterns.\n\u2022 Strong expertise in either Java or Python \u2014 must be proficient in one and have working exposure to the other.\n\u2022 Experience developing scalable backend services and RESTful APIs using Spring Boot or FastAPI, with exposure to microservices, asynchronous processing, and ML/AI integration\n\u2022 Proven experience implementing and maintaining CI/CD pipelines using Jenkins, GitHub Actions, GitLab CI, or Azure DevOps.\n\u2022 Proficiency with containerization (Docker) and orchestration (Kubernetes) for scalable deployment environments.\n\u2022 Understanding of infrastructure as code (IaC) tools such as Terraform, Helm, or Ansible.\n\u2022 Experience in build automation, artifact management, and release pipelines.\n\u2022 Familiarity with monitoring and logging solutions (Grafana, Prometheus, ELK Stack, CloudWatch).\n\u2022 Hands-on experience with Azure, including Azure App Services, Azure Kubernetes Service (AKS), Azure Functions, and Azure DevOps pipelines.\n\u2022 Exposure to cloud security, scalability, and cost optimization principles.\n\u2022 Familiarity with MLOps/AIOps/LLMOps tools\n\u2022 Familiarity with LangChain, Azure OpenAI, or OpenAI API for building intelligent applications and conversational AI systems.\n\u2022 Proficient in Git-based workflows (branching, merging, code reviews, pull requests).\n\u2022 Experience working in Agile/Scrum environments with cross-functional teams.Ability to mentor junior developers and contribute to architecture design discussions.\n\u2022 Strong communication skills and problem-solving mindset.\n\u2022 Ability to prioritize, organize and exhibit good time management skills.\n\u2022 Ability and willingness to innovate and learn new technologies quickly.\n\u2022 Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.\n\u2022 Require work related experience with Java, Eclipse, Unit Testing, Git\n\nJob Responsibilities:\n\u2022 Ability to deliver rapid iterations of software features\n\u2022 Develop innovative and scalable AI solutions for business problems.\n\u2022 Work with software development teams to implement common practices, components and frameworks for support rapid and scalable AI features.\n\u2022 Works collaboratively with other cross-functional teams to achieve goals.\n\u2022 Work on triaging issues reported by product teams\n\u2022 Work with publications team members to help document features for PTC help center.\n\u2022 Design, develop and execute all levels of software testing including unit, integration, performance, and system tests\n\u2022 Passionate about automation.\n\u2022 Additional, related duties as necessary\n\nNice-to- have Skills/Experience:\n\u2022 Prefer experience with Unix/Linux, Agile/Scrum, JIRA/Atlassian Tools\n\u2022 Value experience with relational DBs, Apache Libraries, Azure/Cloud, Distributed/Parallel Computing\n\u2022 CI/CD & DevOps best practices for AI-driven applications\n\u2022 Knowledge of data pipelines, ETL tools, or MLOps frameworks\n\u2022 Experience with API gateways, service mesh, and observability tools\n\u2022 Familiarity with security best practices, performance optimization, and automated testing.\n\nLife at PTC is about more than working with today\u2019s most cutting-edge technologies to transform the physical world. It\u2019s about showing up as you are and working alongside some of today\u2019s most talented industry leaders to transform the world around you.\n\nIf you share our passion for problem-solving through innovation, you\u2019ll likely become just as passionate about the PTC experience as we are. Are you ready to explore your next career move with us?\n\nLife at PTC is about more than working with today\u2019s most cutting-edge technologies to transform the physical world. It\u2019s about showing up as you are and working alongside some of today\u2019s most talented industry leaders to transform the world around you.\n\nIf you share our passion for problem-solving through innovation, you\u2019ll likely become just as passionate about the PTC experience as we are. Are you ready to explore your next career move with us?\n\nWe respect the privacy rights of individuals and are committed to handling Personal Information responsibly and in accordance with all applicable privacy and data protection laws. Review our Privacy Policy here.\"",
    "url": "https://in.linkedin.com/jobs/view/technical-lead-ai-java-python-at-ptc-4324702003?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-28T00:00:00.000Z"
  },
  {
    "title": "SDE2 Python/ Django Developer",
    "company": "Bombay Softwares",
    "location": null,
    "salary": "",
    "description": "\u2022 Responsibilities\n\u2022 Write reusable, testable, and efficient code.\n\u2022 Design and implement low-latency, high-availability, and performant applications.\n\u2022 Design and create RESTful APIs for internal and partner consumption.\n\u2022 Implement security and data protection.\n\u2022 Debug code on the platform (written by self or others) to find the root cause of any ongoing issues and rectify them.\n\u2022 Database query optimization & design and implement scalable database schemas that represent and support business processes.\n\u2022 Implement web applications in Python, SQL, Javascript, HTML, and CSS.\n\u2022 Provide technical leadership to teammates through coaching and mentorship.\n\u2022 Delegate tasks and set deadlines.\n\u2022 Monitor team performance and report on performance.\n\u2022 Collaborate with other software developers, business analysts to plan, design and develop applications.\n\u2022 Maintain client relationships and ensure Company deliverables meet highest expectations of the client.\n\u2022 Qualification & SkillsMandatory\n\u2022 Bachelors/Masters degree in Computer Science, Engineering.\n\u2022 3+ years experience in Django/Flask.\n\u2022 Solid database skills in relational databases.\n\u2022 Knowledge of how to build and use RESTful APIs.\n\u2022 Strong knowledge of version control.\n\u2022 Hands-on experience on working on Linux systems.\n\u2022 Familiarity with ORM (Object Relational Mapper) libraries\n\u2022 Experience with SQL Alchemy is a plus.",
    "url": "https://in.bebee.com/job/5f72caf4549aaa023eb549acd1b03f90?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "[15h Left] Python-Senior Software Engineer",
    "company": "Nitor Infotech, an Ascendion Company",
    "location": null,
    "salary": "",
    "description": "Job Title: Senior Software Engineer\nJob Location: Pune\nJob Description:\nCompany Introduction\nJoin Nitor Infotech, an Ascendion company, where we innovate to create impactful software solutions. Our commitment to excellence and collaboration empowers our engineering team to deliver high-quality products that meet the needs of our clients.\nJob Overview\nWe are looking for a Python Developer to join our engineering team and help us develop and maintain various software products. Python FullStack Engineer Lead with responsibilities include writing and testing code, debugging programs and integrating applications with third-party web services. To be successful in this role, you should have experience using server-side logic and work well in a team.\n- Usual working hours to interface with U.S. clients and colleagues.\n- Good English verbal communication skills required\n- Group presentation skills preferred\n- Ability to work independently and collaboratively required.\n- Positive attitude and strong work ethic required\nKey Responsibilities\n- Write effective, scalable code.\n- Develop back-end components to improve responsiveness and overall performance.\n- Integrate user-facing elements into applications.\n- Test and debug programs.\n- Improve functionality of existing systems.\n- Implement security and data protection solutions.\n- Assess and prioritize feature requests.\nMust-Have Skills\n- At least 5+ years in web development and solid understanding of web technologies.\n- Strong expertise Python Full stack and Django development.\n- Knowledge of object-relational mapping (ORM).\n- Familiarity with front-end technologies (like JavaScript and HTML5).\n- Team spirit.\n- Good problem-solving skills.\n- 2+ years hands on work experience in ReactJS.\n- GraphQL experience.\n- Working experience in GCP serverless.\n- Good to have exposure or knowledge in Redux.\n- Good understanding of programming algorithms, data structures, etc.\n- Develop RESTful web services.\n- Maintain and develop application database integration.\n- Good understanding of Docker, Microservices architecture.\n- Good understanding of CI/ CD principles.\n- Work closely with other team members.\n- Learn new technologies quickly.\nEducation\n- MCS/MCA in Computer Science, Engineering, or a relevant field.\nWhat We Offer\n- Competitive salary and performance bonuses.\n- Comprehensive health and wellness benefits.\n- Opportunities for professional growth and development.\n- Flexible work arrangements.\n- Inclusive and collaborative culture.",
    "url": "https://in.jobrapido.com/jobpreview/6334149617747230720?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-29T00:00:00.000Z"
  },
  {
    "title": "Data Scientist- Gen AI (3-5 years exp only)",
    "company": "confidential",
    "location": "Pune",
    "salary": "",
    "description": "As a Data Scientist, you'll play a crucial role in supporting data-driven projects, performing routine data analysis tasks, and assisting with model development and testing. Your role involves contributing to various stages of the data science lifecycle and providing insights that help shape business strategies. This position is suited for those with a foundational understanding of data science and are eager to deepen their expertise.\n\nResponsibilities:\n\u2022 Contribute to more advanced data collection and preprocessing efforts.\n\u2022 Assist in developing and testing machine learning models.\n\u2022 Perform descriptive data analysis and provide preliminary insights.\n\u2022 Create visualizations and reports to support data findings.\n\u2022 Manage and maintain data repositories efficiently.\n\u2022 Support senior data scientists in feature creation and selection.\n\u2022 Participate in collaborative projects with cross-functional teams.\n\u2022 Help automate data processing tasks using scripts.\n\u2022 Contribute to model validation and performance testing.\n\u2022 Stay informed about emerging data science tools and methodologies.\n\nSkills:\n\u2022 Advanced Data Cleaning: Enhanced preprocessing and data wrangling techniques.\n\u2022 Intermediate Python: Proficiency in Python for data science tasks.\n\u2022 SQL: More advanced SQL querying skills.\n\u2022 Data Visualization: Ability to create meaningful visualizations using tools like Tableau or Matplotlib.\n\u2022 Machine Learning Basics: Understanding of basic machine learning concepts and algorithms.\n\u2022 Statistical Analysis: Intermediate statistical methods and their applications.\n\u2022 Communication: Articulating data insights clearly to non-technical stakeholders.\n\u2022 Problem-Solving: Effective in identifying data-related issues and providing solutions.\n\nApplicants may be required to appear onsite at a Wolters Kluwer office as part of the recruitment process.",
    "url": "https://in.jooble.org/jdp/-5701870864767254657?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-03T00:00:00.000Z"
  },
  {
    "title": "Associate Data Science Engineer",
    "company": "Cognologix",
    "location": "Pune",
    "salary": "",
    "description": "Associate Data Science Engineer\nWe are seeking an experienced Data Science Engineer with 1+ years of experience implementing AI/ML solutions. The role focuses on developing AI applications and developing cloud-native solutions.\n\nYou will work on:\nWe are looking for a self-driven Data Science Professional to be a member of our Data & AI Practice. We help many of our clients in building advanced analytics solutions (from traditional ML to deep learning, Computer Vision, Gen AI & Automation). You will work on some of the cutting-edge AI technologies to build meaningful products & solutions.\nJob Location: Pune\n\nWhat you will do (Responsibilities):\n\u2022 Perform high-level work both independently and collaboratively as a project member.\n\u2022 Collaborate with Product Management team, elicit AI/ML use case specific requirements, explore and evaluate approaches\n\u2022 Develop Computer Vision, NLP, Deep Learning, multi-modal Gen AI based application features & demos according to the requirements and needs.\n\u2022 Explore new tools, technologies, frameworks in ML, DL, CV, Gen AI technologies and experiments.\n\nWhat you bring (Skills):\n\u2022 1+ years of end-to-end project lifecycle experience (Analysis, Design, Development, Testing, Deployment & Monitoring) in building AI application\n\u2022 Sound knowledge in Linear Algebra, Statistics, Probability\n\u2022 Strong Knowledge & Experience in Python and Python data science ecosystem: Pandas, NumPy, SciPy, scikit-learn, NLTK etc.\n\u2022 Experience with machine learning, deep learning, and/or NLP/NLG frameworks (like Keras, TensorFlow or PyTorch etc.), HuggingFace Transformers and libraries (like scikit-learn, spacy, CoreNLP etc.)\n\u2022 Sound Knowledge of deep learning models for computer vision tasks.\n\u2022 Understanding of image processing, Object detection frameworks and image classification areas\n\u2022 Sound Knowledge in Generative AI /LLM\u2019s models, frameworks, tools & technologies.\n\u2022 Experience in Prompt Engineering & Langchain / LlamaIndex.\n\u2022 Excellent analytical, problem solving and communication skills\n\nGreat if you know (Skills):\n\u2022 Experience in Vector search, RAG frameworks, Function Calling, Agentic Frameworks\n\u2022 Exposure to Cloud-based services such as AWS (Preferred), Azure or GCP\n\u2022 Experience with async programming and RESTful APIs (FastAPI)\n\u2022 Sound understanding of CI-CD, Containerization & Orchestration\n\u2022 Experience with Scrum and/or other Agile development processes\n\u2022 Exposure to MlOps, LLMOps \u2013 model and experiment versioning, hyper parameter tuning, model deployment and monitoring aspects\n\u2022 Sound understanding of data visualization aspects\n\nAdvantage Cognologix:\n\u2022 A higher degree of autonomy, startup culture & small teams\n\u2022 Opportunities to become an expert in emerging technologies\n\u2022 Remote working options for the right maturity level\n\u2022 Competitive salary & family benefits\n\u2022 Performance based career advancement\n\nAbout Cognologix:\nCognologix helps companies disrupt by reimagining their business models and innovate like a Startup. We are at the forefront of digital disruption and take a business-first approach to help meet our client\u2019s strategic goals.\nWe are a Data focused organization helping our clients to deliver their next generation of products in the most efficient, modern, and cloud-native way.",
    "url": "https://careers.cognologix.com/jobs/I51tD9YU1xzC/associate-data-science-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T05:00:00.000Z"
  },
  {
    "title": "DeepTek.ai - Senior Data Scientist - Python / Deep Learning",
    "company": "DeepTek Medical Imaging Pvt Ltd",
    "location": "Pune",
    "salary": "",
    "description": "Description :\n\nKey Responsibilities :\n\u2022 Lead the design, development, and optimization of deep learning models for medical image analysis, including tasks like segmentation, classification, object detection.\n\u2022 Provide technical leadership and mentorship to junior data scientists and engineers, fostering best practices in research methodology, coding standards, and documentation.\n\u2022 Perform advanced error analysis, bias assessment, and domain generalization studies to ensure robustness across diverse populations and imaging devices.\n\u2022 Guide data storage, preprocessing and annotation strategies, collaborating with clinical experts to ensure data quality and clinical validity.\n\u2022 Collaborate cross-functionally with radiologists, regulatory teams, and product stakeholders to align AI development with clinical requirements and compliance standards.\n\nExperience :\n\u2022 3+ years Data Science / Machine Learning experience\n\nRequired Skills :\n\u2022 Strong programming skills in Python and familiarity with data science and image processing libraries (e.g.,\n\nNumPy, pandas, scikit-learn, OpenCV, PIL).\n\u2022 Strong fundamental knowledge of machine learning, computer vision and image processing.\n\u2022 Hands-on experience with deep learning frameworks like Keras or PyTorch.\n\u2022 Demonstrated experience with both CNNs and transformer-based architectures (e.g., ViT, Swin) for segmentation, detection, and classification tasks.\n\u2022 Strong background with model evaluation and error analysis.\n\u2022 Ability to bridge data science with engineering tasks, ensuring smooth integration of AI models into production workflows.\n\u2022 Hands-on experience with model optimization techniques (e.g distillation, ONNX conversion) for efficient inference.\n\u2022 Hands-on experience with containerization tools like Docker.\n\nDesired Skills :\n\u2022 Familiarity with healthcare / radiology datasets, DICOM standards, and PACS integration.\n\u2022 Experience with domain adaptation, and robustness strategies for cross-site / cross-device generalization.\n\u2022 Experience with scalable backend development for AI applications\n\nQualification :\n\u2022 Bachelors or Masters degree in Computer Science, Data Science, Machine Learning, Statistics, or a related field.\n\n(ref : hirist.tech)",
    "url": "https://in.talent.com/view?id=4a965bcff8b2&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Technical Lead-Gen AI Data science",
    "company": "Birlasoft",
    "location": "Pune",
    "salary": "",
    "description": "Country/Region: IN\n\nRequisition ID: 30302\n\nWork Model:\n\nPosition Type:\n\nSalary Range:\n\nLocation: INDIA - PUNE - BIRLASOFT OFFICE - HINJAWADI\n\nTitle: Technical Lead-Gen AI Data science\n\nDescription:\n\nArea(s) of responsibility\n\nGen ai data science\n\u2022 Must have 6+ years of experience working in Data science, Machine learning and especially NLP technologies.\n\u2022 Exposure to various LLM technologies and solid understanding of Transformer Encoder Networks.\n\u2022 Able to apply deep learning and generative modeling techniques to develop LLM solutions in the field of Artificial Intelligence.\n\u2022 Utilize your extensive knowledge and expertise in machine learning (ML) with a focus on generative models, including but not limited to generative adversarial networks (GANs), variational autoencoders (VAEs), and transformer-based architectures.\n\u2022 Solid understanding of Model development, model serving, training/re-training techniques in a data sparse environment.\n\u2022 Very good understanding of Prompt engineering techniques in developing Instruction based LLMs.\n\u2022 Must be able to design and implement state-of-the-art generative models for natural language processing (NLP) tasks such as text generation, text completion, language translation, and document summarization.\n\u2022 Work with SAs and collaborate with cross-functional teams to identify business requirements and deliver solutions that meet the customer needs.\n\u2022 Passionate to learn and stay updated with the latest advancements in generative AI and LLM.\n\u2022 Nice to have -contributions to the research community through publications, presentations, and participation in relevant conferences or workshops.\n\u2022 Evaluate and preprocess large-scale datasets, ensuring data quality and integrity, and develop data pipelines for training and evaluation of generative models.\n\u2022 Ability to articulate to business stakeholders on the hallucination effects and various model behavioral analysis techniques followed.",
    "url": "https://www.recruit.net/job/technical-gen-ai-data-science-jobs/12B17787640C5BFD?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-03T00:00:00.000Z"
  },
  {
    "title": "WFH Machine Learning Jobs in Pune",
    "company": "Turing.com",
    "location": "Pune",
    "salary": "",
    "description": "We, at Turing, are looking for experienced ML engineers who will design and develop machine learning and deep learning systems, machine learning tests and implement Ml algorithms to help in creating AI solutions. Apply for machine learning jobs in Pune and get a chance to work closely with global software engineers, AI/ML enthusiasts and gain unique experiences.",
    "url": "https://www.turing.com/jobs/machine-learning-jobs-in-pune?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "DATA SCIENCE POWER BI INTERNSHIP PUNE",
    "company": "confidential",
    "location": "Pune",
    "salary": "",
    "description": "Maxgen Technologies Pvt ltd is an it company based in pune .We are offering data science internship with power bi program to engineering and diploma candidates..\n\nBenefit we are offering\n\nenjoying work environment .\n\nsmooth shift timing.\n\nlive project in internship.\n\nlong time or short time internship.\n\nhybrid mode internship.\n\nvisit us\n\ncontact us View phone number on foundit.in, View phone number on foundit.in,View phone number on foundit.in ,View phone number on foundit.in,\n\naddress 6th Floor, Konark Icon, 601, above Maruti Suzuki, Magarpatta, Pune, Maharashtra",
    "url": "https://in.jooble.org/jdp/1298935089934152488?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "Industry Consultant - Manufacturing + Data Science",
    "company": "Khoobi Consulting",
    "location": "IN",
    "salary": "",
    "description": "Responsibility:\n\n- Help customers identify opportunities of monetizing their data assets to drive growth and profitability.\n\n- Understand customer's engineering, supply chain and production planning requirements and design digital solutions for customers that have AI and AI-Agents embedded in them.\n\n- Act as a bridge between customer business stakeholders and development teams comprising of Data Scientists and Solution Architects.\n\n- Publish Whitepapers on topics covering application of AI to solve domain specific issues and drive growth in the industry.\n\nEssential Skills:\n\n- Ability to manage senior customer stakeholders.\n\n- Ability to help customers understand how Industry 4.0 practices can be applied in their environment.\n\n- Ability to lead requirement gathering and solutioning workshops with customers.\n\n- Ability to understand the latest development in AI research and relate them to areas where they can be applied.\n\nExperience:\n\n- Overall 15 20 years.\n\nDomain:\n\n- Minimum 10 years in Manufacturing (Production Planning, Maintenance, Automation, Control Systems, Supply Chain).\n\n- Preferred Experience in Actual Automation and Control Systems experience preferred.\n\nTechnical: Minimum 5 years in Control Systems data, Digital Applications implementation.\n\nKnowledge:\n\n- Strong in applying Statistics knowledge.\n\n- Machine Learning / Deep Learning / LLM / Agents.\n\nQualifications.\n\n- Masters or Bachelor's degree in Computer Science, Engineering or related field.\n\nWorking Arrangements.\n\n- 100% work from office.",
    "url": "https://www.iimjobs.com/j/industry-consultant-manufacturing-data-science-1632852?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Science Specialist \u2013 Group Legal",
    "company": "UBS",
    "location": "Pune",
    "salary": "",
    "description": "Job Reference #\n322337BR\n\nJob Type\nFull Time\n\nYour role\nAre you ready to work on data science projects to drive digital transformation? Join our newly established Data and Analytics Team within Group Legal and play a key role in redefining data as an asset. Collaborate closely with IT teams, data analysts, and architects to design and deliver cutting-edge AI solutions that enhance business capabilities.\n\nWe are seeking a senior data scientist to:\n\u2022 work with various stakeholders to translate reporting requirements into actionable tasks and implement product enhancements.\n\u2022 design, build, and deploy high-performance AI/ML/NLP models to meet business objectives.\n\u2022 monitor and optimize model performance, ensuring quality, stability, and scalability.\n\u2022 clean, manipulate and process raw data into useful information to be suitable for business purposes.\n\u2022 validate AI/ML opportunities, define business cases, and create roadmaps for implementation.\n\u2022 document model performance, governance, and validation processes comprehensively.\n\u2022 mentor and guide junior data scientists and analysts, fostering technical excellence across the team.\n\nYour team\nYou\u2019ll be part of the Data and Analytics Team within Group Legal\u2019s COO function\u2014a culturally diverse and collaborative group with members in multiple locations. The team\u2019s mission is to manage Group Legal\u2019s data as a strategic asset, ensure compliance with the Bank-wide Data Management Framework (DMF), and deliver advanced analytics and reporting solutions. You\u2019ll develop expertise in the technical tools and services that power our capabilities\n\nYour expertise\n\u2022 a minimum of 3 years of experience delivering data science projects, either in a leading consultancy or in-house at a large organization.\n\u2022 proficiency in developing end-to-end ML and NLP solutions, including data sourcing, feature engineering, model training, evaluation, and visualization.\n\u2022 experience in state-of-the-art ML algorithms (e.g., XGBoost, Neural Networks) and techniques (e.g., supervised, unsupervised, or reinforcement learning).\n\u2022 proficiency in building ML & NLP / LLM solutions using common ML libraries and frameworks (e.g. Pandas, Sklearn, TensorFlow, Transformers, OpenAI, Huggingface)\n\u2022 hands-on experience with NLP applications such as named entity recognition, text classification, sentiment analysis, or chatbot development.\n\u2022 familiarity with MLOps practices, containerized solutions (Docker, Kubernetes), and cloud platforms like Azure, AWS, or Google Cloud.\n\u2022 ability to explain technical concepts to non-technical stakeholders.\n\u2022 a strong team player and communication\n\nAbout Us\nUBS is the world\u2019s largest and the only truly global wealth manager. We operate through four business divisions: Global Wealth Management, Personal & Corporate Banking, Asset Management and the Investment Bank. Our global reach and the breadth of our expertise set us apart from our competitors.\n\nWe have a presence in all major financial centers in more than 50 countries.\n\nJoin us\nAt UBS, we know that it's our people, with their diverse skills, experiences and backgrounds, who drive our ongoing success. We\u2019re dedicated to our craft and passionate about putting our people first, with new challenges, a supportive team, opportunities to grow and flexible working options when possible. Our inclusive culture brings out the best in our employees, wherever they are on their career journey. And we use artificial intelligence (AI) to work smarter and more efficiently. We also recognize that great work is never done alone. That\u2019s why collaboration is at the heart of everything we do. Because together, we\u2019re more than ourselves.\n\nWe\u2019re committed to disability inclusion and if you need reasonable accommodation/adjustments throughout our recruitment process, you can always contact us.\n\nDisclaimer / Policy Statements\nUBS is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills and experiences within our workforce.\n\nYour Career Comeback\nWe are open to applications from career returners. Find out more about our program on ubs.com/careercomeback.",
    "url": "https://in.linkedin.com/jobs/view/data-science-specialist-%E2%80%93-group-legal-at-ubs-4303173565?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "AI ML Python data science trainer",
    "company": "myinternship.in",
    "location": "Pune",
    "salary": "",
    "description": "Looking for an experienced AI, ML, Data Science & Analytics Trainer to deliver engaging, hands-on sessions covering Python, Machine Learning, and Power BI.\nShould have strong practical knowledge, real-world project exposure, and passion for teaching.\nResponsible for curriculum delivery, student mentoring, and guiding on live projects.\n\nJob Type: Full-time\n\nWork Location: In person",
    "url": "https://www.glassdoor.co.in/job-listing/ai-ml-python-data-science-trainer-myinternship-in-JV_IC2856202_KO0,33_KE34,49.htm?jl=1009923636335&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Science Instructor",
    "company": "Itvedant Education Pvt. Ltd.",
    "location": "Pune",
    "salary": "",
    "description": "Responsibilities:\n\n\u25cf Conducting classroom and online lectures on programming languages (Data Science, Python,\n\nData Analytics) and related technologies to students\n\n\u25cf Assigning and evaluating coursework, quizzes, and projects\n\n\u25cf Providing one-on-one assistance and mentoring to students as required\n\n\u25cf Ensuring that the course curriculum is up-to-date and relevant to industry standards\n\n\u25cf Collaborating with other trainers and course developers to develop new training materials\n\n\u25cf Maintaining accurate student records and progress reports\n\n\u25cf Creating a positive and engaging learning environment for students\n\n\u25cf Participating in faculty meetings, staff development programs, and other professional\n\ndevelopment activities as required\n\n\u25cf Staying up-to-date with the latest trends and developments and related technologies\n\nRequirements:\n\n\u25cf A Bachelor's or Master's degree in Computer Science or a related field\n\n\u25cf A minimum of 1 years of experience as a trainer\n\n\u25cf Excellent communication and interpersonal skills\n\n\u25cf Strong knowledge of Python, Machine Learning, Data Science, Data Analytics, Deep\n\nLearning, NLP and related technologies\n\n\u25cf Experience working with databases such as PostgreSQL and MySQL\n\n\u25cf A passion for teaching and helping students achieve their career goals\n\n\u25cf Ability to work independently as well as in a team environment",
    "url": "https://in.linkedin.com/jobs/view/data-science-instructor-at-itvedant-education-pvt-ltd-4320264933?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Part-time Data Analyst",
    "company": "Online Surveys",
    "location": "Edmonston",
    "salary": "",
    "description": "Company Overview\n\nEarn extra income from the comfort of your home by sharing your opinions with brands that care about real consumer feedback. This platform makes it easy to participate in surveys on your schedule \u2014 no experience required, no commuting, and no complicated setup. Just log in, give your insights, and get rewarded.\n\nRole and Responsibilities\n\nThis is a fully remote, task-based opportunity where you decide when and how often you participate. Survey topics vary widely, and most only take a few minutes to complete.\n\u2022 Complete surveys on products, services, entertainment, and lifestyle topics\n\u2022 Provide honest feedback and share personal experiences\n\u2022 Check your account regularly for new survey opportunities\n\u2022 (Optional) Join extended research studies or paid product testing\n\nRequired Skills and Experience\n\u2022 Must be 18 years or older and based in the U.S.\n\u2022 Ability to read, understand, and respond to online prompts\n\u2022 Access to a smartphone, tablet, or computer with internet connection\n\nPreferred Qualifications\n\u2022 Prior experience with survey platforms or apps is a plus\n\u2022 Reliable internet and regular device usage\n\u2022 Self-motivated and proactive in checking for new surveys\n\nCompensation\n\u2022 Surveys pay between $1\u2013$25 depending on length and complexity\n\u2022 Fast and flexible payouts via PayPal, bank transfer, or e-gift cards\n\u2022 Work 100% remotely \u2014 no commuting, no dress code\n\u2022 No fees, no required hours, and no long-term commitments\n\nAbout the Company\n\nOnline Surveys partners with trusted global brands to deliver valuable insights from real people. Built on transparency, simplicity, and fair compensation, our platform empowers anyone to earn on their terms \u2014 one survey at a time.",
    "url": "https://futurelane.nexthiredesk.com/viewjob/g1bbnhbaxyd7-3533f601-b0b6ab6f6fd1a7b414dbb5b3?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Entry Level Business/Data Analyst at Asta CRS Inc. Washington DC",
    "company": "Asta CRS Inc.",
    "location": "Washington",
    "salary": "",
    "description": "Entry Level Business/Data Analyst job at Asta CRS Inc.. Washington DC. Job Description\n\nJob Description\n\nWe are seeking Junior Business & Data Analyst's with 6 months to 1 year of experience to become an integral part of our team! You will analyze data to understand business and market trends in order to increase company revenue and efficiency.\n\nMultiple job openings, Nationwide . Must be willing to relocate .Candidates must be located in USA.\n\nResponsibilities:\n\u2022 Use data to understand business patterns and trends\n\u2022 Analyze internal and external data through quantitative research\n\u2022 Communicate findings to company through standard and ad hoc reports\n\u2022 Promote best practices in data analysis and reporting\n\u2022 Collaborate with cross-functional teams\n\nQualifications:\n\u2022 Bachelor's degree\n\u2022 Knowledge of SQL,statistical tools and business reporting\n\u2022 Strong problem solving and critical thinking skills\n\u2022 Strong attention to detail & Good communication\n\u2022 Ability to prioritize and multitask\n\n\"Asta CRS, Inc. is an Equal Opportunity Employer M/F/V/D.\" ASTA CRS is proud to state that we are enrolled with the USCIS for the E-Verification Program .\nCompany Description\n\nASTA Corporate Resource Solutions Inc is one of the Fastest Growing IT Companies in Northern America and the DC Metro Area with its headquarters in Ashburn, Virginia. ASTA CRS is an Information Technology Provider delivering superior quality software development, consulting, and staffing solutions to our client partners. We are 19 Years in this Industry.\n\nASTA CRS services are uniquely positioned to support clients in achieving profound efficiencies and relentlessly delivering results. ASTA CRS is a long-time and trusted resource for its clients and partners.\n\nAsta CRS, Inc. is an Equal Opportunity Employer M/F/V/D. ASTA CRS is proud to state that we are enrolled with the USCIS for the E-Verification Program. Company Description\n\nASTA Corporate Resource Solutions Inc is one of the Fastest Growing IT Companies in Northern America and the DC Metro Area with its headquarters in Ashburn, Virginia. ASTA CRS is an Information Technology Provider delivering superior quality software development, consulting, and staffing solutions to our client partners. We are 19 Years in this Industry.\n\nASTA CRS services are uniquely positioned to support clients in achieving profound efficiencies and relentlessly delivering results. ASTA CRS is a long-time and trusted resource for its clients and partners.\n\nAsta CRS, Inc. is an Equal Opportunity Employer M/F/V/D. ASTA CRS is proud to state that we are enrolled with the USCIS for the E-Verification Program.",
    "url": "https://strattonconsulting.com/work/job/entry-level-businessdata-analyst-at-asta-crs-inc-washington-dc-S2JTMUR4QUJQbFF2cVlvendtRGlMM0J2Z0E9PQ==?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Data Analyst TS/SCI Polygraph",
    "company": "Leidos",
    "location": "McLean",
    "salary": "",
    "description": "Description\n\nLeidos has a new and exciting opportunity for a Data Analyst in our National Security Sector's (NSS) Cyber & Analytics Business Area (CABA). Our talented team is at the forefront in Security Engineering, Computer Network Operations (CNO), Mission Software, Analytical Methods and Modeling, Signals Intelligence (SIGINT), and Cryptographic Key Management. At Leidos, we offer competitive benefits, including Paid Time Off, 11 paid Holidays, 401K with a 6% company match and immediate vesting, Flexible Schedules, Discounted Stock Purchase Plans, Technical Upskilling, Education and Training Support, Parental Paid Leave, and much more. Join us and make a difference in National Security!\n\nLeidos is seeking a highly skilled and motivated Data Analyst to support a critical National Security program. The ideal candidate will have extensive experience analyzing workforce data, building data visualizations, and providing analytic support for various human capital initiatives. This position requires a deep understanding of data analysis tools, the ability to communicate findings clearly, and a strong background in workforce analytics.\n\nResponsibilities Include:\n\u2022 Analyze workforce data, including metrics related to hiring, retention, attrition, and organizational mobility, to identify trends and labor projections.\n\u2022 Build and modify data visualization dashboards, reports, and other analytical products to meet client needs.\n\u2022 Assist in the development and maintenance of position description libraries to standardize role information across the organization.\n\u2022 Administer and manage relational databases, ensuring data integrity and accessibility.\n\u2022 Normalize, standardize, and integrate disparate raw data sets for consistent analysis.\n\u2022 Support survey design and execution across 18 Intelligence Community (IC) agencies.\n\u2022 Provide data analytic support for surveys, data calls, and other human capital efforts, ensuring accurate and timely insights.\n\u2022 Manage HR data and conduct thorough analysis to support workforce planning and decision-making processes.\n\nBasic Qualifications:\n\u2022 Bachelor's degree and 8-12 years of data analysis experience, a Master's degree and 6-10 years of data analysis experience, or no degree with 12+ years of experience\n\u2022 Prior experience in data analysis within the Intelligence Community (IC).\n\u2022 Strong ability to communicate technical or analytical findings in an easily understandable format through graphic, written, and verbal means.\n\u2022 Proficiency in Tableau is required, with experience building data visualizations and dashboards.\n\u2022 Proficient in MS Office tools, including Excel, Tableau, Python, and SQL.\n\u2022 Clearance Required: Must have TS/SCI with Polygraph.\n\nPreferred Qualifications:\n\u2022 Familiarity with additional tools such as Cognos, VBA, R, SPSS, SAS, LimeSurvey, Personal Operations Portal system, PD Library, and Lawson.\n\u2022 Experience in workforce analytics and workforce planning, particularly in the context of human capital management and strategy.\n\nAt Leidos, the opportunities are boundless. We challenge our staff with interesting assignments that allow them to thrive professionally and personally. For us, helping you grow your career is good business. We look forward to learning more about you \u2013 apply today.\n\nAt Leidos, we don\u2019t want someone who \"fits the mold\"\u2014we want someone who melts it down and builds something better. This is a role for the restless, the over-caffeinated, the ones who ask, \u201cwhat\u2019s next?\u201d before the dust settles on \u201cwhat\u2019s now.\u201d\n\nIf you\u2019re already scheming step 20 while everyone else is still debating step 2\u2026 good. You\u2019ll fit right in.\n\nOriginal Posting:\nOctober 29, 2025\n\nFor U.S. Positions: While subject to change based on business needs, Leidos reasonably anticipates that this job requisition will remain open for at least 3 days with an anticipated close date of no earlier than 3 days after the original posting date as listed above.\n\nPay Range:\nPay Range $89,700.00 - $162,150.00\n\nThe Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law.\n\nAbout Leidos\n\nLeidos is an industry and technology leader serving government and commercial customers with smarter, more efficient digital and mission innovations. Headquartered in Reston, Virginia, with 47,000 global employees, Leidos reported annual revenues of approximately $16.7 billion for the fiscal year ended January 3, 2025. For more information, visit www.Leidos.com.\n\nPay and Benefits\n\nPay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available at www.leidos.com/careers/pay-benefits.\n\nSecuring Your Data\n\nBeware of fake employment opportunities using Leidos\u2019 name. Leidos will never ask you to provide payment-related information during any part of the employment application process (i.e., ask you for money), nor will Leidos ever advance money as part of the hiring process (i.e., send you a check or money order before doing any work). Further, Leidos will only communicate with you through emails that are generated by the Leidos.com automated system \u2013 never from free commercial services (e.g., Gmail, Yahoo, Hotmail) or via WhatsApp, Telegram, etc. If you received an email purporting to be from Leidos that asks for payment-related information or any other personal information (e.g., about you or your previous employer), and you are concerned about its legitimacy, please make us aware immediately by emailing us at LeidosCareersFraud@leidos.com.\n\nIf you believe you are the victim of a scam, contact your local law enforcement and report the incident to the U.S. Federal Trade Commission.\n\nCommitment to Non-Descrimination\n\nAll qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",
    "url": "https://careers.leidos.com/jobs/16974419-data-analyst-ts-slash-sci-polygraph?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Payor Data Analyst- Remote",
    "company": "Lensa",
    "location": "Washington",
    "salary": "",
    "description": "Lensa is a career site that helps job seekers find great jobs in the US. We are not a staffing firm or agency. Lensa does not hire directly for these jobs, but promotes jobs on LinkedIn on behalf of its direct clients, recruitment ad agencies, and marketing partners. Lensa partners with DirectEmployers to promote this job for Sharecare. Clicking \"Apply Now\" or \"Read more\" on Lensa redirects you to the job board/employer site. Any information collected there is subject to their terms and privacy notice.\n\nJob Description\n\nSharecare is the leading digital health company that helps people - no matter where they are in their health journey - unify and manage all their health in one place. Our comprehensive and data-driven virtual health platform is designed to help people, providers, employers, health plans, government organizations, and communities optimize individual and population-wide well-being by driving positive behavior change. Driven by our philosophy that we are all together better, at Sharecare, we are committed to supporting each individual through the lens of their personal health and making high-quality care more accessible and affordable for everyone. To learn more, visit?www.sharecare.com.\n\nJob Summary\n\nThe Payor Data Analyst ensure consistent and effective management of client data within existing Sharecare processes, works to drive data quality and follows governance for Audit Data analytics, responsible for the management and quality control of datasets in preparation for production and reporting usage. Serves as a SME on client level data, data submission and ingestion processes and other assigned data heavy processes.\n\nEssential Job Functions\n\u2022 Act as the Day-to-Day processor of incoming client data.\n\u2022 Operate as the point of escalation for clients and team members\n\u2022 Runs reports for internal and/or external clients. Provide data elements for key reports to leaders.\n\u2022 Assist with data collection, entry, processing, and delivery to systems.\n\u2022 Works to Identify data shortfalls and liaisons with data and development teams to close gaps and/or improve data fidelity\n\u2022 Proposes solutions to ensure business continuity.\n\u2022 Provide operational support specific to client data to payor engagement managers.\n\u2022 Ensure mastery understanding of all internal and external data and reporting\n\u2022 Prepare, proof, and edit documents and spreadsheets\n\u2022 Other duties as assigned\n\nQualifications\n\u2022 Knowledge of programming languages like Structured Query Language (SQL)\n\u2022 Proficiency in Microsoft Excel for data set analyzing.\n\u2022 Presentation skills\n\u2022 Bachelors' degree preferred\n\u2022 Strong Conscious Leadership skills\n\u2022 Effective problem-solving skills\n\u2022 Excellent verbal and written skills necessary for communication with clients, providers, and internal partners\n\u2022 Ability to work independently and collaboratively as a team member\n\u2022 Ability to travel within the United States as needed\n\nSharecare and its subsidiaries are Equal Opportunity Employers and E-Verify users. Qualified applicants will receive consideration for employment without regard to race, color, sex, national origin, sexual orientation, gender identity, religion, age, equal pay, disability, genetic information, protected veteran status, or other status protected under applicable law.\n\nSharecare is an Equal Opportunity Employer and doesn't discriminate on the basis of race, color, sex, national origin, sexual orientation, gender identity, religion, age, disability, genetic information, protected veteran status,or other non-merit factor.\n\nIf you have questions about this posting, please contact support@lensa.com",
    "url": "https://www.linkedin.com/jobs/view/payor-data-analyst-remote-at-lensa-4294313064?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Human Capital Data Analyst",
    "company": "Fusion Innovation",
    "location": "McLean",
    "salary": "",
    "description": "Job Description\n\nFusion Innovation's recent growth has earned us a top spot in the Inc 5000 Fastest Growing Private Companies in America and in Washington Business Journal's Best Places to Work multiple years in a row. Our team members are passionate about their work and are empowered to contribute their unique skills and perspectives to our projects. Here at Fusion, we put people first. When you join us, you don't just join a company, you join a family. If you are ready to be part of a fun and engaging team where your innovative ideas are heard, supported, and make ever lasting mission impacts for our Nation's most sensitive programs, you have come to the right place.\n\nPosition Overview\n\nWe are seeking a highly skilled and motivated Human Capital Data Analyst to support a critical National Security program. The ideal candidate will have extensive experience analyzing workforce data, building data visualizations, and providing analytic support for various human capital initiatives. This position requires a deep understanding of data analysis tools, the ability to communicate findings clearly, and a strong background in workforce analytics.\n\nResponsibilities:\n\u2022 Analyze workforce data, including metrics related to hiring, retention, attrition, and organizational mobility, to identify trends and labor projections.\n\u2022 Build and modify data visualization dashboards, reports, and other analytical products to meet client needs.\n\u2022 Assist in the development and maintenance of position description libraries to standardize role information across the organization.\n\u2022 Administer and manage relational databases, ensuring data integrity and accessibility.\n\u2022 Normalize, standardize, and integrate disparate raw data sets for consistent analysis.\n\u2022 Support survey design and execution across 18 Intelligence Community (IC) agencies.\n\u2022 Provide data analytic support for surveys, data calls, and other human capital efforts, ensuring accurate and timely insights.\n\u2022 Manage HR data and conduct thorough analysis to support workforce planning and decision-making processes.\n\n,\nRequired Skills\n\u2022 Active Top Secret/SCI with Polygraph.\n\u2022 BA/BS degree and 3+ years of relevant experience, MA/MS degree and 0+ years of experience or no degree +9 years\n\u2022 Prior experience in data analysis within the Intelligence Community (IC).\n\u2022 Strong ability to communicate technical or analytical findings in an easily understandable format through graphic, written, and verbal means.\n\u2022 Proficiency in Tableau is required, with experience building data visualizations and dashboards.\n\u2022 Proficient in MS Office tools, including Excel, Tableau, Python, and SQL.\n\n,\nDesired Skills\n\u2022 Familiarity with additional tools such as Cognos, VBA, R, SPSS, SAS, LimeSurvey, Personal Operations Portal system, PD Library, and Lawson.\n\u2022 Experience in workforce analytics and workforce planning, particularly in the context of human capital management and strategy.\n\nPlease note that all applicants must be U.S. citizens and require additional screening from our clients.\n\nFusion Innovation LLC is an Equal Opportunity/Affirmative Action Employer.\n\n,\nAbout Fusion Innovation\n\nOur primary focus is on developing people to further their own unique craft. This includes helping our team become more experienced leaders, learn a team-first mentality, strive for more innovation, be thought leaders, and better overall people. By putting our people first and treating them as family and helping to develop their careers in a unique and specific fashion, we\u2019re not just giving them more opportunities to grow and be successful, we\u2019re also raising the bar for what our customers, families, and communities receive.\n\nDon\u2019t Just Join a Company - Join a Family\n\nExciting work, innovative colleagues, great teammates, unique customers, and a company that invests in you personally and professionally. We work hard to make Fusion Innovation a place that makes people excited to come to work; where colleagues stay connected and engaged; and where loved ones are welcomed with open arms.\n\nWe hope this makes us feel less like a company and more like a family. We achieve this by our commitments to you, our culture, and our employee focused perks.",
    "url": "https://www.indeed.com/viewjob?jk=dd515198c75ac6a9&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Customer Experience Business Operations Analyst",
    "company": "KONG Company",
    "location": "Washington",
    "salary": "",
    "description": "CX Business Ops Analyst\n\nAre you ready to power the World's connections?\n\nIf you don't think you meet all of the criteria below but are still interested in the job, please apply. Nobody checks every box - we're looking for candidates that are particularly strong in a few areas, and have some interest and capabilities in others.\nAbout the Role\n\nWe are seeking a dedicated CX Business Ops Analyst with a proven track record in Professional Services or Customer Success data analysis, ideally with experience in enterprise software environments.\n\nAs a member of the Customer Experience (CX) Operations team, you will support the CX (Professional Services, Customer Success, Support, Education) organisation's growth and optimisation, while sitting in the broader Revenue Operations team.\n\nIn this role, you will have the opportunity to interface with everyone in the CX team as you build our internal analytics to help guide CX team members to deliver maximum value to Kong customers.\n\nYou will support both strategic and tactical initiatives and will function as the primary CX Ops point of contact for all data, reporting, and analytics questions on a day-to-day basis.\nWhat You'll Be Doing Work across SQL data warehouses (Snowflake and Bigquery), Tableau, Google Sheets, and Google Slides depending on the nature of the analysis and reporting. We use ETL and reverse ETL technologies to update our CRM and data warehouses and organise data transformations with DBT. Create, maintain, analyse, and present reports, metrics, and dashboards across all levels and roles of the CX team. Build and maintain slide decks for key CX Cadences (QBRs, All-Hands, Board Decks,...) Build and maintain the CX data dictionary and reporting suite for all roles and levels of CX. Analyse, model, and forecast Professional Services KPIs for internal and external resources. Own the user adoption and documentation of CX analytics. Manage CX team inquiries and ad-hoc requests across data, reporting, and analytics. Help improve customer data points and run projects as necessary to ensure data integrity. What You'll Bring A passion for data, user experience, and automation. Strong customer service attitude, and ability to work independently and in a fast-paced environment. A team player who works well in a collaborative environment. Proficiency with SQL for data analysis and modelling. Experience with DBT is a plus. Advanced Gsheet and Gslides skills; Tableau reporting expertise, Basic Salesforce reporting skills. Reliability and attention to detail. Excellent written and communication skills. Ability to concisely articulate complex issues and solutions to different audiences. A team player who works well in a collaborative environment. 3-5 year of relevant business experience.\n\nKong Inc., a leading developer of cloud API technologies, is on a mission to enable companies around the world to become \"API-first\" and securely accelerate AI adoption. For more information about Kong, please visit or follow us on X @thekonginc.",
    "url": "https://www.whatjobs.com/jobs/data-analysis?id=2237038735&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-03T00:00:00.000Z"
  },
  {
    "title": "Senior Data Analyst",
    "company": "Resource Management Concepts, Inc.",
    "location": "Indian Head",
    "salary": 115000,
    "description": "RMC is hiring a Senior Data Analyst to support our Navy customer in Indian Head, MD. The selected applicant will be responsible for performing as a technical lead on data science projects. Duties may include{{:}}\n\u2022 Collaborate with departments, divisions, branches, and IT teams to define quality-aligned metrics and data projects that support the Command's strategic objectives\n\u2022 Provide tailored communications to stakeholders in meetings, demos, and other customer engagements, as well as support analytic innovation, development, and data analytics; brief technical topics to a non-technical audience\n\u2022 Establish advanced analysis and data visualization methodologies, models, and tools to derive outcomes and impacts\n\u2022 Utilize predictive data models, quantitative analyses, and visualization of targeted data sources; utilize data visualization tools to design and deliver infographics and dashboards across a range of media platforms\n\u2022 Leverage knowledge of databases and methodologies to determine appropriate sources, determine indicators and relationships, and generate intelligence support packages\n\u2022 Integrate with Quality databases (such as iPDM, PDREP, CAPA, MCMS)\n\u2022 Analyze structured and unstructured data sources; handle, analyze and manage imperfect data; track trends and irregularities\n\u2022 Identify and process raw data, trends, analysis, and assessments in order to aggregate disparate information\n\u2022 Implement version control and branching strategies; manage overall configuration and control of data sources, digital products (dashboards/visualizations, reports, etc.)\n\u2022 Deliver data pipelines with an emphasis on quality, efficiency, and scalability; document data science work and participate in peer reviews\n\u2022 Utilize machine learning algorithms and statistical modeling techniques\n\nRequirements\n\u2022 Candidate must possess a bachelor's degree in mathematics, statistics, computer science, data science or field directly related to this position and 5+ years of overall experience in the field of data science; 3+ of those years should be with hands-on experience in data exploration, data cleaning, data analysis, data visualization and data mining utilizing MS Power Platform - PowerBI, Power Apps, Power Automate, Power Pages, Copilot Studio; Dynamic 365; MS Dataverse; Tableau; and big data technologies (such as Hadoop, Spark)\n\u2022 Current DCWF/DoDI 8140.03 certification of CompTIA Security+ or higher\n\u2022 Minimum 5 years' experience using Microsoft 365, Teams, SharePoint\n\u2022 An active DoD SECRET clearance is required to start. Applicant selected may be subject to a security investigation and must meet eligibility requirements for access to classified information\n\u2022 Strong analytical skills, with experience in analytics and exploratory data analysis\n\u2022 Must have strong problem-solving skills and experience juggling competing priorities\n\u2022 Candidate must have strong oral and written communication skills; solid track record of delivering data-driven projects\n\u2022 Experience working in a team environment\n\nDesired{{:}}\n\u2022 Experience processing Laboratory Information Management System (LIMS) data sets\n\u2022 Experience utilizing data science tools and statistical programming languages (such as R, SQL, and Python); working with RESTful APIs\n\u2022 Certification(s) - Fundamentals for MS Power Platform, Azure and/or Dynamic 365\n\nBenefits\n\nAt RMC, we're committed to your career growth! RMC differentiates itself from other firms through its investment in our employees. We invest our resources to train, certify, educate, and build our employees. RMC can offer you a great place to work with a small company feel and give you the experience, tuition assistance, and certifications that will take your career to the next level. This also includes a competitive paid vacation package with 11 paid federal holidays. Additionally, we also offer high-quality, low-deductible healthcare plans, pet insurance, and a competitive 401K package.\n\nSalary at RMC is determined by various factors, including but not limited to location, a candidate's specific combination of education, knowledge, skills, competencies, and experience, as well as contract-specific requirements. The current salary range for this position will be $115,000 to $145,000 (annually).",
    "url": "https://www.linkedin.com/jobs/view/senior-data-analyst-at-resource-management-concepts-inc-4320712291?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T13:00:00.000Z"
  },
  {
    "title": "Sr. Data Analyst with TS/SCI Polygraph",
    "company": "Leidos",
    "location": "Bethesda",
    "salary": "",
    "description": "Description\n\nLeidos has a new and exciting opportunity for a Senior Data Analyst in our National Security Sector's (NSS) Cyber & Analytics Business Area (CABA). Our talented team is at the forefront in Security Engineering, Computer Network Operations (CNO), Mission Software, Analytical Methods and Modeling, Signals Intelligence (SIGINT), and Cryptographic Key Management. At Leidos, we offer competitive benefits, including Paid Time Off, 11 paid Holidays, 401K with a 6% company match and immediate vesting, Flexible Schedules, Discounted Stock Purchase Plans, Technical Upskilling, Education and Training Support, Parental Paid Leave, and much more. Join us and make a difference in National Security!\n\nLeidos is seeking a Senior Data Analyst to support an Intelligence Community (IC) program in Bethesda, MD. An Active TS/SCI with polygraph security clearance is required to be considered for this position. The candidate will support Government staff in the following:\n\nResponsibilities Include:\n\u2022 Work with teams of data and system engineers to design, develop, build, analyze, and evaluate data management systems to include database modeling and design, relational database architecture, metadata and repository creation and configuration management.\n\u2022 Use data mapping, data mining and data transformational analysis tools to design and develop data repositories.\n\u2022 Integrate disparate raw data from across the federated enterprise using any supported variation of the Extract, Transform, and Load (ETL) process.\n\u2022 Analyze enterprise level Services of Common Concern to determine gaps, opportunities, and trends to improve enterprise services.\n\u2022 Design, build and maintain data visualization dashboards, reports, and other products to suit client needs.\n\u2022 Provide data analytic support to design and execute surveys, data calls, and other data gathering processes across a federated network enterprise.\n\u2022 Ability to clearly communicate technical or analytic findings in an easily understood narrative via graphical, written, and verbal formats.\n\u2022 Use statistical methods, machine learning, natural language processing, large language models, and pattern recognition to identify insights and trends.\n\u2022 Design and build intuitive dashboards and visualizations to convey analytical outcomes.\n\nBasic Qualifications:\n\u2022 Bachelor's degree and 8-12 years of data analysis experience, a Master's degree and 6-10 years of data analysis experience, or no degree with 12+ years of experience\n\u2022 Requires visualization and trend analysis experience.\n\u2022 Requires the ability to elicit information from a broad user base and provide applicable analytic mythologies to provide actionable insights.\n\u2022 Proficiency with multiple data analytic tools like Access, Excel, Python, R, SQL, VBA.\n\u2022 Proficiency in visualizing and presenting data using platforms such as Tableau, Power BI, or equivalent\n\u2022 Requires demonstrated ability with data analysis, data engineering, and data enrichment\n\u2022 Clearance Required: Must have TS/SCI with Polygraph.\n\nPreferred Qualifications:\n\u2022 5 years\u2019 experience within the Intelligence Community\n\u2022 Hands-on experience with Jira and Confluence\n\u2022 Experience developing, deploying, and managing applications in a cloud environment.\n\nAt Leidos, the opportunities are boundless. We challenge our staff with interesting assignments that allow them to thrive professionally and personally. For us, helping you grow your career is good business. We look forward to learning more about you \u2013 apply today.\n\nIf you're looking for comfort, keep scrolling. At Leidos, we outthink, outbuild, and outpace the status quo \u2014 because the mission demands it. We're not hiring followers. We're recruiting the ones who disrupt, provoke, and refuse to fail. Step 10 is ancient history. We're already at step 30 \u2014 and moving faster than anyone else dares.\n\nOriginal Posting:\nSeptember 22, 2025\n\nFor U.S. Positions: While subject to change based on business needs, Leidos reasonably anticipates that this job requisition will remain open for at least 3 days with an anticipated close date of no earlier than 3 days after the original posting date as listed above.\n\nPay Range:\nPay Range $89,700.00 - $162,150.00\n\nThe Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law.\n\nAbout Leidos\n\nLeidos is an industry and technology leader serving government and commercial customers with smarter, more efficient digital and mission innovations. Headquartered in Reston, Virginia, with 47,000 global employees, Leidos reported annual revenues of approximately $16.7 billion for the fiscal year ended January 3, 2025. For more information, visit www.Leidos.com.\n\nPay and Benefits\n\nPay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available at www.leidos.com/careers/pay-benefits.\n\nSecuring Your Data\n\nBeware of fake employment opportunities using Leidos\u2019 name. Leidos will never ask you to provide payment-related information during any part of the employment application process (i.e., ask you for money), nor will Leidos ever advance money as part of the hiring process (i.e., send you a check or money order before doing any work). Further, Leidos will only communicate with you through emails that are generated by the Leidos.com automated system \u2013 never from free commercial services (e.g., Gmail, Yahoo, Hotmail) or via WhatsApp, Telegram, etc. If you received an email purporting to be from Leidos that asks for payment-related information or any other personal information (e.g., about you or your previous employer), and you are concerned about its legitimacy, please make us aware immediately by emailing us at LeidosCareersFraud@leidos.com.\n\nIf you believe you are the victim of a scam, contact your local law enforcement and report the incident to the U.S. Federal Trade Commission.\n\nCommitment to Non-Descrimination\n\nAll qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",
    "url": "https://careers.leidos.com/jobs/16778122-sr-data-analyst-with-ts-slash-sci-polygraph?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Federal - Data Analytics Consultant",
    "company": "Accenture",
    "location": "Washington",
    "salary": "",
    "description": "Organization: Accenture Federal Services\nLocation: Washington, DC\n\nAccenture Federal Services, a wholly owned subsidiary of Accenture LLP, is a U.S. company with offices in Arlington, Virginia. Accenture's federal business has served every cabinet-level department and 30 of the largest federal organizations. Accenture Federal Services transforms bold ideas into breakthrough outcomes for clients at defense, intelligence, public safety, civilian and military health organizations.\nWe believe that great outcomes are everything. It\u2019s what drives us to turn bold ideas into breakthrough solutions. By combining digital technologies with what works across the world\u2019s leading businesses, we use agile approaches to help clients solve their toughest problems fast\u2014the first time. So, you can deliver what matters most.\n\nCount on us to help you embrace new ways of working, building for change and put customers at the core. A wholly owned subsidiary of Accenture, we bring over 30 years of experience serving the federal government, including every cabinet-level department. Our 7,200 dedicated colleagues and change makers work with our clients at the heart of the nation\u2019s priorities in defense, intel, public safety, health and civilian to help you make a difference for the people you employ, serve and protect.\n\nKey Responsibilities:\n\u2022 Works closely with client Project Lead to plan and execute data studies and analysis\n\u2022 Applies advanced analytical processes to the planning, design, and implementation of complex finance data with a focus on developing the strategic use of the data and improve program effectiveness to support sound business decisions\n\u2022 Manage and manipulate data sets including defining variables, performing calculations and summarizations, and data visualizations\n\u2022 Defines detailed criteria for analytics and making authoritative recommendations using study results\n\u2022 Develops and implements a wide range of new and innovative quantitative methods for modeling and forecasting\n\u2022 Defines data requirements and analytical techniques\n\u2022 Prepares executive briefings to support decision making\n\u2022 Apply analytical, technical, and writing skills to support facilitation, analysis, modeling, and documentation tasks\n\nBasic Qualifications:\n\u2022 1 year of experience with data manipulation\n\u2022 2 years of consulting/data reporting analytics experience to include experience with Data Mining/Visualization/Analysis tools\n\u2022 1 year of experience with Python or R\n\u2022 U.S. Citizenship required\n\nAn active security clearance or the ability to obtain one may be required for this role.\n\nCandidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\n\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).\n\nAccenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\n\nEqual Employment Opportunity\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\n\nJob candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\n\nAccenture is committed to providing veteran employment opportunities to our service men and women.",
    "url": "https://onmogul.com/jobs/federal-data-analytics-consultant-98e6181d-6e41-4bc8-9052-4137e2e0b94b?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Journeyman HRM Data Analyst",
    "company": "Novel Applications of Vital Information",
    "location": "McLean",
    "salary": 100000,
    "description": "Residency Status: ALL CANDIDATES MUST BE A U.S. CITIZEN\n\nSecurity Clearance: ALL CANDIDATES MUST POSSESS AN ACTIVE TS/SCI w/CI poly for consideration of this position.\n\nTime Type: Full-Time, Daytime Schedule\n\nTravel Reimbursement: Yes (within a 50-mile radius to the worksite)\n\nGovernment Funded: Yes\n\nCompany Benefits: Yes\n\nSalary Range: $100k to $140k\n\nCompany Overview:\n\nNAOVI (Novel Applications, Inc.) is a premier technology services company that provides solutions in the areas of Cyber Security, Information Management and Systems Integration. NAOVI is a business that combines experience, creativity, flexibility, pragmatism, and cost-effective solutions in order to deliver measurable business value to our clients.\n\nHeadquartered in Fredericksburg, Virginia, NAOVI employs engineers, analysts, IT specialists and other professionals who strive to be the best at everything they do.\n\nNAOVI is an AA/EEO Employer - Minorities/Women/Veterans/Disabled. Visit our company website at www.novelapplications.com to review and apply for our current openings.\n\nJob Description\n\nNAOVI is seeking a skilled Journeyman HRM Data Analyst seeking a highly skilled and motivated Human Capital Data Analyst to support a critical National Security program. The ideal candidate will have extensive experience analyzing workforce data and building data visualizations and providing analytic support for various human capital initiatives. This position requires a deep understanding of data analysis tools, the ability to communicate findings clearly, and a strong background in workforce analytics.\n\nPrimary responsibilities:\n\u2022 Analyze workforce data, including metrics related to hiring, retention, attrition, and organizational mobility, to identify trends and labor projections.\n\u2022 Build and modify data visualization dashboards, reports, and other analytical products to meet client needs.\n\u2022 Assist in the development and maintenance of position description libraries to standardize role information across the organization.\n\u2022 Administer and manage relational databases, ensuring data integrity and accessibility.\n\u2022 Normalize, standardize, and integrate disparate raw data sets for consistent analysis.\n\u2022 Support survey design and execution across 18 Intelligence Community (IC) agencies.\n\u2022 Provide data analytic support for surveys, data calls, and other human capital efforts, ensuring accurate and timely insights.\n\u2022 Manage HR data and conduct thorough analysis to support workforce planning and decision-making processes.\n\nRequired:\n\u2022 BA/BS degree and 3+ years of relevant experience, MA/MS degree and 0+ years of experience or no degree with 9+ years.\n\u2022 TS/SCI with Polygraph clearance is required.\n\u2022 Prior experience in data analysis within the Intelligence Community (IC).\n\u2022 Strong ability to communicate technical or analytical findings in an easily understandable format through graphic, written, and verbal means.\n\u2022 Proficiency in Tableau is required, with experience building data visualizations and dashboards.\n\u2022 Proficient in MS Office tools, including Excel, Tableau, Python, and SQL.\n\nPreferred:\n\u2022 Familiarity with additional tools such as Cognos, VBA, R, SPSS, SAS, LimeSurvey, Personal.\n\u2022 Operations Portal system, PD Library, and Lawson.\n\u2022 Experience in workforce analytics and workforce planning, particularly in the context of human capital management and strategy.\n\nCompany Benefits:\n\u2022 401k\n\u2022 Health, Dental and Vision\n\u2022 Long-Term and Short-Term Disability\n\u2022 3 Weeks\u2019 Paid Vacation\n\u2022 5 Day Paid Sick Leave\n\u2022 11 Paid Holidays\n\u2022 Travel Reimbursement (50-mile radius to the work location).",
    "url": "https://www.ziprecruiter.com/c/Novel-Applications-of-Vital-Information/Job/Journeyman-HRM-Data-Analyst/-in-Mclean,VA?jid=89e6f0075550cb2a&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-30T00:00:00.000Z"
  },
  {
    "title": "Tech Data Analyst",
    "company": "Antal International",
    "location": "Pune",
    "salary": "",
    "description": "About the Role\n\nWe are seeking a result-driven SAS and SQL professional with over 10 years of experience in delivering robust data-driven solutions across domains like Credit Risk, Fraud Management, Campaign Analytics, and Healthcare.\nKey Responsibilities\n\u2022 Develop and optimize SAS Base programs and SQL queries for data extraction, transformation, and loading (ETL) into enterprise data warehouses.\n\u2022 Perform data cleansing, manipulation, and preparation from various sources including databases, flat files, APIs, and Excel/CSV.\n\u2022 Build and support BI applications and dashboards using SAS tools (Visual Analytics, Visual Investigator, SAS DI Studio) and Power BI.\n\u2022 Work on DevOps pipeline for code promotion and deployment using tools like Git, Jenkins, and Bitbucket.\n\u2022 Design and maintain fraud detection systems, campaign management flows, and credit risk models (PD, LGD, EAD).\n\u2022 Handle performance tuning of SQL/SAS jobs and monitor batch job execution via UNIX scripting and Control-M scheduler.\n\u2022 Actively participate in Agile ceremonies, collaborating with stakeholders, product owners, and cross-functional teams.\n\u2022 Develop and maintain technical documentation, support UAT/Production releases, and resolve incidents within defined SLAs.\n\u2022 Provide support and enhancements to existing SAS BI applications and ensure timely delivery of reports and analytics.\nRequired Skills and Qualifications:\n\nPrimary skills\n\u2022 SAS Base, SAS Advanced, SAS Macros\n\u2022 SQL (Teradata, Oracle)\n\u2022 Power BI\n\u2022 UNIX Shell Scripting\n\u2022 DevOps Tools: Git, Jenkins, Bitbucket\n\u2022 Data Modeling: Star & Snowflake schemas\n\u2022 Qualification: Bachelor's or Master's degree in Computer Science, Information Technology, or related field\nDomain Expertise\nBanking & Financial Services\n\u2022 Credit Risk (Basel III, IFRS9, RWA Calculations)\n\u2022 Fraud Detection & Alerts Management\n\u2022 Campaign Management (Normative, Commercial, Informative)\nSoft Skills & Additional Strengths\n\u2022 Strong analytical and problem-solving abilities\n\u2022 Effective communication and documentation skills\n\u2022 Quick learner and adaptive to emerging technologies\n\u2022 Proven track record of automation, process optimization, and cross-team collaboration",
    "url": "https://in.bebee.com/job/76d98763a317432212a830e981769da2?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T16:00:00.000Z"
  },
  {
    "title": "Senior Data Analyst/Back-office SME",
    "company": "Luxoft",
    "location": "Pune",
    "salary": "",
    "description": "Project description\n\nOur client is a UK subsidiary of a global financial house working in multiple markets and asset classes.\n\nWe are currently looking to Senior Data Analyst with solid experience in banking back office. Successful candidate will work in the technology team within Operations for EMEA. The role is for maintenance and enhancement of back office technology platforms, focusing on trade settlement, collateral management, reconciliations, and cash funding processes.\n\nThe candidate will work closely with the heads of operations departments and SMEs, operating as a senior data analyst and programmer to support system operation and development.\n\nStrong communication and interpersonal skills are required. The candidate must have a well-organized and structured approach to managing small/medium projects and working with senior stakeholders. The role allows for a good working from office/working from home balance, 2 days in the office are required. The working hours for the role should be close to UK to ensure sufficient intersection with the rest of the team.\n\nResponsibilities\n\u2022 Support and enhance back-office technology platforms, focusing on trade settlement, collateral management, reconciliations, and cash funding processes.\n\u2022 Develop and maintain complex SQL queries and scripts for data analysis, reporting, and operational support.\n\u2022 Collaborate with global technology and business teams to understand requirements and deliver solutions.\n\u2022 Participate in code reviews, version control (Git), and contribute to best practices around code branching and merging.\n\u2022 Take ownership of delegated tasks and projects, ensuring timely and high-quality delivery.\n\u2022 Troubleshoot and resolve issues across multiple systems and interfaces.\n\u2022 Document processes, workflows, and technical solutions clearly and concisely.\n\nSkills\n\nMust have\n\nAdvanced SQL skills (query optimization, data analysis, troubleshooting).\n\nExperience with at least one programming language (Python or Java preferred).\n\nFamiliarity with code repositories (Git) and understanding of branching, merging, and code management best practices.\n\nProduct knowledge of OTC derivatives, repo, and SBL.\n\nStrong analytical and problem-solving skills.\n\nExperience with XML and MQ messaging.\n\nAbility and experience of working under pressure\n\nboth autonomously and within a team.\n\nAbility to liaise with business and IT stakeholders at all levels of the organization.\n\nExposure to investment banking back office functions, especially trade settlement, collateral management, reconciliations, and cash funding.\n\nNice to have\n\u2022 Java, Python, Control-M",
    "url": "https://in.jooble.org/jdp/-1016191238164374378?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "(Bams/Bhms) Healthcare Data Analyst",
    "company": "Core Clinical Services",
    "location": "Pune",
    "salary": "",
    "description": "Salary Range : Rs. 15000 - Rs. 20000 , based on skills, experience, and interview performance\n\nEducational Requirement : Graduate\n\nWork Arrangement : Work From Office\n\nGender Preference : Both male and female can apply\n\nSkills Requirement : No predefined skills necessary\n\nExperience Requirement : Fresher\n\nLocation : Deccan Gymkhana\n\nWorking Hours : 7-8 hours a day | Monday to Saturday | day shift\n\nAdditional Info : Looking For Bams/Bhms Graduates (2023 & Later) For Part-Time It Healthcare Role In Pune. Use Clinical Knowledge For Data Accuracy, Summarization & Analysis. Monsat | Day & Evening Shift | Immediate Joiners | Hr@Coreclinicals.Com. Move Beyond Traditional Medicine And Build Your Career In It Healthcare- Future Of Modern Medicine.",
    "url": "https://www.workindia.in/jobs/bamsbhms_healthcare_data_analyst-deccan_gymkhana-pune-8335430/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Analyst",
    "company": "Barclays",
    "location": "Pune",
    "salary": "",
    "description": "Step into the role of Analyst at Barclays, where you'll provide first-class support by conducting in-depth due diligence, ensuring compliance with regulatory requirements, and safeguarding our clients and organization with expertise and care.\n\nYou may be assessed on key critical skills relevant for success in role such as:\n\u2022 Oversee day-to-day accounting of investment portfolios, including debt, equity, mutual funds, and alternative investments.\n\u2022 Ensure accurate and timely recording of all investment transactions as per relevant Indian accounting standards and regulatory frameworks (e.g., IRDAI, SEBI, RBI).\n\u2022 Monitor compliance with investment limits and guidelines.\n\u2022 Manage the end-to-end process of tax computation, filing, and compliance for investment-related activities.\n\u2022 Stay updated with changes in Indian tax laws and their impact on the business.\n\u2022 Lead and coordinate statutory, internal, and tax audits related to investments.\n\u2022 Prepare and review audit schedules, support documentation, and responses to audit queries.\n\u2022 Ensure adherence to financial controls, internal policies, and statutory requirements.\n\u2022 Lead, mentor, and manage a team of finance professionals.\n\u2022 Foster a culture of accountability, transparency, and continuous improvement.\n\u2022 Ability to lead team of chartered accountants/semi chartered accountants\n\nYou may be assessed on key essential skills relevant for success in role, such as risk and controls, change and transformation, business acumen, strategic thinking and digital and technology, as well as job-specific technical skills.\n\nThis role is based out of Pune.\n\nPurpose of the role\n\nTo support PBWM with day-to-day processing, reviewing, reporting, and issue resolution.\n\nAccountabilities\n\u2022 Support with day-to-day Private Bank and Wealth Management initiatives including processing, reviewing, reporting, and issue resolution with regards to accounts, products and services.\n\u2022 Support the management of the banks client relations to clearly identify their needs and provide a service that meets expectations.\n\u2022 Collaboration with teams across the bank to align and integrate Private Bank and Wealth Management processes.\n\u2022 Identification of areas for improvement and providing recommendations for change in Private Bank and Wealth Management processes.\n\u2022 Development and implementation of Private Bank and Wealth Management procedures and controls to mitigate risks and maintain operational efficiency.\n\u2022 Development of reports and presentations on Private Bank and Wealth Management performance and communicate findings to internal senior stakeholders.\n\u2022 Identification of industry trends and developments to implement best practice in Private Bank and Wealth Management Services.\n\u2022 Participation in projects and initiatives to improve Private Bank and Wealth Management efficiency and effectiveness.\n\nAnalyst Expectations\n\u2022 To perform prescribed activities in a timely manner and to a high standard consistently driving continuous improvement.\n\u2022 Requires in-depth technical knowledge and experience in their assigned area of expertise\n\u2022 Thorough understanding of the underlying principles and concepts within the area of expertise\n\u2022 They lead and supervise a team, guiding and supporting professional development, allocating work requirements and coordinating team resources.\n\u2022 If the position has leadership responsibilities, People Leaders are expected to demonstrate a clear set of leadership behaviours to create an environment for colleagues to thrive and deliver to a consistently excellent standard. The four LEAD behaviours are: L \u2013 Listen and be authentic, E \u2013 Energise and inspire, A \u2013 Align across the enterprise, D \u2013 Develop others.\n\u2022 OR for an individual contributor, they develop technical expertise in work area, acting as an advisor where appropriate.\n\u2022 Will have an impact on the work of related teams within the area.\n\u2022 Partner with other functions and business areas.\n\u2022 Takes responsibility for end results of a team\u2019s operational processing and activities.\n\u2022 Escalate breaches of policies / procedure appropriately.\n\u2022 Take responsibility for embedding new policies/ procedures adopted due to risk mitigation.\n\u2022 Advise and influence decision making within own area of expertise.\n\u2022 Take ownership for managing risk and strengthening controls in relation to the work you own or contribute to. Deliver your work and areas of responsibility in line with relevant rules, regulation and codes of conduct.\n\u2022 Maintain and continually build an understanding of how own sub-function integrates with function, alongside knowledge of the organisations products, services and processes within the function.\n\u2022 Demonstrate understanding of how areas coordinate and contribute to the achievement of the objectives of the organisation sub-function.\n\u2022 Make evaluative judgements based on the analysis of factual information, paying attention to detail.\n\u2022 Resolve problems by identifying and selecting solutions through the application of acquired technical experience and will be guided by precedents.\n\u2022 Guide and persuade team members and communicate complex / sensitive information.\n\u2022 Act as contact point for stakeholders outside of the immediate function, while building a network of contacts outside team and external to the organisation.\n\nAll colleagues will be expected to demonstrate the Barclays Values of Respect, Integrity, Service, Excellence and Stewardship \u2013 our moral compass, helping us do what we believe is right. They will also be expected to demonstrate the Barclays Mindset \u2013 to Empower, Challenge and Drive \u2013 the operating manual for how we behave.",
    "url": "https://search.jobs.barclays/job/pune/analyst/13015/87927804016?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Data and  Analytics",
    "company": "Kone",
    "location": "IN",
    "salary": "",
    "description": "A Data and Machine Learning Specialist is responsible for managing, analyzing, and leveraging data to drive business insights and develop predictive models. This role combines elements of data science, data engineering, data management, and machine learning to ensure data-driven decision-making and innovation.\n\nResponsibilities:\n\u2022 Data Collection & Management: Gather, clean, and organize data from various sources to ensure its accuracy and accessibility.\n\u2022 Data Analysis: Utilize statistical methods and machine learning tools to analyze data and uncover trends and patterns.\n\u2022 Pipeline Development: Design and maintain efficient data pipelines and architectures to facilitate seamless data flow.\n\u2022 Model Development: Create, test, and optimize machine learning models and algorithms to solve complex problems.\n\u2022 Reporting & Visualization: Present findings through detailed reports and visualizations to communicate insights effectively.\n\u2022 Collaboration: Work closely with cross-functional teams, including software engineers, data scientists, and business analysts, to implement data-driven solutions.\n\u2022 Performance Optimization: Continuously improve data delivery, scalability, and model performance.\n\u2022 Documentation: Maintain thorough documentation of processes, models, and results.\n\nRequirements:\n\u2022 Bachelors or equivalent degree with over 5+ years of experience and proficiency in programming languages such as Python, SQL.\n\u2022 Strong knowledge of cloud platforms like AWS, Google Cloud, or Microsoft Azure.\n\u2022 Experience with data visualization tools and techniques.\n\u2022 Solid understanding of machine learning algorithms and statistical analysis.\n\u2022 Excellent problem-solving skills and attention to detail.\n\u2022 Ability to collaborate effectively with diverse teams.\n\nAt KONE, we are focused on creating an innovative and collaborative working culture where we value the contribution of each individual. Employee engagement is a key focus area for us and we encourage participation and the sharing of information and ideas. Sustainability is an integral part of our culture and the daily practice. We follow ethical business practices and we seek to develop a culture of working together where co-workers trust and respect each other and good performance is recognized. In being a great place to work, we are proud to offer a range of experiences and opportunities that will help you to achieve your career and personal goals and enable you to live a healthy and balanced life.\n\nRead more on www.kone.com/careers",
    "url": "https://careers.kone.com/fi-fi/avoimet-tyopaikat/r0648559/data-and-analytics/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-03T00:00:00.000Z"
  },
  {
    "title": "Analyst- MDM",
    "company": "Eaton",
    "location": "Pune",
    "salary": "",
    "description": "What you\u2019ll do:\n\nThis position will be responsible for managing and maintaining product master data and enterprise product hierarchy within Eaton\u2019s Product Data Hub, with a strong focus on ensuring the hierarchy is always accurate and up-to-date. The role also ensures a high level of product data quality, consistency, and completeness for data flowing to Eaton.com, Order Center, and various other digital and eCommerce initiatives.\n\n\"Own and manage the enterprise product hierarchy across MDM system and platforms.\n\nCreate and update product hierarchy to reflect accurate product categorization and business alignment.\n\nAssociate products correctly to the hierarchy, ensuring consistency across ERP, CRM, finance, Eaton.com, and other systems.\n\nCollaborate with product line teams to align on hierarchy structure and product-to-hierarchy mapping.\n\nWork closely with finance teams to ensure product hierarchies are current and accurately reflected in financial systems.\n\nWrite and edit a heavy volume of product information such as product descriptions, product attributes, and unstructured content.\n\nIdentify inconsistencies in product information and work through enterprise governance processes for standardization.\n\nProvide tactical assistance to Product Lifecycle Management in enterprise/business systems and services.\n\nImplement and manage Master Data Management (MDM) processes to ensure data integrity and consistency across all systems.\n\nDevelop and enforce data governance policies and procedures to maintain high-quality master data.\n\nEnsure accuracy, completeness, and health requirements for product data globally.\n\nCollect, organize, create, document, and enter detailed attribute information.\n\nCollaborate with cross-functional teams to define and document MDM requirements and standards.\n\nWork with Product Data Hub tools to build a centralized product database for products.\n\nPossess experience in Product Lifecycle Management, product development, and product data management.\n\nMonitor and report on MDM metrics to ensure continuous improvement in data quality.\n\nCollaborate with technical teams for system improvements and testing of integration mappings between different applications and PDH.\n\nQualifications:\n\nDegree in Business Administration/Marketing/Commerce or similar\n\nAt least 1-year exp in Data Management and Analysis.\n\nSkills:\n\nAbility to work effectively in team environment and independently\n\n\"\u2022 Master Data Management - PIM, Product data management, hierarchy management\n\n\u2022 Experience in Advanced Excel is must\n\n\u2022 Experience is Power BI and SQL is good to have.\n\n\u2022 Good to have knowledge of Stibo.\n\n\u2022 Good communication, Team player.\"\n\n\"\u2022 Drive for results\n\n\u2022 Makes Decisions & Solves Problems\n\n\u2022 Demonstrates a Collaborative Style\n\n\u2022 Promotes and Champions Change\n\n\u2022 Business Acumen\n\n\u2022 Pursues personal development\n\n\u2022 Strong work ethic, flexibility, and a desire to actively contribute to the group\u2019s success\n\n\u2022 Ability to prioritize multiple tasks\n\n\u2022 Team player. Ability to handle high-pressure, fast-paced environment requiring diligence to detail\n\n\u2022 Proven analytical and critical thinking skills",
    "url": "https://in.linkedin.com/jobs/view/analyst-mdm-at-eaton-4320439229?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Data Analytics Intmd Analyst",
    "company": "Citi",
    "location": "Pune",
    "salary": "",
    "description": "The Data Analytics Intmd Analyst is a developing professional role. Deals with most problems independently and has some latitude to solve complex problems. Integrates in-depth specialty area knowledge with a solid understanding of industry standards and practices. Good understanding of how the team and area integrate with others in accomplishing the objectives of the subfunction/ job family. Applies analytical thinking and knowledge of data analysis tools and methodologies. Requires attention to detail when making judgments and recommendations based on the analysis of factual information. Typically deals with variable issues with potentially broader business impact. Applies professional judgment when interpreting data and results. Breaks down information in a systematic and communicable manner. Developed communication and diplomacy skills are required in order to exchange potentially complex/sensitive information. Moderate but direct impact through close contact with the businesses' core activities. Quality and timeliness of service provided will affect the effectiveness of own team and other closely related teams.\n\nResponsibilities:\n\u2022 Integrates in-depth data analysis knowledge with a solid understanding of industry standards and practices.\n\u2022 Demonstrates a Good understanding of how data analytics teams and area integrate with others in accomplishing objectives.\n\u2022 Applies project management skills.\n\u2022 Applies analytical thinking and knowledge of data analysis tools and methodologies.\n\u2022 Analyzes factual information to make accurate judgments and recommendations focused on local operations and broader impacts.\n\u2022 Applies professional judgment when interpreting data and results breaking down information in a systematic and communicable manner.\n\u2022 Employs developed communication and diplomacy skills to exchange potentially complex/sensitive information.\n\u2022 Demonstrates attention to quality and timeliness of service to ensure the effectiveness of the team and group.\n\u2022 Provides informal guidance or on-the-job-training to new team members.\n\u2022 Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency.\n\nQualifications:\n\u2022 2-5 years relevant experience\n\u2022 Knowledge of tools for statistical modeling of large data sets\n\u2022 Ability to effectively use complex analytical, interpretive and problem solving techniques\n\u2022 Demonstrated interpersonal, verbal and written communication skills\n\nEducation:\n\u2022 Bachelor's/University degree or equivalent experience\n\nThis job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.\n\nJob Family Group:\nTechnology\n\nJob Family:\nData Analytics\n\nTime Type:\nFull time\n\nMost Relevant Skills\nPlease see the requirements listed above.\n\nOther Relevant Skills\nFor complementary skills, please see above and/or contact the recruiter.\n\nCiti is an equal opportunity employer, and qualified candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other characteristic protected by law.\n\nIf you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.\n\nView Citi's EEO Policy Statement and the Know Your Rights poster.",
    "url": "https://in.bebee.com/job/352897611c75f4fcc35e5c1138243e29?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Salesforce Data Analyst (Pune Division)",
    "company": "Zensar Technologies",
    "location": "Pune",
    "salary": "",
    "description": "Job Title: Salesforce Data Analyst\n\nExp-5-8 Years\n\nLocation-Remote\n\nJob Summary:\n\nThe Salesforce Data Analyst is a bridge between raw data and business insight. This role is responsible for ensuring data integrity, transforming data into actionable reports and dashboards, and empowering stakeholders to make data-driven decisions. The focus is on using data to answer business questions and drive efficiency.\n\nKey Responsibilities:\n\n- Data Governance & Quality:\n- Monitor and maintain data quality, hygiene, and completeness within Salesforce.\n- Develop and enforce data standards, validation rules, and duplicate management processes.\n- Perform regular data audits and lead data cleansing initiatives.\n- Reporting & Dashboarding:\n- Design, build, and maintain complex reports, dashboards, and report folders in Salesforce.\n- Translate business requirements from stakeholders (Sales, Marketing, Service) into technical reporting specifications.\n- Empower business users with self-service reporting capabilities through training and documentation.\n- Business Analysis & Insight:\n- Analyze data trends to provide insights on sales performance, pipeline health, marketing campaign ROI, and customer support metrics.\n- Support strategic planning by providing data-backed recommendations.\n- Document business processes and data flows.\n- Support & Collaboration:\n- Act as a primary point of contact for ad-hoc data and reporting requests.\n- Collaborate with Salesforce Administrators and Developers to communicate business needs for new fields, objects, or automation.\n\nRequired Skills & Qualifications:\n\n- Experience: 4+ years of experience as a Data Analyst, Sales Operations Analyst, or similar role, with a primary focus on Salesforce.\n- Technical Skills:\n- Expert-level proficiency in Salesforce Reports & Dashboards .\n- Strong skills in Excel/Google Sheets (PivotTables, VLOOKUPs, Charts).\n- Solid understanding of the Salesforce data model (Standard Objects like Account, Contact, Prospect, Lead; and their relationships).\n- Basic understanding of Salesforce security (Profiles, Permission Sets, Roles, Sharing Rules) as it pertains to data access in reports.\n- Soft Skills:\n- Excellent communication and storytelling skills to explain data findings to non-technical audiences.\n- Strong analytical and problem-solving mindset.\n- Meticulous attention to detail.\n\nNice-to-Have Skills:\n\n- Experience with Tableau , Power BI , or Einstein Analytics .\n- Familiarity with a data manipulation language (e.g., SQL ).\n- Salesforce certifications like Salesforce Certified Administrator or Tableau CRM & Einstein Discovery Consultant",
    "url": "https://in.jobrapido.com/jobpreview/241517918850908160?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-10-31T00:00:00.000Z"
  },
  {
    "title": "Production Analyst - Associate | Pune, IN",
    "company": "Deutsche Bank",
    "location": "Pune",
    "salary": "",
    "description": "Job Title: Production Analyst\n\nCorporate Title: Associate\n\nLocation: Pune, India\n\nRole Description\n\u2022 Private Bank Germany Service Operations - provides 2nd Level Application Support for business applications used in branches, by mobile sales or via internet. The department is responsible for the stability of the applications.\n\u2022 Incident Management and Problem Management are the main processes that account for the required stability. In-depth application knowledge and understanding of the business processes that the applications support are our main assets.\n\u2022 The Service Management Analyst acts as a hands-on technician executing several tasks in relation to the required services within the Service Management environment. The Service Management Analyst role supports the respective functional teams and provides expertise and assistance to ensure effective services are provided by Service Management.\n\u2022 The main tasks of the Service Management Analyst are: Monitoring and tracking activities, analyzing issues, supporting the resolution of issues and conflicts and preparing reports and meetings. The Service Management Analyst has knowledge of and experience in all relevant tools used in the Service Management environment. What we'll offer you\n\nAs part of our flexible scheme, here are just some of the benefits that you'll enjoy\n\u2022 Best in class leave policy\n\u2022 Gender neutral parental leaves\n\u2022 100% reimbursement under childcare assistance benefit (gender neutral)\n\u2022 Sponsorship for Industry relevant certifications and education\n\u2022 Employee Assistance Program for you and your family members\n\u2022 Comprehensive Hospitalization Insurance for you and your dependents\n\u2022 Accident and Term life Insurance\n\u2022 Complementary Health screening for 35 yrs. and above Your key responsibilities\n\nService Operations Management\n\nThe Service Management Analyst with focus on Service Operations will be responsible for undertaking Service Operation support activities including run book, incident, and problem resolution where these have been assigned.\n\nArea specific tasks / responsibilities:\n\u2022 Undertake start of day, intra-day, end of day and end of period procedures as defined in the Service Operations run book to ensure that production configuration items deliver required services\n\u2022 Ensure familiarity with the applications, tools, feeds, data, batch files etc that are being managed and / or supported\n\u2022 Maintain a thorough understanding, sufficient to meet target Service Level Agreements, of the knowledge required to provide effective technical support (including understanding of market feeds, reference data problems, batch processes, system interfaces, business rules etc.)\n\u2022 Derive and apply strategies for resolving and solving application incidents/problems. Apply business and required technical skill sets to resolve issue promptly and accurately. Seek early advice where appropriate.\n\u2022 Bank knowhow is needful, especially knowledge about Mortgages and Consumer Credits. Your skills and experience\n\u2022 Develop a good understanding of the activities required to execute Service Management functions.\n\u2022 Follow all guidelines and controls for the relevant processes to ensure compliance and quality.\n\u2022 Undertake specific functions within the relevant Service Management process as identified for the specific Service Management area.\n\u2022 Participate in regular meetings with stakeholders, prepare and document meetings, track progress.\n\u2022 Collect, interpret, and respond to changes in production data, as appropriate.\n\u2022 Track the implementation of resolution tasks.\n\u2022 Provide regular and reliable reporting of relevant data to meet management requirements.\n\u2022 Understand thoroughly the end-to-end application support process and escalation procedures, become fully conversant with all support tools that will be used to provide effective support in the relevant area (i.e. service operations).\n\u2022 Maintain an end-to-end view of the application and infrastructure landscape.\n\u2022 Provide feedback and communicates results to stakeholders.\n\u2022 Provide input and contribute in Service Management related audits.\n\u2022 Engage with other Service Management groups to understand business requirements.\n\u2022 Perform review of specifications.\n\u2022 Collect, analyze, and produce metrics on process data for KPIs to find out improvements.\n\u2022 Identify risks and issues related to the area.\n\u2022 Provide governance to ensure appropriate planning and reporting.\n\u2022 Experience/Exposure\n\u2022 Language Skills: English, German (nice to have)\n\u2022 Needful technical skills: Unix, Oracle SQL, Shell Scripting, Cloud technologies, Oracle WebLogic and TomCat, Batch-Job Controlling Tool (Automic/AutoSys/Control-M), Nice to have\n\u2022 RedHat OpenShift knowledge, Python and Java knowledge. Education\n\u2022 Bachelor's degree from an accredited college or university with a concentration in IT or Computer Science related discipline (equivalent diploma or technical faculty)\n\u2022 ITIL V4 foundation certification (preferred) How we'll support you\n\u2022 Training and development to help you excel in your career\n\u2022 Coaching and support from experts in your team\n\u2022 A culture of continuous learning to aid progression\n\u2022 A range of flexible benefits that you can tailor to suit your needs About us and our teams\n\nPlease visit our company website for further information:\n\nhttps://www.db.com/company/company.html\n\nWe strive for a culture in which we are empowered to excel together every day. This includes acting responsibly, thinking commercially, taking initiative and working collaboratively.\nTogether we share and celebrate the successes of our people. Together we are Deutsche Bank Group.\nWe welcome applications from all people and promote a positive, fair and inclusive work environment.",
    "url": "https://www.efinancialcareers.com/jobs-India-Pune-Production_Analyst_-_Associate.id23376770?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Data Scientist",
    "company": "Snowflake",
    "location": "Pune",
    "salary": "",
    "description": "Snowflake is about empowering enterprises to achieve their full potential \u2014 and people too. With a culture that\u2019s all in on impact, innovation, and collaboration, Snowflake is the sweet spot for building big, moving fast, and taking technology \u2014 and careers \u2014 to the next level.\n\nSnowflake is seeking a Data Scientist to join our expanding Enterprise AI & ML team. This role involves working on diverse AI/ML and data science initiatives, utilizing Snowflake's Data Cloud and Cortex AI. The successful candidate will design and develop scalable data science and machine learning solutions, build interactive AI applications, and collaborate on operationalizing intelligent systems to enhance data-driven decision-making throughout the company. This position focuses on applying data science, AI & ML skill sets to various domain specific business data problems across Snowflake.\n\nON THE ENTERPRISE AI & ML TEAM AT SNOWFLAKE, YOU WILL:\n\u2022 Design, prototype, and deploy data science and AI solutions.\n\u2022 Conduct end to end experimentation, including data exploration, feature engineering, model development, and validation.\n\u2022 Build and maintain Streamlit applications to visualize models, showcase insights, and enable business stakeholders to interact with AI driven solutions.\n\u2022 Develop and optimize LLM based applications, workflows, and operations; with a focus on retrieval, generation, semantic understanding and fine-tuning.\n\u2022 Partner cross functionally with data engineers, analysts, and product teams to translate ambiguous business problems into measurable outcomes.\n\nOUR IDEAL CANDIDATE WILL HAVE:\n\u2022 2 to 4 years of experience applying data science, machine learning, or AI techniques in real world business settings.\n\u2022 Strong programming skills in Python, proficiency in SQL for large scale data manipulation.\n\u2022 Familiarity with frameworks such as scikit-learn, XGBoost etc.\n\u2022 Understanding of LLM architectures, embeddings, vector search, and RAG pipelines.\n\u2022 Experience working on cloud platforms.\n\u2022 Strong analytical, storytelling, and communication skills to translate technical insights into actionable recommendations.\n\u2022 A mindset of curiosity, ownership, and collaboration, with an eagerness to work on open-ended problems.\n\u2022 Experience operationalizing AI & ML models in a production setting.\n\nSnowflake is growing fast, and we\u2019re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.\n\nHow do you want to make your impact?\n\nFor jobs located in the United States, please visit the job posting on the Snowflake Careers Site for salary and benefits information: careers.snowflake.com",
    "url": "https://careers.snowflake.com/us/en/job/SNCOUSE5563EEBE22F4F83ABADA6BD2B014860EXTERNALENUSF7C857F3DD284045B0C758E492307EC3/Data-Scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Software Engineer - L2 (Software Engineer I)",
    "company": "Griphic",
    "location": "Chhatrapati Sambhajinagar",
    "salary": "",
    "description": "Software Engineer -\n\nL2 (Software Engineer I)\n\nLocation & Type : Delhi, Full-time\n\nCTC Range (LPA) : 23.75 - 28.00\n\nRole Overview\n\nAs a Software Engineer I, you will\n\nown features or modules end-to-end\n\nacross backend and frontend. You\u2019ll deliver reliable, maintainable, production-ready code while collaborating closely with Product, Design, and AI teams. This role requires comfort moving between\n\nAPIs, databases, and modern frontend and backend frameworks .\n\nWhat You\u2019ll Do\n\nOwn and deliver\n\nfeatures / modules\n\nwith minimal supervision.\n\nWrite and review\n\ndesign proposals\n\nbefore implementation.\n\nBuild and scale backend services in\n\nNode.js\n\nand integrate AI services in\n\nPython.\n\nDevelop\n\nREST / GraphQL APIs\n\nwith strong error handling and performance.\n\nWork with\n\nPostgres\n\nand\n\nMongoDB\n\nto design schemas and optimize queries.\n\nEnsure quality with\n\nunit, integration, and regression tests,\n\nenforce CI / CD quality gates.\n\nAdd metrics, logs, and dashboards for observability.\n\nResolve issues in staging / production and take\n\non-call ownership\n\nfor your modules.\n\nProvide mentorship and review feedback to junior engineers.\n\nTechnical Qualifications\n\nMinimum 2\u20133 years of professional software engineering experience.\n\nProficiency in\n\nNode.js\n\nand\n\nPython .\n\nStrong experience designing and consuming\n\nREST APIs,\n\nexposure to\n\nGraphQL .\n\nSolid understanding of\n\nPostgres\n\nschema design and query optimization.\n\nProficiency with\n\nMongoDB\n\naggregation pipelines and indexing.\n\nFamiliarity with\n\nAWS ECS / ECR , containers, and monitoring basics.\n\nStrong CI / CD experience (automated testing, deployments, rollbacks).\n\nSolid debugging and troubleshooting skills with logs and metrics.\n\nNice to Have\n\nKubernetes (EKS) experience.\n\nInfrastructure-as-Code (Terraform, CDK).\n\nAdvanced observability tools (Prometheus, Grafana, OpenTelemetry).\n\nExperience with distributed systems and microservices.\n\nExposure to frontend frameworks.\n\nUI / UX sensibility and experience collaborating closely with design teams\n\nAbout the Company\n\nGriphic is founded by IIT Delhi engineers with a vision to enrich lives through technological innovation. We combine cutting-edge AI with hyper-realistic virtual experiences to solve problems and disrupt industries. Our team includes IIT Delhi engineers, AI / ML experts, VR developers, and 3D specialists. Backed by SKETS Studio (700+ professionals in BIM, architecture, VR, and 3D visualization), we are building the future of immersive web applications.",
    "url": "https://in.talent.com/view?id=2ba22dfcadf8&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Software Tester Executive",
    "company": "Esbee Dynamed Pvt Ltd.",
    "location": "Chhatrapati Sambhajinagar",
    "salary": "",
    "description": "Job Title :\n\nQuality Check Executive \u2013 Products\n\nExperience : 1\u20132 Years\n\nCompany Description\n\nEsbee Dynamed Pvt Ltd., established in 1999, is a trusted provider of advanced surgical devices and OR integration systems. In 2023, the company launched its own OR Integration systems, further enhancing its innovative portfolio. With ISO 9001-certified production facilities, Esbee Dynamed specializes in precision-engineered products, including media management systems, surgical recording technologies, and customized software tools for digitizing the operating room. The company is dedicated to creating high-quality, innovative technology that simplifies workflows and improves clinical outcomes. Based in Mumbai, Esbee Dynamed continues to expand its footprint in digital health solutions.\n\nRole Description\n\nThis is a full-time on-site role for a Software Tester Executive, located in Mumbai. The Software Tester Executive will be responsible for executing test cases, assessing software quality, and ensuring adherence to quality assurance standards. Day-to-day responsibilities include analyzing system requirements, conducting thorough testing processes, identifying bugs, and collaborating closely with the software development team to improve system functionality. The role involves proactive problem-solving and ensuring optimal product performance before delivery.\n\nQualifications\n\nProficiency in Test Execution and Software Testing to assess and validate system functionality\n\nStrong Analytical Skills to evaluate software requirements and identify potential defects\n\nExperience with Quality Assurance practices to ensure product reliability and compliance\n\nKnowledge of designing and implementing effective Test Cases\n\nAbility to collaborate with cross-functional teams for timely issue resolution\n\nFamiliarity with industry-standard testing tools and methodologies\n\nBachelor's degree in Computer Science, Information Technology, or a related field\n\nAttention to detail and a commitment to delivering high-quality results",
    "url": "https://in.talent.com/view?id=f5c05ca0bd11&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Software Development Engineer-II",
    "company": "Srujanee",
    "location": "Chhatrapati Sambhajinagar",
    "salary": "",
    "description": "Job Title : Software Development Engineer-II\n\nLocation : Remote\n\nCompany : Srujanee\n\nExperience Required : 4-6 years\n\nDepartment : Product Engineering\n\nBrief : Senior Full Stack Developer experienced with Next.Js, Node.Js, MongoDb and Express.Js\n\nResponsibility :\n\n1.\u2060 \u2060Architecture & Development\n\n2.\u2060 \u2060Design, develop, and maintain scalable applications using Next.js, Node.js, MongoDB, and Express.js (MERN + Next.js).\n\n3.\u2060 \u2060Drive the migration from existing MERN stack to Next.js for improved performance and SEO.\n\n4.\u2060 \u2060Integrate AI / ML APIs (e.g., speech-to-text, NLP, translation, summarization) into core workflows.\n\n5.\u2060 \u2060Build RESTful and GraphQL APIs to power both web and mobile apps.\n\n6.\u2060 \u2060Implement server-side rendering (SSR) and static site generation (SSG) for multilingual SEO.\n\n7.\u2060 \u2060Collaborate cross-functionally with Product Managers, Designers, and AI Engineers.\n\n8.\u2060 \u2060Mentor junior developers, perform code reviews, and ensure high code quality.\n\n9.\u2060 \u2060Participate in sprint planning, architecture discussions, and release management\n\n10. Proven experience in designing scalable architectures and building resilient systems with features like caching strategies, load balancing, database optimization and monitoring / alerting frameworks.\n\nRequired Skills & Qualifications\n\u2022 Bachelor\u2019s / Master\u2019s degree in Computer Science, Engineering, or equivalent.\n\u2022 5\u20138 years of experience in full-stack web development, preferably in SaaS or content platforms.\n\u2022 Strong proficiency in :\n\u2022 Frontend : Next.js, React.js, Redux, TypeScript, Tailwind CSS.\n\u2022 Backend : Node.js, Express.js, MongoDB (or equivalent NoSQL DBs).\n\nKey Traits We Value\n\n1.\u2060 \u2060Ownership mindset and bias toward action.\n\n2.\u2060 \u2060Strong attention to detail and performance metrics.\n\n3.\u2060 \u2060Passion for language technology, culture, and accessibility.\n\n4.\u2060 \u2060Collaborative attitude \u2014 thrives in startup and growth environments.",
    "url": "https://in.talent.com/view?id=61937cdf3e08&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Principal Software Engineer (Java+AI)",
    "company": "Informatica",
    "location": "Chhatrapati Sambhajinagar",
    "salary": "",
    "description": "Build Your Career at Informatica\n\nWe seek innovative thinkers who believe in the power of data to drive meaningful change. At Informatica, we welcome adventurous, work-from-anywhere minds eager to solve the world's most complex challenges. Our employees are empowered to push their bold ideas forward, and we are united by a shared passion for using data to do the extraordinary for each other and the world.\n\nPrincipal Software Engineer - AI Agentic Integration\n\nAbout The Role\n\nWe're looking for an experienced Principal Software Engineer experienced in designing and building scalable, cloud-native, and AI-powered platforms, with experience with Agent Engineering. You will help architect and develop the next-generation Agent platform that powers Informatica's products globally.\n\nWe're looking for hands-on engineer with expertise in Java, microservices, AI / ML frameworks, and container orchestration technologies.\n\nYou will work with the Integration AI team reporting to Director, Development.\n\nTechnology You'll Use\n\nJava, Python, Microservices Architecture, Langchain, LLMs, MCP, Cloud platforms (AWS, Azure, GCP), Kubernetes, Docker, AI / ML frameworks and Vector Databases.\n\nYour Role Responsibilities? Here's What You'll Do\n\nDesign and develop a scalable, reliable, and Agent Engineering platform applying AI / ML and cloud-native technologies.\n\nCollaborate with architects, product management, QA, and geographically dispersed peers across Agile teams to deliver end-to-end components and solutions.\n\nLead efforts to incubate and architect next-generation platforms for heterogeneous, complex systems using modern technologies.\n\nInterpret broad, new product requirements into detailed technical designs and implementation plans.\n\nChampion software engineering best practices, including high code quality, testing, automation, and architectural decisions.\n\nEstimate project efforts, identify risks, and help meet schedules.\n\nMentor engineers at several levels to foster learning, innovation, and.\n\nFacilitate cross-team collaboration, promote design discussions, and promote technical vision for Agent platform plans.\n\nWhat We'd Like to See\n\nExpertise in Java with hands-on experience in design, coding, and scaling SaaS or AI / ML applications using microservices architecture.\n\nKnowledge of cloud-native deployment and container orchestration (Kubernetes, Docker).\n\nFamiliarity with Python and AI / ML frameworks.\n\nExperience with distributed systems, databases, and scalable architecture patterns.\n\nAgile development experience and experience with continuous improvement.\n\nPrior experience leading engineering teams in a distributed environment.\n\nExperience working with major cloud providers (AWS, Azure, Google Cloud).\n\nHands-on with modern frontend frameworks like React is beneficial.\n\nRole Essentials\n\nMinimum 8+ years of professional experience developing enterprise-grade software, with backend development skills.\n\nExpertise in Java with hands-on experience in designing, code, and scaling SaaS or AI / ML applications using microservices architecture.\n\nExperience in Langchain, LLMs, MCP and AI orchestration frameworks",
    "url": "https://in.talent.com/view?id=6607c02039d0&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Software Engineer Backend",
    "company": "Solvei8",
    "location": "Chhatrapati Sambhajinagar",
    "salary": "",
    "description": "Job Title: Software Engineer II\nSolvei8 (pronounced solve-it) is a one-stop integrated factory cloud solutions provider for the apparel and footwear industry, under the parent company Buyogo AG. With innovation, agility, and customer-centricity at the core, Solvei8 is focused on providing solutions that optimize factory processes, increase visibility, and lead to better data-driven decisions.\n\nWe follow microservice architecture with the server-side code modelled as multiple microservices written in Java or Scala. We use Kafka and Flink for communication and in-stream processing. You'd get to work on relational (Postgres), no-SQL (Mongo) and big-data DBs (HBase, Druid).\n\nGood to have:\n\u2022 Experience with other databases like Apache Druid, Redis, Cassandra or Elasticsearch.\n\u2022 Having functional programming language understanding.\n\u2022 Having understanding of distributed systems.\n\u2022 Experience with testing frameworks like JUnit.\n\u2022 Experience in product based companies.\n\u2022 Graduates from top tier colleges would be preferred.",
    "url": "https://in.bebee.com/job/a6677179593c272de527e730922535db?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-07T17:00:00.000Z"
  },
  {
    "title": "Software Architect Technical Lead",
    "company": "Huxley",
    "location": "Chhatrapati Sambhajinagar",
    "salary": "",
    "description": "At Huxley, we connect skilled professionals with exciting career opportunities through our partnership with top-tier tech companies.\n\nOur client, a leading technology firm headquartered in Tokyo, is driving innovation in fintech and digital advertising domains.\n\nEngineering teams build scalable microservices using Java and Spring Boot, supported by modern infrastructure tools such as Kafka, Kubernetes, and MongoDB.\n\nThe organization fosters a collaborative and growth-oriented culture, welcoming engineers who are passionate about learning, experimenting with new technologies, and contributing to mission-critical systems that operate at massive scale.\n\u2022 Key Qualifications:\n\u2022 Extensive experience in backend development, particularly using Java and Spring Boot frameworks (7+ years preferred).\n\u2022 Proven leadership in technical roles, with hands-on experience guiding engineering teams (3+ years).\n\u2022 Demonstrated ability to architect and implement secure, scalable APIs for enterprise-grade platforms.\n\u2022 Strong grasp of agile development practices and full software lifecycle management.\n\u2022 Analytical mindset with a keen eye for detail and a proactive approach to solving complex problems.\n\u2022 Effective communicator with the ability to collaborate across cross-functional teams and stakeholders.",
    "url": "https://in.bebee.com/job/447dbbc6bf18780dfde78f72f6bbca6a?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-07T00:00:00.000Z"
  },
  {
    "title": "Junior Revenue Operations",
    "company": "RunLoyal: Pet Software",
    "location": "Chhatrapati Sambhajinagar",
    "salary": "",
    "description": "Junior Revenue Operations\n\nThe Junior Revenue Operations role at RunLoyal involves managing subscriptions, revenue, and analytics. The ideal candidate will have strong analytical skills, experience with Excel/Google Sheets, and a passion for learning SaaS operations.\nKey Responsibilities\n\u2022 Manage subscription data and pricing updates.\n\u2022 Maintain accurate revenue and subscription reports in Excel/Google Sheets.\n\u2022 Support monthly revenue tracking and forecasting.\n\u2022 Monitor SaaS metrics like MRR, ARR, churn, and LTV.\n\u2022 Maintain data hygiene in HubSpot (CRM) and Stripe (billing platform).\n\u2022 Collaborate with Customer Success and Sales teams to align subscription records.\n\u2022 Document processes and contribute ideas for automation.\nQualifications\n\u2022 Recently completed or pursuing a postgraduate program (MBA Finance / Business Analytics / M.Sc. Data Analytics / related field).\n\u2022 Strong interest in SaaS, finance, or revenue operations.\n\u2022 Comfortable working with Excel/Google Sheets (formulas, pivots, charts).\n\u2022 Analytical mindset with attention to detail.\n\u2022 Strong communication skills and willingness to learn new tools (HubSpot, Stripe).\n\u2022 Proactive, curious, and eager to grow in a SaaS environment.",
    "url": "https://in.bebee.com/job/ceb0baaa9e0719eda10fc44b98a96581?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-07T00:00:00.000Z"
  },
  {
    "title": "Engineer 5, Software Development & Engineering-3085",
    "company": "Freewheel",
    "location": "Reston",
    "salary": "",
    "description": "FreeWheel, a Comcast company, provides comprehensive ad platforms for publishers, advertisers, and media buyers. Powered by premium video content, robust data, and advanced technology, we\u2019re making it easier for buyers and sellers to transact across all screens, data types, and sales channels. As a global company, we have offices in nine countries and can insert advertisements around the world.\n\nJob Summary\nnull\n\nJob Description\n\nDUTIES: Provide technical leadership in designing and developing new software and web applications using C++, Golang, and Scala in a Linux environment; work with distributed systems; process data using Big Data technologies, including Spark, Presto, and Snowflake; develop backend software for the MRM Forecasting platform; respond to real-time production MRM Forecasting P1/2 Escalation tickets; troubleshoot and debug software issues; support applications under development and customize current applications; assist with the software update process for existing applications, and roll-outs of software releases; analyze, test, and assist with the integration of new applications; document all development activity; research, write, and edit documentation and technical requirements, including software designs, evaluation plans, test results, technical manuals, and formal recommendations and reports; monitor and evaluate competitive applications and products; review literature, patents, and current practices relevant to the solution of assigned projects; collaborate with project stakeholders to identify product and technical requirements; conduct analysis to determine integration needs; and guide and mentor junior-level engineers. Position is eligible to work remotely one or more days per week, per company policy.\n\nREQUIREMENTS: Bachelor\u2019s degree, or foreign equivalent, in Computer Science, Engineering, or related technical field, and seven (7) years of experience developing software using C++ and Golang; processing data using Big Data technologies, including Spark and Presto; working with distributed systems; of which five (5) years include developing software using Scala; developing backend forecasting functions for advertising platforms, including inventory forecasting, campaign performance forecasting, and A/B testing; and developing software in a Linux environment\n\nDisclaimer: This information has been designed to indicate the general nature and level of work performed by employees in this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications.\n\nComcast is an equal opportunity workplace. We will consider all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran status, genetic information, or any other basis protected by applicable law.\n\nSkills:\n\nScala (Programming Language); Presto; Go Programming Language\n\nBase pay is one part of the Total Rewards that Comcast provides to compensate and recognize employees for their work. Most sales positions are eligible for a Commission under the terms of an applicable plan, while most non-sales positions are eligible for a Bonus. Additionally, Comcast provides best-in-class Benefits to eligible employees. We believe that benefits should connect you to the support you need when it matters most, and should help you care for those who matter most. That\u2019s why we provide an array of options, expert guidance and always-on tools, that are personalized to meet the needs of your reality \u2013 to help support you physically, financially and emotionally through the big milestones and in your everyday life. Please visit the compensation and benefits summary on our careers site for more details.",
    "url": "https://jobs.comcast.com/job/reston/engineer-5-software-development-and-engineering-3085/47546/88123072448?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Software Engineer, Tech Lead",
    "company": "Freddie Mac",
    "location": "McLean",
    "salary": "",
    "description": "At Freddie Mac, our mission of Making Home Possible is what motivates us, and it\u2019s at the core of everything we do. Since our charter in 1970, we have made home possible for more than 90 million families across the country. Continue your career journey where your work contributes to a greater purpose.\n\nPosition Overview:\n\nThe Enterprise Business Technology Office (BTO) at Freddie Mac enables business operational excellence through the flexible use of technology. The team supports the needs of the enterprise groups, including the chief administrative office, compliance, enterprise risk management, finance, human resources, diversity and outreach, internal audit and legal. In addition to championing and empowering business partners, Enterprise BTO takes steps to improve efficiency and effectiveness across the organization.\n\nOur IT Development Tech Lead position is in the Development Factory Group, which sits in the Enterprise BTO. We are a fast-paced team that interacts with all areas of Freddie Mac\u2019s business, provides solid experience and knowledge across the IT spectrum. Our team is made up of hardworking individuals who thrive in an exciting work environment and enjoy utilizing their problem-solving skills. The role will act as a Lead on database upgrade projects on different platforms, driving end to end implementation in all environments while simultaneously providing technical guidance to project execution team. The position will also ensure adherence to standards and procedures across all platforms and be ready to step outside of his/her comfort zone to troubleshoot software issues. This role will ensure a high level of quality and accuracy in project delivery across all lines.\n\nOur Impact:\n\nThe Development Factory helps provide efficient and rapid delivery for IT scope affecting applications across the enterprise. The Dev Factory model promotes a more collaborative and productive work environment by bringing development, testing and operations together. It is the combination of skills, process, practices, and tools that enhances our ability to deliver services at large scale with high velocity and reliability.\n\nYour Impact:\n\nTechnical Leadership\n\u2022 Lead database upgrade projects from analysis to implementation, owning and overseeing all activities involved for various RDBMS platforms (SAP ASE, Oracle, PostgreSQL, DB2, MSSQL Server, AWS Aurora, etc.)\n\u2022 Be able to provide subject matter expertise in AWS Aurora and at least two of the above technologies.\n\u2022 Drive technical decisions in collaboration with engineering teams, providing insights based on a deep understanding of the architecture and technologies involved.\n\u2022 Lead performance troubleshooting and tuning tasks.\n\u2022 Provide technical leadership and strategic direction for database transformation initiatives from one platform to another.\n\u2022 Document standard operating procedures and platform level checklists for the team to follow and ensure compliance across the board.\n\u2022 Mentor junior team members and provide direction wherever necessary.\n\u2022 Identify areas for continuous improvement and automate tasks, wherever possible.\n\u2022 Ability to multitask and provide DB SME support to a large group of developers and testers, sometimes in parallel.\n\u2022 Provide troubleshooting support for application/database issues involving multiple technologies during development/testing and deployment phases and provide solutions.\n\u2022 Work with TS counterparts and coordinate server/instance and database builds, database refreshes and security implementations.\n\u2022 Employ extensive professional experience and creativity to resolve sophisticated technical problems\n\u2022 Document lessons learned, help maintain knowledge database\n\nTechnology/Business Partnership\n\u2022 Collaboratively work with all other IT Teams to identify \u201cWin/Win\u201d opportunities and improve efficiency\n\u2022 Championing and influencing technology decisions with business partners, IT management and Team members on matters concerning multiple sophisticated projects which requires the ability to negotiate while maintaining effective relationships\n\u2022 Champion current trends in the industry partnering with Engineering and Architecture Services\n\u2022 Driving technical solutions in alignment with architectural roadmaps\n\u2022 Engage with Engineering and other technology partners in the project inception phase to understand environment complexities and define remediation strategy and test strategy\n\nQualifications:\n\u2022 Bachelor's degree in Computer Science or Engineering or equivalent\n\u2022 Production / Application DBA with 10 - 15 years of experience in database administration.\n\u2022 Proficient in multiple RDBMS platforms including SAP ASE (Sybase), Oracle, MSSQL Server, PostgreSQL, DB2 and AWS Aurora.\n\u2022 Hands-on experience with AWS database services (Amazon RDS, Aurora, DMS, SCT).\n\u2022 Understanding of AWS networking, security (IAM, VPC, Security Groups), and storage options.\n\u2022 10+ years of experience in database version upgrades and cross-platform migrations.\n\u2022 Experience migrating from on-prem databases to AWS Aurora\n\u2022 Proficient in different replication technologies/high availability solutions for databases.\n\u2022 Strong UNIX knowledge and proficiency in shell scripts.\n\u2022 Working knowledge of PERL, Python and other similar scripting languages.\n\u2022 Strong troubleshooting and problem-solving skills.\n\u2022 Good understanding of hardware performance, memory and I/O.\n\u2022 Experience with DBMS specific tools for query/explain plans, database advisors, query snapshots, ability to understand them and troubleshoot the problems.\n\u2022 Strong understanding of database interfacing technologies such as ODBC, JDBC and DBMS Native clients.\n\u2022 Working knowledge of Snowflake and data pipelines is a plus.\n\nKeys to Success in this Role:\n\u2022 Good interpersonal, communication, relationship building and team working skills\n\u2022 Proven ability to communicate optimally with various teams, both business and technical, to achieve goals.\n\u2022 Ability to communicate clearly, efficiently, persuasively.\n\u2022 Motivated to learn new technologies and identify process improvements and efficiencies.\n\nWe consider all applicants for all positions without regard to gender, race, color, religion, national origin, age, marital status, veteran status, sexual orientation, gender identity/expression, physical and mental disability, pregnancy, ethnicity, genetic information or any other protected categories under applicable federal, state or local laws. We will ensure that individuals are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.\n\nFreddie Mac offers a comprehensive total rewards package to include competitive compensation and market-leading benefit programs. Information on these benefit programs is available on our Careers site.\n\nThis position has an annualized market-based salary range of $138,000 - $206,000 and is eligible to participate in the annual incentive program. The final salary offered will generally fall within this range and is dependent on various factors including but not limited to the responsibilities of the position, experience, skill set, internal pay equity and other relevant qualifications of the applicant.",
    "url": "https://careers.freddiemac.com/us/en/job/JR16212/Software-Engineer-Tech-Lead?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-08T00:00:00.000Z"
  },
  {
    "title": "Staff Software Engineer - *HYBRID*-(Go, Java, React, Microservices, Kubernetes)",
    "company": "GEICO",
    "location": null,
    "salary": 115000,
    "description": "At GEICO, we offer a rewarding career where your ambitions are met with endless possibilities.\n\nEvery day we honor our iconic brand by offering quality coverage to millions of customers and being there when they need us most. We thrive through relentless innovation to exceed our customers\u2019 expectations while making a real impact for our company through our shared purpose.\n\nWhen you join our company, we want you to feel valued, supported and proud to work here. That\u2019s why we offer The GEICO Pledge: Great Company, Great Culture, Great Rewards and Great Careers.\n\nGEICO is seeking an experienced Staff Engineer to join our team that brings a passion for building high performance, low maintenance, zero-downtime platforms, and applications. You will help drive our insurance business transformation as we transition from a traditional IT model to a tech organization with engineering excellence as its mission, while co-creating the culture of psychological safety and continuous improvement.\n\nIn this role you will collaborate with the Distinguished Engineer and Senior Engineers to innovate and build new systems, improve, and enhance existing systems as well as identify new opportunities to apply your knowledge to solve critical problems. You will lead the strategy and execution of a technical roadmap that will increase the velocity of delivering products and unlock new engineering capabilities.\n\nAs a Staff Engineer, You Will\n\u2022 Focus on multiple areas and provide technical thought leadership to the enterprise\n\u2022 Collaborate with product managers, team members, customers, and other engineering teams to solve our toughest problems\n\u2022 Develop and execute technical software development strategy for the Platform Engineering domain\n\u2022 Be accountable for the quality, usability, and performance of the solutions\n\u2022 Be a role model and mentor, helping to coach and strengthen the technical expertise and know-how of our engineering and product community. Influence and educate executives\n\u2022 Consistently share best practices and improve processes within and across teams\n\u2022 Analyze cost and forecast, incorporating them into business plans\n\u2022 Determine and support resource requirements, evaluate operational processes, measure outcomes to ensure desired results, demonstrate adaptability and sponsor continuous learning\n\u2022 Take on-call and operation support\n\nQualifications\n\u2022 Deep hands-on experience in complex system design, data pipeline and architectures, scalable distributed systems\n\u2022 Fluent in at least one OOP languages such as Java, Go, Python, C++, etc.\n\u2022 Exemplary ability to design, perform experiments, and influence engineering direction and product roadmap\n\u2022 Experience partnering with engineering teams and transferring research to production\n\u2022 Experience with continuous delivery and infrastructure as code\n\u2022 In-depth knowledge of CS data structures and algorithms\n\u2022 Experience solving analytical problems with quantitative approaches\n\u2022 Knowledge of developer tooling across the software development life cycle (task management, source code, building, deployment, test automation and related tools, operations, real-time communication)\n\u2022 Experience with open-source messaging and event streaming platforms with emphasis on building enterprise scale platforms\n\u2022 Experience in CI/CD pipeline and related open-source tools like GIT/Jenkin/CircleCI/SonarQube and knowledge in Terraform/Ansible will be a plus\n\u2022 Knowledge on Open-source monitoring software like Grafana and Prometheus will be a plus\n\u2022 Familiarity with other messaging and event solutions like Azure Service Bus and Azure Event Hub will be a plus\n\nExperience\n\u2022 6+ years of professional experience.\n\u2022 4+ years of experience in open-source frameworks\n\u2022 3+ years of experience with architecture and design\n\u2022 3+ years of experience with AWS, GCP, Azure or similar cloud service preferred\n\nEducation\n\u2022 Bachelor\u2019s degree in Computer Science, Information Systems, or equivalent education or work experience\n\nAnnual Salary\n\n$115,000.00 - $230,000.00\n\nThe above annual salary range is a general guideline. Multiple factors are taken into consideration to arrive at the final hourly rate/ annual salary to be offered to the selected candidate. Factors include, but are not limited to, the scope and responsibilities of the role, the selected candidate\u2019s work experience, education and training, the work location as well as market and business considerations.\n\nAt this time, GEICO will not sponsor a new applicant for employment authorization for this position.\n\nThe GEICO Pledge\n\nGreat Company: At GEICO, we help our customers through life\u2019s twists and turns. Our mission is to protect people when they need it most and we\u2019re constantly evolving to stay ahead of their needs.\n\nWe\u2019re an iconic brand that thrives on innovation, exceeding our customers\u2019 expectations and enabling our collective success. From day one, you\u2019ll take on exciting challenges that help you grow and collaborate with dynamic teams who want to make a positive impact on people\u2019s lives.\n\nGreat Careers: We offer a career where you can learn, grow, and thrive through personalized development programs, created with your career \u2013 and your potential \u2013 in mind. You\u2019ll have access to industry leading training, certification assistance, career mentorship and coaching with supportive leaders at all levels.\n\nGreat Culture: We foster an inclusive culture of shared success, rooted in integrity, a bias for action and a winning mindset. Grounded by our core values, we have an an established culture of caring, inclusion, and belonging, that values different perspectives. Our teams are led by dynamic, multi-faceted teams led by supportive leaders, driven by performance excellence and unified under a shared purpose.\n\nAs part of our culture, we also offer employee engagement and recognition programs that reward the positive impact our work makes on the lives of our customers.\n\nGreat Rewards: We offer compensation and benefits built to enhance your physical well-being, mental and emotional health and financial future.\n\u2022 Comprehensive Total Rewards program that offers personalized coverage tailor-made for you and your family\u2019s overall well-being.\n\u2022 Financial benefits including market-competitive compensation; a 401K savings plan vested from day one that offers a 6% match; performance and recognition-based incentives; and tuition assistance.\n\u2022 Access to additional benefits like mental healthcare as well as fertility and adoption assistance.\n\u2022 Supports flexibility- We provide workplace flexibility as well as our GEICO Flex program, which offers the ability to work from anywhere in the US for up to four weeks per year.\n\nThe equal employment opportunity policy of the GEICO Companies provides for a fair and equal employment opportunity for all associates and job applicants regardless of race, color, religious creed, national origin, ancestry, age, gender, pregnancy, sexual orientation, gender identity, marital status, familial status, disability or genetic information, in compliance with applicable federal, state and local law. GEICO hires and promotes individuals solely on the basis of their qualifications for the job to be filled.\n\nGEICO reasonably accommodates qualified individuals with disabilities to enable them to receive equal employment opportunity and/or perform the essential functions of the job, unless the accommodation would impose an undue hardship to the Company. This applies to all applicants and associates. GEICO also provides a work environment in which each associate is able to be productive and work to the best of their ability. We do not condone or tolerate an atmosphere of intimidation or harassment. We expect and require the cooperation of all associates in maintaining an atmosphere free from discrimination and harassment with mutual respect by and for all associates and applicants.",
    "url": "https://www.linkedin.com/jobs/view/staff-software-engineer-hybrid-go-java-react-microservices-kubernetes-at-geico-4314525559?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Senior Software Engineer - Remote",
    "company": "Halvik",
    "location": "Washington",
    "salary": 95000,
    "description": "Halvik Corp delivers a wide range of services to 13 executive agencies and 15 independent agencies. Halvik is a highly successful WOB business with more than 50 prime contracts and 500+ professionals delivering Digital Services, Advanced Analytics, Artificial Intelligence/Machine Learning, Cyber Security and Cutting-Edge Technology across the US Government. Be a part of something special!\n\nJob Desription\n\nWorking under general supervision, this role collaborates closely with solution architects, system engineers, and platform specialists to design, develop, and enhance data-driven software capabilities. The engineer will contribute to the planning, design, development, and utilization of modern software frameworks, ensuring seamless integration with cloud and enterprise systems.\n\nThe ideal candidate has strong experience with Python, React and TypeScript, cloud-based data engineering environments, and hands-on development in Palantir Foundry (highly preferred). This role requires a mix of front-end development, data engineering, platform integration, and pipeline orchestration.\n\nKey Responsibilities\n\u2022 Working with team mates, conduct requirements analysis and determine end-user technical needs.\n\u2022 Design, develop, test, and deploy software applications using Python, React & TypeScript.\n\u2022 Build, maintain, and troubleshoot complex data pipelines (ETL/ELT) and data workflows.\n\u2022 Collaborate with hardware, data, and cloud engineering teams to optimize system performance.\n\u2022 Develop and integrate applications within Palantir Foundry (ontology, pipelines, operational apps).\n\u2022 Create and manage data models, ontology components, and semantic relationships.\n\u2022 Implement secure and scalable code aligned with cloud architectures (AWS/Azure).\n\u2022 Develop interactive dashboards, UI components, and operational tools.\n\u2022 Integrate ML and AI models into operational environments when required.\n\u2022 Apply DevSecOps best practices, version control, and CI/CD pipeline workflows.\n\u2022 Monitor system performance and ensure data quality, accessibility, and reliability.\n\u2022 Document solution designs, data flows, and implementation details.\n\nRequired Qualifications\n\u2022 Must hold a current Secret Clearance\n\u2022 BA/BS in Computer Science, Engineering, Data Science, Mathematics, or related field OR equivalent experience\n\u2022 5+ years' experience with machine learning, data engineering, or platform-based AI delivery\n\u2022 Strong proficiency with React & TypeScript\n\u2022 Proficient in Python for data and pipeline development\n\u2022 Experience with:\n\u2022 SQL and database technologies\n\u2022 JavaScript/ES6+\n\u2022 PySpark/Spark and large-scale data processing\n\u2022 Cloud platforms (AWS or Azure)\n\u2022 Experience designing and supporting ETL/ELT pipelines and data integration\n\u2022 Front-end UI/UX concepts and component-based design\n\u2022 Data visualization and analytics capabilities\n\nDesired Qualifications\n\u2022 Hands-on experience with Palantir Foundry\n\u2022 Pipeline Builder\n\u2022 Foundry Ontology\n\u2022 Application & workflow development\n\u2022 Ability to build low-code/no-code operational apps in Foundry\n\u2022 Familiarity with containerization (Docker/Kubernetes)\n\u2022 Experience implementing security, access controls, and best practices within enterprise systems\n\u2022 Understanding of ML model deployment and inference workflows\n\nHalvik offers a competitive full benefits package including:\nCompany-supported medical, dental, vision, life, STD, and LTD insurance\nBenefits include 11 federal holidays and PTO\nEligible employees may receive performance-based incentives in recognition of individual and/or team achievements.\n401(k) with company matching\nFlexible Spending Accounts for commuter, medical, and dependent care expenses\nTuition Assistance\nCharitable Contribution matching\n\nHalvik Corp is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status.\n\nHalvik's pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law.",
    "url": "https://www.ziprecruiter.com/c/Halvik/Job/Senior-Software-Engineer-Remote/-in-Washington,DC?jid=10a7305ff73bf1bb&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "System Software Engineer",
    "company": "Robotics Technologies",
    "location": "Reston",
    "salary": "",
    "description": "\u2022 Job ID:\n\nJ50980\n\u2022 Job Title:\n\nSystem Software Engineer\n\u2022 Location:\n\nReston, VA\n\u2022 Duration:\n\n14 Months + Extension\n\u2022 Hourly Rate:\n\nDepending on Experience (DOE)\n\u2022 Work Authorization:\n\nUS Citizen, Green Card, OPT-EAD, CPT, H-1B,\nH4-EAD, L2-EAD, GC-EAD\n\u2022 Client:\n\nTo Be Discussed Later\n\u2022 Employment Type:\n\nW-2, 1099, C2C\n\nKey Responsibilities\n\nBenchmark Creation & Validation\n\u2022 Curate authentic issues, solutions, and test suites from live repositories.\n\u2022 Ensure each task includes complete unit + integration tests for automated verification.\n\nQuality Assurance & Feedback\n\u2022 Provide structured feedback on peer solutions for clarity, robustness, and performance.\n\u2022 Maintain consistency and scalability of benchmark task distribution.\n\nDebugging & Documentation\n\u2022 Debug, optimise, and document benchmark code for reliability and reproducibility.\n\nIdeal Qualifications\n\u2022 3 \u2013 10 years professional frontend engineering experience.\n\u2022 Strong proficiency in React, TypeScript, and modern JavaScript tooling.\n\u2022 Comfortable writing thorough tests (Jest, React Testing Library, Cypress, etc.).\n\u2022 Clear technical writing skills and keen attention to detail.\n\nEqual Opportunity Employer\n\nROBOTICS TECHNOLOGIES LLC is an equal opportunity employer inclusive of female, minority, disability and veterans, (M/F/D/V). Hiring, promotion, transfer, compensation, benefits, discipline, termination and all other employment decisions are made without regard to race, color, religion, sex, sexual orientation, gender identity, age, disability, national origin, citizenship/immigration status, veteran status or any other protected status. ROBOTICS TECHNOLOGIES LLC will not make any posting or employment decision that does not comply with applicable laws relating to labor and employment, equal opportunity, employment eligibility requirements or related matters. Nor will ROBOTICS TECHNOLOGIES LLC require in a posting or otherwise U.S. citizenship or lawful permanent residency in the U.S. as a condition of employment except as necessary to comply with law, regulation, executive order, or federal, state, or local government contract",
    "url": "https://www.indeed.com/viewjob?jk=27751d17d62c4278&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Software Engineer, Lead",
    "company": "Booz Allen Hamilton",
    "location": "Springfield",
    "salary": "",
    "description": "Job Number: R0228182\n\nSoftware Engineer, Lead\n\nThe Opportunity:\n\nAs a full stack developer, you can resolve a problem with a complete end-to-end solution in a fast, agile environment. If you\u2019re looking for the chance to not just develop software, but to create a system that will make a difference, we need you on our team. We\u2019re looking for an experienced developer like you with the skills needed to develop software and systems from vision to production-ready.\n\nThis role is more than just coding. As a full stack developer at Booz Allen, you\u2019ll use your passion to master new tools and techniques and identify needed system improvements. You\u2019ll help clients overcome their most difficult challenges using the latest architectural approaches, tools, and technologies. You\u2019ll make sure the solution developed by the team considers the current architecture and operating environment, as well as future functionality and enhancements. You will be responsible for the design, development, testing, and maintenance of the new software applications modernized for deployment in Cloud environments to migrate existing GETS functionality.\n\nWork with us as we shape systems for the better.\n\nJoin us. The world can\u2019t wait.\n\nYou Have:\n\u2022 8+ years of experience designing, modifying, developing, writing, and implementing software programming applications using agile methods\n\u2022 8+ years of experience in software development with basic programming languages, technologies, tools, or web development stacks\n\u2022 Experience with Agile methodology, extreme programming, software engineering, product management, and software products\n\u2022 Experience writing source code for new applications or generating and enhancing code samples for existing applications\n\u2022 Experience using back-end and front-end languages to develop complete solutions\n\u2022 Experience creating solutions to complex problems within a collaborative, cross-functional team\n\u2022 Experience writing scripts and code to automate and record the results of tests of integration and interoperability between services\n\u2022 Knowledge of the development of test plans and verifying and validating the results of unit tests conducted by other development teams\n\u2022 TS/SCI clearance with a polygraph\n\u2022 Bachelor\u2019s degree and 5+ years of experience in software development, or Master\u2019s degree and 3+ years of experience in software development\n\nNice If You Have:\n\u2022 Experience acquiring client requirements and resolving workflow problems through automation optimization\n\u2022 Experience with Red Hat, Windows Server, Oracle, JMeter, Jenkins, Swagger, Nexus, Apigee, GitHub, GitLab, or equivalent software packages\n\u2022 Experience with programming and scripting languages such as Java, Bash, Curl, XML, JSON, SQL, or JavaScript, and C2S and data center operations\n\u2022 Experience with Amazon Web Services (AWS)\n\u2022 Knowledge of software accreditation and security procedures\n\u2022 Ability to work with automated testing tools to perform testing and maintenance\n\nClearance:\n\nApplicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required.\n\nCompensation\n\nAt Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.\n\nSalary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $86,800.00 to $198,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees. This posting will close within 90 days from the Posting Date.\n\nIdentity Statement\n\nAs part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.\n\nWork Model\n\nOur people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.\n\u2022 If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility.\n\u2022 If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role.\n\nCommitment to Non-Discrimination\n\nAll qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law.",
    "url": "https://www.linkedin.com/jobs/view/software-engineer-lead-at-booz-allen-hamilton-4320966679?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Software Engineer, Senior",
    "company": "Freddie Mac",
    "location": "McLean",
    "salary": "",
    "description": "At Freddie Mac, our mission of Making Home Possible is what motivates us, and it\u2019s at the core of everything we do. Since our charter in 1970, we have made home possible for more than 90 million families across the country. Continue your career journey where your work contributes to a greater purpose.\n\nPosition Overview:\n\nAre you looking for development beyond the ordinary? A place full of exciting challenges and the engineers up to solving them? If so, welcome to Financial Engineering. This is the place where the models become software and where many of the numbers that drive our business decisions are produced.\n\nFreddie Mac\u2019s Investments & Capital Markets Division is currently seeking Financial Software Developer to participate in implementing all of the firm\u2019s quantitative models and analytics.\n\nApply and learn why there's #MoreatFreddieMac!\n\nOur Impact:\n\nThe Investments and Capital Markets (I&CM) division is responsible for management of the retained portfolio as well as Freddie Mac's debt funding, liquidity management and interest-rate hedging. The division is also responsible for I&CM securitization.\n\nYour Impact:\n\u2022 Will combine software development, quantitative analysis, and collaboration skills to help build high-performance, scalable and fault tolerant solutions.\n\u2022 Will encourage a creative and analytical mindset\n\u2022 Design and develop high-performance financial libraries using C++, Java, and Python. Adhere to best practices in coding, testing, and software architecture to build modular and maintainable code.\n\u2022 Implement complex financial models with a focus on accuracy and efficiency.\n\u2022 Perform model tie out, regression, and integration testing to ensure software quality. Develop automated testing scripts in Python to adhere to technological development standards.\n\u2022 Write and maintain technical documentation and guidelines to facilitate smooth implementation.\n\u2022 Troubleshoot and resolve integration issues in a timely manner.\n\u2022 Work closely with end-users to understand their needs and enhance library functionality accordingly.\n\u2022 Work closely with cross-functional teams to align development efforts with business objectives.\n\u2022 Collaborate with application teams to integrate financial libraries into existing systems and workflows.\n\u2022 Assist in defining project scope, objectives, and deliverables in collaboration with stakeholders.\n\u2022 Provide guidance and support to junior developers, helping them to enhance their technical skills and professional growth.\n\u2022 Conduct code reviews and offer constructive feedback to improve code quality and efficiency.\n\u2022 Facilitate knowledge sharing sessions and workshops to introduce new technologies and methodologies.\n\nQualifications:\n\u2022 BS in Computer Science, Information Systems or other related field or equivalent working experience; advanced degree preferred\n\u2022 Typically, 5 - 7 years of Programming experience of developing and testing with C++ and Python\n\u2022 Financial knowledge, preferably some fixed Income knowledge, with solid quantitative skills (statistics, econometrics, algebra)\n\nKeys to Success in this Role:\n\u2022 Hands on with programming and troubleshooting\n\u2022 Solid math and analytical skills\n\u2022 Interest in growing financial knowledge\n\u2022 Collaborative working approach\n\u2022 Ability to communicate effective with modelers, analysts, and developers\n\nWe consider all applicants for all positions without regard to gender, race, color, religion, national origin, age, marital status, veteran status, sexual orientation, gender identity/expression, physical and mental disability, pregnancy, ethnicity, genetic information or any other protected categories under applicable federal, state or local laws. We will ensure that individuals are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.\n\nFreddie Mac offers a comprehensive total rewards package to include competitive compensation and market-leading benefit programs. Information on these benefit programs is available on our Careers site.\n\nThis position has an annualized market-based salary range of $130,000 - $196,000 and is eligible to participate in the annual incentive program. The final salary offered will generally fall within this range and is dependent on various factors including but not limited to the responsibilities of the position, experience, skill set, internal pay equity and other relevant qualifications of the applicant.",
    "url": "https://careers.freddiemac.com/us/en/job/JR16158/Software-Engineer-Senior?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Full Stack Java Developer, Mid with Security Clearance",
    "company": "RMantra Solutions",
    "location": "Ashburn",
    "salary": "",
    "description": "Full Stack Java Developer, Mid\n\u2022 US Citizens ONLY\n\u2022 Clearance: DoD TS or DHS Full BI\n\u2022 Work schedule: Hybrid * **This position REQUIRES onsite support in Ashburn, VA, 2 times a week**\n\u2022 Work Location: Ashburn, VA The position is focused on delivering performance-based IT services and repeatable solutions. Our team is looking for a developer that can support applications in a cloud-based, large-scale enterprise environment with the goal of learning new technologies to optimize efficiency and improve performance. As such, this individual must be able to manage assigned tasks and solve technical problems and be able to work well individually and in small to medium-sized teams. The development role will be one of many within a team of 10+ people, and close interactions with other agile delivery teams across PSPD, CBP, and external applications will be necessary for success. **This position REQUIRES the candidate to be in Ashburn, VA, twice a week** Primary Responsibilities\n\u2022 Learn and support the implementation of workflow and rules technology integration across multiple applications\n\u2022 Provide assistance and support for less experienced team members\n\u2022 Track assigned tasks to completion within a team of 10+ developers.\n\u2022 Identify and resolve technical issues that arise\n\u2022 Work independently\n\u2022 Employ ingenuity and creativity to develop new technical solutions and systems to achieve functional objectives\n\u2022 Communicate with internal team members across multiple areas and client team members.\n\u2022 Research, evaluate, and stay current on emerging tools, techniques, and technologies including cloud services Basic Qualifications\n\u2022 BA/BS with 8+ years of relevant experience or 6+ years of relevant experience with Master's Degree: OR 9 years of experience in lieu of degree\n\u2022 Must be able to maintain and obtain a CBP Background Investigation prior to start\n\u2022 Experience evaluating business needs, refining requirements to identify appropriate solutions, and ability to resolve difficult issues\n\u2022 Experience with agile-based implementations\n\u2022 Strong communication skills with ability to interact effectively across multiple teams Preferred Qualifications\n\u2022 Knowledge of workflows and rules engines\n\u2022 Experience in Java\n\u2022 Experience working with PostgreSQL and AWS\n\u2022 Knowledge of Test-Driven Development (TDD)/Behavioral-Driven Development (BDD)\n\u2022 Experience applying a continuous integration/deployment approach to project or program delivery\n\u2022 Familiarity with AI concepts and code assistance tools\n\u2022 Experience in the following tools and/or technologies:\n\u2022 JDK 21 and above (strongly preferred)\n\u2022 Python, JavaScript\n\u2022 Redis/Memcached/Elasticache\n\u2022 WebServices including REST interfaces development\n\u2022 Messaging solutions including Kafka, ActiveMQ, SQS, SNS If you want to apply, please send an email to",
    "url": "https://www.linkedin.com/jobs/view/full-stack-java-developer-mid-with-security-clearance-at-rmantra-solutions-4335093036?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-08T00:00:00.000Z"
  },
  {
    "title": "Software Developer",
    "company": "KBR",
    "location": "Springfield",
    "salary": "",
    "description": "Title:\nSoftware Developer\n\nBelong. Connect. Grow. with KBR!\n\nKBR\u2019s National Security Solutions team provides high-end engineering and advanced technology solutions to our customers in the intelligence and national security communities. In this position, your work will have a profound impact on the country\u2019s most critical role \u2013 protecting our national security.\n\nWhy Join Us?\n\u2022 Innovative Projects: KBR\u2019s work is at the forefront of engineering, logistics, operations, science, program management, mission IT and cybersecurity solutions.\n\u2022 Collaborative Environment: Be part of a dynamic team that thrives on collaboration and innovation, fostering a supportive and intellectually stimulating workplace.\n\u2022 Impactful Work: Your contributions will be pivotal in designing and optimizing defense systems that ensure national security and shape the future of space defense.\n\nThis is a contingent position based upon contract award.\n\nKBR is seeking a mid-level Software Developers to support government customers in Springfield, VA. The Software Developer provides software development and technical expertise to support and enable a test and evaluation program\u2019s modernization goals. The software engineer will work closely with the scientists and engineers in the image quality domain to identify manual and analytic tasks for automation. Through market research and Analysis of Alternatives (AoA), the Software Developer will propose new epics or additions to existing epics to accomplish automation goals. Task automation services will include code and script generation, code testing, support to code security accreditation, and documenting. In support of the DevOps environment, this role will support decomposing existing business process and test tool capabilities into micro-services capable of deployment through a DevOps infrastructure. Additionally, this role will provide the expertise to effectively analyze the output of DevOps tools and assist the customer in incorporating the results into overall assessments.\n\nResponsibilities:\n\u2022 Conduct engineering analysis to identify all tasks (both manual and analytic) associated with assessment of system capabilities and interfaces, sensor parameters or functions, or GEOINT services.\n\u2022 Conduct engineering analysis to identify candidate tasks for automation.\n\u2022 Conduct market research to identify automation technologies available on the commercial market that align with mission needs.\n\u2022 Automate selected tasks through code/script generation, or by identifying existing in-house or commercially available solutions (including open-source alternatives); identify opportunities to consolidate tasks or processes to maximize efficiency or minimize cost.\n\u2022 Developed tools shall support objectives such as: functionality testing, step automation, continuous integration automation, automated system monitoring, load testing, service virtualization, performance profiling, etc.\n\u2022 Implement accepted automation solutions in the DevTest environment or internal test environment as directed.\n\u2022 Design and develop automation scripts, tools, or applications, and appropriate test scenarios to verify the performance, capacity, and scalability of services and capabilities.\n\u2022 Provide expertise to analyze output of automated test tools, scripts, applications, and processes to evaluate against established criteria and develop a recommendation to the government and product vendor.\n\u2022 Provide expert level support of test automation capable of creating and running scripts within government furnished automation and testing tools (e.g. HP ALM, CA Service virtualization, etc.) development.\n\u2022 Provide web application design, development, and maintenance\n\u2022 for test related web, and tools projects\n\u2022 for Intelligence Community (IC) Common Operating Environment (COE) Test Environment (IC CTE)-related web and tools projects.\n\u2022 Provide support and expertise to develop custom product quality assessment tools for the full range of traditional and non-traditional imaging systems, products, and data formats.\n\u2022 Collaborate with image quality engineers and image scientists to develop custom product quality assessment tools, as well as to understand and support existing in-house developed engineering tools/code written in Matlab, IDL, Python, Visual Basic, etc.; provide updates and improvements to these tools as needed.\n\u2022 Provide technical support and expertise to use, update, and maintain the existing in-house developed image quality test tools and future development.\n\u2022 Provide management, test tool development and technical support to the customers mission support tools.\n\u2022 Analyze performance trends and user experience data to identify parameters for automated governance processes that will facilitate a digital/automated Go/No Go capability.\n\u2022 Develop, implement, and maintain an automated governance process in a variety of environments including: bare metal, DevOps, and cloud computing environments.\n\nRequired Education, Experience, & Skills:\n\u2022 Bachelor's degree in Computer Science, Computer Engineering, Information Science, Data Science, or other related field.\n\u2022 4 - 7 years of software development experience using one or more object-oriented programming languages such as C++ or Java\n\u2022 Scripting Python, SQL, or similar\n\u2022 Strong verbal and written communications skills are required, as well as the ability to maintain professionalism in a diverse customer environment\n\u2022 Database Administration\n\u2022 ActiveMQ\n\u2022 HTTPD and website maintenance\n\u2022 PKI management and user authentication\n\u2022 Experience with agile development\n\nSecurity Clearance Requirements: Active TS/SCI with Poly\n\nBelong, Connect and Grow at KBR\n\nAt KBR, we are passionate about our people and our Zero Harm culture. These inform all that we do and are at the heart of our commitment to, and ongoing journey toward being a People First company. That commitment is central to our team of team\u2019s philosophy and fosters an environment where everyone can Belong, Connect and Grow. We Deliver \u2013 Together.\n\nKBR is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, disability, sex, sexual orientation, gender identity or expression, age, national origin, veteran status, genetic information, union status and/or beliefs, or any other characteristic protected by federal, state, or local law.",
    "url": "https://careers.kbr.com/us/en/job/R2098969/Software-Developer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-03T00:00:00.000Z"
  },
  {
    "title": "Staff Software Engineer L6 (Frontend)",
    "company": "Inovalon",
    "location": "Bowie",
    "salary": 165000,
    "description": "Inovalon was founded in 1998 on the belief that technology, and data specifically, would empower the transformation of the entire healthcare ecosystem for the better, improving both outcomes and economics. At Inovalon, we believe that when our customers are successful in their missions, healthcare improves. Therefore, we focus on empowering them with data-driven solutions. And the momentum is building.\n\nTogether, as ONE Inovalon, we are a united force delivering solutions that address healthcare\u2019s greatest needs. Through our mission-based culture of inclusion and innovation, our organization brings value not just to our customers, but to the millions of patients and members they serve.\n\nOverview:\u202fWe are seeking a Staff Software Development Engineer to lead the design and development of a customer-facing healthcare application that empowers health plans and providers to deliver better patient care and improved healthcare outcomes. This is a high-impact role requiring deep frontend/backend expertise, distributed systems design, and hands-on development skills within a cloud-native, microservices-based environment. This position brings subject matter expertise as a functional lead and is tasked with ensuring a high level of discipline and productivity\n\nYou will work on mission-critical systems that manage sensitive health data, contribute to architectural decisions, and mentor engineers across teams. Your work will directly influence the quality and scalability of our platform used by thousands of healthcare professionals.\n\nDuties and Responsibilities:\n\u2022 Design, build and maintain scalable data pipelines and access patterns related to healthcare.\n\u2022 Research, evaluate and utilize new technologies/tools/frameworks centered around high-volume data processing in AWS.\n\u2022 Document and estimate technical scope and design as needed.\n\u2022 Design and implement distributed data processing pipelines using tools and languages prevalent in the big data ecosystem.\n\u2022 Involve and drive a culture of collaborative reviews of designs, code and test plans.\n\u2022 Work with business stakeholders and architecture engineering leads to ensure quality solutions are implemented and engineering standard methodologies adhered to.\n\u2022 DevOps Focus \u2013 Utilize and advance continuous integration and deployment frameworks.\n\u2022 Provide\u202fstrong technical leadership, raise the technical bar,\u202fmaintain\u202fdata and\u202fresults-driven\u202fculture, nurture a team culture of high collaboration and trust.\n\u2022 Influence and coach junior engineers both within and outside of your team; be a role model for\u202fan open, honest, and inclusive approach to problem\u202fsolving.\n\u2022 Adhere to all confidentiality, HIPAA, regulatory, and other such policies, procedures, and requirements as outlined within Employer\u2019s Operating Policies and Procedures in all ways and at all times with respect to any aspect of the data handled or services rendered in the scope of work; and\n\u2022 Maintain compliance with Inovalon\u2019s policies, procedures and mission statements, and fulfill those responsibilities and/or duties that may be reasonably provided by Inovalon for the purpose of achieving operational and financial success.\n\nRequired Qualifications:\n\u2022 10+ years of experience in software development & architecture\n\u2022 Minimum 5 years of experience in front-end architecture and UI leadership.\n\u2022 Strong hands-on expertise with\n\u2022 .NET Core/ C#\n\u2022 Angular or React\n\u2022 Microservices, Rest API\u2019s, Event driven architecture\n\u2022 Cloud Platforms: AWS (Preferred), GCP, Azure\n\u2022 PostgreSQL/SQL Server/ Dynamo DB\n\u2022 Proficient in architecture patterns: layered, clean architecture, etc.\n\u2022 Proactively identifies UI/UX improvements or performance bottlenecks\n\u2022 Excellent Verbal & written communication skills\n\u2022 Strong problem-solving, debugging & Performance tuning skills\n\nPreferred Qualifications:\n\u2022 Experience working with distributed teams and global delivery models. Experience leading, mentoring and coaching technology teams.\n\u2022 Prior experience working in healthcare or health-tech environments.\n\u2022 Familiarity with FHIR, HL7, or healthcare-specific data standards.\n\u2022 Active contributor to open-source projects or internal technical communities.\n\nEducation:\n\u2022 Bachelor's degree in computer science, Software Engineering, or Information Technology\n\nPhysical Demands and Work Environment:\n\u2022 Sedentary work (i.e., sitting for long periods of time).\n\u2022 Subject to inside environmental conditions.\n\u2022 Travel for this position will include less than 10% locally, usually for training purposes.\n\nInovalon Offers a Competitive Salary And Benefits Package\n\nIn addition to the base compensation, this position may be eligible for performance-based incentives.\n\nThe actual base pay offered may vary depending on multiple factors including, but not limited to, job-related knowledge/skills, experience, business needs, geographical location, and internal equity. At Inovalon, it is not typical for an individual to be hired at or near the top end of the range for their role, and compensation decisions are dependent upon the facts and circumstances of each position and candidate.\n\nInovalon invests in associates to help them stay healthy, save for long-term financial goals, and manage the demands of work and personal commitments. That\u2019s why Inovalon offers a valuable benefits package with a wide range of choices to meet associate needs, which may include health insurance, life insurance, company-paid disability, 401k, 18+ days of paid time off, and more.\n\nBase Compensation Range\n\n$165,000\u2014$220,000 USD\n\nThis position is not eligible for immigration sponsorship (e.g. H-1B, TN, or E-3). Applicants must be authorized to work in the United States as a condition of employment. (This is only applicable for US-based positions)\n\nIf you don\u2019t meet every qualification listed but are excited about our mission and the work described, we encourage you to apply. Inovalon is most interested in finding the best candidate for the job, and you may be just the right person for this or other roles.\n\nBy embracing inclusion, we enhance our work environment and drive business success. Inovalon strives to provide equal opportunities to the communities where we operate and to our clients and everyone whom we serve. We endeavor to create a culture of inclusion in which our associates feel empowered to bring their full, authentic selves to work and pursue their professional goals in an equitable setting. We understand that by fostering this type of culture, and welcoming different perspectives, we generate innovation and growth.\n\nInovalon is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirement.\n\nTo review the legal requirements, including all labor law posters, please visit this link\n\nTo review the California Consumer Privacy Statement: Disclosures for California Residents, please visit this link",
    "url": "https://www.linkedin.com/jobs/view/staff-software-engineer-l6-frontend-at-inovalon-4337904121?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Software Engineer I",
    "company": "CoStar Group",
    "location": "Arlington",
    "salary": "",
    "description": "Overview\n\nJob Description\n\nCoStar Group (NASDAQ: CSGP) is a leading global provider of commercial and residential real estate information, analytics, and online marketplaces. Included in the S&P 500 Index and the NASDAQ 100, CoStar Group is on a mission to digitize the world\u2019s real estate, empowering all people to discover properties, insights and connections that improve their businesses and lives.\n\nWe have been living and breathing the world of real estate information and online marketplaces for over 35 years, giving us the perspective to create truly unique and valuable offerings to our customers. We\u2019ve continually refined, transformed and perfected our approach to our business, creating a language that has become standard in our industry, for our customers, and even our competitors. We continue that effort today and are always working to improve and drive innovation. This is how we deliver for our customers, our employees, and investors. By equipping the brightest minds with the best resources available, we provide an invaluable edge in real estate.\n\nYou will be joining our finance tech team, responsible for enabling the payment processing functionality of our business.\n\nYou will work on systems that power the user experience for our consumers and internal associates that power all our company channels and organizations, including Homes.com, Costar.com, Apartments.com, LoopNet.com and more. You\u2019ll be solving more than just 1-off problems, but larger scale systems that are highly dynamic and are built for growth.\n\nThis position is in Arlington and is in office Monday through Thursday and work from home on Friday.\n\nResponsibilities\n\u2022 Develop and maintain engaging, responsive, and high-performance web applications using React, TypeScript, and Tailwind CSS.\n\u2022 Build reusable, scalable, and secure UI components and libraries with a focus on maintainability and performance.\n\u2022 Collaborate with cross-functional teams, including designers, backend developers, and product managers to transform business needs into technical solutions.\n\u2022 Contribute to and maintain shared component libraries and front-end architecture.\n\u2022 Build microservices and RESTful APIs to move complex data across domains.\n\u2022 Drive and lead software design by developing standards and performing code reviews, resulting in a robust, efficient, and maintainable code base.\n\u2022 Continually evaluate emerging technologies to identify opportunities, trends, and best practices that can be leveraged to strengthen CoStar\u2019s technology platform and develop practices.\n\u2022 Mentor other engineers, working together with shared goals and an open mindset to learn.\n\u2022 Develop comprehensive application testing procedures to ensure high-quality applications for tens of thousands of users.\n\nBasic Qualifications\n\u2022 Bachelor\u2019s Degree required from an accredited, not for profit, in person university or college.\n\u2022 3+ years of software development experience\n\u2022 A track record of commitment to prior employers\n\u2022 Demonstrated experience in architecting, designing and building large scale distributed, services-oriented systems and web applications in an agile environment\n\u2022 Experience developing frontend applications using React and Node with TypeScript\n\u2022 Experience building RESTful APIs using strongly typed languages\n\u2022 Strong grasp of web standards, accessibility, and security best practices.\n\u2022 Proficient understanding of source control tools such as Git.\n\u2022 Familiarity with CI/CD deployment processes\n\nPreferred Qualifications And Skills\n\u2022 Experience with SQL and databases\n\u2022 Experience with Elasticsearch or OpenSearch\n\u2022 Application experience with C#/NodeJS\n\u2022 Familiarity with observability tools like Kibana, Data Dog and other monitoring frameworks\n\u2022 Strong communication skills (to both business and technical partners)\n\u2022 Data modeling experience from conceptual, logical and physical designs\n\u2022 Cloud computing experience with providers like, AWS, Azure or GCP\n\nWhat\u2019s In It For You\n\nWhen you join CoStar Group, you\u2019ll experience a collaborative and innovative culture working alongside the best and brightest to empower our people and customers to succeed.\n\nWe offer you generous compensation and performance-based incentives. CoStar Group also invests in your professional and academic growth with internal training, and tuition reimbursement.\n\nOur Benefits Package Includes (but Is Not Limited To)\n\u2022 Comprehensive healthcare coverage: Medical / Vision / Dental / Prescription Drug\n\u2022 Life, legal, and supplementary insurance\n\u2022 Virtual and in person mental health counseling services for individuals and family\n\u2022 Commuter and parking benefits\n\u2022 401(K) retirement plan with matching contributions\n\u2022 Employee stock purchase plan\n\u2022 Paid time off\n\u2022 Tuition reimbursement\n\u2022 On-site fitness center and/or reimbursed fitness center membership costs (location dependent), with yoga studio, Pelotons, personal training, group exercise classes\n\u2022 Access to CoStar Group\u2019s Diversity, Equity, & Inclusion Employee Resource Groups\n\u2022 Complimentary gourmet coffee, tea, hot chocolate, fresh fruit, and other healthy snacks\n\nWe welcome all qualified candidates who are currently eligible to work full-time in the United States to apply. However, please note that CoStar Group is not able to provide visa sponsorship for this position.\n\nCoStar Group is an Equal Employment Opportunity Employer; we maintain a drug-free workplace and perform pre-employment substance abuse testing",
    "url": "https://www.linkedin.com/jobs/view/software-engineer-i-at-costar-group-4334870165?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-07T20:00:00.000Z"
  },
  {
    "title": "Software Engineer 2 with Security Clearance",
    "company": "ClearanceJobs",
    "location": "Capitol Heights",
    "salary": 185000,
    "description": "Looking to FAST-track your career at RealmOne? RealmOne was built on the principle that people matter first and foremost. We believe in providing a strong work/life balance by investing in our employees and encouraging professional and personal growth. We do this by offering exceptional benefits, flexible schedules, and the tools necessary to achieve success through paid training, mentoring, and the opportunity to work alongside top-notch industry professionals. Join us on this journey as we execute this mission-critical contract providing support for data analytics and DevOps engineering! Your effort and expertise are crucial to the success and execution of this impactful mission. This opportunity supports a team of Software Engineers, System Administrators, and Systems Engineers, providing support across a range of mission-critical functions. Job Description:\n\u2022 The Software Engineer develops, maintains, and enhances complex and diverse software systems (e.g., processing-intensive analytics, novel algorithm development, manipulation of extremely large data sets, real-time systems, and business management information systems) based upon documented requirements. Works individually or as part of a team. Reviews and tests software components for adherence to the design requirements and documents test results. Resolves software problem reports. Utilizes software development and software design methodologies appropriate to the development environment. Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new development, and requirements analysis and synthesis from system level to individual software components. The Level 2 Software Engineer shall possess the following capabilities:\n\u2022 Analyze user requirements to derive software design and performance requirements.\n\u2022 Design and code new software or modify existing software to add new features.\n\u2022 Debug existing software and correct defects.\n\u2022 Integrate existing software into new or modified systems or operating environments.\n\u2022 Develop simple data queries for existing or proposed databases or data repositories.\n\u2022 Provide recommendations for improving documentation and software development process standards.\n\u2022 Develop or implement algorithms to meet or exceed system performance and functional standards.\n\u2022 Assist with developing and executing test procedures for software components.\n\u2022 Write or review software and system documentation.\n\u2022 Develop software solutions by analyzing system performance standards, confer with users or system engineers; analyze systems flow, data usage and work processes; and investigate problem areas.\n\u2022 Serve as team lead at the level appropriate to the software development process being used on any particular project.\n\u2022 Modify existing software to correct errors, to adapt to new hardware, or to improve its performance.\n\u2022 Design, develop and modify software systems, using scientific analysis and mathematical models to predict and measure outcome and consequences of design.\n\u2022 Design or implement complex database or data repository interfaces/queries.\n\u2022 Oversee one or more software development teams and ensure the work is completed in accordance with the constraints of the software development process being used on any particular project.\n\u2022 Design or implement complex algorithms requiring adherence to strict timing, system resource, or interface constraints; Perform quality control on team products.\n\u2022 Confer with system engineers and hardware engineers to derive software requirements and to obtain information on project limitations and capabilities, performance requirements and interfaces.\n\u2022 Coordinate software system installation and monitor equipment functioning to ensure operational specifications are met.\n\u2022 Implement recommendations for improving documentation and software development process standards. Qualifications:\n\u2022 Fourteen (14) years' experience as a SWE, in programs and contracts of similar scope, type, and complexity is required.\n\u2022 Bachelor's degree in computer science or related discipline from an accredited college or university is required. Four (4) years of additional SWE experience on projects with similar software processes may be substituted for a bachelor's degree. Position requires active Security Clearance with appropriate Polygraph Pay Range: 185,000-235,000 The RealmOne pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Our approach to crafting offers considers various factors to establish an equitable and competitive compensation package. These considerations include, but are not limited to, the extent and intricacy of the role's responsibilities, the candidate's educational background, their work experience, and the specific competencies crucial for success in the role. RealmOne Benefits:\n\u2022 Healthcare Coverage + Insurance: Medical: Three (3) rich healthcare options through CareFirst with 100% or majority company-paid premiums. Tax-advantaged health savings account available with generous employer contribution. Dental + Vision: 100% employer-paid for employees and family, with a buy-up option available.\n\u2022 Retirement + Savings: 401K\n\u2022 10% TOTAL CONTRIBUTION\n\u2022 5% safe harbor\n\u2022 5% annual profit share (both immediately vested!).\n\u2022 Paid Time Off + More: 4 weeks starting PTO\n\u2022 11 federal holidays + 2 floating holidays\n\u2022 Paid hours for company-required training.\n\u2022 Career Growth + Development: Access to FREE 24/7 learning via Udemy\n\u2022 Opportunities to participate in tech councils, industry initiatives, etc. - $7,500 annual Educational & Professional Development Assistance.\n\u2022 MORE BENEFITS...FOR EVERY LIFESTYLE!\n\u2022 Paid parental leave\n\u2022 Adoption assistance\n\u2022 Annual swag drops\n\u2022 Flexible work schedules -Generous referral bonus program\n\u2022 Employee appreciation + family-friendly corporate events ...and much more. ABOUT US\n\u2022 RealmOne is a mid-sized science and technology company dedicated to solving our customers' toughest mission challenges.\n\u2022 Headquartered in Columbia, MD., RealmOne supplies advanced cybersecurity, data science, and software engineering services and products to customers in the Government and commercial sectors.\n\u2022 RealmOne delivers encompassing mission assurance and critical systems support to government customers across various U.S. locations to include Colorado, Georgia, Hawaii, Texas, Utah, and Virginia.\n\u2022 RealmOne has won numerous awards, including Top Workplaces by the Baltimore Sun. Across more than 20 prime contracts, RealmOne is a premier innovator for the Government and Department of Defense, and our team is located across the United States.",
    "url": "https://www.linkedin.com/jobs/view/software-engineer-2-with-security-clearance-at-clearancejobs-4338025834?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-07T20:00:00.000Z"
  },
  {
    "title": "Junior Embedded Software Engineer",
    "company": "Two Six Technologies",
    "location": "Arlington",
    "salary": 85976,
    "description": "At Two Six Technologies, we build, deploy, and implement innovative products that solve the world\u2019s most complex challenges today. Through unrivaled collaboration and unwavering trust, we push the boundaries of what\u2019s possible to empower our team and support our customers in building a safer global future.\n\nOverview Of Opportunity\n\nTwo Six Technologies is looking for a Junior Embedded Software Engineer to join our team in Arlington, Virginia. The team is composed of intellectual individuals, passionate about embedded cybersecurity research. The team is growing and looking for someone with a low-level software development background who understands how to transition proofs-of-concept into operational capabilities to support national security missions. The team wants to talk to you if you actively perform in-depth embedded software engineering!\n\nResponsibilities Include\n\u2022 Maturing proof-of-concept R&D technology to operational fieldable solutions\n\u2022 Build test automation using Gitlab to leverage range deployments and solution evaluation\n\u2022 Developing APIs and other interfaces bridging the software/hardware technology overlap\n\u2022 Support of scalable and modular design methodology\n\u2022 Engaging in technical exchanges with transition partners and key stakeholders\n\nMinimum Qualifications\n\u2022 Bachelor\u2019s degree in Computer Science, Computer/Electrical Engineering, or related Scientific Domain\n\u2022 Minimum of 1 years of experience with one or more of the following modern development languages: Python, C , C++, Embedded C\n\u2022 Minimum of 1 years experience with Operating Systems internals (privilege and user groups, binary memory layout) and Trusted Execution Environments such as ARM TrustZone\n\u2022 Ability to work on-site at Arlington, VA headquarters\n\nNice To Haves\n\u2022 Basic understanding of memory management concepts (Heap, Stack, Virtual Memory, MMU, Physical vs. Virtual)\n\u2022 Experience with testing, CI/CD pipelines, and virtual machine test ranges\n\u2022 Experience with firmware/driver development across Linux and/or Windows Operating Systems\n\u2022 Graduate degree in Computer Science, Computer/Electrical Engineering, or related Scientific Domain\n\nSecurity Clearance\n\u2022 Active Secret clearance and must be eligible and willing to obtain and maintain a TS/SCI clearance\n\nTwo Six Technologies is committed to providing competitive and comprehensive compensation packages that reflect the value we place on our employees and their contributions. We believe in rewarding skills, experience, and performance. Our offerings include but are not limited to, medical, dental, and vision insurance, life and disability insurance, retirement benefits, paid leave, tuition assistance and professional development.\n\nThe projected salary range listed for this position is annualized. This is a general guideline and not a guarantee of salary. Salary is one component of our total compensation package and the specific salary offered is determined by various factors, including, but not limited to education, experience, knowledge, skills, geographic location, as well as contract specific affordability and organizational requirements.\n\nSalary Range\n\n$85,976\u2014$128,964 USD\n\nLooking for other great opportunities? Check out Two Six Technologies Opportunities for all our Company\u2019s current openings!\n\nReady to make the first move towards growing your career? If so, check out the Two Six Technologies Candidate Journey! This will give you step-by-step directions on applying, what to expect during the application process, information about our rich benefits and perks along with our most frequently asked questions. If you are undecided and would like to learn more about us and how we are contributing to essential missions, check out our Two Six Technologies News page! We share information about the tech world around us and how we are making an impact! Still have questions, no worries! You can reach us at Contact Two Six Technologies. We are happy to connect and cover the information needed to assist you in reaching your next career milestone.\n\nTwo Six Technologies is an Equal Opportunity Employer and does not discriminate in employment opportunities or practices based on race (including traits historically associated with race, such as hair texture, hair type and protective hair styles (e.g., braids, twists, locs and twists)), color, religion, national origin, sex (including pregnancy, childbirth or related medical conditions and lactation), sexual orientation, gender identity or expression, age (40 and over), marital status, disability, genetic information, and protected veteran status or any other characteristic protected by applicable federal, state, or local law.\n\nIf you are an individual with a disability and would like to request reasonable workplace accommodation for any part of our employment process, please send an email to accommodations@twosixtech.com. Information provided will be kept confidential and used only to the extent required to provide needed reasonable accommodations.\n\nAdditionally, please be advised that this business uses E-Verify in its hiring practices.\n\nBy submitting the following application, I hereby certify that to the best of my knowledge, the information provided is true and accurate.",
    "url": "https://www.linkedin.com/jobs/view/junior-embedded-software-engineer-at-two-six-technologies-4334857363?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-07T18:00:00.000Z"
  },
  {
    "title": "Senior Software Developer - Frontend, Backend, Stack, or Mobile",
    "company": "Walmart",
    "location": "Washington",
    "salary": 108000,
    "description": "Position Summary...\n\nWhat you'll do... As a part of Walmart Global Tech, you\u2019ll build industry defining reusable customer and partner facing services and products to lead differentiated experiences and revenue. You will be in the unique position to be of service to both our customers (1P as well as 3P) and our associates as a member of this organization supporting all segments of Walmart. If you are the type of person who feels a personal stake in everything that you work on, has a love for data, enjoys solving complex problems, has a passion for privacy, knows how to foster strong relationships and build trust, and works for the success of the entire team.\n\nAbout Team:\nOur team works closely with our US stores and eCommerce business to better serve customers by empowering team members, stores, and merchants with technological innovation. From groceries and entertainment to sporting goods and crafts, Walmart U.S. offers an extensive selection that our customers value, whether they shop online at Walmart.com, through one of our mobile apps, or in-store. Focus areas include customers, stores and employees, in-store service, merchant tools, merchant data science, and search and personalization.\n\nWhat you'll do:\n\u2022 Design, build, and maintain high-performance front-end applications for our 1P and 3P customers.\n\u2022 Develop robust, maintainable, reusable code for managing functionality, configuration, deployment, monitoring, performance, scalability, availability, security, and alerting for software test, integration, and production environments.\n\u2022 Plan and implement a series of steps which potentially includes reconfiguration, integration, removal, or addition of application components to enhance the application's functionality, resiliency, usability, and security.\n\u2022 Understand the Business/Stakeholder/Technical requirements and assist in analyzing the existing solutions to address the needs. Assist in creation of simple, modular, extensible functional design for the product/solution in adherence to the requirements.\n\u2022 Assess gaps/ updates/ modifications between the customer/business expectations and the existing product/solutions.\n\u2022 Analyze defects from past projects/solutions to avoid recurrence of similar defects.\n\u2022 Analyze system performance impacting the complete product for non-functional requirements like reliability, operability, performance efficiency and security. Troubleshoot performance and availability bottlenecks for the application.\n\u2022 Develop, maintain, and enhance automated test cases (adopting Shift Left practice) and deployment procedures.\n\u2022 Follow coding and design best practices developed by the teams and contribute towards their continuous improvement.\n\u2022 Plan Hardware Capacity for high traffic business Events.\n\u2022 Design Build and maintain Observability aspects of application.\n\u2022 Review Peer Code and help create a culture of continuous improvements on the architecture.\n\u2022 Work with relevant stakeholders on launching AB tests for different functionalities getting rolled out.\n\nWhat you'll bring:\n\u2022 Experience in creating user interfaces using appropriate and relevant technologies (e.g., HTML 5 coding, CSS (Cascading Style Sheets) libraries like Bootstrap, etc.) using best practices and appropriate design patterns.\n\u2022 Relevant front end programming experience in relevant languages and frameworks (e.g., Java, Python, JavaScript, Spring, Node, React, Angular etc.)\n\u2022 Experience integrating with scalable back-end services (e.g., REST / graph-QL).\n\u2022 Experience in functional, integration and E2E (End 2 End) testing tools and practices.\n\u2022 Experience with code repositories and version control practices.\n\u2022 Experience with CI/CD pipelines and best practices. Automated deployment experience is a plus.\n\u2022 Experience in software quality and operational excellence practices.\n\u2022 Experience in agile development methodology.\n\u2022 Good analytical and problem-solving skills.\n\nAbout Walmart Global Tech\nImagine working in an environment where one line of code can make life easier for hundreds of millions of people. That\u2019s what we do at Walmart Global Tech. We\u2019re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world\u2019s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart an illustrious career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.\n\nFlexible, hybrid work:\nWe use a hybrid way of working that is primarily in the office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.\n#WGTMPQ4\n\nAt Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.\n\n\u200e\n\n\u200e\n\n\u200e\nYou will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.\n\n\u200e\n\nFor information about PTO, see https://one.walmart.com/notices.\n\n\u200e\n\n\u200e\nLive Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.\n\n\u200e\nEligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.\n\n\u200e\n\nFor information about benefits and eligibility, see One.Walmart.\n\n\u200e\nThe annual salary range for this position is $108,000.00-$216,000.00\n\n\u200e\nAdditional compensation includes annual or quarterly performance bonuses.\n\n\u200e\nAdditional compensation for certain positions may also include:\n\n\u200e\n\n\u200e\n- Stock\n\n\u200e\n\n\u200e\n\nMinimum Qualifications...\n\nOutlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.\n\nOption 1: Bachelor's degree in computer science, computer engineering, computer information systems, software engineering, or related area and 3 years\u2019 experience in software engineering or related area.Option 2: 5 years\u2019 experience in software engineering or related area.\n\nPreferred Qualifications...\n\nOutlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.\n\nMaster\u2019s degree in Computer Science, Computer Engineering, Computer Information Systems, Software Engineering, or related area and 1 year's experience in software engineering or related area., We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart\u2019s accessibility standards and guidelines for supporting an inclusive culture.\n\nPrimary Location...\n\n10790 Parkridge Dr. Suite 200, Reston, VA 20191, United States of America\n\nWalmart and its subsidiaries are committed to maintaining a drug-free workplace and has a no tolerance policy regarding the use of illegal drugs and alcohol on the job. This policy applies to all employees and aims to create a safe and productive work environment.",
    "url": "https://www.ziprecruiter.com/c/Walmart/Job/Senior-Software-Developer-Frontend,-Backend,-Stack,-or-Mobile/-in-Washington,DC?jid=1b2def81a6c9bbe6&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-06T00:00:00.000Z"
  },
  {
    "title": "Senior Software Engineer (Python, React, AWS)",
    "company": "Capital One",
    "location": "McLean",
    "salary": "",
    "description": "Senior Software Engineer (Python, React, AWS)\n\nDo you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Full Stack Software Engineers who are passionate about marrying data with emerging technologies. As a Capital One Software Engineer, you\u2019ll have the opportunity to be on the forefront of driving a major transformation within Capital One.\n\nWhat You\u2019ll Do:\n\u2022 Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies\n\u2022 Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, mentoring other members of the engineering community\n\u2022 Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment\n\u2022 Utilize programming languages like JavaScript, Java, HTML/CSS, TypeScript, SQL, Python, and Go, Open Source RDBMS and NoSQL databases, Container Orchestration services including Docker and Kubernetes, and a variety of AWS tools and services\n\nBasic Qualifications:\n\u2022 Bachelor\u2019s Degree\n\u2022 At least 3 years of experience in software engineering (Internship experience does not apply)\n\nPreferred Qualifications:\n\u2022 5+ years of experience in at least one of the following: JavaScript, Java, TypeScript, SQL, Python, or Go\n\u2022 1+ years of experience with AWS, GCP, Microsoft Azure, or another cloud service\n\u2022 3+ years of experience in open source frameworks\n\u2022 2+ years of experience in Agile practices\n\nAt this time, Capital One will not sponsor a new applicant for employment authorization for this position.\n\nThe minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.\n\nMcLean, VA: $158,600 - $181,000 for Senior Software Engineer\n\nNew York, NY: $173,000 - $197,400 for Senior Software Engineer\n\nRichmond, VA: $144,200 - $164,600 for Senior Software Engineer\n\nCandidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter.\n\nThis role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\n\nThis role is expected to accept applications for a minimum of 5 business days.\n\nNo agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\n\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\n\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\n\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",
    "url": "https://www.capitalonecareers.com/job/mclean/senior-software-engineer-python-react-aws/1732/88135518240?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Sr. Software Engineer - Javascript, HTML5, CSS, React, AngularJS, Vue",
    "company": "Walmart",
    "location": "Washington",
    "salary": 108000,
    "description": "Position Summary...\n\nWhat you'll do... As a part of Walmart Global Tech, you\u2019ll build industry defining reusable customer and partner facing services and products to lead differentiated experiences and revenue. You will be in the unique position to be of service to both our customers (1P as well as 3P) and our associates as a member of this organization supporting all segments of Walmart. If you are the type of person who feels a personal stake in everything that you work on, has a love for data, enjoys solving complex problems, has a passion for privacy, knows how to foster strong relationships and build trust, and works for the success of the entire team.\n\nAbout Team:\nOur team works closely with our US stores and eCommerce business to better serve customers by empowering team members, stores, and merchants with technological innovation. From groceries and entertainment to sporting goods and crafts, Walmart U.S. offers an extensive selection that our customers value, whether they shop online at Walmart.com, through one of our mobile apps, or in-store. Focus areas include customers, stores and employees, in-store service, merchant tools, merchant data science, and search and personalization.\n\nWhat you'll do:\n\u2022 Design, build, and maintain high-performance front-end applications for our 1P and 3P customers.\n\u2022 Develop robust, maintainable, reusable code for managing functionality, configuration, deployment, monitoring, performance, scalability, availability, security, and alerting for software test, integration, and production environments.\n\u2022 Plan and implement a series of steps which potentially includes reconfiguration, integration, removal, or addition of application components to enhance the application's functionality, resiliency, usability, and security.\n\u2022 Understand the Business/Stakeholder/Technical requirements and assist in analyzing the existing solutions to address the needs. Assist in creation of simple, modular, extensible functional design for the product/solution in adherence to the requirements.\n\u2022 Assess gaps/ updates/ modifications between the customer/business expectations and the existing product/solutions.\n\u2022 Analyze defects from past projects/solutions to avoid recurrence of similar defects.\n\u2022 Analyze system performance impacting the complete product for non-functional requirements like reliability, operability, performance efficiency and security. Troubleshoot performance and availability bottlenecks for the application.\n\u2022 Develop, maintain, and enhance automated test cases (adopting Shift Left practice) and deployment procedures.\n\u2022 Follow coding and design best practices developed by the teams and contribute towards their continuous improvement.\n\u2022 Plan Hardware Capacity for high traffic business Events.\n\u2022 Design Build and maintain Observability aspects of application.\n\u2022 Review Peer Code and help create a culture of continuous improvements on the architecture.\n\u2022 Work with relevant stakeholders on launching AB tests for different functionalities getting rolled out.\n\nWhat you'll bring:\n\u2022 Experience in creating user interfaces using appropriate and relevant technologies (e.g., HTML 5 coding, CSS (Cascading Style Sheets) libraries like Bootstrap, etc.) using best practices and appropriate design patterns.\n\u2022 Relevant front end programming experience in relevant languages and frameworks (e.g., Java, Python, JavaScript, Spring, Node, React, Angular etc.)\n\u2022 Experience integrating with scalable back-end services (e.g., REST / graph-QL).\n\u2022 Experience in functional, integration and E2E (End 2 End) testing tools and practices.\n\u2022 Experience with code repositories and version control practices.\n\u2022 Experience with CI/CD pipelines and best practices. Automated deployment experience is a plus.\n\u2022 Experience in software quality and operational excellence practices.\n\u2022 Experience in agile development methodology.\n\u2022 Good analytical and problem-solving skills.\n\nAbout Walmart Global Tech\nImagine working in an environment where one line of code can make life easier for hundreds of millions of people. That\u2019s what we do at Walmart Global Tech. We\u2019re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world\u2019s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart an illustrious career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.\n\nFlexible, hybrid work:\nWe use a hybrid way of working that is primarily in the office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.\n#WGTMPQ4\n\nAt Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.\n\n\u200e\n\n\u200e\n\n\u200e\nYou will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.\n\n\u200e\n\nFor information about PTO, see https://one.walmart.com/notices.\n\n\u200e\n\n\u200e\nLive Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.\n\n\u200e\nEligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.\n\n\u200e\n\nFor information about benefits and eligibility, see One.Walmart.\n\n\u200e\nThe annual salary range for this position is $108,000.00-$216,000.00\n\n\u200e\nAdditional compensation includes annual or quarterly performance bonuses.\n\n\u200e\nAdditional compensation for certain positions may also include:\n\n\u200e\n\n\u200e\n- Stock\n\n\u200e\n\n\u200e\n\nMinimum Qualifications...\n\nOutlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.\n\nOption 1: Bachelor's degree in computer science, computer engineering, computer information systems, software engineering, or related area and 3 years\u2019 experience in software engineering or related area.Option 2: 5 years\u2019 experience in software engineering or related area.\n\nPreferred Qualifications...\n\nOutlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.\n\nMaster\u2019s degree in Computer Science, Computer Engineering, Computer Information Systems, Software Engineering, or related area and 1 year's experience in software engineering or related area., We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart\u2019s accessibility standards and guidelines for supporting an inclusive culture.\n\nPrimary Location...\n\n10790 Parkridge Dr. Suite 200, Reston, VA 20191, United States of America\n\nWalmart and its subsidiaries are committed to maintaining a drug-free workplace and has a no tolerance policy regarding the use of illegal drugs and alcohol on the job. This policy applies to all employees and aims to create a safe and productive work environment.",
    "url": "https://www.ziprecruiter.com/c/Walmart/Job/Sr.-Software-Engineer-Javascript,-HTML5,-CSS,-React,-AngularJS,-Vue/-in-Washington,DC?jid=c634f99c3fd209b8&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-06T00:00:00.000Z"
  },
  {
    "title": "Software Engineer",
    "company": "Peraton",
    "location": "Washington",
    "salary": 104000,
    "description": "Basic Qualifications:\n\u2022 U.S. Citizenship Required.\n\u2022 Must have the ability to obtain / maintain a Public Trust clearance.\n\u2022 Bachelor\u2019s degree and 8 years of experience; or Masters degree and 6 years; or Associate\u2019s degree and 10 years\u2019 experience; or HS diploma/equivalent and 12 years experience.\n\u2022 Hands-on knowledge of software engineering.\n\u2022 Strong proficiency in modern programming languages (e.g., Java, C++, Python, C#).\n\u2022 Proven expertise in software architecture design, testing, and lifecycle management.\n\u2022 Experience with cloud platforms and cloud-native software development.\n\u2022 Proficiency with version control systems (Git), automated testing frameworks, and software quality assurance tools.\n\nPreferred Qualifications:\n\u2022 Direct FAA or NAS configuration management experience.\n\u2022 Familiarity with FAA systems, NextGen modernization programs, or other large-scale federal IT programs.\n\u2022 Ability to conduct risk assessments, trade studies, and technical evaluations to support decision-making.\n\u2022 Experience preparing documentation for compliance, audits, and technical reviews.\n\u2022 Advanced degree (Master\u2019s or Ph.D.) in Computer Science, Engineering, or related technical discipline.\n\u2022 Professional certifications such as AWS Certified Solutions Architect, Microsoft Certified Azure Solutions Expert, or CISSP.\n\u2022 Experience leading software efforts for FAA, DOT, DHS, DoD, or other large-scale federal programs.\n\u2022 Familiarity with aviation systems, air traffic management software, or mission-critical operational environments.\n\u2022 Published research, white papers, or conference presentations in software engineering or aviation technology domains.\n\u2022 Expertise in AI/ML, advanced analytics, or next-generation automation for aviation systems.\n\n#BNATC\n\n#BNATC\n\n#BNATC\n\n#BNATC\n\nJoin Peraton in advancing the safety, efficiency, and modernization of the National Airspace System (NAS) through the FAA\u2019s Business, National Airspace, and Technical Computing Services (BNATCS) contract. As a trusted partner to the Federal Aviation Administration, Peraton helps deliver the systems and services that keep our nation\u2019s skies safe and connected. We\u2019re looking for innovative professionals who thrive in mission-critical environments and are passionate about shaping the future of air traffic management. This is your chance to make an impact on one of the world\u2019s most vital transportation infrastructures, working alongside leaders in aviation, engineering, data science, and systems integration.\n\nAt Peraton, you won\u2019t just support the mission \u2014 you\u2019ll define it.\n\nHelp shape the future of U.S. airspace safety and efficiency. We are seeking a Software Engineer to join our team of qualified, diverse individuals. The ideal candidate will provide technical leadership, oversight, and hands-on expertise in support of the Federal Aviation Administration (FAA). You will serve as a trusted advisor to program leadership, ensuring that applications meet rigorous safety, security, and performance standards, while also mentoring engineering teams and shaping long-term software strategy. Whether you\u2019re mid-career, senior, or ready to lead, your expertise in federal contracts management will directly impact how millions of travelers move safely through the skies.\n\nIn this position, you will:\n\u2022 guide the design, development, integration, and sustainment of software systems that enable the FAA\u2019s mission.\n\u2022 Provide technical leadership and architectural guidance on FAA software development and integration projects.\n\u2022 Lead or oversee the design, coding, testing, and deployment of mission-critical applications.\n\u2022 Ensure compliance with FAA standards, cybersecurity requirements, and federal software development best practices.\n\u2022 Serve as an advisor to FAA leadership, providing technical insight on software modernization strategies, tools, and emerging technologies.\n\u2022 Conduct design reviews, code inspections, and quality assurance evaluations to ensure technical accuracy and compliance.\n\u2022 Collaborate with systems engineers, cybersecurity experts, and program managers to align software with broader system objectives.\n\u2022 Support proposal and capture activities, including technical solutioning and cost estimation.\n\u2022 Mentor and coach junior and mid-level software engineers, fostering a culture of excellence and continuous learning.\n\u2022 Stay current with emerging technologies (AI/ML, cloud-native architectures, DevSecOps pipelines) and recommend adoption where applicable.\n\u2022 Prepare and present technical briefings, reports, and recommendations for FAA leadership and stakeholders.\n\nWhy This Role Matters\n\nThe FAA is the cornerstone of aviation safety and innovation. As a Software Engineer \u2013 Advisor, your work will directly impact air traffic management, safety-critical applications, and modernization programs that millions of passengers rely on daily. Your leadership will ensure that complex software initiatives are delivered on time, on budget, and in full compliance with federal and aviation standards\u2014helping to secure the future of the National Airspace System (NAS).",
    "url": "https://www.careers.peraton.com/jobs/software-engineer-washington-d-c-160226-jobs--information-technology--?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "Part-time Software Engineer (Python, AWS)",
    "company": "Capital One",
    "location": "McLean",
    "salary": "",
    "description": "Part-time Software Engineer (Python, AWS)\n\nNote: This is a professional-level position. Students and recent graduates please check out our Student Programs.\n\nDo you love building and pioneering in the technology space, while solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? If so, you\u2019ll love the work we\u2019re doing at Capital One. Here, you'll be part of a big team of makers, breakers, doers and disruptors, who solve real problems to meet real customer needs. We are seeking Software Engineers who are passionate about marrying data with emerging technologies.\n\nThe traditional 40-hour work week might not work for everyone so Capital One\u2019s Technology organization is rethinking how work gets done.\n\nAs a Part-time Software Engineer at Capital One, you\u2019ll be part of an innovative new program that aims to grow our diverse and inclusive workforce by increasing part-time employment opportunities.\n\nPart-time Program Associates will work with their managers to determine a schedule that best meets the team\u2019s and the individual\u2019s needs and that falls within 20 - 32 hours per week. On occasion, support for an off hours implementation rollout and/or issues resolution may be required with advanced notice provided.\n\nWhat you\u2019ll do:\n\u2022 Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies\n\u2022 Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal and external technology communities, mentoring other members of the engineering community\n\u2022 Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment\n\u2022 Utilize programming languages like Java, Python, SQL, Node, Go, and Scala, Open Source RDBMS and NoSQL databases, Container Orchestration services including Docker and Kubernetes, and a variety of AWS tools and services\n\nBasic Qualifications:\n\u2022 Bachelor\u2019s Degree\n\u2022 At least 3 years of experience in software engineering\n\nPreferred Qualifications:\n\u2022 Master's Degree\n\u2022 2+ years of experience in Agile practices\n\u2022 1+ years of experience with AWS, GCP, Microsoft Azure, or another cloud service\n\u2022 4+ years of experience in at least one of the following: Java, Scala, Python, Go, Javascript/TypeScript, Angular/React.js, or Node.js\n\u2022 2+ years of experience working with big data technologies (e.g. Hadoop, Spark, Presto)\n\u2022 2+ years of experience working on streaming data applications (e.g. Kafka, Kinesis, Flink, or Spark Streaming)\n\u2022 4+ years of experience in open source frameworks\n\nAt this time, Capital One will not sponsor a new applicant for employment authorization, or offer any immigration related support for this position (i.e. H1B, F-1 OPT, F-1 STEM OPT, F-1 CPT, J-1, TN, E-2, E-3, L-1 and O-1, or any EADs or other forms of work authorization that require immigration support from an employer).\n\nThe minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.\n\nMcLean, VA: $158,600 - $181,000 for Senior Software Engineer\n\nCandidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter.\n\nThis role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\n\nThis role is expected to accept applications for a minimum of 5 business days.\n\nNo agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\n\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\n\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\n\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",
    "url": "https://www.capitalonecareers.com/job/mclean/part-time-software-engineer-python-aws/1732/85741011360?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Software Engineer, Sr",
    "company": "Freddie Mac",
    "location": "McLean",
    "salary": "",
    "description": "At Freddie Mac, our mission of Making Home Possible is what motivates us, and it\u2019s at the core of everything we do. Since our charter in 1970, we have made home possible for more than 90 million families across the country. Continue your career journey where your work contributes to a greater purpose.\n\nPosition Overview:\n\nThe Software Engineer, Sr. leads the technical strategy, advocating for simplicity and challenging constraints to achieve Agile design. They actively engage in problem-solving, balancing visionary leadership with execution. Additionally, they ensure that technical implementations align with architectural solutions.\n\nOur Impact:\n\nThe BTO enhances IT delivery efficiency across MD Digital teams by integrating development, testing, and operations in the foundational space. This collaborative environment combines skills, processes, practices, and tools to improve large-scale service delivery with high speed and reliability.\n\nYour Impact:\n\nThe role centers on providing technical leadership to a team responsible for developing data components and applications for Modern Delivery teams. This involves guiding the team to meet project goals and development schedules by ensuring solutions adhere to technical specifications and design requirements. The leader is tasked with making critical technical and architectural decisions, influencing the design of technology, infrastructure, and system configuration to optimize scalability and capacity. In software development, the role includes analyzing business requirements, proposing design options aligned with the technical roadmap, and developing microservices-based solutions using Java/JEE frameworks, UI frameworks, Docker, and OpenShift. This also involves handling technical upgrades and migrations, focusing on middleware, database transitions to the cloud, and enhancing application performance and scalability.\n\nThe role extends to DevOps, where responsibilities include designing scaling strategies, developing automation scripts, and mentoring in build automation using Docker and container technologies, as well as orchestration tools like OpenShift, Kubernetes, EKS, and the Atlassian tool suite. Additionally, in application remediation and support, the individual provides proactive advice throughout the development lifecycle to prevent and address quality issues early, develops model applications and microservices based on Java web services frameworks, and trains and mentor\u2019s junior staff. They also work on fixing software security vulnerabilities identified in SAST and FOSS scanning, contribute to design and code reviews, and document lessons learned to maintain a knowledge database.\n\nQualifications:\n\u2022 A minimum of 5-7 years of experience engineering exciting solutions.\n\u2022 Bachelor\u2019s degree in computer science or engineering or equivalent experience. Advanced studies/degree preferred\n\u2022 5 + years of demonstrated experience working in modernized development teams.\n\u2022 At least 5+ years of experience developing front end & orchestration layers\u2019 technologies: Java, Spring Boot, RESTful APIs, Angular, Node JS, JavaScript, Typescript, HTML 5, and CSS\n\u2022 2+ years of experience in database technologies - MongoDB, Postgres, etc.\n\u2022 2+ Experience developing with large microservice based architectures, container orchestration frameworks.\n\u2022 3+ years of experience using DevOps (CI/CD) Jenkins, GitHub, Bitbucket, Spinnaker, JUnit, Cypress, Cucumber JS unit testing library.\n\u2022 2+ years\u2019 experience with cloud platforms AWS/Azure/Google\n\u2022 Excellent communication skills. The incumbent will be responsible for interfacing and influencing with the business lines as well as others across IT.\n\nKeys to Success in this Role:\n\nThe ideal candidate possesses a collaborative attitude and aims to be innovative, demonstrating thoughtfulness and the ability to inspire others. They excel in time management and organizational skills, quickly learn new technologies and tools, and have solid knowledge of development and testing tools. Proactive by nature, they prioritize customer satisfaction and maintain a strong focus on operational excellence.\n\nWe consider all applicants for all positions without regard to gender, race, color, religion, national origin, age, marital status, veteran status, sexual orientation, gender identity/expression, physical and mental disability, pregnancy, ethnicity, genetic information or any other protected categories under applicable federal, state or local laws. We will ensure that individuals are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.\n\nFreddie Mac offers a comprehensive total rewards package to include competitive compensation and market-leading benefit programs. Information on these benefit programs is available on our Careers site.\n\nThis position has an annualized market-based salary range of $127,000 - $191,000 and is eligible to participate in the annual incentive program. The final salary offered will generally fall within this range and is dependent on various factors including but not limited to the responsibilities of the position, experience, skill set, internal pay equity and other relevant qualifications of the applicant.",
    "url": "https://careers.freddiemac.com/us/en/job/JR15717/Software-Engineer-Sr?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-08T00:00:00.000Z"
  },
  {
    "title": "Mobile Software Engineer",
    "company": "Walmart",
    "location": "Arlington",
    "salary": 108000,
    "description": "Position Summary...\n\nWhat you'll do... As a part of Walmart Global Tech, you\u2019ll build industry defining reusable customer and partner facing services and products to lead differentiated experiences and revenue. You will be in the unique position to be of service to both our customers (1P as well as 3P) and our associates as a member of this organization supporting all segments of Walmart. If you are the type of person who feels a personal stake in everything that you work on, has a love for data, enjoys solving complex problems, has a passion for privacy, knows how to foster strong relationships and build trust, and works for the success of the entire team.\n\nAbout Team:\nOur team works closely with our US stores and eCommerce business to better serve customers by empowering team members, stores, and merchants with technological innovation. From groceries and entertainment to sporting goods and crafts, Walmart U.S. offers an extensive selection that our customers value, whether they shop online at Walmart.com, through one of our mobile apps, or in-store. Focus areas include customers, stores and employees, in-store service, merchant tools, merchant data science, and search and personalization.\n\nWhat you'll do:\n\u2022 Design, build, and maintain high-performance front-end applications for our 1P and 3P customers.\n\u2022 Develop robust, maintainable, reusable code for managing functionality, configuration, deployment, monitoring, performance, scalability, availability, security, and alerting for software test, integration, and production environments.\n\u2022 Plan and implement a series of steps which potentially includes reconfiguration, integration, removal, or addition of application components to enhance the application's functionality, resiliency, usability, and security.\n\u2022 Understand the Business/Stakeholder/Technical requirements and assist in analyzing the existing solutions to address the needs. Assist in creation of simple, modular, extensible functional design for the product/solution in adherence to the requirements.\n\u2022 Assess gaps/ updates/ modifications between the customer/business expectations and the existing product/solutions.\n\u2022 Analyze defects from past projects/solutions to avoid recurrence of similar defects.\n\u2022 Analyze system performance impacting the complete product for non-functional requirements like reliability, operability, performance efficiency and security. Troubleshoot performance and availability bottlenecks for the application.\n\u2022 Develop, maintain, and enhance automated test cases (adopting Shift Left practice) and deployment procedures.\n\u2022 Follow coding and design best practices developed by the teams and contribute towards their continuous improvement.\n\u2022 Plan Hardware Capacity for high traffic business Events.\n\u2022 Design Build and maintain Observability aspects of application.\n\u2022 Review Peer Code and help create a culture of continuous improvements on the architecture.\n\u2022 Work with relevant stakeholders on launching AB tests for different functionalities getting rolled out.\n\nWhat you'll bring:\n\u2022 Experience in creating user interfaces using appropriate and relevant technologies (e.g., HTML 5 coding, CSS (Cascading Style Sheets) libraries like Bootstrap, etc.) using best practices and appropriate design patterns.\n\u2022 Relevant front end programming experience in relevant languages and frameworks (e.g., Java, Python, JavaScript, Spring, Node, React, Angular etc.)\n\u2022 Experience integrating with scalable back-end services (e.g., REST / graph-QL).\n\u2022 Experience in functional, integration and E2E (End 2 End) testing tools and practices.\n\u2022 Experience with code repositories and version control practices.\n\u2022 Experience with CI/CD pipelines and best practices. Automated deployment experience is a plus.\n\u2022 Experience in software quality and operational excellence practices.\n\u2022 Experience in agile development methodology.\n\u2022 Good analytical and problem-solving skills.\n\nAbout Walmart Global Tech\nImagine working in an environment where one line of code can make life easier for hundreds of millions of people. That\u2019s what we do at Walmart Global Tech. We\u2019re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world\u2019s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart an illustrious career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.\n\nFlexible, hybrid work:\nWe use a hybrid way of working that is primarily in the office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.\n#WGTMPQ4\n\nAt Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.\n\n\u200e\n\n\u200e\n\n\u200e\nYou will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.\n\n\u200e\n\nFor information about PTO, see https://one.walmart.com/notices.\n\n\u200e\n\n\u200e\nLive Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.\n\n\u200e\nEligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.\n\n\u200e\n\nFor information about benefits and eligibility, see One.Walmart.\n\n\u200e\nThe annual salary range for this position is $108,000.00-$216,000.00\n\n\u200e\nAdditional compensation includes annual or quarterly performance bonuses.\n\n\u200e\nAdditional compensation for certain positions may also include:\n\n\u200e\n\n\u200e\n- Stock\n\n\u200e\n\n\u200e\n\nMinimum Qualifications...\n\nOutlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.\n\nOption 1: Bachelor's degree in computer science, computer engineering, computer information systems, software engineering, or related area and 3 years\u2019 experience in software engineering or related area.Option 2: 5 years\u2019 experience in software engineering or related area.\n\nPreferred Qualifications...\n\nOutlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.\n\nMaster\u2019s degree in Computer Science, Computer Engineering, Computer Information Systems, Software Engineering, or related area and 1 year's experience in software engineering or related area., We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart\u2019s accessibility standards and guidelines for supporting an inclusive culture.\n\nPrimary Location...\n\n10790 Parkridge Dr. Suite 200, Reston, VA 20191, United States of America\n\nWalmart and its subsidiaries are committed to maintaining a drug-free workplace and has a no tolerance policy regarding the use of illegal drugs and alcohol on the job. This policy applies to all employees and aims to create a safe and productive work environment.",
    "url": "https://www.ziprecruiter.com/c/Walmart/Job/Mobile-Software-Engineer/-in-Arlington,VA?jid=52f2239463fd2e88&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-06T00:00:00.000Z"
  },
  {
    "title": "Systems Software Engineer",
    "company": "Cloud Software Group",
    "location": "Pune",
    "salary": "",
    "description": "Job Summary:\n\nWe are seeking a highly skilled and detail-oriented Engineer and QA with hands-on experience in\ndeploying and testing applications in containerized environments using Kubernetes and\nOpenShift. This role will focus specifically on testing IBI WebFOCUS applications, and\ncandidates with prior experience or understanding of WebFOCUS will be given preference.\nThe ideal candidate should be comfortable working in Linux environments,\nand capable of scripting automation tools for different processes. Familiarity with cloud\nplatforms like AWS and GCP is also a plus.\n\nKey Responsibilities:\n\n\u25cf Deploy IBI WebFOCUS applications into Kubernetes and OpenShift clusters.\n\u25cf Develop, maintain, and execute automated and manual test cases for functional,\nregression, and integration testing.\n\u25cf Write shell scripts and automation tools to facilitate QA tasks and deployment validation.\n\u25cf Troubleshoot issues in containerized environments and collaborate with DevOps,\nDevelopers, and Product teams.\n\u25cf Assist in CI/CD pipeline integration and QA automation strategies.\n\u25cf Document test plans and test reports.\n\u25cf Contribute to continuous improvement of QA practices, tooling, and frameworks.\n\nRequired Skills & Qualifications:\n\n\u25cf Strong experience in Docker and containerization.\n\u25cf Hands-on experience with Kubernetes and OpenShift (deployment, scaling, debugging).\n\u25cf Hands-on experience with tools like Helm, helmfile, kubectl, oc, Jenkins, Git, etc.\n\u25cf Strong Linux skills, including file system, networking, and troubleshooting.\n\u25cf Proficiency in Shell scripting (Bash or similar).\n\u25cf Experience writing and maintaining test cases (manual and automated).\n\u25cf Basic knowledge of cloud platforms such as AWS or GCP.\n\nPreferred Qualifications:\n\n\u25cf Experience working with or testing IBI WebFOCUS platform.\n\u25cf Experience with CI/CD tools and practices.\n\u25cf Knowledge of application logging and monitoring tools.\n\u25cf Exposure to performance and security testing tools.\n\nAbout Us:\n\nCloud Software Group is one of the world\u2019s largest cloud solution providers, serving more than 100 million users around the globe. When you join Cloud Software Group, you are making a difference for real people, each of whom count on our suite of cloud-based products to get work done \u2014 from anywhere. Members of our team will tell you that we value passion for technology and the courage to take risks. Everyone is empowered to learn, dream, and build the future of work. We are on the brink of another Cambrian leap -- a moment of immense evolution and growth. And we need your expertise and experience to do it. Now is the perfect time to move your skills to the cloud.\n\nCloud Software Group is firmly committed to Equal Employment Opportunity (EEO) and to compliance with all federal, state and local laws that prohibit employment discrimination. All qualified applicants will receive consideration for employment without regard to age, race, color, creed, sex or gender, sexual orientation, gender identity, gender expression, ethnicity, national origin, ancestry, citizenship, religion, genetic carrier status, disability, pregnancy, childbirth or related medical conditions (including lactation status), marital status, military service, protected veteran status, political activity or affiliation, taking or requesting statutorily protected leave and other protected classifications.\n\nIf you need a reasonable accommodation due to a disability during any part of the application process, please email us at AskHR@cloud.com for assistance.",
    "url": "https://careers.cloud.com/jobs/systems-software-engineer-pune-maharashtra-india?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "IT Software Developer",
    "company": "Siemens",
    "location": "Pune",
    "salary": "",
    "description": "Hello eager tech expert!\n\nTo create a better future, you need to think outside the box. That\u2019s why we at Siemens need innovators who aren\u2019t afraid to push boundaries to join our diverse team of tech gurus. Got what it takes? Then help us create lasting, positive impact!\n\nSiemens Financial Services IT is establishing a strategic Tech Hub in India to drive our digital transformation initiatives worldwide. This isn't just a job \u2013 it's an opportunity to build your international career while working with cutting-edge technologies that power financial operations across the globe.\n\nWe are looking for a Senior Low Code Developer to join our Chapter Process Digitalization.\n\nWe are a self-organized, multidisciplinary, team developing innovative solutions for Siemens Financial Services. Our jointly defined purpose is: \u201cWith our deep business knowledge, low-code skills, and service mindset, we create financial solutions to accelerate digitalization of business processes from requirement-engineering to quality-centered delivery, so that our colleagues & customers are happy, efficient, and successful.\u201d\n\nYou\u2019ll break new ground by:\n\u2022 Participate in intakes and provide estimations for potential upcoming projects.\n\u2022 Develop new applications in Scrum teams for projects delivered worldwide.\n\u2022 Enhance and support existing applications.\n\u2022 Be the go-to person for all architectural and central technical topics.\n\u2022 Be responsible for our Developer Guidelines.\n\u2022 Be responsible for the Quality Gates in our projects/applications.\n\u2022 Be responsible for the implementation of core components and the development of our technological roadmap.\n\u2022 Provide guidance and instructions to other team members, coaching younger talents (e.g. trainees).\n\nYou\u2019re excited to build on your existing expertise, including:\n\u2022 Master\u2019s degree in computer science, Mathematics, Engineering, or in a related field.\n\u2022 Proven track record with at least 3 years of working experience on agile projects as a software developer.\n\u2022 Experience in translating customer requirements, conception, and presentation of solutions.\n\u2022 Quick understanding of business processes and requirements in a financial context.\n\u2022 Motivation to meet deadlines, hands-on mentality, flexibility, proactivity, and willingness to learn new technologies.\n\u2022 Disposition to grow further, learn new technologies, and help others grow along.\n\u2022 Good communication and organizational skills.\n\u2022 Business fluent English written and spoken; German proficiency would be nice to have.\n\u2022 Experience with Mendix is highly valued.\n\u2022 Experience in other low-code development platforms is also valued (e.g. Outsystems).\n\u2022 Experience in IT projects in a financial context or any financial qualification.\n\u2022 Open mentality and eagerness to learn everyday.\n\nCreate a better #TomorrowWithUs!\n\nWe value your unique identity and perspective and are fully committed to providing equitable opportunities and building a workplace that reflects the diversity of society. Come bring your authentic self and create a better tomorrow with us.\n\nProtecting the environment, conserving our natural resources, fostering the health and performance of our people as well as safeguarding their working conditions are core to our social and business commitment at Siemens.\n\nThis role is based in Pune. You\u2019ll also get to visit other locations in India and beyond, so you\u2019ll need to go where this journey takes you. In return, you\u2019ll get the chance to work with an international team and working on global topics.",
    "url": "https://in.linkedin.com/jobs/view/it-software-developer-at-siemens-4320825459?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Principle software Engineer -Pune (9-15 years )",
    "company": "Energy Exemplar",
    "location": "Pune",
    "salary": "",
    "description": "About The Position\n\nReporting to the Software Engineering Manager as a member of the Development team in India, the Software Engineer is responsible for delivering quality and performant software and design to handle the vast array of use cases that our customers have today. This role is responsible for Developing Software Solutions by learning information needs, discussing with managers, studying systems flow, data usage, finding problem areas and coming up with solutions & following the software development lifecycle.\n\nLocation: 4th Floor, WeWork Amanora Crest, Amanora Park Town, Magarpatta, Hadapsar, Pune, Maharashtra 411028\n\nWork Type: Hybrid (3 days a week in office)\n\nWe Are Looking For\n\u2022 9+ years of experience in product development field\n\u2022 2+ years of recent experience in building products on cloud\n\u2022 Strong understanding of data structures, algorithms, and designing for performance\n\u2022 Strong knowledge in OOPS with .Net, C# or relevant technologies with SQL Server or any RDBMS\n\u2022 For Fullstack roles, hands-on experience in development with either Angular, VueJS or React\n\u2022 Experience with Microservices Architecture\n\u2022 Hands-on experience in building products for Unix systems in addition to Windows\n\u2022 Working knowledge of CI/CD pipelines and AWS/Azure cloud services\n\u2022 Knowledge of asynchronous programming and WebAPI development is required\n\u2022 Knowledge and awareness of cloud/ application security is a must (OWASP at the minimum)\n\u2022 Extensive experience in mentoring junior engineers to success\n\u2022 Strong logical, analytics and problem-solving skills\n\u2022 Must be able to work effectively across team boundaries\n\u2022 Attention to details\n\u2022 Strong oral and written communication skills\n\nCandidate Requirements & Qualifications\n\u2022 Graduate/Master's degree in Computer Science, Engineering, or a related discipline\n\u2022 Strong logical, analytics and problem-solving skills\n\u2022 Must be able to work effectively across team boundaries\n\u2022 Attention to details\n\u2022 Ability to work independently\n\nMandate: Data structure and Algorithm, system design , Complex sql queries to write and cloud hands on experience is must",
    "url": "https://in.jooble.org/jdp/5257435270169579862?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Software Engineer - PLSQL/Oracle",
    "company": "Avaloq",
    "location": "Pune",
    "salary": "",
    "description": "It is a dynamic team of business analysts and software developers spread across development centers globally. We follow an agile process, working closely within our own team but also with other related teams and clients to develop new product features and maintain existing ones in live use.\n\nThe team works with clients and partners to develop and deliver innovative solutions to meet market demands and help shape the back-office landscape of tomorrow.\n\nAs the owner of the functionality, the team is part of many exciting and challenging projects.\n\nWe are looking for a highly motivated Software Engineer who is interested in designing and developing scalable solutions for the financial services industry.\n\nThis job represents a unique opportunity to advance your development skills and acquire banking and wealth management domain experience. You will become an expert of Avaloq core banking software and the corresponding business processes in the industry.\n\u2022 Drive the design of new product features and functionality in collaboration with business analysts, product owners, software architects and fellow developers\n\u2022 Analyze and implement customer requirements\n\u2022 Customize our software to fit our clients\u2019 needs\n\u2022 Extend Avaloq\u2019s standard product configuration\n\u2022 Provide technical support for customer projects\n\u2022 Maintain existing functionality\n\u2022 Work in an Agile environment, helping to constantly improve our processes and introduce new technologies\n\u2022 Provide support to other development teams\n\u2022 Work on interdisciplinary innovation projects\n\u2022 Ensure high quality of our software via code reviews and automated testing",
    "url": "https://www.avaloq.com/careers/job-openings/744000091553835-software-engineer-plsql-oracle?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Senior Software Engineer - Full Stack (.Net, React.Js)",
    "company": "Mastercard",
    "location": "Pune",
    "salary": "",
    "description": "Job Title:\n\nSenior Software Engineer - Full Stack (.Net, React.Js)\n\nOverview:\n\nOverview\n\nWe are the global technology company behind the world\u2019s fastest payments processing network. We are a vehicle for commerce, a connection to financial systems for the previously excluded, a technology innovation lab, and the home of Priceless\u00ae. We ensure every employee has the opportunity to be a part of something bigger and to change lives. We believe as our company grows, so should you. We believe in connecting everyone to endless, priceless possibilities.\n\nOur team within Mastercard \u2013 Services within Mastercard:\n\nServices within Mastercard is responsible for acquiring, engaging, and retaining customers by managing fraud and risk, enhancing cybersecurity, and improving the digital payments experience. We provide value-added services and leverage expertise, data-driven insights, and execution.\n\nData Analytics and AI Solution:\n\nWithin the Services Technology Team, the Data Analytics and AI Solution program that is comprised of a rich set of products that provide accurate perspectives on Portfolio Optimization, Acquirer Optimizer , CDE and Ad Insights. Currently, we are enhancing our customer experience with new user interfaces, utilizing new data sets and algorithms to further enhance analytical capabilities, and generating scalable big data processes.\n\nWe are looking for an innovative senior software engineering who will be responsible for the design and build of a full stack web application and data pipelines, and thrive in a fast-paced, agile environment. This individual will partner closely with other areas of the business to build and enhance solutions that drive value for our customers.\n\nEngineer will work in small, flexible teams. Every team member contributes to designing, building, and testing features. The range of work you will encounter varies from building intuitive, responsive UIs to designing backend data models, architecting data flows, and beyond.\n\nRole\n\nAs a Senior Software Engineer, you will:\n\n- participate in scoping, design and implementation of complex features.\n- Lead and push the boundaries of analytics and powerful, scalable applications.\n- Design and implement intuitive, responsive UIs that allow issuers/acquirer's/fintech's to better understand data and analytics.\n- Build and maintain analytics and data models to enable performant and scalable products.\n- Ensure a high-quality code base by writing and reviewing performant, well-tested code.\n- Mentor junior software engineers and teammates.\n- Drive innovative improvements to team development processes.\n- Partner with Product Managers and Customer Experience Designers to develop a deep understanding of users and use cases and apply that knowledge to scoping and building new modules and features.\n- Collaborate across teams with exceptional peers who are passionate about what they do.\n\nAll about you / Ideal Candidate Qualifications\n\n- 8+ years of full stack engineering experience in an agile production environment.\n- Experience leading the design and implementation of complex features in full-stack applications.\n- Experience leading a large project and working with other developers.\n- Strong technologist eager to learn new technologies and frameworks. The following is a plus:\n- Proficiency with .NET/C#, React, Redux, Typescript, Java JDK 11-17, Spring Boot, Spring Security, Maven, Hibernate / JPA, REST, and SQL Server or other object-oriented languages, front-end frameworks, and/or relational database technologies.\n- Solid experience with RESTful APIs and JSON/SOAP based API.\n- Experience with SQL, Multi-threading, Message Queuing & Distributed Systems.\n- Experience with Design Patterns.\n- Expertise in Junit or other automated unit testing frameworks.\nKnowledge of Splunk or other alerting and monitoring solutions.\n- Fluent in the use of Git, Jenkins.\n- Knowledge of cloud native development such as cloud foundry, AWS, etc.\n- Customer-centric development approach.\n- Passion for analytical / quantitative problem solving.\n- Ability to identify and implement improvements to team development processes.\n- Strong collaboration skills with experience collaborating across many people, roles, and geographies.\n- Motivation, creativity, self-direction, and desire to thrive on small project teams.\n- Superior academic record with a degree in Computer Science or related technical field.\n- Strong written and verbal English communication skills.\n\nTo find US Salary Ranges, visit People Place. Under the Compensation tab, select \"Salary Structures.\" Within the text of \"Salary Structures,\" click on the link \"salary structures 2025,\" through which you will be able to access the salary ranges for each Mastercard job family. For more information regarding US benefits, visit People Place and review the Benefits tab and the Time Off & Leave tab.",
    "url": "https://careers.mastercard.com/us/en/job/R-261022/Senior-Software-Engineer-Full-Stack-Net-React-Js?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "\u25b7 [Urgent Search] Principle software Engineer -Pune (9-15 years )",
    "company": "Energy Exemplar",
    "location": "Pune",
    "salary": "",
    "description": "About The Position\n\nReporting to the Software Engineering Manager as a member of the Development team in India, the Software Engineer is responsible for delivering quality and performant software and design to handle the vast array of use cases that our customers have today. This role is responsible for Developing Software Solutions by learning information needs, discussing with managers, studying systems flow, data usage, finding problem areas and coming up with solutions & following the software development lifecycle.\n\nLocation: 4th Floor, WeWork Amanora Crest, Amanora Park Town, Magarpatta, Hadapsar, Pune, Maharashtra 411028\n\nWork Type: Hybrid (3 days a week in office)\n\nWe Are Looking For\n\n- 9+ years of experience in product development field\n- 2+ years of recent experience in building products on cloud\n- Strong understanding of data structures, algorithms, and designing for performance\n- Strong knowledge in OOPS with .Net, C# or relevant technologies with SQL Server or any RDBMS\n- For Fullstack roles, hands-on experience in development with either Angular, VueJS or React\n- Experience with Microservices Architecture\n- Hands-on experience in building products for Unix systems in addition to Windows\n- Working knowledge of CI/CD pipelines and AWS/Azure cloud services\n- Knowledge of asynchronous programming and WebAPI development is required\n- Knowledge and awareness of cloud/ application security is a must (OWASP at the minimum)\n- Extensive experience in mentoring junior engineers to success\n- Strong logical, analytics and problem-solving skills\n- Must be able to work effectively across team boundaries\n- Attention to details\n- Strong oral and written communication skills\n\n-\n\nCandidate Requirements & Qualifications\n\n- Graduate/Master's degree in Computer Science, Engineering, or a related discipline\n- Strong logical, analytics and problem-solving skills\n- Must be able to work effectively across team boundaries\n- Attention to details\n- Ability to work independently\n\nMandate: Data structure and Algorithm, system design , Complex sql queries to write and cloud hands on experience is must",
    "url": "https://in.jobrapido.com/jobpreview/2606900169903439872?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-06T00:00:00.000Z"
  },
  {
    "title": "Software Engineering (Embedded software engineer, Full stack, DevOps)",
    "company": "Kone",
    "location": "Pune",
    "salary": "",
    "description": "Job Title : Full Stack Developer\n\nJob Location: Pune/Chennai\n\nJob Description:\n\nA Full Stack Developer is responsible for developing and maintaining both the front-end and back-end of web applications. This role involves working with a variety of technologies and languages to create fully functional platforms.\n\nResponsibilities:\n\u2022 Front-End Development: Design and implement user interfaces using HTML, CSS, and JavaScript.\n\u2022 Back-End Development: Develop server-side logic, databases, and APIs using languages like Python, Java, or Node.js.\n\u2022 Database Management: Create and manage databases to ensure data integrity and performance.\n\u2022 Integration: Integrate front-end and back-end components to create seamless applications.\n\u2022 Testing & Debugging: Test and debug applications to ensure functionality and performance.\n\u2022 Collaboration: Work with cross-functional teams to deliver high-quality software solutions.\n\nRequirements:\n\u2022 Bachelor\u2019s degree or equivalent education with over 4+ years hands-on experience.\n\u2022 Proficiency in front-end and back-end technologies.\n\u2022 Experience with databases and server management.\n\u2022 Strong problem-solving skills and attention to detail.\n\u2022 Ability to work collaboratively in a team environment\n\nJob Title: Embedded Engineer\n\nJob Location: Pune/Chennai\n\nJob Description:\n\nAn Embedded Engineer designs, develops, and maintains embedded systems and software. This role involves working with hardware and software to create efficient and reliable systems.\n\nResponsibilities:\n\u2022 System Design: Design and implement software for embedded devices and systems.\n\u2022 Development: Write and test code in languages such as C, C++, and assembly.\n\u2022 Integration: Integrate software with hardware components to ensure smooth operation.\n\u2022 Optimization: Enhance system efficiency, stability, and scalability.\n\u2022 Troubleshooting: Identify and resolve issues in embedded systems.\n\u2022 Collaboration: Work with hardware engineers and other team members to develop comprehensive solutions.\n\nRequirements:\n\u2022 Bachelor\u2019s degree or equivalent education\n\u2022 Proficiency in programming languages like C and C++.\n\u2022 Experience with embedded systems and real-time operating systems.\n\u2022 Strong analytical and problem-solving skills.\n\u2022 Ability to work effectively in a collaborative environment .\n\nAt KONE, we are focused on creating an innovative and collaborative working culture where we value the contribution of each individual. Employee engagement is a key focus area for us and we encourage participation and the sharing of information and ideas. Sustainability is an integral part of our culture and the daily practice. We follow ethical business practices and we seek to develop a culture of working together where co-workers trust and respect each other and good performance is recognized. In being a great place to work, we are proud to offer a range of experiences and opportunities that will help you to achieve your career and personal goals and enable you to live a healthy and balanced life.\n\nRead more on www.kone.com/careers",
    "url": "https://careers.kone.com/en/find-jobs/r0648551/software-engineering-embedded-software-engineer-full-stack-devops/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "Sr. Software Dev Engineer Test",
    "company": "MetLife",
    "location": "Pune",
    "salary": "",
    "description": "Requirements\n\nDescription and Requirements\n\nRole Value Proposition :\n\nMetLife is the leading provider of Group Benefits. The Group Disability technology organization is a diverse team of technologists, all working towards the common goal of ensuring the customer is at the center of everything we do. As a Sr Software Dev Engineer Tester in the Group Disability technology organization, you will be responsible for conducting thorough, hands-on testing to ensure the functionality and quality of our deliverables. You will work closely with developers, product owners, and other stakeholders to identify and resolve issues, ensuring development deliverables meet both functional and user experience standards. The ideal candidate will have a keen eye for detail and a passion for delivering high-quality results.\n\nAs a Sr Software engineer in test, you are responsible for the design, development, implementation and maintenance of solutions supporting Disability & Absence products at MetLife - products that provide income protection and job protection to millions of employees across the United States. You will collaborate closely with the Scrum Lead, Product Owner and ART Leadership. You will have an opportunity to impact every part of the system and iterate over solutions to be the very best you can be to deliver for our customers.\n\nYou will be responsible for thought leadership, creative problem solving, and applying your expertise in a complex environment. Your responsibilities include writing full stack code, reviewing code written by the team, design and development of systems, frameworks, applications, and APIs.\n\nKey Responsibilities :\n\u2022 Partners with software engineers to write efficient test automation code using coding standards and best practices. Writes manual test where automated is not supported.\n\u2022 Assist in Software Architectural Design.\n\u2022 Develop/enhance and document automated testing framework, tools and dashboards\n\u2022 Leads the planning and documenting test strategies and acceptance criteria based on customer needs\n\u2022 Leads and participates in test execution (new builds and regression), test suite grooming, analyze the reports, troubleshoot & investigate the failures. Performs peer reviews of automation codebase.\n\u2022 Investigate, diagnose and repair problems, testing bugs, and creating and managing bug reports.\n\u2022 Understanding the business processes at the feature level to pro-actively look for ways to innovate and improve the testing process to gain efficiencies.\n\nExpected behaviors:\n\u2022 A self-starter capable of acting independently and proactively requiring minimal management oversight.\n\u2022 Ability to work across cultures and geographies to encourage team to adopt best practices\n\nEducation :\n\u2022 BS/MS in Comp Science/IS.\n\nExperience : 5 to 6\n\nTechnical Skill :\n\nRequired:\n\u2022 7+ years related work experience successfully delivered on large, complex projects with demonstrated technical leadership in delivery.\n\u2022 Strong understanding of software development life cycles (SDLC), software development methodologies, and quality processes.\n\u2022 Experience with various testing types including functional, regression, integration, system, and user acceptance testing.\n\u2022 Proficient in writing clear, concise, and comprehensive test plans and test cases.\n\u2022 Experience in test-first practices, including Test Drive Development (TDD) and Behavior-Driven Development (BDD)\n\u2022 Familiarity with Agile frameworks and regression testing.\n\u2022 Experience with Tosca and Azure.\n\nPreferred:\n\u2022 BS/MS in Comp Science/IS.\n\u2022 Disability product experience or Insurance industry knowledge.\n\u2022 Experience using DevSecOps processes/tools and AI/ Co-Pilot.\n\u2022 Experience testing Web, Mobile, Data Intensive and Responsive Web Design applications.\n\u2022 Experience working in cross-functional, multi-location teams.\n\u2022 Experience in SAFe, Agile methodology, tools, and Agile integration with Waterfall.\n\nOther Critical Requirements :\n\u2022 SAFE\n\u2022 Collaboration\n\u2022 Communication/Presentation\n\u2022 Agile Practices\n\u2022 DevSecOps, CI/CD\n\u2022 Collaboration Tools\n\u2022 Product/Business/Industry Knowledge\n\u2022 Database Development tools\n\u2022 System and Technology Integration\n\u2022 Code testing, evaluation and peer\n\nreview\n\u2022 Technical Troubleshooting\n\u2022 Applicable Development\n\nLanguage\n\u2022 Writing & executing automated\n\ntests\n\u2022 Integration and Testing tools (e.g.\n\nDocker, Selenium Grid, Jenkins,\n\nLettuce, Cucumber)\n\nAbout MetLife\n\nRecognized on Fortune magazine's list of the \"World's Most Admired Companies\" and Fortune World\u2019s 25 Best Workplaces\u2122, MetLife, through its subsidiaries and affiliates, is one of the world\u2019s leading financial services companies; providing insurance, annuities, employee benefits and asset management to individual and institutional customers. With operations in more than 40 markets, we hold leading positions in the United States, Latin America, Asia, Europe, and the Middle East.\n\nOur purpose is simple - to help our colleagues, customers, communities, and the world at large create a more confident future. United by purpose and guided by our core values - Win Together, Do the Right Thing, Deliver Impact Over Activity, and Think Ahead - we\u2019re inspired to transform the next century in financial services. At MetLife, it\u2019s #AllTogetherPossible .\u202fJoin us!",
    "url": "https://in.linkedin.com/jobs/view/sr-software-dev-engineer-test-at-metlife-4321275656?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-07T00:00:00.000Z"
  },
  {
    "title": "Software Engineer - PLSQL/Oracle",
    "company": "Avaloq",
    "location": "Pune",
    "salary": "",
    "description": "It is a dynamic team of business analysts and software developers spread across development centers globally. We follow an agile process, working closely within our own team but also with other related teams and clients to develop new product features and maintain existing ones in live use.\n\nThe team works with clients and partners to develop and deliver innovative solutions to meet market demands and help shape the back-office landscape of tomorrow.\n\nAs the owner of the functionality, the team is part of many exciting and challenging projects.\n\nWe are looking for a highly motivated Software Engineer who is interested in designing and developing scalable solutions for the financial services industry.\n\nThis job represents a unique opportunity to advance your development skills and acquire banking and wealth management domain experience. You will become an expert of Avaloq core banking software and the corresponding business processes in the industry.\n\u2022 Drive the design of new product features and functionality in collaboration with business analysts, product owners, software architects and fellow developers\n\u2022 Analyze and implement customer requirements\n\u2022 Customize our software to fit our clients\u2019 needs\n\u2022 Extend Avaloq\u2019s standard product configuration\n\u2022 Provide technical support for customer projects\n\u2022 Maintain existing functionality\n\u2022 Work in an Agile environment, helping to constantly improve our processes and introduce new technologies\n\u2022 Provide support to other development teams\n\u2022 Work on interdisciplinary innovation projects\n\u2022 Ensure high quality of our software via code reviews and automated testing",
    "url": "https://www.avaloq.com/careers/job-openings/744000091553835-software-engineer-plsql-oracle?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "\u25b7 [Urgent Search] Principle software Engineer -Pune (9-15 years )",
    "company": "Energy Exemplar",
    "location": "Pune",
    "salary": "",
    "description": "About The Position\n\nReporting to the Software Engineering Manager as a member of the Development team in India, the Software Engineer is responsible for delivering quality and performant software and design to handle the vast array of use cases that our customers have today. This role is responsible for Developing Software Solutions by learning information needs, discussing with managers, studying systems flow, data usage, finding problem areas and coming up with solutions & following the software development lifecycle.\n\nLocation: 4th Floor, WeWork Amanora Crest, Amanora Park Town, Magarpatta, Hadapsar, Pune, Maharashtra 411028\n\nWork Type: Hybrid (3 days a week in office)\n\nWe Are Looking For\n\n- 9+ years of experience in product development field\n- 2+ years of recent experience in building products on cloud\n- Strong understanding of data structures, algorithms, and designing for performance\n- Strong knowledge in OOPS with .Net, C# or relevant technologies with SQL Server or any RDBMS\n- For Fullstack roles, hands-on experience in development with either Angular, VueJS or React\n- Experience with Microservices Architecture\n- Hands-on experience in building products for Unix systems in addition to Windows\n- Working knowledge of CI/CD pipelines and AWS/Azure cloud services\n- Knowledge of asynchronous programming and WebAPI development is required\n- Knowledge and awareness of cloud/ application security is a must (OWASP at the minimum)\n- Extensive experience in mentoring junior engineers to success\n- Strong logical, analytics and problem-solving skills\n- Must be able to work effectively across team boundaries\n- Attention to details\n- Strong oral and written communication skills\n\n-\n\nCandidate Requirements & Qualifications\n\n- Graduate/Master's degree in Computer Science, Engineering, or a related discipline\n- Strong logical, analytics and problem-solving skills\n- Must be able to work effectively across team boundaries\n- Attention to details\n- Ability to work independently\n\nMandate: Data structure and Algorithm, system design , Complex sql queries to write and cloud hands on experience is must",
    "url": "https://in.jobrapido.com/jobpreview/2606900169903439872?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-06T00:00:00.000Z"
  },
  {
    "title": "Senior Software Engineer - Salesforce Marketing Cloud",
    "company": "Mastercard",
    "location": "Pune",
    "salary": "",
    "description": "Job Title:\n\nSenior Software Engineer - Salesforce Marketing Cloud\n\nOverview:\n\nJob Description Summary\nSenior Software Engineer \u2013 Salesforce Marketing Cloud\n\nWho is Mastercard?\nMastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.\nOur decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.\n\nOverview\nThe Marketing Technology Solutions team at Mastercard is looking for a Senior Software Engineer with a focus on Salesforce Marketing Cloud development to design, develop, and maintain solutions that support Mastercard's B2B marketing initiatives. The primary initiative is to migrate from multiple Pardot (Marketing Cloud Engagement), HubSpot, and Marketo platforms to a single Salesforce Marketing Cloud (SFMC) marketing automation platform. This role is key in developing the custom campaigns, journeys, data extensions, automations and integrations that will support this transition and enabling advanced marketing capabilities across multiple channels. The ideal candidate is a hands-on engineer with a strong background in Salesforce Marketing Cloud implementation, customization, and development with a deep understanding of marketing automation and customer journey building. This candidate should thrive as a member of a small, collaborative team, have passion for building scalable solutions, and be committed to driving business impact through software.\n\nRole\nIn this position, you will:\n\u2022 Implement and support the migration from various multiple marketing automation platforms to a single enterprise B2B Salesforce Marketing Cloud platform.\n\u2022 Design, develop, and maintain Salesforce Marketing Cloud campaigns, journeys, data extensions, automations and integrations.\n\u2022 Develop custom Salesforce-based solutions to support Mastercard\u2019s marketing ecosystem including Lightning components, Apex code, etc.\n\u2022 Continuously monitor, troubleshoot, and optimize Salesforce Marketing Cloud to ensure performance, reliability, and scalability.\n\u2022 Work closely with cross-functional teams, including data engineers, marketing, and analytics, to integrate Salesforce Marketing Cloud with other systems and tools.\n\u2022 Collaborate with business stakeholders to understand requirements and translate them into scalable and efficient software solutions.\n\u2022 Mentor junior engineers and contribute to team knowledge sharing, ensuring adherence to best practices in software development.\n\nAll About You\nThe ideal candidate for this position should:\n\u2022 Have proven experience developing and implementing email campaigns in Salesforce Marketing Cloud.\n\u2022 Be skilled in AMPscript, SQL, and Automation Studio.\n\u2022 Be proficient in Salesforce development, including Apex, Lightning Web Components (LWC), and Salesforce APIs.\n\u2022 Have a solid understanding of web technologies and modern frameworks (JavaScript, HTML, CSS, RESTful APIs).\n\u2022 Be skilled in integration patterns, including Salesforce-to-Salesforce and RESTful API integrations.\n\u2022 Have experience in designing and building scalable, efficient, and reliable applications in Salesforce to meet the needs of global marketing initiatives.\n\u2022 Possess a strong problem-solving mindset with a focus on delivering high-quality, maintainable code.\n\u2022 Be proactive, innovative, and committed to continually improving software development processes.\n\nDesirable Capabilities:\n\u2022 Salesforce Marketing Cloud certifications preferred.\n\u2022 Knowledge of data governance, security best practices, and compliance considerations in Salesforce development.\n\u2022 Experience with Data Cloud (SFDC) and other Salesforce products is a plus.\n\u2022 Familiarity with agile development practices and tools (e.g., Jira, Git, CI/CD pipelines).\n\u2022 Strong communication skills, with the ability to collaborate effectively with both technical and non-technical stakeholders.\n\nCorporate Security Responsibility\nEvery person working for, or on behalf of, Mastercard is responsible for information security. All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and therefore, it is expected that the successful candidate for this position must:\n\n\u2022 Abide by Mastercard\u2019s security policies and practices;\n\u2022 Ensure the confidentiality and integrity of the information being accessed;\n\u2022 Report any suspected information security violation or breach, and\n\u2022 Complete all periodic mandatory security trainings in accordance with Mastercard\u2019s guidelines.\n\nTo find US Salary Ranges, visit People Place. Under the Compensation tab, select \"Salary Structures.\" Within the text of \"Salary Structures,\" click on the link \"salary structures 2025,\" through which you will be able to access the salary ranges for each Mastercard job family. For more information regarding US benefits, visit People Place and review the Benefits tab and the Time Off & Leave tab.",
    "url": "https://careers.mastercard.com/us/en/job/R-256887/Senior-Software-Engineer-Salesforce-Marketing-Cloud?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-03T00:00:00.000Z"
  },
  {
    "title": "Systems Software Engineer",
    "company": "Cloud Software Group",
    "location": "Pune",
    "salary": "",
    "description": "Job Summary:\n\nWe are seeking a highly skilled and detail-oriented Engineer and QA with hands-on experience in\ndeploying and testing applications in containerized environments using Kubernetes and\nOpenShift. This role will focus specifically on testing IBI WebFOCUS applications, and\ncandidates with prior experience or understanding of WebFOCUS will be given preference.\nThe ideal candidate should be comfortable working in Linux environments,\nand capable of scripting automation tools for different processes. Familiarity with cloud\nplatforms like AWS and GCP is also a plus.\n\nKey Responsibilities:\n\n\u25cf Deploy IBI WebFOCUS applications into Kubernetes and OpenShift clusters.\n\u25cf Develop, maintain, and execute automated and manual test cases for functional,\nregression, and integration testing.\n\u25cf Write shell scripts and automation tools to facilitate QA tasks and deployment validation.\n\u25cf Troubleshoot issues in containerized environments and collaborate with DevOps,\nDevelopers, and Product teams.\n\u25cf Assist in CI/CD pipeline integration and QA automation strategies.\n\u25cf Document test plans and test reports.\n\u25cf Contribute to continuous improvement of QA practices, tooling, and frameworks.\n\nRequired Skills & Qualifications:\n\n\u25cf Strong experience in Docker and containerization.\n\u25cf Hands-on experience with Kubernetes and OpenShift (deployment, scaling, debugging).\n\u25cf Hands-on experience with tools like Helm, helmfile, kubectl, oc, Jenkins, Git, etc.\n\u25cf Strong Linux skills, including file system, networking, and troubleshooting.\n\u25cf Proficiency in Shell scripting (Bash or similar).\n\u25cf Experience writing and maintaining test cases (manual and automated).\n\u25cf Basic knowledge of cloud platforms such as AWS or GCP.\n\nPreferred Qualifications:\n\n\u25cf Experience working with or testing IBI WebFOCUS platform.\n\u25cf Experience with CI/CD tools and practices.\n\u25cf Knowledge of application logging and monitoring tools.\n\u25cf Exposure to performance and security testing tools.\n\nAbout Us:\n\nCloud Software Group is one of the world\u2019s largest cloud solution providers, serving more than 100 million users around the globe. When you join Cloud Software Group, you are making a difference for real people, each of whom count on our suite of cloud-based products to get work done \u2014 from anywhere. Members of our team will tell you that we value passion for technology and the courage to take risks. Everyone is empowered to learn, dream, and build the future of work. We are on the brink of another Cambrian leap -- a moment of immense evolution and growth. And we need your expertise and experience to do it. Now is the perfect time to move your skills to the cloud.\n\nCloud Software Group is firmly committed to Equal Employment Opportunity (EEO) and to compliance with all federal, state and local laws that prohibit employment discrimination. All qualified applicants will receive consideration for employment without regard to age, race, color, creed, sex or gender, sexual orientation, gender identity, gender expression, ethnicity, national origin, ancestry, citizenship, religion, genetic carrier status, disability, pregnancy, childbirth or related medical conditions (including lactation status), marital status, military service, protected veteran status, political activity or affiliation, taking or requesting statutorily protected leave and other protected classifications.\n\nIf you need a reasonable accommodation due to a disability during any part of the application process, please email us at AskHR@cloud.com for assistance.",
    "url": "https://careers.cloud.com/jobs/systems-software-engineer-pune-maharashtra-india?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Senior Software Engineer",
    "company": "Johnson Controls International",
    "location": "Pune",
    "salary": "",
    "description": "\u00b7 Bachelor's Degree in Software Engineering, Computer Science or a closely related discipline. Total 10 years experience in which at least 6 years are direct hands-on software development experience.\n\n\u00b7 Proficient in Object Oriented, interface driven design and implementation\n\n\u00b7 Proficient in Microsoft .NET Framework and related development languages and tools\n\n\u00b7 Strong hand's on development experience using language such as C#, .NET, Web API and others\n\n\u00b7 Understanding of web technologies such as JavaScript, jQuery, HTMLX, XML, and JSON\n\n\u00b7 Understanding of implementing database driven and service oriented design and architecture\n\n\u00b7 Understanding modern unit testing practice and major vendor frameworks\n\n\u00b7 Understanding large scale, multi-threaded and asynchronous design and implementation\n\n\u00b7 Solid knowledge of Microsoft SQL Server database as a programming platform providing data access and related development languages and tools\n\n\u00b7 Good knowledge of Azure Cosmos DB\n\n\u00b7 Understanding of web-based communication protocols such as HTTP, HTTPS, Web Socket, UDP etc.\n\n\u00b7 Must be self-motivated and able to perform well in a collaborative team environment.\n\n\u00b7 Understanding of security protocols and models for web-based applications and development framework\n\n\u00b7 Understanding of Windows operation system, Windows based web and application server platform and their its security models\n\n\u00b7 Experience with source control systems and change management tools (e.g. Git, TFVC, GitHub etc.)\n\n\u00b7 Experience in working within a team and provide one on one coaching and leadership to other team members\n\n\u00b7 Must be comfortable with Azure DevOps tool, Jira etc.\n\n\u00b7 Excellent oral and written communication skills\n\n\u00b7 Strong analytical and problem-solving skills\n\nPreferred\n\n\u00b7 Experience with Cloud platform(Azure, GCP, or AWS)\n\n\u00b7 Knowledge of Scrum/Agile\n\n\u00b7 Experience using AI tools like GitHub Copilot as a pair programmer.\n\n\u00b7 Experience with Datawarehousing using Snowflake and Business Analytics using Power BI\n\n\u00b7 Integration experience with authentication and authorization services (OAuth, ADFS)",
    "url": "https://jobs.johnsoncontrols.com/job/WD30251257?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "Senior Software Engineer - Cloud",
    "company": "Barclays",
    "location": "Pune",
    "salary": "",
    "description": "Join us as a Senior Software Engineer - Cloud at Barclays, where you will be responsible for supporting the successful delivery of location strategy projects to plan, budget, agreed quality and governance standards. You'll spearhead the evolution of our digital landscape, driving innovation and excellence. You will harness cutting-edge technology to revolutionise our digital offerings, ensuring unparalleled customer experiences.\n\nTo be successful as a Senior Software Engineer \u2013 Cloud you should have experience with:\n\u2022 Software development experience \u2013 ideally in GoLang (preferred) or Java.\n\u2022 Experience designing, building and maintaining cloud environments in particular AWS Serverless Technology - Lambda, DynamoDB, Connect, API Gateway, Cloud Formation.\n\u2022 Considerable analytical and problem-solving skills.\n\u2022 Ability to work independently and within a team.\n\u2022 Create solution designs supporting multiple integration points on different platforms across the Bank, recognize potential performance and security issues early in the lifecycle\n\u2022 Participate in technical design discussions and present them in tech forums.\n\u2022 Produce high quality, performant and well-documented code adhering to secure coding principles.\n\u2022 Ability to drive the end-to-end software development lifecycle\n\u2022 Experience with automation at all levels of software development.\n\u2022 Work closely with Product Owners to understand business and customer problems and how our applications can help solve them\n\u2022 Manage work using both Scrum and Kanban Agile methodologies, supporting continuous improvements in team productivity whilst sensibly managing risks and issues\n\u2022 Review code changes made by others, helping to support their personal development and the overall quality and reliability of our products\n\u2022 Support releases through to production, identifying and implementing improvements to our Continuous Integration and Deployment (CI/CD) processes where relevant\n\nSome other highly valued skills may include:\n\u2022 Cloud Concepts - Strong understanding of pros and cons of Cloud Computing and Cloud Models.\n\u2022 Adaptability to a fast-paced, evolving IT landscape.\n\u2022 You will value Continuous Improvement, and work to identify and understand issues affecting quality and deliveries, in order to make effective improvements\n\u2022 Strongly customer focused and an exceptional problem solver\n\u2022 Good understanding of Engineering Practices (like XP, TDD.)\n\u2022 Good communication skills.\n\nYou may be assessed on key critical skills relevant for success in role, such as risk and controls, change and transformation, business acumen, strategic thinking and digital and technology, as well as job-specific technical skills.\n\nThis role is based out of Pune.\n\nPurpose of the role\n\nTo design, develop and improve software, utilising various engineering methodologies, that provides business, platform, and technology capabilities for our customers and colleagues.\n\nAccountabilities\n\u2022 Development and delivery of high-quality software solutions by using industry aligned programming languages, frameworks, and tools. Ensuring that code is scalable, maintainable, and optimized for performance.\n\u2022 Cross-functional collaboration with product managers, designers, and other engineers to define software requirements, devise solution strategies, and ensure seamless integration and alignment with business objectives.\n\u2022 Collaboration with peers, participate in code reviews, and promote a culture of code quality and knowledge sharing.\n\u2022 Stay informed of industry technology trends and innovations and actively contribute to the organization\u2019s technology communities to foster a culture of technical excellence and growth.\n\u2022 Adherence to secure coding practices to mitigate vulnerabilities, protect sensitive data, and ensure secure software solutions.\n\u2022 Implementation of effective unit testing practices to ensure proper code design, readability, and reliability.\n\nAssistant Vice President Expectations\n\u2022 To advise and influence decision making, contribute to policy development and take responsibility for operational effectiveness. Collaborate closely with other functions/ business divisions.\n\u2022 Lead a team performing complex tasks, using well developed professional knowledge and skills to deliver on work that impacts the whole business function. Set objectives and coach employees in pursuit of those objectives, appraisal of performance relative to objectives and determination of reward outcomes\n\u2022 If the position has leadership responsibilities, People Leaders are expected to demonstrate a clear set of leadership behaviours to create an environment for colleagues to thrive and deliver to a consistently excellent standard. The four LEAD behaviours are: L \u2013 Listen and be authentic, E \u2013 Energise and inspire, A \u2013 Align across the enterprise, D \u2013 Develop others.\n\u2022 OR for an individual contributor, they will lead collaborative assignments and guide team members through structured assignments, identify the need for the inclusion of other areas of specialisation to complete assignments. They will identify new directions for assignments and/ or projects, identifying a combination of cross functional methodologies or practices to meet required outcomes.\n\u2022 Consult on complex issues; providing advice to People Leaders to support the resolution of escalated issues.\n\u2022 Identify ways to mitigate risk and developing new policies/procedures in support of the control and governance agenda.\n\u2022 Take ownership for managing risk and strengthening controls in relation to the work done.\n\u2022 Perform work that is closely related to that of other areas, which requires understanding of how areas coordinate and contribute to the achievement of the objectives of the organisation sub-function.\n\u2022 Collaborate with other areas of work, for business aligned support areas to keep up to speed with business activity and the business strategy.\n\u2022 Engage in complex analysis of data from multiple sources of information, internal and external sources such as procedures and practises (in other areas, teams, companies, etc).to solve problems creatively and effectively.\n\u2022 Communicate complex information. 'Complex' information could include sensitive information or information that is difficult to communicate because of its content or its audience.\n\u2022 Influence or convince stakeholders to achieve outcomes.\n\nAll colleagues will be expected to demonstrate the Barclays Values of Respect, Integrity, Service, Excellence and Stewardship \u2013 our moral compass, helping us do what we believe is right. They will also be expected to demonstrate the Barclays Mindset \u2013 to Empower, Challenge and Drive \u2013 the operating manual for how we behave.",
    "url": "https://search.jobs.barclays/job/pune/senior-software-engineer-cloud/13015/84362143888?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Software Engineer II - Fullstack (Dotnet + Angular)",
    "company": "Chase- Candidate Experience page",
    "location": "Pune",
    "salary": "",
    "description": "You\u2019re ready to gain the skills and experience needed to grow within your role and advance your career \u2014 and we have the perfect software engineering opportunity for you.\n\nAs a Software Engineer II at JPMorgan Chase within the Consumer and Community Banking division, you will be part of an agile team dedicated to enhancing, designing, and delivering the software components of the firm's cutting-edge technology products in a secure, stable, and scalable manner. As an emerging member of the software engineering team, you will execute software solutions through the design, development, and technical troubleshooting of various components within a technical product, application, or system, while acquiring the skills and experience necessary to advance in your role.\n\nJob responsibilities\n\u2022 Executes standard software solutions, design, development, and technical troubleshooting\n\u2022 Writes secure and high-quality code using the syntax of at least one programming language with limited guidance\n\u2022 Designs, develops, codes, and troubleshoots with consideration of upstream and downstream systems and technical implications\n\u2022 Applies knowledge of tools within the Software Development Life Cycle toolchain to improve the value realized by automation\n\u2022 Applies technical troubleshooting to break down solutions and solve technical problems of basic complexity\n\u2022 Gathers, analyzes, and draws conclusions from large, diverse data sets to identify problems and contribute to decision-making in service of secure, stable application development\n\u2022 Learns and applies system processes, methodologies, and skills for the development of secure, stable code and systems\n\u2022 Adds to team culture of diversity, opportunity, inclusion, and respect\n\nRequired qualifications, capabilities, and skills\n\u2022 Formal training or certification on software engineering concepts and 2+ years applied experience\n\u2022 Hands on experience in programming, analytical & logical skills of C# & .net core.\n\u2022 Hands on experience in the background tasks with hosted services.\n\u2022 Experience in developing secure, high performance, highly available and complex API's.\n\u2022 Experience in AWS services like S3, SNS, SQS, Lambda, DynamoDB.\n\u2022 Experience in Micro-services architecture.\n\u2022 Good understanding of DB Design and Design Patterns\u201d for building elegant and extensible systems.\n\u2022 Excellent understanding of OOP\u2019s concepts.\n\u2022 Experience in developing secure, high performance, highly available and complex API's\n\nPreferred qualifications, capabilities, and skills\n\u2022 Familiarity with modern front-end technologies\n\u2022 Exposure to cloud technologies",
    "url": "https://jpmc.fa.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1002/job/210672849?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Software Engineer II",
    "company": "Johnson Controls International",
    "location": "Pune",
    "salary": "",
    "description": "Senior Software Engineer\n\nJob Level: Senior Software Engineer\n\nExperience Level: 4-7 Years\n\nLocation: Pune (Hybrid)\n\nReporting To: Application Delivery Lead (ADL)\n\nNotice Period: Immediate to 60 Days\n\nWhat we do:\n\nBuild your best future with the Johnson Controls team.\n\nAs a global leader with 130+ years of legacy in smart, healthy and sustainable buildings, our mission is to reimagine the performance of buildings to serve people, places and the planet. Join a winning team that enables you to build your best future! Our teams are uniquely positioned to support a multitude of industries across the globe. You will have the opportunity to develop yourself through meaningful work projects and learning opportunities. We strive to provide our employees with an experience, focused on supporting their physical, financial, and emotional wellbeing.\n\nWe are a \u201cGreat Place To Work\u201d Certified organization. Become a member of the Johnson Controls family and thrive in an empowering company culture where your voice and ideas will be heard \u2013 your next great opportunity is just a few clicks away!\n\nWhat We Offer:\n\nCompetitive salary Paid vacation/holidays/sick time. On the job/cross training opportunities. Encouraging and collaborative team environment. Dedication to safety through our Zero Harm policy.\n\nWhat you will enjoy doing:\n\nWorking on cutting edge technologies. Working on innovative products. To be part of Cross functional team.\n\nJob Description:\n\nWe at Johnson Controls are seeking experienced Software Engineers with expertise in Front End, Backend and Database. The preferred experience is in ASP.Net, C#, .Net Core, Angular 7+, React, React.Js, SQL, MySQL and Azure to join our dynamic team. The ideal candidate will have a proven track record of designing, developing, and maintaining web applications and services. This role requires a deep understanding of modern web development technologies and cloud platforms. As a Software Developer, you will be responsible for creating high-quality software solutions that meet the needs of our clients and organization.\n\nWhat You Will Do In this role:\n\nSoftware Development: Design, develop, and maintain web applications and services using any of the Frontend, Backend and Database technologies like ASP.Net, C#, Angular 11+, .Net Core, React, Java, NodeJs, SQL, MySQL, MongoDB. Front-end Development: Build responsive, user-friendly interfaces using Angular 7 or React to ensure an excellent user experience. Back-end Development: Create efficient and scalable server-side components and APIs using Asp.Net, .Net Core, C#, Java, NodeJs etc. Database Management: Design and optimize databases like SQL/MySQL/MogoDB to ensure data integrity, security, and performance. Cloud Integration: Implement and deploy applications on Azure, leveraging cloud services for scalability, reliability, and security. Code Review: Collaborate with team members to conduct code reviews, provide feedback, and ensure coding best practices are followed. Testing and Quality Assurance: Develop and execute unit tests and participate in integration testing to maintain high-quality code. Documentation: Create and maintain technical documentation, including specifications, architectural diagrams, and code documentation. Troubleshooting and Debugging: Investigate and resolve software defects and issues in a timely manner. Performance Optimization: Continuously monitor and improve application performance, security, and scalability. Adherence to Best Practices: Stay current with industry trends, best practices, and emerging technologies to ensure the software remains up-to-date and competitive. Collaboration: Work closely with cross-functional teams, including project managers, designers, and other developers to deliver projects on time and within budget.\n\nMust Have:\n\nBachelor\u2019s degree in computer science/MCA or related field. 4-7 years of Full-stack Development Experience in web technologies. Hand-on experience on of the Frontend and Backend technologies HTML, CSS, JavaScript, Angular, React, ASP.Net, C#, .Net Core, NodeJs etc. Hands-on experience of Object-Oriented concepts. Experience on database design and optimization. Ex. SQL or MySQL. Strong problem-solving and debugging skills. Innovation thinking. Experience working in Agile teams. Actively Participate in all SCRUM/SAFe ceremonies.\n\nShould Have:\n\nParticipate in designs, HLDs, LLDs, architectures etc. Participate in estimating PBIs, stories and tasks. Follow best practices and coding standards to maintain code quality. Work in fast-paced environment with cross functional teams. Demonstrate and adhere to the Agile/Lean/SAFe practices. Good hands-on experience in any of the version control or source control tools. Ex. Git, Github, Gitlab, Bitbucket, SVN etc. Experience in system testing, integration testing. Hands-on experience in writing unit test cases to ensure maximum code coverage. Strong problem-solving and debugging skills. Demonstrate newly developed features to relevant stakeholders.\n\nGood to Have:\n\nUnderstanding of Dev Ops and DevSec Ops practices. Understanding of cloud platforms like, Azure, AWS, GCloud etc. Knowledge on writing project documents. Ex. User manuals, User Guides, API Specifications, FSD etc. Experience on creating mock up\u2019s, wireframes. Designing or executing test cases for the features. Knowledge on using Microsoft tools.",
    "url": "https://jobs.johnsoncontrols.com/job/WD30251111?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-03T00:00:00.000Z"
  },
  {
    "title": "Lead Full Stack Software Engineer",
    "company": "MetLife",
    "location": "Pune",
    "salary": "",
    "description": "Requirements\n\nDescription and Requirements\n\nRole Value Proposition :\n\nMetLife is the leading provider of Group Benefits. The Group Disability technology organization is a diverse team of technologists, all working towards the common goal of ensuring the customer is at the center of everything we do. As a Senior Software Dev Engineer Tester in the Group Disability technology organization, you will be responsible for conducting thorough, hands-on testing to ensure the functionality and quality of our deliverables. You will work closely with developers, product owners, and other stakeholders to identify and resolve issues, ensuring development deliverables meet both functional and user experience standards. The ideal candidate will have a keen eye for detail and a passion for delivering high-quality results.\n\nAs a Lead full-stack engineer you are responsible for the design, development, implementation and maintenance of solutions supporting Disability & Absence products at MetLife - products that provide income protection and job protection to millions of employees across the United States. You will collaborate closely with the Scrum Lead, Product Owner and ART Leadership. You will have an opportunity to impact every part of the system and iterate over solutions to be the very best you can be to deliver for our customers.\n\nYou will be responsible for thought leadership, creative problem solving, and applying your expertise in a complex environment. Your responsibilities include writing full stack code, reviewing code written by the team, design and development of systems, frameworks, applications, and APIs.\n\nKey Responsibilties :\n\u2022 Leads the creation of architectural specifications, ensuring feasibility, functionality, and integration with existing systems/platforms. Works towards enabling self service capabilities for business partners.\n\u2022 Lead the collection and documentation of user requirements as well as lead the development of user stories and estimates into technology solutions for large complex features in collaboration with Product Owner.\n\u2022 Lead the detailed technical design and development of applications/platforms. Partner with Product owner in planning. Responsible for ensuring disaster recovery, privacy and security are aligned to enable application/platform stability. Responsible for development using multiple technology stack capabilities (Front/Back End, API, Database Mgmt, Hosting technologies, etc.), and definition of the testing stack.\n\u2022 Leads peer reviews of solution designs and related code for complex features. Ensures code meets best practice guidelines set by application/platform vendor.\n\u2022 Investigate and resolve production management incidents, problems, and service requests. Manages prioritization of problems, incidents, and service requests with Product Owner.\n\u2022 Leads team in production support activities of complex nature and/or Product. Leads the effort in upgrading or patching applications/platforms as needed.\n\u2022 Maintain awareness of trends and issues in area of technical expertise, evaluate new technologies or technology opportunities, and provide analysis of their potential impact to champion the customer\n\u2022 Hands on development with UI, Backend, Database, APIs, DevOps. Specifically React, Java, SQL, Micro services, Azure DevOps. Similar related technologies will be an asset.\n\u2022 Mentor, motivate, influence, drive innovation, and coach broader technical team. Provide technical and solution guidance to the team. Conduct design and code reviews for the team delivery.\n\u2022 Develop iterative implementation plans and strategies. Estimate user stories, as part of release plan and participate in iteration plan exercises. Responsible for developing and maintaining SRE runbooks.\n\u2022 Key participant in user story breakdowns, user story elaboration, and user story reviews\n\u2022 Serve as an escalation point for deployments, and change oversight, enabling highly visible business priorities.\n\nExpected behaviors:\n\u2022 A self-starter capable of acting independently and proactively requiring minimal management oversight.\n\u2022 Ability to work across cultures and geographies to encourage team to adopt best practices\n\nEducation :\n\nPreferred:\n\u2022 BS/MS in Comp Science/IS.\n\nExperience : 7+\n\nTechnical Skill :\n\nRequired:\n\u2022 8+ years related work experience successfully delivered on large, complex projects with demonstrated technical leadership in delivery.\n\u2022 End-to-end system design that balances the tradeoffs between technical solution, business value and operational simplicity.\n\u2022 Core hands-on development skills in JavaScript (React or Angular), Java, OOP, SQL, JSON, No-SQL (MongoDB, CosmosDB), Kubernetes, and Scripting.\n\u2022 Experience developing CRUD APIs, and critical applications from the ground up.\n\u2022 Experience with Queues/Kafka, Micro services, message brokers, integration patterns.\n\u2022 Experience developing and deploying applications using GCP or Azure OR AWS solutions.\n\u2022 Advanced knowledge of the principles in software engineering, system analysis and design, design and analysis of algorithms, computer system architecture, and data structures.\n\nPreferred:\n\u2022 BS/MS in Comp Science/IS.\n\u2022 Disability product experience or Insurance industry knowledge.\n\u2022 Experience using AI/ Co-Pilot.\n\u2022 Experience with Python.\n\u2022 Experience working in cross-functional, multi-location teams.\n\u2022 Experience in SAFe, Agile methodology, tools, and Agile integration with Waterfall.\n\nOther Critical Requirements :\n\nSAFe for Teams\n\nSAFe Scrum Master Certification (SSM)\n\u2022 Collaboration\n\u2022 Communication/Presentation\n\u2022 Agile Practices\n\u2022 Collaboration Tools\n\u2022 Product/Business/Industry Knowledge\n\u2022 Customer experience\n\nAbout MetLife\n\nRecognized on Fortune magazine's list of the \"World's Most Admired Companies\" and Fortune World\u2019s 25 Best Workplaces\u2122, MetLife, through its subsidiaries and affiliates, is one of the world\u2019s leading financial services companies; providing insurance, annuities, employee benefits and asset management to individual and institutional customers. With operations in more than 40 markets, we hold leading positions in the United States, Latin America, Asia, Europe, and the Middle East.\n\nOur purpose is simple - to help our colleagues, customers, communities, and the world at large create a more confident future. United by purpose and guided by our core values - Win Together, Do the Right Thing, Deliver Impact Over Activity, and Think Ahead - we\u2019re inspired to transform the next century in financial services. At MetLife, it\u2019s #AllTogetherPossible .\u202fJoin us!",
    "url": "https://in.linkedin.com/jobs/view/lead-full-stack-software-engineer-at-metlife-4321146038?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-07T00:00:00.000Z"
  },
  {
    "title": "Vision Plus Developer/Senior Software Engineer",
    "company": "HSBC",
    "location": "Pune",
    "salary": "",
    "description": "Some careers shine brighter than others.\n\nIf you\u2019re looking for a career that will help you stand out, join HSBC and fulfil your potential. Whether you want a career that could take you to the top, or simply take you in an exciting new direction, HSBC offers opportunities, support and rewards that will take you further.\n\nHSBC is one of the largest banking and financial services organisations in the world, with operations in 64 countries and territories. We aim to be where the growth is, enabling businesses to thrive and economies to prosper, and, ultimately, helping people to fulfil their hopes and realise their ambitions.\n\nWe are currently seeking an experienced professional to join our team in the role of Senior Software Engineer\n\u2022 Design, Code, Test, Debug, and Record COBOL programs in CICS/VSAM/JCL environment\n\u2022 Understand the Design and Requirements and develop and execute custom application features and functions\n\u2022 Understand the BRD and break the requirements into MVP\u2019s and stories\n\u2022 Create estimates for small to medium size projects\n\u2022 Create high level design and as well as analyse and develop code as per specifications\n\u2022 Follow standards and controls to ensure quality of outcome\n\u2022 Support production deployment and post development implementation activities\n\u2022 Perform application support as necessary; participate in the Crisis Calls for production incidents\n\u2022 Identify and work on system performance improvement\n\nTo be successful in this role, you should meet the following requirements:\n\u2022 5+ experience in development and maintenance of medium to complex banking applications such as credit card processing\n\u2022 Strong knowledge of VisionPLUS product.\n\u2022 Strong hands-on working knowledge in CMS module\n\u2022 Strong knowledge of COBOL and CICS\n\u2022 Well versed with Mainframe technologies such as Endevor, Changeman and batch scheduling activities.\n\u2022 Experience in design and development of medium complex problems\n\u2022 Good knowledge and experience of DevOps & Agile discipline\n\u2022 Strong interpersonal and communications skills\n\nYou\u2019ll achieve more when you join HSBC.\n\nwww.hsbc.com/careers\n\nHSBC is committed to building a culture where all employees are valued, respected and opinions count. We take pride in providing a workplace that fosters continuous professional development, flexible working and opportunities to grow within an inclusive and diverse environment. Personal data held by the Bank relating to employment applications will be used in accordance with our Privacy Statement, which is available on our website.\n\nIssued by \u2013 HSBC Software Development India",
    "url": "https://in.linkedin.com/jobs/view/vision-plus-developer-senior-software-engineer-at-hsbc-4334930166?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-07T21:00:00.000Z"
  },
  {
    "title": "Software Engineering Intern",
    "company": "Panasonic",
    "location": "Pune",
    "salary": "",
    "description": "Overview\n\nSoftware Engineering Intern\n\nWho We Are:\u202f\n\nEver wonder who brings the entertainment to your flights? Panasonic Avionics Corporation is #1 in the industry for delivering inflight products such as movies, games, WiFi, and now Bluetooth headphone connectivity!\u202f\u202f\n\nHow exciting would it be to be a part of the innovation that goes into creating technology that delights millions of people in an industry that\u2019s here to stay! Wintith our company\u2019s history spanning over 40 years, you will have stability, career growth opportunities, and will work with the brightest minds in the industry. And we are committed to a diverse and inclusive culture that will help our organization thrive! We seek diversity in many areas such as background, culture, gender, ways of thinking, skills and more.\u202f\n\nIf you want to learn more about us visit us at www.panasonic.aero. And for a full listing of open job opportunities go to www.panasonic.aero/join-us/.\u202f\u202f\n\nResponsibilities\n\nThe Position:\u202f\n\nWe are offering internship opportunities starting January 2026 for final-year students from Computer, IT, and E&TC streams. The internship will run for 4-6 months, and based on performance and business requirement, selected interns may receive full-time offers as MTS I (Software/Test) roles.\n\nAs a Software Engineer Intern, you will collaborate with experienced engineers to design, develop, and test software solutions. This internship offers hands-on experience in real-world projects, exposure to agile development practices, and an opportunity to contribute meaningfully to our technology platforms.\n\nYou will:\n\u2022 Participate in code reviews, debugging, and performance optimization.\n\u2022 Collaborate with cross-functional teams in agile sprints and stand-ups.\n\u2022 Document software features and technical specifications\n\nBenefits\n\u2022 Exposure to software development practices.\n\u2022 Mentorship from senior engineers.\n\u2022 Opportunity to convert to a full-time role based on performance\n\u2022 Assist in the development and testing of software modules and applications.\n\nQualifications\n\nWhat We\u2019re Looking For:\u202f\n\u2022 Proficiency in at least one programming language (e.g., Python, Java, C++, JavaScript)\n\u2022 Understanding of object-oriented programming and software design principles.\n\u2022 Familiarity with web technologies (HTML, CSS, JavaScript) and databases (SQL).\n\u2022 Strong analytical and problem-solving skills.\n\u2022 Ability to work independently and in a team environment\n\nPreferred Skills\n\u2022 Exposure to frameworks like React, Angular, or Node.js.\n\u2022 Experience with Git, CI/CD tools, or cloud platforms (AWS, Azure).\n\u2022 Knowledge of testing methodologies and tools.\n\nEducation\n\u2022 Pursuing a bachelor's degree in computer science, Software Engineering, Information Technology, or a related field.\n\u2022 Must be in the final year of study (4th year)\n\nOur Principles:\u202f\n\nContribution to Society | Fairness & Honesty | Cooperation & Team Spirit | Untiring Effort for Improvement | Courtesy & Humility | Adaptability | Gratitude\u202f\n\nWhat We Offer:\u202f\n\nAt Panasonic Avionics Corporation we realize the most important aspects in leading our industry are the bright minds behind everything we do. We are proud to offer our employees a highly competitive, comprehensive and flexible benefits program.\u202f\n2025-46369",
    "url": "https://careers.na.panasonic.com/jobs/46369?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-07T00:00:00.000Z"
  },
  {
    "title": "Senior Software Engineer(Java,Selenium,Rest assured, Rest API)",
    "company": "Mastercard",
    "location": "Pune",
    "salary": "",
    "description": "Our Purpose\n\nMastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we\u2019re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.\n\nTitle And Summary\n\nSenior Software Engineer(Java,Selenium,Rest assured, Rest API)\n\nOverview\n\nAs a Senior Quality Assurance Analyst on the Business Payment Service (BPS) team, you\u2019ll bring your deep expertise with modern, full-stack, test practices & tools to create world-class UX and microservice-based solutions. We\u2019re building a global business-to-business (B2B) technology platform to help businesses of all sizes streamline how they manage payments when buying or selling products & services. As a global business, the software you develop and test for Mastercard will deliver software operating at-scale, requiring focus on performance, security, and reliability.\n\nYou will work in our Mastercard tech hub in Pune, India that provides a state-of-the-art environment for technology teams to thrive in a collaborative Agile engineering culture. You will be a key part of how Mastercard transforms the B2B space to standardize, automate, and optimize digital payment efficiency for Buyers and Sellers.\n\nRole\n\u2022 Be a leading contributor to the team to plan, design and develop microservice-based solutions.\n\u2022 Create and execute test plans and cases that your team uses to verify that working software matches acceptance criteria for user stories.\n\u2022 Build automated tests using modern client and server-side frameworks & tools.\n\u2022 Deliver software with exceptional quality and security that operates at scale.\n\u2022 Perform & participate in code reviews, retrospectives, and review Pull Requests using Git.\n\u2022 Collaborate with software engineers, test engineers and product owners.\n\u2022 Coordinate with DevOps engineers on the use and automation of the build pipeline.\n\u2022 Track quality metrics and focus on continuous improvement practices\n\u2022 Provide technical leadership to test engineers.\n\u2022 Ensure that you test for 12-factor app design principles.\n\u2022 Ensure that systems you test comply with Mastercard best practices and governance models including security, operations, and Enterprise Architecture requirements.\n\nAll About You\n\u2022 You have a solid foundation in Computer Science fundamentals, web applications, and familiarity with microservices-based software architecture.\n\u2022 You have demonstrated experience working in a cross-functional, Agile software development practice.\n\u2022 You have a deep understanding of web technologies including HTML5, CSS, Javascript, and front-end frameworks such as Angular.\n\u2022 You have experience testing applications using Java and PCF.\n\u2022 You have experience testing apps using storage technologies such as PostgreSQL or Oracle and delivering solutions that leverage them at massive scale.\n\u2022 You have deep experience with automated testing and tools such as Cucumber, Selenium, Insomnia, Pact, WireMock, and REST-assured.\n\u2022 You have experience successfully releasing software in a continuous delivery model using Git.\n\u2022 You enjoy working in an Agile team focused on continuous improvement.\n\u2022 You have a strong desire to deepen your knowledge, collaborate within a team, and mentor junior test engineers.\n\u2022 You are passionate about the art of delivering the highest quality software to customers and doing the right thing.\n\u2022 You have excellent communication skills with both technical and non-technical people.\n\nCorporate Security Responsibility\n\nAll activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:\n\u2022 Abide by Mastercard\u2019s security policies and practices;\n\u2022 Ensure the confidentiality and integrity of the information being accessed;\n\u2022 Report any suspected information security violation or breach, and\n\u2022 Complete all periodic mandatory security trainings in accordance with Mastercard\u2019s guidelines.",
    "url": "https://in.linkedin.com/jobs/view/senior-software-engineer-java-selenium-rest-assured-rest-api-at-mastercard-4337859884?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-06T00:00:00.000Z"
  },
  {
    "title": "Lead Software Engineer",
    "company": "Principal Global Services",
    "location": "Pune",
    "salary": "",
    "description": "Responsibilities\n\nKey Responsibilities:\n\u2022 Exploration on Development frameworks and implement best practice, reviews and design solution\n\u2022 Coding and Development using Java/J2EE, Typescript, JSON etc.\n\u2022 Create and implement CI/CD pipeline for delivery projects\n\u2022 Research, learn and perfrom POC on new DevOps framework\n\u2022 Suggest alternate toolset and best pratice for implement\n\u2022 Help in delivery improvement by using DevOps and Automation\n\u2022 Qualifications\n\nMust Have\nEducation: Graduate - Bachelors degree (any stream)\nSkill set:\n\u2022 Engineering graduate with 8-10 years of min IT expereince.\n\n- Expertise on DevOps toolset like Jenkins, Github, AWS CI/CD pipleine, scripting etc.\n\n- Knowledge in Java/J2EE frameworks, Spring boot, Python, Typescript, Java script etc.\n\n- Knowledge on development environment and processes\n\nCompetencies:\n\u2022 Make sound business decision\n\u2022 Embrace Change\n\u2022 Build strong Partnership\n\u2022 Get results\n\u2022 Act Strategically\n\u2022 Lead Cultivate Talent",
    "url": "https://careers.principal.com/in/jobs/48140?lang=en-us&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-03T00:00:00.000Z"
  },
  {
    "title": "Software Engineer Senior Consultant I",
    "company": "Allstate",
    "location": "Pune",
    "salary": "",
    "description": "At Allstate, great things happen when our people work together to protect families and their belongings from life\u2019s uncertainties. And for more than 90 years our innovative drive has kept us a step ahead of our customers\u2019 evolving needs. From advocating for seat belts, air bags and graduated driving laws, to being an industry leader in pricing sophistication, telematics, and, more recently, device and identity protection.\n\nJob Description\nSoftware Engineer Sr Consultant I implement applications following 12-factor principles to build out the product and iterative enhancements. They own the full stack of software products; developing and implementing frontends (web or mobile), and backend services. They leverage test driven development and continuous integration to ensure agility and quality of products. They actively participate in the decision-making process of the team ensuring that the simplest appropriate technology and design is chosen to meet user needs.\n\nJob Title: Senior Software Engineer\n\nAbout Arity and Our Ad Platform Team\nArity, a technology company founded by Allstate, is transforming transportation by leveraging one of the largest driving behavior databases globally. Arity\u2019s ad platform team plays a key role in the programmatic advertising ecosystem, specifically via Arity PMP (Private Marketplace), which offers brands a unique way to reach highly targeted audiences based on driving behaviors and predictive analytics. Our team uses advanced telematics data to help insurers, advertisers, and transportation companies optimize strategies while enhancing customer experiences and reducing operational costs.\n\nJob Description\nWe are seeking a highly skilled Senior Software Engineer with 8 years of experience in software development, particularly in the .NET stack, React and AWS. The ideal candidate will have hands-on experience building and scaling microservices in a high-traffic environment. They will work closely with a high-performing team, contributing to the design, development, and deployment of our cutting-edge ad platform while expanding their knowledge of modern technologies like React, Go, and telematics-based programmatic advertising.\n\nKey Responsibilities\n\u2022 Collaborate with Architects, Engineers, and Business stakeholders to understand technical and business requirements and deliver scalable solutions.\n\u2022 Design, develop, and maintain microservices using C#, Go, React and AWS services like Lambda, S3, and RDS.\n\u2022 Participate in code reviews, design discussions, and team retrospectives to foster a collaborative and high-performance engineering culture.\n\u2022 Build and enhance CI/CD pipelines to ensure reliable and secure deployments.\n\u2022 Implement performance monitoring and optimization practices to ensure the reliability of high-transaction systems.\n\u2022 Expand technical expertise in modern stacks, including React and Go.\n\nExperience & Qualifications\n\u2022 4-8 years of professional experience in Microsoft .NET and C# development.\n\u2022 Proficiency in building and maintaining cloud-native applications, preferably on AWS.\n\u2022 Experience designing, developing, and deploying microservices in a high-traffic or real-time environment.\n\u2022 Experience in frontend technologies like React, CSS, HTML, JavaScript.\n\u2022 Familiarity with database technologies such as Redis, DynamoDB, RedShift is a plus.\n\u2022 Strong problem-solving skills, with experience working in agile, cross-functional teams.\n\u2022 Exposure to ad-tech or telematics is a plus, with a keen interest in programmatic advertising.\n\nWhy Join Us?\n\u2022 Be part of a team that is transforming how businesses leverage driving behavior data for smarter advertising.\n\u2022 Work in a collaborative, innovative, and growth-oriented environment that values learning and technical excellence.\n\u2022 Opportunities to work on advanced cloud-native architectures and cutting-edge technologies like React, Go, and big data tools.\n\nPrimary Skills\n\nShift Time\n\nRecruiter Info\nYateesh\n\nybgaa@allstate.com\n\nAbout Allstate\n\nJoining our team isn\u2019t just a job \u2014 it\u2019s an opportunity. One that takes your skills and pushes them to the next level. One that encourages you to challenge the status quo. One where you can shape the future of protection while supporting causes that mean the most to you. Joining our team means being part of something bigger \u2013 a winning team making a meaningful impact.\n\nThe Allstate Corporation is one of the largest publicly held insurance providers in the United States. Ranked No. 84 in the 2023 Fortune 500 list of the largest United States corporations by total revenue, The Allstate Corporation owns and operates 18 companies in the United States, Canada, Northern Ireland, and India. Allstate India Private Limited, also known as Allstate India, is a subsidiary of The Allstate Corporation. The India talent center was set up in 2012 and operates under the corporation's Good Hands promise. As it innovates operations and technology, Allstate India has evolved beyond its technology functions to be the critical strategic business services arm of the corporation. With offices in Bengaluru and Pune, the company offers expertise to the parent organization\u2019s business areas including technology and innovation, accounting and imaging services, policy administration, transformation solution design and support services, transformation of property liability service design, global operations and integration, and training and transition.\n\nLearn more about Allstate India here.",
    "url": "https://www.allstate.jobs/job/22607855/software-engineer-senior-consultant-i/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-03T00:00:00.000Z"
  },
  {
    "title": "Senior Systems Software Engineer",
    "company": "Cloud Software Group",
    "location": "Pune",
    "salary": "",
    "description": "About This Team:\n\nWe are seeking a highly motivated and experienced Senior Systems Software Engineer to join our ibi WebFOCUS development team.\nIn this role, you will play a crucial part in ensuring the quality and new implementation of our flagship business intelligence and analytics WebFOCUS platform.\nThe ibi WebFOCUS platform helps organizations manage and use their data to make better decisions by providing tools for data access, integration, and analysis.\nThe company provides solutions for industries like financial services, healthcare, government, and retail.\n\nAbout this Role:\n\nThe Senior Systems Software Engineer requires ~ 4 - 10 years experience working in Agile development processes.\nThe Senior Systems Software Engineer will be responsible for resolving customer implement new features based on standard Object-Oriented processes.\nSenior Systems Software Engineer requires knowledge of web-based/backend applications and quick learner who can work well independently and as part of a team.\nThe goal of the Senior Systems Software Engineer is to ensure, implement new features and resolve defects on a timely manager following Object-Oriented processes.\n\nKey Responsibilities\n\nAnalyze requirements and design specifications for New Feature implementation\nParticipates in Feature Teams and Standups\nWork with Product Management/QA and provide feedback, suggestions and improvement recommendations of product functionality, design, etc.\nImplement and maintain new Unit Tests for the CICD process.\nResolve defects on a timely manager, especially for customer defects.\nWorks closely with QA and Product Management.\nCollaborate with cross-functional teams on product features to ensure that software requirements are met\n\nRequirements\n\n-Minimum of 4 - 10 years development Experience\n-Client/Server methodology\n-Full understanding of Object-Oriented methodology\n-Windows / Unix Knowledge\n-RDBMS - MSSQL / Oracle / DB2 / PostgreSQL etc..\n-Unit testing for the CICD pipeline\n-Understanding of Software Development Life Cycle\n-Agile / Scrum Experience\n-WebFOCUS Knowledge\n\n- Strong programming skills in Java (JavaScript is a plus), expertise in Data\nStructure,Algorithms and Spring\n\n- Experience with Object-Oriented Design\n\n- Full understaning of internals for the IBI tools, enhancement and support..\n\nAbout Us:\n\nCloud Software Group is one of the world\u2019s largest cloud solution providers, serving more than 100 million users around the globe. When you join Cloud Software Group, you are making a difference for real people, each of whom count on our suite of cloud-based products to get work done \u2014 from anywhere. Members of our team will tell you that we value passion for technology and the courage to take risks. Everyone is empowered to learn, dream, and build the future of work. We are on the brink of another Cambrian leap -- a moment of immense evolution and growth. And we need your expertise and experience to do it. Now is the perfect time to move your skills to the cloud.\n\nCloud Software Group is firmly committed to Equal Employment Opportunity (EEO) and to compliance with all federal, state and local laws that prohibit employment discrimination. All qualified applicants will receive consideration for employment without regard to age, race, color, creed, sex or gender, sexual orientation, gender identity, gender expression, ethnicity, national origin, ancestry, citizenship, religion, genetic carrier status, disability, pregnancy, childbirth or related medical conditions (including lactation status), marital status, military service, protected veteran status, political activity or affiliation, taking or requesting statutorily protected leave and other protected classifications.\n\nIf you need a reasonable accommodation due to a disability during any part of the application process, please email us at AskHR@cloud.com for assistance.",
    "url": "https://careers.cloud.com/jobs/senior-systems-software-engineer-pune-maharashtra-india-9436be73-cf1e-4dac-a2f8-66c241b94f29?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Senior Software Engineer \u2013 Guidewire PolicyCenter Integration",
    "company": "EPAM Systems",
    "location": "Pune",
    "salary": "",
    "description": "EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.\n\nJoin our team as a Senior Software Engineer specializing in Guidewire PolicyCenter integration.\n\nYou will collaborate with cross-functional teams to deliver scalable and reusable integration solutions aligned with business needs. This role offers an opportunity to work on high-quality Guidewire platform projects with a focus on continuous improvement and production support. Apply now to contribute your expertise in Guidewire integrations and insurance industry processes.\n\nRESPONSIBILITIES\n\u2022 Collaborate with technical and business leaders during Guidewire PolicyCenter implementations to review requirements and estimate configuration and technical efforts\n\u2022 Design and validate technical specifications aligned with user stories and Guidewire development best practices\n\u2022 Utilize Guidewire accelerators and architectural patterns to expedite integration and product development\n\u2022 Develop code that adheres to standards, undergoes unit testing, and receives thorough peer reviews\n\u2022 Create integration solutions including batch processes, message queues, and event messaging\n\u2022 Develop integrations for both internal and external consumers using Guidewire EDGE APIs and extended models\n\u2022 Build reusable domain-based API solutions leveraging Guidewire EDGE-oriented models\n\u2022 Establish and execute unit and integration tests, automating as agreed\n\u2022 Conduct code reviews and ensure comprehensive testing in continuous integration and deployment pipelines\n\u2022 Manage code gate-checking before promotion to higher environments\n\u2022 Provide support throughout lifecycle phases including production support and maintenance\n\u2022 Lead and guide integration efforts while facilitating collaboration among teams\n\nREQUIREMENTS\n\u2022 5-8 years of experience with Guidewire PolicyCenter integration development\n\u2022 Overall 5+ years of experience in web-based Java/J2EE or .NET application development\n\u2022 Strong expertise in Guidewire Edge APIs with experience exposing Guidewire functionality to external consumers\n\u2022 Advanced knowledge of XML, JSON, and SQL\n\u2022 Experience with transactional, account, and user-management integrations involving Guidewire PolicyCenter\n\u2022 Proficiency in web service hosting and consumption using Guidewire EDGE Layer\n\u2022 Background in designing and developing REST APIs or web services to expose Guidewire features\n\u2022 Experience leading offshore teams preferred\n\u2022 Familiarity with the commercial property and casualty insurance industry\n\u2022 Competency in Agile methodologies and tools such as TFS, Rally, or JIRA\n\u2022 Experience with source control tools like GIT or TFS\n\u2022 Strong understanding of Guidewire integration concepts, including batch processing, message queues, and event processing\n\u2022 Proficient problem-solving and analytical skills\n\u2022 Capability to manage multiple tasks and deadlines effectively\n\nNICE TO HAVE\n\u2022 Experience with Guidewire Product Designer, GX Model, and Product Model development\n\u2022 Leadership experience in offshore team management\n\u2022 Knowledge of reconciliation processes within insurance integrations\n\nWE OFFER\n\u2022 Opportunity to work on technical challenges that may impact across geographies\n\u2022 Vast opportunities for self-development: online university, knowledge sharing opportunities globally, learning opportunities through external certifications\n\u2022 Opportunity to share your ideas on international platforms\n\u2022 Sponsored Tech Talks & Hackathons\n\u2022 Unlimited access to LinkedIn learning solutions\n\u2022 Possibility to relocate to any EPAM office for short and long-term projects\n\u2022 Focused individual development\n\u2022 Benefit package\n\u2022 Health benefits\n\u2022 Retirement benefits\n\u2022 Paid time off\n\u2022 Flexible benefits\n\u2022 Forums to explore beyond work passion (CSR, photography, painting, sports, etc.)",
    "url": "https://www.epam.com/careers/job-listings/job.epamgdo_bltjxafrp5o0svuprgv_en-us_Pune_India.senior-software-engineer-guidewire-policycenter-integration_pune_india?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Software Engineer Advanced- Python Major -Java AI",
    "company": "Siemens Digital Industries Software",
    "location": "Pune",
    "salary": "",
    "description": "Siemens Digital Industries Software is a leading provider of solutions for the design, simulation, and manufacture of products across many different industries. Formula 1 cars, skyscrapers, ships, space exploration vehicles, and many of the objects we see in our daily lives are being conceived and manufactured using our Product Lifecycle Management (PLM) software\n\nWe are seeking AI Backend Engineers to play a pivotal role in building our Agentic Workflow Service and Retrieval-Augmented Generation (RAG) Service. In this hybrid role, you'll leverage your expertise in both backend development and machine learning to create robust, scalable AI-powered systems using AWS Kubernetes, Amazon Bedrock models, AWS Strands Framework, and LangChain / LangGraph.\n\nKey Requirements\n\u2022 Design and implement core backend services and APIs for agentic framework and RAG systems\n\u2022 LLM-based applications using Amazon Bedrock models\n\u2022 RAG systems with advanced retrieval mechanisms and vector database integration\n\u2022 Implement agentic workflows using technologies such as AWS Strands Framework, LangChain / LangGraph\n\u2022 Design and develop microservices that efficiently integrate AI capabilities\n\u2022 Create scalable data processing pipelines for training data and document ingestion\n\u2022 Optimize model performance, inference latency, and overall system efficiency\n\u2022 Implement evaluation metrics and monitoring for AI components\n\u2022 Write clean, maintainable, and well-tested code with comprehensive documentation\n\u2022 Collaborate with multiple cross-functional team members including DevOps, product, and frontend engineers\n\u2022 Stay current with the latest advancements in LLMs and AI agent architectures\n\nQualifications :\n\u2022 3 to 9 years of total software engineering experience\n\u2022 Backend development experience with strong Python programming skills\n\u2022 Experience in ML/AI engineering, particularly with LLMs and generative AI applications\n\u2022 Experience with microservices architecture, API design, and asynchronous programming\n\u2022 Demonstrated experience building RAG systems and working with vector databases\n\u2022 LangChain/LangGraph or similar LLM orchestration frameworks\n\u2022 Strong knowledge of AWS services, particularly Bedrock, Lambda, and container services\n\u2022 Experience with containerization technologies and Kubernetes\n\u2022 Understanding of ML model deployment, serving, and monitoring in production environments\n\u2022 Knowledge of prompt engineering and LLM fine-tuning techniques\n\u2022 Excellent problem-solving abilities and system design skills\n\u2022 Strong communication skills and ability to explain complex technical concepts\n\u2022 Experience in Kubernetes, AWS Serverless\n\u2022 Experience in working with Databases (SQL, NoSQL) and data structures\n\u2022 Ability to learn new technologies quickly\n\u2022 Must have AWS certifications - Associate Architect / Developer / Data Engineer / AI Track\n\u2022 Must have familiarity with streaming architectures and real-time data processing\n\u2022 Must have experience with ML experiment tracking and model versioning\n\u2022 Must have understanding of ML/AI ethics and responsible AI development\n\u2022 Experience with AWS Strands Framework\n\u2022 Knowledge of semantic search and embedding models\n\u2022 Contributions to open-source ML/AI projects\n\nWe are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, veteran status, or disability status.\n\nWe are Siemens\n\nA collection of over 377,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit, and business need. Bring your curiosity and creativity and help us shape tomorrow! We offer a comprehensive reward package which includes a competitive basic salary, bonus scheme, generous holiday allowance, pension, and private healthcare.\n\nSiemens Software. \u2018Transform the everyday'\n\n,\n\n#SWSaaS",
    "url": "https://in.linkedin.com/jobs/view/software-engineer-advanced-python-major-java-ai-at-siemens-digital-industries-software-4321198096?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-07T00:00:00.000Z"
  },
  {
    "title": "IT Software Developer",
    "company": "Siemens",
    "location": "Pune",
    "salary": "",
    "description": "Hello eager tech expert!\n\nTo create a better future, you need to think outside the box. That\u2019s why we at Siemens need innovators who aren\u2019t afraid to push boundaries to join our diverse team of tech gurus. Got what it takes? Then help us create lasting, positive impact!\n\nSiemens Financial Services IT is establishing a strategic Tech Hub in India to drive our digital transformation initiatives worldwide. This isn't just a job \u2013 it's an opportunity to build your international career while working with cutting-edge technologies that power financial operations across the globe.\n\nWe are looking for a Senior Low Code Developer to join our Chapter Process Digitalization.\n\nWe are a self-organized, multidisciplinary, team developing innovative solutions for Siemens Financial Services. Our jointly defined purpose is: \u201cWith our deep business knowledge, low-code skills, and service mindset, we create financial solutions to accelerate digitalization of business processes from requirement-engineering to quality-centered delivery, so that our colleagues & customers are happy, efficient, and successful.\u201d\n\nYou\u2019ll break new ground by:\n\u2022 Participate in intakes and provide estimations for potential upcoming projects.\n\u2022 Develop new applications in Scrum teams for projects delivered worldwide.\n\u2022 Enhance and support existing applications.\n\u2022 Be the go-to person for all architectural and central technical topics.\n\u2022 Be responsible for our Developer Guidelines.\n\u2022 Be responsible for the Quality Gates in our projects/applications.\n\u2022 Be responsible for the implementation of core components and the development of our technological roadmap.\n\u2022 Provide guidance and instructions to other team members, coaching younger talents (e.g. trainees).\n\nYou\u2019re excited to build on your existing expertise, including:\n\u2022 Master\u2019s degree in computer science, Mathematics, Engineering, or in a related field.\n\u2022 Proven track record with at least 3 years of working experience on agile projects as a software developer.\n\u2022 Experience in translating customer requirements, conception, and presentation of solutions.\n\u2022 Quick understanding of business processes and requirements in a financial context.\n\u2022 Motivation to meet deadlines, hands-on mentality, flexibility, proactivity, and willingness to learn new technologies.\n\u2022 Disposition to grow further, learn new technologies, and help others grow along.\n\u2022 Good communication and organizational skills.\n\u2022 Business fluent English written and spoken; German proficiency would be nice to have.\n\u2022 Experience with Mendix is highly valued.\n\u2022 Experience in other low-code development platforms is also valued (e.g. Outsystems).\n\u2022 Experience in IT projects in a financial context or any financial qualification.\n\u2022 Open mentality and eagerness to learn everyday.\n\nCreate a better #TomorrowWithUs!\n\nWe value your unique identity and perspective and are fully committed to providing equitable opportunities and building a workplace that reflects the diversity of society. Come bring your authentic self and create a better tomorrow with us.\n\nProtecting the environment, conserving our natural resources, fostering the health and performance of our people as well as safeguarding their working conditions are core to our social and business commitment at Siemens.\n\nThis role is based in Pune. You\u2019ll also get to visit other locations in India and beyond, so you\u2019ll need to go where this journey takes you. In return, you\u2019ll get the chance to work with an international team and working on global topics.",
    "url": "https://in.linkedin.com/jobs/view/it-software-developer-at-siemens-4320825459?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Principle software Engineer -Pune (9-15 years )",
    "company": "Energy Exemplar",
    "location": "Pune",
    "salary": "",
    "description": "About The Position\n\nReporting to the Software Engineering Manager as a member of the Development team in India, the Software Engineer is responsible for delivering quality and performant software and design to handle the vast array of use cases that our customers have today. This role is responsible for Developing Software Solutions by learning information needs, discussing with managers, studying systems flow, data usage, finding problem areas and coming up with solutions & following the software development lifecycle.\n\nLocation: 4th Floor, WeWork Amanora Crest, Amanora Park Town, Magarpatta, Hadapsar, Pune, Maharashtra 411028\n\nWork Type: Hybrid (3 days a week in office)\n\nWe Are Looking For\n\u2022 9+ years of experience in product development field\n\u2022 2+ years of recent experience in building products on cloud\n\u2022 Strong understanding of data structures, algorithms, and designing for performance\n\u2022 Strong knowledge in OOPS with .Net, C# or relevant technologies with SQL Server or any RDBMS\n\u2022 For Fullstack roles, hands-on experience in development with either Angular, VueJS or React\n\u2022 Experience with Microservices Architecture\n\u2022 Hands-on experience in building products for Unix systems in addition to Windows\n\u2022 Working knowledge of CI/CD pipelines and AWS/Azure cloud services\n\u2022 Knowledge of asynchronous programming and WebAPI development is required\n\u2022 Knowledge and awareness of cloud/ application security is a must (OWASP at the minimum)\n\u2022 Extensive experience in mentoring junior engineers to success\n\u2022 Strong logical, analytics and problem-solving skills\n\u2022 Must be able to work effectively across team boundaries\n\u2022 Attention to details\n\u2022 Strong oral and written communication skills\n\nCandidate Requirements & Qualifications\n\u2022 Graduate/Master's degree in Computer Science, Engineering, or a related discipline\n\u2022 Strong logical, analytics and problem-solving skills\n\u2022 Must be able to work effectively across team boundaries\n\u2022 Attention to details\n\u2022 Ability to work independently\n\nMandate: Data structure and Algorithm, system design , Complex sql queries to write and cloud hands on experience is must",
    "url": "https://in.jooble.org/jdp/5257435270169579862?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Systems Software Engineer",
    "company": "Cloud Software Group",
    "location": "Pune",
    "salary": "",
    "description": "Job Summary:\n\nWe are seeking a highly skilled and detail-oriented Engineer and QA with hands-on experience in\ndeploying and testing applications in containerized environments using Kubernetes and\nOpenShift. This role will focus specifically on testing IBI WebFOCUS applications, and\ncandidates with prior experience or understanding of WebFOCUS will be given preference.\nThe ideal candidate should be comfortable working in Linux environments,\nand capable of scripting automation tools for different processes. Familiarity with cloud\nplatforms like AWS and GCP is also a plus.\n\nKey Responsibilities:\n\n\u25cf Deploy IBI WebFOCUS applications into Kubernetes and OpenShift clusters.\n\u25cf Develop, maintain, and execute automated and manual test cases for functional,\nregression, and integration testing.\n\u25cf Write shell scripts and automation tools to facilitate QA tasks and deployment validation.\n\u25cf Troubleshoot issues in containerized environments and collaborate with DevOps,\nDevelopers, and Product teams.\n\u25cf Assist in CI/CD pipeline integration and QA automation strategies.\n\u25cf Document test plans and test reports.\n\u25cf Contribute to continuous improvement of QA practices, tooling, and frameworks.\n\nRequired Skills & Qualifications:\n\n\u25cf Strong experience in Docker and containerization.\n\u25cf Hands-on experience with Kubernetes and OpenShift (deployment, scaling, debugging).\n\u25cf Hands-on experience with tools like Helm, helmfile, kubectl, oc, Jenkins, Git, etc.\n\u25cf Strong Linux skills, including file system, networking, and troubleshooting.\n\u25cf Proficiency in Shell scripting (Bash or similar).\n\u25cf Experience writing and maintaining test cases (manual and automated).\n\u25cf Basic knowledge of cloud platforms such as AWS or GCP.\n\nPreferred Qualifications:\n\n\u25cf Experience working with or testing IBI WebFOCUS platform.\n\u25cf Experience with CI/CD tools and practices.\n\u25cf Knowledge of application logging and monitoring tools.\n\u25cf Exposure to performance and security testing tools.\n\nAbout Us:\n\nCloud Software Group is one of the world\u2019s largest cloud solution providers, serving more than 100 million users around the globe. When you join Cloud Software Group, you are making a difference for real people, each of whom count on our suite of cloud-based products to get work done \u2014 from anywhere. Members of our team will tell you that we value passion for technology and the courage to take risks. Everyone is empowered to learn, dream, and build the future of work. We are on the brink of another Cambrian leap -- a moment of immense evolution and growth. And we need your expertise and experience to do it. Now is the perfect time to move your skills to the cloud.\n\nCloud Software Group is firmly committed to Equal Employment Opportunity (EEO) and to compliance with all federal, state and local laws that prohibit employment discrimination. All qualified applicants will receive consideration for employment without regard to age, race, color, creed, sex or gender, sexual orientation, gender identity, gender expression, ethnicity, national origin, ancestry, citizenship, religion, genetic carrier status, disability, pregnancy, childbirth or related medical conditions (including lactation status), marital status, military service, protected veteran status, political activity or affiliation, taking or requesting statutorily protected leave and other protected classifications.\n\nIf you need a reasonable accommodation due to a disability during any part of the application process, please email us at AskHR@cloud.com for assistance.",
    "url": "https://careers.cloud.com/jobs/systems-software-engineer-pune-maharashtra-india?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Software Engineer II - Fullstack (Dotnet + Angular)",
    "company": "Chase- Candidate Experience page",
    "location": "Pune",
    "salary": "",
    "description": "You\u2019re ready to gain the skills and experience needed to grow within your role and advance your career \u2014 and we have the perfect software engineering opportunity for you.\n\nAs a Software Engineer II at JPMorgan Chase within the Consumer and Community Banking division, you will be part of an agile team dedicated to enhancing, designing, and delivering the software components of the firm's cutting-edge technology products in a secure, stable, and scalable manner. As an emerging member of the software engineering team, you will execute software solutions through the design, development, and technical troubleshooting of various components within a technical product, application, or system, while acquiring the skills and experience necessary to advance in your role.\n\nJob responsibilities\n\u2022 Executes standard software solutions, design, development, and technical troubleshooting\n\u2022 Writes secure and high-quality code using the syntax of at least one programming language with limited guidance\n\u2022 Designs, develops, codes, and troubleshoots with consideration of upstream and downstream systems and technical implications\n\u2022 Applies knowledge of tools within the Software Development Life Cycle toolchain to improve the value realized by automation\n\u2022 Applies technical troubleshooting to break down solutions and solve technical problems of basic complexity\n\u2022 Gathers, analyzes, and draws conclusions from large, diverse data sets to identify problems and contribute to decision-making in service of secure, stable application development\n\u2022 Learns and applies system processes, methodologies, and skills for the development of secure, stable code and systems\n\u2022 Adds to team culture of diversity, opportunity, inclusion, and respect\n\nRequired qualifications, capabilities, and skills\n\u2022 Formal training or certification on software engineering concepts and 2+ years applied experience\n\u2022 Hands on experience in programming, analytical & logical skills of C# & .net core.\n\u2022 Hands on experience in the background tasks with hosted services.\n\u2022 Experience in developing secure, high performance, highly available and complex API's.\n\u2022 Experience in AWS services like S3, SNS, SQS, Lambda, DynamoDB.\n\u2022 Experience in Micro-services architecture.\n\u2022 Good understanding of DB Design and Design Patterns\u201d for building elegant and extensible systems.\n\u2022 Excellent understanding of OOP\u2019s concepts.\n\u2022 Experience in developing secure, high performance, highly available and complex API's\n\nPreferred qualifications, capabilities, and skills\n\u2022 Familiarity with modern front-end technologies\n\u2022 Exposure to cloud technologies",
    "url": "https://jpmc.fa.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1002/job/210672849?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Senior Software Engineer",
    "company": "Johnson Controls International",
    "location": "Pune",
    "salary": "",
    "description": "\u00b7 Bachelor's Degree in Software Engineering, Computer Science or a closely related discipline. Total 10 years experience in which at least 6 years are direct hands-on software development experience.\n\n\u00b7 Proficient in Object Oriented, interface driven design and implementation\n\n\u00b7 Proficient in Microsoft .NET Framework and related development languages and tools\n\n\u00b7 Strong hand's on development experience using language such as C#, .NET, Web API and others\n\n\u00b7 Understanding of web technologies such as JavaScript, jQuery, HTMLX, XML, and JSON\n\n\u00b7 Understanding of implementing database driven and service oriented design and architecture\n\n\u00b7 Understanding modern unit testing practice and major vendor frameworks\n\n\u00b7 Understanding large scale, multi-threaded and asynchronous design and implementation\n\n\u00b7 Solid knowledge of Microsoft SQL Server database as a programming platform providing data access and related development languages and tools\n\n\u00b7 Good knowledge of Azure Cosmos DB\n\n\u00b7 Understanding of web-based communication protocols such as HTTP, HTTPS, Web Socket, UDP etc.\n\n\u00b7 Must be self-motivated and able to perform well in a collaborative team environment.\n\n\u00b7 Understanding of security protocols and models for web-based applications and development framework\n\n\u00b7 Understanding of Windows operation system, Windows based web and application server platform and their its security models\n\n\u00b7 Experience with source control systems and change management tools (e.g. Git, TFVC, GitHub etc.)\n\n\u00b7 Experience in working within a team and provide one on one coaching and leadership to other team members\n\n\u00b7 Must be comfortable with Azure DevOps tool, Jira etc.\n\n\u00b7 Excellent oral and written communication skills\n\n\u00b7 Strong analytical and problem-solving skills\n\nPreferred\n\n\u00b7 Experience with Cloud platform(Azure, GCP, or AWS)\n\n\u00b7 Knowledge of Scrum/Agile\n\n\u00b7 Experience using AI tools like GitHub Copilot as a pair programmer.\n\n\u00b7 Experience with Datawarehousing using Snowflake and Business Analytics using Power BI\n\n\u00b7 Integration experience with authentication and authorization services (OAuth, ADFS)",
    "url": "https://jobs.johnsoncontrols.com/job/WD30251257?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "Software Engineer - PLSQL/Oracle",
    "company": "Avaloq",
    "location": "Pune",
    "salary": "",
    "description": "It is a dynamic team of business analysts and software developers spread across development centers globally. We follow an agile process, working closely within our own team but also with other related teams and clients to develop new product features and maintain existing ones in live use.\n\nThe team works with clients and partners to develop and deliver innovative solutions to meet market demands and help shape the back-office landscape of tomorrow.\n\nAs the owner of the functionality, the team is part of many exciting and challenging projects.\n\nWe are looking for a highly motivated Software Engineer who is interested in designing and developing scalable solutions for the financial services industry.\n\nThis job represents a unique opportunity to advance your development skills and acquire banking and wealth management domain experience. You will become an expert of Avaloq core banking software and the corresponding business processes in the industry.\n\u2022 Drive the design of new product features and functionality in collaboration with business analysts, product owners, software architects and fellow developers\n\u2022 Analyze and implement customer requirements\n\u2022 Customize our software to fit our clients\u2019 needs\n\u2022 Extend Avaloq\u2019s standard product configuration\n\u2022 Provide technical support for customer projects\n\u2022 Maintain existing functionality\n\u2022 Work in an Agile environment, helping to constantly improve our processes and introduce new technologies\n\u2022 Provide support to other development teams\n\u2022 Work on interdisciplinary innovation projects\n\u2022 Ensure high quality of our software via code reviews and automated testing",
    "url": "https://www.avaloq.com/careers/job-openings/744000091553835-software-engineer-plsql-oracle?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Senior Software Engineer - Full Stack (.Net, React.Js)",
    "company": "Mastercard",
    "location": "Pune",
    "salary": "",
    "description": "Job Title:\n\nSenior Software Engineer - Full Stack (.Net, React.Js)\n\nOverview:\n\nOverview\n\nWe are the global technology company behind the world\u2019s fastest payments processing network. We are a vehicle for commerce, a connection to financial systems for the previously excluded, a technology innovation lab, and the home of Priceless\u00ae. We ensure every employee has the opportunity to be a part of something bigger and to change lives. We believe as our company grows, so should you. We believe in connecting everyone to endless, priceless possibilities.\n\nOur team within Mastercard \u2013 Services within Mastercard:\n\nServices within Mastercard is responsible for acquiring, engaging, and retaining customers by managing fraud and risk, enhancing cybersecurity, and improving the digital payments experience. We provide value-added services and leverage expertise, data-driven insights, and execution.\n\nData Analytics and AI Solution:\n\nWithin the Services Technology Team, the Data Analytics and AI Solution program that is comprised of a rich set of products that provide accurate perspectives on Portfolio Optimization, Acquirer Optimizer , CDE and Ad Insights. Currently, we are enhancing our customer experience with new user interfaces, utilizing new data sets and algorithms to further enhance analytical capabilities, and generating scalable big data processes.\n\nWe are looking for an innovative senior software engineering who will be responsible for the design and build of a full stack web application and data pipelines, and thrive in a fast-paced, agile environment. This individual will partner closely with other areas of the business to build and enhance solutions that drive value for our customers.\n\nEngineer will work in small, flexible teams. Every team member contributes to designing, building, and testing features. The range of work you will encounter varies from building intuitive, responsive UIs to designing backend data models, architecting data flows, and beyond.\n\nRole\n\nAs a Senior Software Engineer, you will:\n\n- participate in scoping, design and implementation of complex features.\n- Lead and push the boundaries of analytics and powerful, scalable applications.\n- Design and implement intuitive, responsive UIs that allow issuers/acquirer's/fintech's to better understand data and analytics.\n- Build and maintain analytics and data models to enable performant and scalable products.\n- Ensure a high-quality code base by writing and reviewing performant, well-tested code.\n- Mentor junior software engineers and teammates.\n- Drive innovative improvements to team development processes.\n- Partner with Product Managers and Customer Experience Designers to develop a deep understanding of users and use cases and apply that knowledge to scoping and building new modules and features.\n- Collaborate across teams with exceptional peers who are passionate about what they do.\n\nAll about you / Ideal Candidate Qualifications\n\n- 8+ years of full stack engineering experience in an agile production environment.\n- Experience leading the design and implementation of complex features in full-stack applications.\n- Experience leading a large project and working with other developers.\n- Strong technologist eager to learn new technologies and frameworks. The following is a plus:\n- Proficiency with .NET/C#, React, Redux, Typescript, Java JDK 11-17, Spring Boot, Spring Security, Maven, Hibernate / JPA, REST, and SQL Server or other object-oriented languages, front-end frameworks, and/or relational database technologies.\n- Solid experience with RESTful APIs and JSON/SOAP based API.\n- Experience with SQL, Multi-threading, Message Queuing & Distributed Systems.\n- Experience with Design Patterns.\n- Expertise in Junit or other automated unit testing frameworks.\nKnowledge of Splunk or other alerting and monitoring solutions.\n- Fluent in the use of Git, Jenkins.\n- Knowledge of cloud native development such as cloud foundry, AWS, etc.\n- Customer-centric development approach.\n- Passion for analytical / quantitative problem solving.\n- Ability to identify and implement improvements to team development processes.\n- Strong collaboration skills with experience collaborating across many people, roles, and geographies.\n- Motivation, creativity, self-direction, and desire to thrive on small project teams.\n- Superior academic record with a degree in Computer Science or related technical field.\n- Strong written and verbal English communication skills.\n\nTo find US Salary Ranges, visit People Place. Under the Compensation tab, select \"Salary Structures.\" Within the text of \"Salary Structures,\" click on the link \"salary structures 2025,\" through which you will be able to access the salary ranges for each Mastercard job family. For more information regarding US benefits, visit People Place and review the Benefits tab and the Time Off & Leave tab.",
    "url": "https://careers.mastercard.com/us/en/job/R-261022/Senior-Software-Engineer-Full-Stack-Net-React-Js?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Software Engineering (Embedded software engineer, Full stack, DevOps)",
    "company": "Kone",
    "location": "Pune",
    "salary": "",
    "description": "Job Title : Full Stack Developer\n\nJob Location: Pune/Chennai\n\nJob Description:\n\nA Full Stack Developer is responsible for developing and maintaining both the front-end and back-end of web applications. This role involves working with a variety of technologies and languages to create fully functional platforms.\n\nResponsibilities:\n\u2022 Front-End Development: Design and implement user interfaces using HTML, CSS, and JavaScript.\n\u2022 Back-End Development: Develop server-side logic, databases, and APIs using languages like Python, Java, or Node.js.\n\u2022 Database Management: Create and manage databases to ensure data integrity and performance.\n\u2022 Integration: Integrate front-end and back-end components to create seamless applications.\n\u2022 Testing & Debugging: Test and debug applications to ensure functionality and performance.\n\u2022 Collaboration: Work with cross-functional teams to deliver high-quality software solutions.\n\nRequirements:\n\u2022 Bachelor\u2019s degree or equivalent education with over 4+ years hands-on experience.\n\u2022 Proficiency in front-end and back-end technologies.\n\u2022 Experience with databases and server management.\n\u2022 Strong problem-solving skills and attention to detail.\n\u2022 Ability to work collaboratively in a team environment\n\nJob Title: Embedded Engineer\n\nJob Location: Pune/Chennai\n\nJob Description:\n\nAn Embedded Engineer designs, develops, and maintains embedded systems and software. This role involves working with hardware and software to create efficient and reliable systems.\n\nResponsibilities:\n\u2022 System Design: Design and implement software for embedded devices and systems.\n\u2022 Development: Write and test code in languages such as C, C++, and assembly.\n\u2022 Integration: Integrate software with hardware components to ensure smooth operation.\n\u2022 Optimization: Enhance system efficiency, stability, and scalability.\n\u2022 Troubleshooting: Identify and resolve issues in embedded systems.\n\u2022 Collaboration: Work with hardware engineers and other team members to develop comprehensive solutions.\n\nRequirements:\n\u2022 Bachelor\u2019s degree or equivalent education\n\u2022 Proficiency in programming languages like C and C++.\n\u2022 Experience with embedded systems and real-time operating systems.\n\u2022 Strong analytical and problem-solving skills.\n\u2022 Ability to work effectively in a collaborative environment .\n\nAt KONE, we are focused on creating an innovative and collaborative working culture where we value the contribution of each individual. Employee engagement is a key focus area for us and we encourage participation and the sharing of information and ideas. Sustainability is an integral part of our culture and the daily practice. We follow ethical business practices and we seek to develop a culture of working together where co-workers trust and respect each other and good performance is recognized. In being a great place to work, we are proud to offer a range of experiences and opportunities that will help you to achieve your career and personal goals and enable you to live a healthy and balanced life.\n\nRead more on www.kone.com/careers",
    "url": "https://careers.kone.com/en/find-jobs/r0648551/software-engineering-embedded-software-engineer-full-stack-devops/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "\u25b7 [Urgent Search] Principle software Engineer -Pune (9-15 years )",
    "company": "Energy Exemplar",
    "location": "Pune",
    "salary": "",
    "description": "About The Position\n\nReporting to the Software Engineering Manager as a member of the Development team in India, the Software Engineer is responsible for delivering quality and performant software and design to handle the vast array of use cases that our customers have today. This role is responsible for Developing Software Solutions by learning information needs, discussing with managers, studying systems flow, data usage, finding problem areas and coming up with solutions & following the software development lifecycle.\n\nLocation: 4th Floor, WeWork Amanora Crest, Amanora Park Town, Magarpatta, Hadapsar, Pune, Maharashtra 411028\n\nWork Type: Hybrid (3 days a week in office)\n\nWe Are Looking For\n\n- 9+ years of experience in product development field\n- 2+ years of recent experience in building products on cloud\n- Strong understanding of data structures, algorithms, and designing for performance\n- Strong knowledge in OOPS with .Net, C# or relevant technologies with SQL Server or any RDBMS\n- For Fullstack roles, hands-on experience in development with either Angular, VueJS or React\n- Experience with Microservices Architecture\n- Hands-on experience in building products for Unix systems in addition to Windows\n- Working knowledge of CI/CD pipelines and AWS/Azure cloud services\n- Knowledge of asynchronous programming and WebAPI development is required\n- Knowledge and awareness of cloud/ application security is a must (OWASP at the minimum)\n- Extensive experience in mentoring junior engineers to success\n- Strong logical, analytics and problem-solving skills\n- Must be able to work effectively across team boundaries\n- Attention to details\n- Strong oral and written communication skills\n\n-\n\nCandidate Requirements & Qualifications\n\n- Graduate/Master's degree in Computer Science, Engineering, or a related discipline\n- Strong logical, analytics and problem-solving skills\n- Must be able to work effectively across team boundaries\n- Attention to details\n- Ability to work independently\n\nMandate: Data structure and Algorithm, system design , Complex sql queries to write and cloud hands on experience is must",
    "url": "https://in.jobrapido.com/jobpreview/2606900169903439872?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-06T00:00:00.000Z"
  },
  {
    "title": "Lead Frontend Developer",
    "company": "OptiBridge Technologies",
    "location": "Pune",
    "salary": "",
    "description": "About Us:\n\nOptiBridge Technologies is an ambitious startup on a mission to build AI-powered applications. We are building the future from the ground up, leveraging cutting-edge technology on cloud and AI-driven development to create a product that will redefine the vertical. We are looking for a visionary, hands-on builder to join us as a senior engineer.\n\nPosition Overview:\n\nThis isn't just another developer role; this is a chance to be a Senior Engineer. We are looking for an entrepreneurial and highly skilled Front end Developer in our front end team. You will have unparalleled impact, making critical decisions and writing the code that will form the core of our web and mobile platforms. You will work independently, translating vision and requirements into robust, scalable software. A key part of our strategy is using AI tools to accelerate our development, and you will be central to implementing and championing this modern approach.\n\nKey Responsibilities:\n\nFoundational Leadership: Play a pivotal role in shaping the technical roadmap, and architectural best practices from the ground up.\n\nCloud Architecture & Deployment: Design, deploy, and manage scalable, secure, and cost-effective cloud infrastructure on Azure.\n\nEnd-to-End Front-end Development: Take complete ownership of features, its development, testing, and deployment across our web and mobile applications.\n\nAI-Powered Development: Actively utilize AI development assistants (e.g., GitHub Copilot, Claude Code) to accelerate coding, testing, and debugging, driving efficiency across the board.\n\nBuild & Scale: Write clean, high-quality, and maintainable code. Architect systems that are not only functional today but are built to scale as the company grows.\n\nProblem Solving: Tackle complex technical challenges with autonomy and creativity, making pragmatic decisions that balance speed and quality.\n\nRequired Skills and Qualifications:\n\nExperience: While we value degrees, your portfolio and practical experience are what matter most for this level of autonomy.\n\u2022 5-7 years of experience in Front-end development and it\u2019s technologies\n\u2022 A demonstrated history of building and shipping complex software products.\n\nCloud Proficiency: Strong, hands-on experience with Azure services is a must. Proven ability to design and manage cloud-native architecture is required.\n\nFront-End: Strong command of ReactJS/ Vue.JS, React Native, TypeScript\n\nStartup Mindset: You thrive in a fast-paced environment, are comfortable with ambiguity, and have a \"get-it-done\" attitude. You are a proactive owner, not just a task-doer.\n\nDatabases: Solid experience with both SQL and NoSQL databases on cloud.\n\nDevOps: Experience building CI/CD pipelines for deployment of Front-end applications in cloud\n\nSoft Skills:\n\u2022 Exceptional attention to detail and analytical skills.\n\u2022 Strong problem-solving ability.\n\u2022 Excellent communication and collaboration skills.\n\u2022 A proactive, self-starter attitude with a high degree of ownership \u2013 essential for a startup environment\n\nPreferred Qualifications (Nice-to-Haves):\n\u2022 Experience with containerization and orchestration (Kubernetes).\n\u2022 Knowledge of Infrastructure as Code (e.g., Terraform, AWS CDK).\n\u2022 A keen eye for product and user experience.\n\nWhat We Offer:\n\u2022 A competitive salary.\n\u2022 The opportunity to build a product and company from the ground up.\n\u2022 Maximum autonomy and ownership over the technical direction of the product.\n\u2022 A culture free of red tape, focused on innovation, speed, and impact.\n\nHow to Apply:\n\nInterested candidates should send their resume, and a brief note about why you're passionate to work in a startup along with your application submission.",
    "url": "https://in.linkedin.com/jobs/view/lead-frontend-developer-at-optibridge-technologies-4334784679?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-08T08:00:00.000Z"
  },
  {
    "title": "Consultant-Machine Learning",
    "company": "Deloitte",
    "location": "Pune",
    "salary": "",
    "description": "Summary\n\nPosition Summary\n\nArtificial Intelligence & Engineering\n\nAI & Engineering leverages cutting-edge engineering capabilities to help build, deploy, and operate integrated/verticalized sector solutions in software, data, AI, network, and hybrid cloud infrastructure. These solutions insights are powered by engineering for business advantage, helping transforming mission-critical operations.\n\nJoin our AI & Engineering team to help in transforming technology platforms, driving innovation, and helping help make a significant impact on our clients' success achievements. You\u2019ll work alongside talented professionals reimagining and re-engineering operations and processes that are could be critical to businesses.\n\nPosition Summary\n\nLevel: Consultant\n\nAs an experienced Consultant at Deloitte Consulting, you will be responsible for individually delivering high quality work products within due timelines. Need-basis you will be mentoring and/or directing junior team members/liaising with onsite/offshore teams to understand the functional requirements.\n\nWork you\u2019ll do:\n\nApply industry knowledge to requirements gathering and analysis, ensuring alignment with sector needs. Demonstrate expertise across the entire software development lifecycle, from design and coding to deployment and defect resolution, collaborating with stakeholders for effective delivery. Conduct peer and team reviews to maintain quality standards. Actively engage in Agile practices, including sprint planning, retrospectives, and effort estimation. Build and share business process knowledge, supporting project knowledge management and team training. Proactively recommend process improvements, track efficiency gains, and contribute to automation and innovation, all aimed at enhancing project outcomes and delivering greater value to clients.\n\nThe team:\n\nAI & Data offers a full spectrum of solutions for designing, developing, and operating cutting-edge Data and AI platforms, products, insights, and services. Our offering helps clients innovate, and enhance their data, AI, and analytics capabilities, ensuring they can mature and scale effectively.\n\nAI & Data professionals will work with our clients to:\n\u2022 Design and modernize large-scale data and analytics platforms including data management, governance and the integration of structured and unstructured data to generate insights leveraging cloud, edge and AI/ML technologies, platforms and methodologies for storage, processing\n\u2022 Leverage automation, cognitive and AI based solutions to manage data, predict scenarios and prescribe actions\n\u2022 Drive operational efficiency by managing and upgrading their data ecosystems and application platforms, utilizing analytics expertise and providing As-a-Service models to ensure continuous insights and enhancements.\n\nQualifications\n\nMust Have Skills/Project Experience/Certifications:\n\u2022 3-6 years of relevant hands-on experience in Data Science, Machine Learning, Statistical Modeling\n\u2022 Must have strong hands-on experience with programming languages like Python, PySpark and SQL, and frameworks such as Numpy, Pandas, Scikit-learn, etc.\n\u2022 Expertise in Classification, Regression, Time series, Decision Trees, Optimization, etc.\n\u2022 Hands on knowledge of Docker containerization, GIT, Tableau or PowerBI\n\u2022 Model deployment on Cloud or On-prem will be an added advantage\n\u2022 Familiar with Databricks, Snowflake, or Hyperscalers (AWS/Azure/GCP/NVIDIA)\n\u2022 Deliver large-scale DS/ML end to end projects across multiple industries and domains\n\u2022 Liaison with on-site and client teams to understand various business problem statements, use cases and project requirements\n\u2022 Work with a team of Data Engineers, ML/AI Engineers, DevOps, and other Data & AI professionals to deliver projects from inception to implementation\n\u2022 Utilize maths/stats, AI, and cognitive techniques to analyze and process data, predict scenarios, and prescribe actions.\n\u2022 Drive a human-led culture of Inclusion & Diversity by caring deeply for all team members\n\nGood to Have Skills/Project Experience/Certifications:\n\u2022 Should follow research papers, comprehend and innovate/present the best approaches/solutions related to DS/ML\n\u2022 AI/Cloud certification from a premier institute is preferred.\n\nEducation:\n\u2022 BE/B.Tech/M.C.A./M.Sc (CS) degree or equivalent from accredited university\n\nLocation:\n\u2022 Bengaluru/Hyderabad/Pune/Chennai/Kolkata\n\nOur purpose\n\nDeloitte\u2019s purpose is to make an impact that matters for our people, clients, and communities. At Deloitte, purpose is synonymous with how we work every day. It defines who we are. Our purpose comes through in our work with clients that enables impact and value in their organizations, as well as through our own investments, commitments, and actions across areas that help drive positive outcomes for our communities.\n\nOur people and culture\n\nOur inclusive culture empowers our people to be who they are, contribute their unique perspectives, and make a difference individually and collectively. It enables us to leverage different ideas and perspectives, and bring more creativity and innovation to help solve our clients' most complex challenges. This makes Deloitte one of the most rewarding places to work.\n\nProfessional development\n\nAt Deloitte, professionals have the opportunity to work with some of the best and discover what works best for them. Here, we prioritize professional growth, offering diverse learning and networking opportunities to help accelerate careers and enhance leadership skills. Our state-of-the-art DU: The Leadership Center in India, located in Hyderabad, represents a tangible symbol of our commitment to the holistic growth and development of our people. Explore DU: The Leadership Center in India .\n\nBenefits To Help You Thrive\n\nAt Deloitte, we know that great people make a great organization. Our comprehensive rewards program helps us deliver a distinctly Deloitte experience that helps that empowers our professionals to thrive mentally, physically, and financially\u2014and live their purpose. To support our professionals and their loved ones, we offer a broad range of benefits. Eligibility requirements may be based on role, tenure, type of employment and/ or other criteria. Learn more about what working at Deloitte can mean for you.\n\nRecruiting tips\n\nFrom developing a stand out resume to putting your best foot forward in the interview, we want you to feel prepared and confident as you explore opportunities at Deloitte. Check out recruiting tips from Deloitte recruiters.\n\nRequisition code: 300100",
    "url": "https://in.linkedin.com/jobs/view/consultant-machine-learning-at-deloitte-4320942098?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "CSS-1:3RDi_AI/MLEngineer",
    "company": "The Digital Group",
    "location": "Pune",
    "salary": "",
    "description": "Years of Experience:\n\n5-10 Years\n\nSkills Stack:\n\nGenerative AI, Azure or AWS\n\nShift Timings:\n\n05:30 am - 05:30 am ()\n\nRole and Responsibility Details:\n\nJob Description:\n\nAbout the Role\n\nWe are seeking a highly skilled and motivated Generative AI Engineer with hands-on experience in building and deploying multimodal AI solutions (text, audio, and video) on Azure or AWS AI platforms. The ideal candidate will have deep knowledge of generative AI models (LLMs, diffusion models, etc.), and be capable of designing, developing, and scaling AI/ML solutions using cloud-native tools and services.\n\nKey Responsibilities\n\u2022 Design, develop, and deploy multimodal AI models (text, audio, video) using AWS or Azure AI services.\n\u2022 Integrate LLMs (e.g., OpenAI, Anthropic, Cohere) with proprietary or third-party models to build custom applications.\n\u2022 Utilize Azure OpenAI, AWS Bedrock, SageMaker, or similar services for training and inference workflows.\n\u2022 Develop pipelines for preprocessing, training, evaluation, and fine-tuning of multimodal models.\n\u2022 Collaborate with product and engineering teams to define use cases and translate them into scalable GenAI solutions.\n\u2022 Evaluate and optimize models for latency, accuracy, cost, and ethical considerations.\n\u2022 Implement prompt engineering, RAG (retrieval-augmented generation), vector search, and other advanced techniques.\n\u2022 Stay current with GenAI research trends and contribute to internal knowledge sharing.\n\nRequired Skills & Qualifications\n\u2022 5+ years of experience in AI/ML, with 1 2 years specifically in generative AI / multimodal AI.\n\u2022 Strong proficiency with at least one cloud platform: Azure AI (Azure OpenAI, Cognitive Services, ML Studio) or AWS AI (Bedrock, SageMaker, Transcribe, Rekognition, Polly, etc.).\n\u2022 Hands-on experience with multimodal data processing (e.g., NLP, audio signal processing, video analysis).\n\u2022 Experience with LLMs, transformer architectures, and model fine-tuning (e.g., LoRA, PEFT, adapters).\n\u2022 Proficiency in Python, and libraries such as PyTorch, TensorFlow, Transformers (Hugging Face).\n\u2022 Experience with vector databases (e.g., FAISS, Pinecone, Weaviate) and embedding generation.\n\u2022 Strong understanding of MLOps, CI/CD for ML, and deployment strategies for GenAI models.\n\nQualifications:\n\nB.E\n\nLocations:\n\nPune\n\nContact:\n\nRecruitment Team\n\nEmail: tdg-recruitment@thedigitalgroup.com",
    "url": "https://www.glassdoor.com/job-listing/css-1-3rdi-ai-mlengineer-the-digital-group-JV_IC2856202_KO0,24_KE25,42.htm?jl=1009932482073&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-06T00:00:00.000Z"
  },
  {
    "title": "AI/ML Trainer",
    "company": "Futurism Technologies, INC.",
    "location": "Pune",
    "salary": "",
    "description": "Job Title: AI/ML Trainer\n\nLocation: Pune\n\nQualifications\n\u2022 Bachelor\u2019s or Master\u2019s degree in Computer Science, Data Science, or related field\n\u2022 3+ years of hands-on AI/ML experience (model development, deployment, or applied research).\n\u2022 2+ years of experience delivering technical training (classroom or online).\n\u2022 Strong proficiency in Python, ML/DL libraries (TensorFlow, PyTorch, Scikit-learn), and data tools (Pandas, NumPy, SQL).\n\u2022 Familiarity with Generative AI, LLMs, and prompt engineering is highly desirable.\n\u2022 Excellent presentation, communication, and facilitation skills.\n\nPreferred Skills\n\u2022 Experience delivering corporate training programs or academic workshops.\n\u2022 Knowledge of cloud ML platforms (AWS Sagemaker, Azure ML, GCP Vertex AI).\n\u2022 Ability to simplify complex technical concepts into easy-to-understand lessons.\n\u2022 Strong problem-solving mindset and learner-first approach.\n\nKey Competencies\n\u2022 Engagement-focused: Skilled in keeping learners actively involved.\n\u2022 Clarity of instruction: Can explain complex AI/ML topics with real-world analogies.\n\u2022 Adaptability: Flexible teaching style suited to different learner groups.\n\u2022 Mentorship: Strong inclination to guide, mentor, and motivate learners.\n\u2022 Continuous learner: Keeps up with evolving AI/ML trends and tools.\n\nKey Responsibilities\n\nTraining Delivery\n\u2022 Conduct live training sessions (in-person, virtual, or hybrid) for diverse groups including students, working professionals, and corporate teams.\n\u2022 Teach core AI/ML topics such as supervised/unsupervised learning, deep learning, NLP, computer vision, generative AI, reinforcement learning, and MLOps.\n\u2022 Guide learners through hands-on coding exercises, model building, and deployment practices.\n\u2022 Facilitate Q&A, discussions, and problem-solving during training to ensure strong concept clarity.\n\u2022 Demonstrate the use of industry-standard tools and frameworks such as Python, TensorFlow, PyTorch, Scikit-learn, Hugging Face, and cloud ML platforms.\n\nLearner Engagement & Mentorship\n\u2022 Provide individualized support to learners during training, helping them troubleshoot errors and understand best practices.\n\u2022 Foster an interactive, motivating, and inclusive learning environment.\n\u2022 Mentor learners on mini-projects and capstone assignments to ensure practical application of skills.\n\u2022 Encourage collaboration through group exercises, coding challenges, and hackathon-style workshops.\n\nAssessment & Feedback\n\u2022 Evaluate learner performance through quizzes, assignments, and project reviews.\n\u2022 Offer timely, constructive feedback to learners to accelerate their growth.\n\u2022 Collect learner feedback after each session and adjust teaching methods to enhance learning outcomes.\n\nContinuous Learning & Adaptation\n\u2022 Stay up-to-date with latest advancements in AI/ML (Generative AI, LLMs, MLOps practices, etc.).\n\u2022 Incorporate trending topics and practical industry use cases into session delivery.\n\u2022 Adapt training content delivery to suit varying learner backgrounds (technical vs. non-technical).",
    "url": "https://in.linkedin.com/jobs/view/ai-ml-trainer-at-futurism-technologies-inc-4334466222?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-06T00:00:00.000Z"
  },
  {
    "title": "Project Manager (AI/ML and Computer Vision)",
    "company": "Futops Technologies India Private Limited",
    "location": "Pune",
    "salary": "",
    "description": "Role Overview\n\nWe are seeking an experienced Project Manager with hands-on technical exposure in AI/ML and Computer Vision projects. The ideal candidate will manage end-to-end project delivery \u2014 from requirement gathering and team coordination to client communication and execution \u2014 while ensuring technical excellence and timely completion.\n\nKey Responsibilities\n\u2022 Lead and manage multiple AI/ML and Computer Vision projects from initiation to delivery.\n\u2022 Collaborate with cross-functional teams including data scientists, ML engineers, and software developers.\n\u2022 Define project scope, goals, deliverables, and success metrics.\n\u2022 Ensure timely delivery of milestones while maintaining high technical and quality standards.\n\u2022 Track project progress using suitable tools and techniques, ensuring risks and issues are proactively addressed.\n\u2022 Serve as the primary point of contact for clients, managing expectations and communication effectively.\n\u2022 Support technical discussions and problem-solving with hands-on understanding of Linux, Python, and ML tools.\n\u2022 Prepare project documentation including timelines, reports, and technical summaries.\n\u2022 Contribute to process improvements and best practices within the AI/ML delivery team.\n\u2022 Should have experience in vibe coding and should be able to transform existing team from traditional method of software engineering to more modern approaches using LLM/Agentic tools which produces higher productivity and quality.\n\u2022 Should own quality, schedule and productivity for every project and should be controlling overall cost as well\n\nRequired Skills & Qualifications\n\u2022 Bachelor\u2019s or Master\u2019s degree in Computer Science, Information Technology, or a related field.\n\u2022 4\u20138 years of experience in project management with at least 2+ years managing AI/ML or Computer Vision projects.\n\u2022 Solid understanding of Machine Learning, Deep Learning, and Computer Vision concepts.\n\u2022 Technical proficiency in Python, Linux environment, and familiarity with ML frameworks (TensorFlow, PyTorch, OpenCV, etc.).\n\u2022 Strong understanding of Agile methodologies and software development life cycle (SDLC).\n\u2022 Excellent organizational, leadership, and communication skills.\n\u2022 Ability to manage small, cross-functional teams in a fast-paced environment.\n\u2022 PMP/Agile certification is a plus (not mandatory).\n\nWhat We Offer\n\u2022 Opportunity to work on cutting-edge AI and Computer Vision projects.\n\u2022 Collaborative, growth-oriented work environment.\n\u2022 Exposure to emerging technologies and real-world applications.\n\u2022 Competitive compensation aligned with skills and experience.",
    "url": "https://in.linkedin.com/jobs/view/project-manager-ai-ml-and-computer-vision-at-futops-technologies-india-private-limited-4320779511?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "WFH Machine Learning Jobs in Pune",
    "company": "Turing.com",
    "location": "Pune",
    "salary": "",
    "description": "We, at Turing, are looking for experienced ML engineers who will design and develop machine learning and deep learning systems, machine learning tests and implement Ml algorithms to help in creating AI solutions. Apply for machine learning jobs in Pune and get a chance to work closely with global software engineers, AI/ML enthusiasts and gain unique experiences.",
    "url": "https://www.turing.com/jobs/machine-learning-jobs-in-pune?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Machine Learning Strategist [Immediate Start]",
    "company": "Cybage Software",
    "location": "Pune",
    "salary": "",
    "description": "Role Overview\nCybage is seeking a Practice Head for Machine Learning Systems to lead our AI/ML capability within the CDAI business unit. This is a strategic leadership role that blends deep technical expertise in applied ML systems with practice-building, client consulting, and outcome-based delivery experience.\nThe role requires someone who has built and scaled ML engineering practices in IT services or consulting environments, is able to guide solutioning at a technical level, and can also engage clients in executive workshops to define AI adoption roadmaps.\nKey Responsibilities\nPractice Leadership\n- Define the vision and roadmap for Cybage\u2019s Machine Learning Systems practice, aligned with industry trends and client priorities.\n- Build offerings and frameworks across ML model development, deployment, MLOps, generative AI, and responsible AI governance.\n- Develop accelerators, reference architectures, and reusable assets to differentiate Cybage in the market.\nClient Consulting & Business Growth\n- Lead consultative workshops with client executives to co-create ML/AI strategies, adoption roadmaps, and use-case portfolios.\n- Partner with sales and account teams to drive presales solutioning, proposal creation, and thought leadership.\n- Position Cybage as a strategic partner for ML-driven transformations that are measurable and outcome-driven.\nDelivery Excellence\n- Oversee delivery of ML programs spanning PoCs, pilots, and scaled deployments across industries.\n- Ensure robust MLOps and governance practices for model lifecycle management, monitoring, retraining, and compliance.\n- Provide architectural and technical guidance on ML stacks (e.g., TensorFlow, PyTorch, Hugging Face, MLflow, AWS Sagemaker, Azure ML, GCP Vertex AI, Databricks ML).\n- Drive service-based and outcome-based engagement models, ensuring predictability and value delivery.\nTeam & Capability Building\n- Build and mentor a high-performing team of ML engineers, data scientists, and solution architects.\n- Develop future leaders with consulting and solutioning depth, not just technical skill.\n- Foster collaboration across adjacent practices (Big Data, Cloud, Platform Engineering) to deliver end-to-end AI solutions.\nQualifications\nExperience\n- 15+ years in IT services or consulting, with 7+ years in ML/AI leadership or architecture roles.\n- Proven ability to establish or grow an ML/AI practice, including team building, offering development, and client engagement.\n- Experience with end-to-end ML lifecycle: data prep, feature engineering, model training, evaluation, deployment, monitoring.\n- Exposure to service delivery models (consulting, managed services, outcome-based).\n- Strong background in applied ML use cases (forecasting, personalization, anomaly detection, NLP, computer vision, GenAI).\nSkills & Competencies\n- Technical bent: ability to deep-dive into ML architectures, pipelines, and MLOps practices.\n- Strategic mindset: connect ML initiatives to tangible business outcomes.\n- Leadership: experience in building practices and leading distributed teams (does not need to be at massive scale).\n- Client-facing presence: ability to run workshops, advise senior stakeholders, and simplify complex ML topics.\n- Knowledge of AI governance, ethics, and compliance (responsible AI, data privacy, bias mitigation).",
    "url": "https://in.jobrapido.com/jobpreview/8000578511775465472?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-01T00:00:00.000Z"
  },
  {
    "title": "Generative AI & AI/ML Engineer",
    "company": "Evonence",
    "location": "Pune",
    "salary": "",
    "description": "Experience Level - 5 to 7 Years\n\nLocation - Pune\n\nEvonence is looking for Generative AI & AI/ML Engineer to drive end-to-end AI solution development from architecture and model training to responsible deployment and mentorship. The role balances research, engineering, and leadership, making it ideal for someone with a strong academic background and hands-on experience in production-level AI systems.\n\nKey Responsibilities:\n\u2022 Lead AI initiatives and drive innovation in generative models.\n\u2022 Evaluate and adopt cutting-edge AI trends (e.g., from academic papers, NeurIPS, CVPR).\n\u2022 Be a go-to authority for generative AI direction.\n\u2022 Design production-grade AI systems using frameworks like transformers, GANs, or diffusion models.\n\u2022 Focus on performance, scalability, and security, suggesting deployment on distributed platforms.\n\u2022 Build and fine-tune large-scale models.\n\u2022 Embed Responsible AI practices: mitigate bias, improve transparency.\n\u2022 Act as a bridge between research and product teams.\n\u2022 Mentor junior engineers, encourage cross-team collaboration, and shape internal AI strategy.\n\nRequired Skills:\n\u2022 Advanced degree (PhD or Master's) in AI/ML or related fields.\n\u2022 Expertise in transformer architectures, GANs, diffusion models.\n\u2022 Experience with Python, TensorFlow, JAX, and distributed computing.\n\u2022 Solid grasp of natural language processing, computer vision, or multi-modal AI.\n\nGood to Have:\n\u2022 Experience on Google Cloud Platform (GCP).\n\u2022 Publications or patents in top-tier AI venues.\n\u2022 Contributions to open-source tools like HuggingFace Transformers, TensorFlow, or Diffusers.\n\u2022 Knowledge of AI ethics frameworks and tools like Fairness Indicators, Explainable AI (XAI).",
    "url": "https://in.linkedin.com/jobs/view/generative-ai-ai-ml-engineer-at-evonence-4333914384?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Norton_AI/MLEngineer",
    "company": "The Digital Group",
    "location": "Pune",
    "salary": "",
    "description": "Years of Experience:\n\n4-10 Years\n\nSkills Stack:\n\nPython, PyTorch, TensorFlow, Keras, Transformers, LLM, Pandas, NumPy, SQL, MongoDB\n\nShift Timings:\n\n05:30 am - 05:30 am ((UTC+05:30) Chennai, Kolkata, Mumbai, New Delhi)\n\nRole and Responsibility Details:\n\n\" Design, build, and deploy supervised, unsupervised, and deep learning models. \" Own end-to-end NLP workflows: pre-processing, training, evaluation, fine-tuning. \" Hands-on experience in building and deploying models using Sentence Transformers for semantic embeddings and integrating FAISS or Qdrant for scalable vector similarity search and retrieval. \" Strong understanding of handling limited data scenarios using data augmentation strategies and Monte Carlo simulation techniques to improve model robustness and accuracy. \" Architect models for NER, relation extraction, intent classification, and LLM-based generation like Mistral, LLama etc. \" Integrate ML models with production-grade APIs and Flask/FastAPI endpoints. \" Expertise in Linux/Windows-based ML environments and managing dependencies and virtual environments (venv, conda, pip). \" Work with MLOps best practices: model versioning, reproducibility, monitoring, and rollback strategies. \" Optimize models for speed/memory, leveraging techniques like quantization, ONNX, or TorchScript. \" Deploy and manage machine learning models on cloud platforms using services like ML pipelines, object storage, serverless functions, and container orchestration tools. \" Understanding of Azure Pipelines, Docker, Kubernetes (AKS) if required. \" Understanding of GPU/CPU resource allocation, model parallelization, and scaling.\n\nJob Description:\n\u2022 Design, build, and deploy supervised, unsupervised, and deep learning models.\n\u2022 Own end-to-end NLP workflows: pre-processing, training, evaluation, fine-tuning.\n\u2022 Hands-on experience in building and deploying models using Sentence Transformers for semantic embeddings and integrating FAISS or Qdrant for scalable vector similarity search and retrieval.\n\u2022 Strong understanding of handling limited data scenarios using data augmentation strategies and Monte Carlo simulation techniques to improve model robustness and accuracy.\n\u2022 Architect models for NER, relation extraction, intent classification, and LLM-based generation like Mistral, LLama etc.\n\u2022 Integrate ML models with production-grade APIs and Flask/FastAPI endpoints.\n\u2022 Expertise in Linux/Windows-based ML environments and managing dependencies and virtual environments (venv, conda, pip).\n\u2022 Work with MLOps best practices: model versioning, reproducibility, monitoring, and rollback strategies.\n\u2022 Optimize models for speed/memory, leveraging techniques like quantization, ONNX, or TorchScript.\n\u2022 Deploy and manage machine learning models on cloud platforms using services like ML pipelines, object storage, serverless functions, and container orchestration tools.\n\u2022 Understanding of Azure Pipelines, Docker, Kubernetes (AKS) if required.\n\nUnderstanding of GPU/CPU resource allocation, model parallelization, and scaling.\n\nQualifications:\n\nMTech , B.Tech, B.E\n\nLocations:\n\nPune\n\nContact:\n\nRecruitment Team\n\nEmail: tdg-recruitment@thedigitalgroup.com",
    "url": "https://www.glassdoor.co.in/job-listing/norton-ai-mlengineer-the-digital-group-JV_IC2856202_KO0,20_KE21,38.htm?jl=1009932482116&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-06T00:00:00.000Z"
  },
  {
    "title": "Google Cloud AI/ML Engineer",
    "company": "Evonence",
    "location": "Pune",
    "salary": "",
    "description": "Company Description\n\nEvonence is a Google Cloud partner company specializing in providing Google Cloud solutions to mid-market businesses in North America. Founded in 2014, we are one of the fastest-growing partners in the Google Cloud ecosystem. We support a customer base of over 1000 and have deep technical expertise in Google workspace, Google Cloud infra migrations, and Google Cloud app modernizations.\n\nRole Description\n\nThis is a full-time hybrid role as a Google Cloud AI/ML engineer at Evonence. As a Google Cloud AI/ML engineer, your day-to-day tasks will include working on pattern recognition, computer science, neural networks, statistics, and algorithms. You will be responsible for developing and implementing AI/ML solutions on the Google Cloud Platform. This is a hybrid role, located in Pune, with flexibility for some remote work.\n\nQualifications\n\u2022 3- 7 Years of experience is must\n\u2022 Strong background in pattern recognition, computer science, and neural networks\n\u2022 Proficiency in statistics and algorithms\n\u2022 Experience in developing AI/ML solutions on the Google Cloud Platform\n\u2022 Excellent problem-solving and analytical skills\n\u2022 Strong programming skills in languages such as Python or Java is must\n\u2022 Knowledge of data preprocessing and feature engineering techniques\n\u2022 Experience with machine learning frameworks and libraries\n\u2022 Bachelor's degree in Computer Science, Data Science, or a related field\n\u2022 Google Cloud Platform certification is a plus",
    "url": "https://in.linkedin.com/jobs/view/google-cloud-ai-ml-engineer-at-evonence-4320453771?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-03T00:00:00.000Z"
  },
  {
    "title": "Hiring AL ML Engineer For Pune Baner- 3 Months Contractual JOB",
    "company": "Bolt-on Global Solutions  Services Private Limite",
    "location": "Pune",
    "salary": "",
    "description": "Job Title: AI/ML Engineer\n\nExperience Required: 4 to 8 Years\n\nCONTRACTUAL JOB: 3 MONTHS\n\nLocation: Pune (Work from Office)\n\nAbout the Role\n\nWe are seeking a skilled and passionate AI/ML Engineer with at least 4 years of experience to join our growing team. The ideal candidate will have strong expertise in designing, developing, and deploying machine learning and deep learning models, including Retrieval-Augmented Generation (RAG) systems, along with the ability to translate business problems into data-driven solutions.\n\nKey Responsibilities\n\u2022 Design, build, and deploy scalable machine learning and AI models for real-world applications.\n\u2022 Work closely with data scientists, engineers, and business stakeholders to identify and define AI/ML use cases.\n\u2022 Develop and optimize algorithms for classification, regression, clustering, NLP, computer vision, or recommendation systems.\n\u2022 Conduct model training, validation, and performance tuning.\n\u2022 Evaluate which available ML models, off-the-shelf solution, is most appropriate based on the business context.\n\u2022 Design and implement those models and their pipelines, combining large language models (LLMs) where necessary. Improve accuracy, relevance, and explainability of generated responses.\n\u2022 Implement MLOps practices to ensure reliable deployment and monitoring of models in production.\n\u2022 Collaborate with data engineers to prepare, clean, and transform large datasets.\n\u2022 Stay updated with the latest trends and research in AI/ML and recommend adoption of new approaches where relevant.\n\nRequired Skills & Qualifications\n\u2022 Bachelors/masters degree in computer science, Data Science, Artificial Intelligence, or related field.\n\u2022 4+ years of hands-on experience in AI/ML development.\n\u2022 Hands-on experience with RAG architecture and LLMs (e.g., OpenAI, LLaMA, Cohere, Claude, etc.).\n\u2022 Proficiency in Python and libraries like LangChain, Haystack, Transformers, scikit-learn, PyTorch, TensorFlow, etc.\n\u2022 Strong knowledge of vector similarity search and experience with tools like FAISS, Pinecone, Chroma, or Weaviate.\n\u2022 Experience with data manipulation and analysis (Pandas, NumPy, SQL).\n\u2022 Knowledge of NLP, deep learning, or computer vision techniques.\n\u2022 Familiarity with cloud platforms (AWS, Azure, GCP) and deployment of ML models.\n\u2022 Understanding of MLOps tools (MLflow, Kubeflow, Docker, Kubernetes, CI/CD).\n\u2022 Strong problem-solving skills with the ability to work independently and in teams.\n\nGood to Have\n\u2022 Experience with big data technologies (Spark, Hadoop).\n\u2022 Contribution to open-source ML/AI projects or research publications.",
    "url": "https://in.bebee.com/job/18f2a565f26d39622f06cd638263b93d?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-06T00:00:00.000Z"
  },
  {
    "title": "Looking For immediate joiners - Lab Data Analyst-Python Programming",
    "company": "IQVIA",
    "location": "Pune",
    "salary": "",
    "description": "Job Title : Lab Data Analyst-Python ProgrammingSkill : Python programming, data analysis, review and processingExperience : 2 to 4 yearsLocation : Across PAN IndiaJob OverviewProvide comprehensive clinical lab data expertise as part of a team to develop and maintain Laboratory Data Management (LDM) tasks for the studies awarded to IQVIA Laboratories and meets the external client data reporting needs. May be required to support the development of new systems and processes related to the electronic data transfer process, or the configuration of business rules and master data in study and laboratory information systems. Understand and comply with core standard operating procedures and working instructions.Essential Functions 2-3 years of experience in Data Management and Python Programming. Requires basic knowledge of Python Programming and Data Management procedures obtained through prior work experience or education. Equivalent combination of education, training, computing qualification and experience.\u2022 Capable of taking up, independently or providing inputs for, Python programming activities pertaining to ongoing study requirements or any other adhoc projects in the department\u2022 Create and/or review all appropriate data management documents\u2022 Understand and comply with core standard operating procedures and working instructions\u2022 Develop and maintain good communications and working relationships with LDM team. Serve as back-up for other Data Team Leads\u2022 Interact with internal and external team members to negotiate timelines and responsibilities\u2022 Train and mentor junior staff in DM expertise\u2022 Ensure service and quality meet agreed upon timelines and deliverables in data transmission agreements. Ensure quality checks performed on data files before transmission and obtain peer-review where required. Review own work for accuracy and completeness\u2022 Record all evidence of the data transmission process from data file definition to closure of study\u2022 Ensure that all specification and design documentation are filed and stored according to company policy\u2022 Ensure the internal and external customer queries are timely addressed and resolved effectively\u2022 Multiple communication styles and skill to effectively broker, audience specific [peers, senior team members, internal/external customers] business and interpersonal relationships that lead to positive outcomes and successful business results\u2022 Perform other duties as directed by the functional manager\u2022 Manages the delivery of projects through full data management study life-cycle, from setup to lock\u2022 Supports the identification and resolution of service level issues, as well as the proactive development of contingency plans to mitigate laboratory risk\u2022 Works with customers, scientific team, data managers and internal team members to manage issue escalation, workload projections, and provide technical expertise\u2022 Interacts and communicates with internal and external customers to ensure that timelines are met and that data is delivered following company guidelines and regulatory compliance\u2022 With guidance, manages project timelines and quality issues, and identifies and justifies out-of-scope client requests\u2022 Assists internal team with data entry, review and validation of laboratory reports, and serves as back-up contact when needed\u2022 Performs comprehensive quality control and edit check procedures\u2022 Supports service delivery with comprehensive process and technical expertise in executing projects which includes identifying and resolving issues. Effectively works on corrective and develop preventive action plansQualificationsBachelor's Degree (B. E, B. Tech, B. Pharm):Computer Science with Software Configuration and Validation experience Req",
    "url": "https://www.mployee.me/jobs/view/looking-for-immediate-joiners-lab-data-analyst-python-programming-in-pune-at-iqvia-51125000118/s1?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-03T00:00:00.000Z"
  },
  {
    "title": "BMC Helix ITSM Developer",
    "company": "Ekfrazo Technologies Private Limited",
    "location": "Pune",
    "salary": "",
    "description": "Role: BMC Helix ITSM Developer\n\nLocation: Hinjewadi, Pune\n\nExp: 5+ years\n\u2022 BMC Helix installation exp on new Hardware or cloud.\n\u2022 Exp in BMC Helix Integration with different platform\n\u2022 Remedy ITSM expertise could be added advantage\n\u2022 MUST : Remedy ITSM Developer with upgrade experience. BMC remedy Upgrade\n\u2022 Should be able to understand customer requirements & provide solutions in ITSM module.\n\u2022 Development in ITSM, IM, CM, PM modules as per project requirements Development , Web service integration Unit testing\n\u2022 E2E integration testing support of developed functionalities\n\u2022 Support the deployment process, including sanity testing\n\u2022 Defect resolution Knowledge of SOAP UI,\n\u2022 Unix is desirable Experience in ITSM upgrade projects is added advantage",
    "url": "https://in.linkedin.com/jobs/view/bmc-helix-itsm-developer-at-ekfrazo-technologies-private-limited-4335033121?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-08T09:00:00.000Z"
  },
  {
    "title": "\u25b7 Only 24h Left! Python Developer",
    "company": "Cavista Technologies",
    "location": "Pune",
    "salary": "",
    "description": "At Cavista, our mission is to empower organizations with the world\u2019s best technology solutions. We ensure the highest level of client satisfaction through a global network of innovation, and our software solutions are custom-built to accommodate your domain and requirements. Through world-class consultation, innovative IT solutions and personalized client services, Cavista increases operational efficiency for organizations of all sizes.\n\nCavista is searching for great talent. We are an open, agile environment, where transparent conversation ignites collaboration with a team of great thinkers. Everyone freely contributes, ideas override egos, and the best idea always wins. We embrace new technologies and pride ourselves on sustainable and quality code. In our world, opportunity paired with imagination is limitless and we build what others can only hope to dream. We build the best because we hire only the best! We\u2019ve created an atmosphere allowing you to produce your best work, by catering to the creative.\n\nWho we are looking for\n\nAn exceptional Engineer driven by creating groundbreaking technology to innovate the healthcare value chain. We are at the forefront of digital reinvention of healthcare, helping clients reimagine how advanced technology aids in the delivery of care in the home to patients and operational effectiveness to enterprises. This is an opportunity to join a dynamic team, using deep learning, neuro-linguistic programming (NLP), computer vision, chatbots, and robotics to help us improve various business outcomes and drive innovation.\n\nWe seek problem-solvers to thrive in our environment by making a lasting impact on care model innovations, and digital transformation as we develop technology to make lives better.\n\nWhat you will experience\u2026\n\u2022 A fast-paced, collaborative team-oriented environment that encourages every one to bring their authentic self to work every day.\n\u2022 Professional development for career growth and advancement\n\nWho we are...\n\nWe do business differently, by empowering our team to create fresh ideas which impact lives everywhere. We don\u2019t just dream it; we bring life- changing technology to healthcare impacting the way people work, learn and grow their business. Our edge does not come from our technology, it comes from our people. We work as one team with a common goal to create shared success benefiting everyone.\n\nWhat you will do\u2026\n\u2022 Work on functional design, process design (including scenario design, flow mapping), prototyping, testing, training, and defining support procedures, in collaboration with a diverse solutions delivery team\n\u2022 Support our Solutions Delivery team in conducting assessments of the AI (Artificial Intelligence) and automation market and competitor landscape\n\u2022 Collaborate with stakeholders and project teams supporting process, research and development to meet the needs of our AI strategy\n\u2022 Possess a deep understanding of our business and collaborate with teams on how integrating AI capabilities can help lead to solutions\n\u2022 Contribute to cross-functional teams in identifying and prioritizing key areas of our industry where AI solutions can drive significant business benefit\n\u2022 Analyze and explain AI and machine learning (ML) solutions while setting and maintaining high ethical standards\n\u2022 Knowledgeable of a broad range of technology, strategy, and policy and issues associated with AI in healthcare\n\nWhat you bring\u2026\n\u2022 Bachelor's or master's degree in computer science or related field\n\u2022 Required 2-5 years of Experience in Python\n\u2022 Experience with cloud environments\n\u2022 Experience applying AI to practical and comprehensive technology solutions\n\u2022 Experience with ML, deep learning, R, TensorFlow, Python, NLP,\n\u2022 Knowledge of basic algorithms, object-oriented and functional design principles, and best-practice patterns\n\u2022 Experience in REST API development, NoSQL database design, and RDBMS design and optimizations\n\u2022 Experience with innovation accelerators is a plus\n\u2022 Desire and ability to work effectively in an entrepreneurial and dynamic environment",
    "url": "https://in.talent.com/view?id=9849df2f8163&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-02T00:00:00.000Z"
  },
  {
    "title": "LLM Engineer - Python/Tensorflow",
    "company": "Zorba Consulting India Pvt. Ltd.",
    "location": "Pune",
    "salary": "",
    "description": "Company Description :\n\nAt Zorba AI, we harness the power of Generative AI to help businesses unlock new possibilities and streamline operations. As a cutting-edge Generative AI Solutions company, we specialize in building and integrating advanced AI capabilities that drive meaningful impact across industries. Our expertise ranges from custom AI copilots and chatbots to intelligent data workflows and scalable automation platforms. We operate at the intersection of AI-driven innovation and strategic talent solutions to help organizations access top-tier professionals. Our services include Generative AI solutions, strategic staffing, and advisory and integration support.\n\nRole Description :\n\nThis is a contract remote role for a LLM Engineer with 4+ years of experience. The LLM Engineer will be responsible for developing, deploying, and optimizing large language models (LLMs). The day-to-day tasks include designing NLP solutions, fine-tuning models, collaborating with cross-functional teams, and ensuring model performance and scalability. The role requires continuous research and implementation of the latest advancements in the field.\n\nQualifications :\n\n- Experience in developing, fine-tuning, and deploying large language models (LLMs)\n\n- Strong programming skills in Python, TensorFlow, and PyTorch\n\n- Knowledge in natural language processing (NLP) and machine learning algorithms\n\n- Proficiency in prompt engineering and AI workflow automation\n\n- Experience in cloud platforms like AWS or Google Cloud\n\n- Excellent problem-solving and analytical skills\n\n- Ability to work independently and remotely\n\n- Strong written and verbal communication skills\n\n- Master's or PhD in Computer Science, Data Science, or related field is a plus\n\n(ref:hirist.tech)",
    "url": "https://in.expertini.com/jobs/job/llm-engineer-pythontensorflow-pune-zorba-consulting-india-pvt-ltd-3598717b6711/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Python Developers \u2013 IT Development",
    "company": "Highrise Solutions LLP",
    "location": "Pune",
    "salary": "",
    "description": "Job Description:\n\u2022 Exp : 1-2 years and 4-6 years\n\u2022 CTC: 3-4 LPA (1-2yrs LPA (4-6yrs)\n\u2022 Job Type: Permanent\n\u2022 Job location: Pune (Magarpatta City) (Work from Office is Mandatory)\n\u2022 Shift: US shifts (Flexible)\n\u2022 Notice: Immediate\n\nJob Title: Python Developer\n\nKey Responsibilities:\n\u2022 Design, develop, and maintain Python scripts to automate business application processes.\n\u2022 Build and manage data ingestion pipelines using Python libraries (e.g., Pandas, NumPy, Requests, BeautifulSoup etc).\n\u2022 Integrate Python automation with RPA tools like UiPath to streamline workflows.\n\u2022 Develop and document end-to-end automation workflows, including triggers, exception handling, and logging.\n\u2022 Collaborate with cross-functional teams to identify automation opportunities and implement scalable solutions.\n\u2022 Monitor and optimize existing automation scripts for performance and reliability.\n\u2022 Ensure compliance with data privacy and security standards during automation.\n\nRequired Skills & Qualifications:\n\u2022 Bachelor's degree in Computer Science, Information Technology, or related field.\n\u2022 4+ years of experience in Python programming with a focus on automation.\n\u2022 Strong understanding of RPA concepts and hands-on experience with UiPath.\n\u2022 Proficiency in Python libraries for automation and data handling (e.g., Pandas, Selenium, PyAutoGUI, OpenPyXL).\n\u2022 Experience in building and managing RESTful APIs and integrating third-party services.\n\u2022 Familiarity with workflow orchestration tools and version control systems (e.g., Git).\n\u2022 Ability to write clean, modular, and well-documented code.\n\nPreferred Skills:\n\u2022 Python , UiPath Developer Certification or equivalent. Knowledge of workflow automation tools.\n\u2022 Experience with cloud platforms (AWS or Azure) for deploying automation solutions.\n\u2022 Knowledge of containerization (Docker) and CI/CD pipelines.\n\u2022 Exposure to machine learning or AI-based automation techniques.\n\u2022 Understanding of business process modeling and BPMN standards.\n\nInterview Mode\n\u2022 Teams interview",
    "url": "https://in.bebee.com/job/f8d35b96cec5de7ac7f318b0e9493a93?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-08T05:00:00.000Z"
  },
  {
    "title": "Python Developer with Testing",
    "company": "Luxoft",
    "location": "Pune",
    "salary": "",
    "description": "Project description\n\nWe are seeking a Python Developer with strong expertise in Java and SQL to design, develop, and maintain scalable software solutions within a cloud-enabled environment. The role involves working on high-impact applications, supporting CI/CD pipelines, and leveraging Azure cloud for deployment and management. You will play a key role in architecture discussions, mentoring juniors, and ensuring high-quality software delivery within an Agile/Scrum setup.\n\nResponsibilities\n\nA highly skilled and motivated Data Engineer/Data Scientist with extensive experience in Python, pandas, SQL, and data analysis. Adept mapping data into a new data model, with tested code.\n\nThrives in independent work environments, with a proven ability to deep dive into complex datasets and deliver impactful results.\n\nSkills\n\nMust have\n\nOver 5 years of experience as a Python Developer with a strong focus on testing\n\nProgramming: Python, Pandas, NumPy, SQL\n\nData: Postgres, SQLite, and CSV\n\nTesting: Unit Testing, Integration Testing, CI/CD Pipelines\n\nOther Tools: Git, Jupyter Notebooks\n\nNice to have\n\nPython programming.\n\nFamiliarity with other programming languages and frameworks.\n\nKnowledge of software design patterns and architectural principles.\n\nExposure to other cloud platforms (AWS, GCP).\n\nExperience with Docker, Kubernetes, and containerized deployments.\n\nRelevant certifications (cloud, programming, Agile).\n\nBackground in static reference data or payments systems.\n\nOther\n\nLanguages\n\nEnglish: C2 Proficient\n\nSeniority\n\nSenior\n\nPune, India\n\nReq. VR-117973\n\nPython\n\nBCM Industry\n\n07/11/2025\n\nReq. VR-117973",
    "url": "https://www.simplyhired.co.in/job/IeooToin_yEYKktof4wClG9IoezB1B2AOAaySXQ-dOikjt-Jxq__wg?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Python Developer \u2013 AI Innovation PA25DAIQ1003",
    "company": "SS&C Technologies",
    "location": "Pune",
    "salary": "",
    "description": "As a leading financial services and healthcare technology company based on revenue, SS&C is headquartered in Windsor, Connecticut, and has 27,000+ employees in 35 countries. Some 20,000 financial services and healthcare organizations, from the world's largest companies to small and mid-market firms, rely on SS&C for expertise, scale, and technology.\n\nJob Description\n\nJob Title: Python Developer \u2013 AI Innovation Team \u2013 Digital Development\n\nCompany: SS&C Technologies\n\nLocation: [Specify Location]\n\nDepartment: Digital Product & Innovation - Financial Services (GIDS Digital)\n\nPosition Type: Full-Time\n\nProposed Line Manager: Peter Beardsmore, Head of AI & ML\n\nRole Overview: We are seeking a highly skilled backend Python developer to join our AI Innovation team. In this role, you will be responsible for designing, coding, and maintaining cutting-edge AI innovations that cater to both end clients and internal stakeholders. As a key member of the team, you will deliver scalable and robust software that drives digital transformation within the financial services industry.\n\nYou have interest in and experience leveraging LLMs and creating functional automations and product features. You will make extensive use of enterprise-grade development practices and tools, such as Django and Docker.\n\nKey Responsibilities:\n\u2022 Lead the design, development, and implementation of high-performance Python-based web applications and microservices as part of our AI Innovation programme of work.\n\u2022 A serious enthusiasm for emerging technology and its real-world application, specifically AI technologies such as: predictive modelling, AutoML, fine-tuning and off-the-shelf usage of transformer models including LLMs; for data extraction, code generation, transcription, RAG-based Q&A, and other use cases.\n\u2022 Collaborate closely with product management, business analysts, and other developers to deliver high-quality software that meets client requirements.\n\u2022 Drive the adoption of best practices in coding, testing, and software architecture to ensure high standards of code quality, performance, and scalability.\n\u2022 Participate in all phases of the software development lifecycle, including requirements gathering, design, coding, testing, deployment, and maintenance.\n\u2022 Conduct code reviews, ensuring adherence to established coding standards and architectural guidelines.\n\u2022 Stay updated with emerging technologies, tools, and industry trends to continuously improve SS&C's digital product offerings.\n\u2022 Troubleshoot and resolve complex technical issues across the application stack, ensuring minimal disruption to the business.\n\u2022 Contribute to the strategic planning of the Digital Development function, identifying opportunities for innovation and process improvement.\n\nRequired Qualifications:\n\u2022 Bachelor\u2019s degree in computer science, software engineering, STEM, or a field related to the job in a demonstrable way.\n\u2022 3+ years of experience in Python development, with a focus on building enterprise-level applications.\n\u2022 Strong expertise in Python, Django, and RESTful API design.\n\u2022 Understanding of AI; including recent developments in GenAI and common use cases; how available models and tools can be incorporated and served through backend services.\n\u2022 Proven experience in designing and developing microservices architectures.\n\u2022 Deep understanding of software development principles, design patterns, and best practices.\n\u2022 Familiarity with front-end technologies (e.g., Angular, React) and how they integrate with back-end services.\n\u2022 Experience with cloud platforms such as AWS, Azure, or Google Cloud.\n\u2022 Proficient in database design and development, including experience with SQL and NoSQL databases.\n\u2022 Excellent communication and collaboration skills, with the ability to work effectively in a dynamic, team-oriented environment.\n\nPreferred Qualifications:\n\u2022 Experience in the financial services industry, particularly in investment management or fintech.\n\u2022 Knowledge of DevOps practices, including CI/CD pipelines (Github Actions), containerization (Docker), and orchestration (Kubernetes).\n\u2022 Familiarity with Agile methodologies and tools such as JIRA, Confluence, and Git.\n\u2022 Experience with data manipulation and engineering, including using libraries like Pandas for cleaning, transforming, and analysing datasets.\n\u2022 As much familiarity as possible with the below tech stack:\n\u2022 Poetry\n\u2022 Django, Django Ninja\n\u2022 Postgres\n\u2022 Streamlit\n\u2022 Docker\n\u2022 Github Actions\n\u2022 Terraform\n\u2022 AWS (e.g. S3, RDS, Secrets Manager, ECS & ECR, Bedrock, \u2026)\n\nAbout SS&C: SS&C Technologies is a leading global provider of software solutions and services to the financial services industry. Our innovative technology platforms serve a diverse range of financial institutions, including asset managers, insurance companies, hedge funds, and wealth managers. We empower our clients to deliver superior investment outcomes by providing them with best-in-class digital solutions.\n\nWhat We Offer:\n\u2022 Competitive salary and performance-based bonuses.\n\u2022 Comprehensive benefits package, including health, dental, and retirement plans.\n\u2022 Opportunities for career growth and professional development.\n\u2022 A dynamic and collaborative work environment focused on innovation and excellence.\n\nUnless explicitly requested or approached by SS&C Technologies, Inc. or any of its affiliated companies, the company will not accept unsolicited resumes from headhunters, recruitment agencies, or fee-based recruitment services.\n\nSS&C Technologies is an Equal Employment Opportunity employer and does not discriminate against any applicant for employment or employee on the basis of race, color, religious creed, gender, age, marital status, sexual orientation, national origin, disability, veteran status or any other classification protected by applicable discrimination laws.",
    "url": "https://in.linkedin.com/jobs/view/python-developer-%E2%80%93-ai-innovation-pa25daiq1003-at-ss-c-technologies-4314144869?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "ETL QA with Pyspark & Python",
    "company": "Live Connections",
    "location": "Pune",
    "salary": "",
    "description": "Role - ETL QA with Pyspark & Python\n\nExperience - 6 to 10 years\n\nWork Location - Pune\n\nRequired Notice Period - Immedaite Joiners or 30 days max\n\nJob Description\n\nAs an ETL Tester, you will play a critical role in validating ETL processes and ensuring the accuracy of data extraction, transformation, and loading procedures. You will work closely with ETL developers, data engineers, and data analysts to establish high standards of data quality and integrity.\n\nSkill Requirement:\n\u2022 Experience in ETL testing and knowledge of ETL tools (e.g., Informatica, Talend).\n\u2022 Good Understanding of the Azure Platform and Databricks.\n\u2022 Proficiency in Python, PySpark to write a test script.\n\u2022 Proficiency in SQL and database concepts.\n\u2022 Understanding of data warehousing concepts and methodologies.\n\u2022 Knowledge of dimensional modelling and data warehouse concepts.\n\u2022 Proficiency in Unix/Linux & Shell scripting\n\u2022 Create and execute test plans and test cases for ETL processes.\n\u2022 Validate data flows and ensure data integrity across systems.\n\u2022 Perform data validation and verification activities.\n\u2022 Analyze and troubleshoot erroneous results, determine root causes, and log defects.\n\u2022 Collaborate with development teams to resolve software-related defects.\n\u2022 Review data models, data mappings, and architectural documentation.\n\u2022 Write queries to extract data for test case data comparison.\n\u2022 Ensure all sign-offs on deliverables and that testing meets governance requirements.\n\nTo apply, connect with Abhishek\n\nEmail - abhishek.m@livecjobs.com\n\nWhatsApp - 9154908075",
    "url": "https://in.linkedin.com/jobs/view/etl-qa-with-pyspark-python-at-live-connections-4321701658?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-08T06:00:00.000Z"
  },
  {
    "title": "REF69967Q_2025151745 - Deputy Manager - Data Science + Python - 4 to 6 years - Pune",
    "company": "WNS Global Services",
    "location": "Pune",
    "salary": "",
    "description": "Company Description\n\nWNS (Holdings) Limited (NYSE: WNS), is a leading Business Process Management (BPM) company. We combine our deep industry knowledge with technology and analytics expertise to co-create innovative, digital-led transformational solutions with clients across 10 industries. We enable businesses in Travel, Insurance, Banking and Financial Services, Manufacturing, Retail and Consumer Packaged Goods, Shipping and Logistics, Healthcare, and Utilities to re-imagine their digital future and transform their outcomes with operational excellence.We deliver an entire spectrum of BPM services in finance and accounting, procurement, customer interaction services and human resources leveraging collaborative models that are tailored to address the unique business challenges of each client. We co-create and execute the future vision of 400+ clients with the help of our 44,000+ employees.\n\nJob Description\n\nRoles & Responsibilities:Data Analysis: Analyse large datasets to extract meaningful insights and trends.Model Development: Develop and implement predictive models and machine learning algorithms to solve business problems.Data Cleaning: Ensure data quality by cleaning and pre-processing data.Visualization: Create visualizations to present data insights using tools like Power BI or Python libraries (e.g., Matplotlib, Seaborn).Collaboration: Work closely with data engineers, software developers, and business stakeholders to understand requirements and deliver solutions.Reporting: Generate automated reports and dashboards to provide actionable insights.Research: Stay updated with the latest trends and technologies in data science and machine learning.Technical Skills Required:Programming Languages: Proficiency in Python and SQL.Machine Learning: Experience with machine learning frameworks such as Scikit-learn, TensorFlow, or PyTorch.Data Visualization: Skills in data visualization tools like Power BI, Matplotlib, Seaborn, or Plotly.Statistical Analysis: Strong understanding of statistical methods and techniques.Data Wrangling: Expertise in data wrangling and pre-processing using libraries like Pandas and NumPy.Platforms like Power BI, Power Automate, Apps are good to have.\n\nQualifications\n\nExperience or Prerequisites:Education: Bachelor's or Master's degree in Data Science, Computer Science, Statistics, or a related field.Experience: 3+ years of experience in data science or a related field.Projects: Proven track record of working on data science projects and delivering impactful results.Certifications: Relevant certifications in data science or machine learning are a plus.",
    "url": "https://www.smartrecruiters.com/WNSGlobalServices144/744000092021693-ref69967q-2025151745-deputy-manager-data-science-python-4-to-6-years-pune-?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-06T00:00:00.000Z"
  },
  {
    "title": "Data Eng - DAP",
    "company": "Schaeffler",
    "location": "Pune",
    "salary": "",
    "description": "Schaeffler is a dynamic global technology company and its success has been a result of its entrepreneurial spirit and long history of private ownership. Does that sound interesting to you? As a partner to all of the major automobile manufacturers, as well as key players in the aerospace and industrial sectors, we offer you many development opportunities.\n\nYour Key Responsibilities\n\u2022 Develop data pipelines and applies methods and tools to collect, store, process and analyze complex data sets, globally for assigned operations or functions.\n\u2022 Design, govern, build and operate solutions for large-scale data architectures and applications across businesses and functions.\n\u2022 Select, manage and work hands-on with big data tools and frameworks, and implement ETL (extract, transform, load) tools and processes as well as data virtualization and federation services.\n\u2022 Engineer data integration pipelines and reusable data services using cross-functional data models, semantic technologies and data integration solutions.\n\u2022 Define, implement and apply data governance policies for all data flows of data architectures with focus on the digital platform and data lake.\n\u2022 Define and implement policies for data ingestion, retention, lineage, access, data service API management and usage, in collaboration with data management and IT functions.\n\nYour Qualifications\n\u2022 Graduate Degree in Computer Science, Applied Computer Science, Software Engineering\n\u2022 3 to 5 years\n\nAs a global company with employees around the world, it is important to us that we treat each other with respect and value all ideas and perspectives. By appreciating our differences, we inspire creativity and drive innovation. In this way, we contribute to sustainable value creation for our stakeholders and society as a whole. Together, we advance how the world moves.\n\nExciting assignments and outstanding development opportunities await you because we impact the future with innovation. We look forward to your application.\n\nwww.schaeffler.com/careers\n\nYour Contact\n\nSchaeffler Technology Solutions India Pvt. Ltd.\n\nKalyani More\n\nFor technical questions, please contact this email address: technical-recruiting-support-AP@schaeffler.com\n\nKeywords: Experienced; Engineer; Full-Time; Unlimited; Digitalization & Information Technology;",
    "url": "https://in.linkedin.com/jobs/view/data-eng-dap-at-schaeffler-4275383085?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-08T00:00:00.000Z"
  },
  {
    "title": "Data Analysis and Data Science Manager",
    "company": "confidential",
    "location": "Pune",
    "salary": "",
    "description": "The purpose of this role is to lead and manage customer analysis deep dives, execute the strategies outlined by senior leadership, and manage the day-to-day communication with clients.\n\nModel Development & Deployment\n\nExtensive Experience in building Information retrieval systems and relevance engineering\n\nDeveloping algorithms and building predictive models from the ground up, using machine learning and deep learning frameworks\n\nBuild AI models from scratch and help product managers and other stakeholders with analysis and implementation\n\nTransform machine learning models into APIs that can be integrated with other applications Training for AI engineers\n\nAt least 5 years of experience putting Machine Learning models into production AI Engineer Job Description Template\n\nProgramming Languages\n\nPython, SQL\n\nMachine Learning & AI Technologies\n\nAdvanced knowledge in Machine Learning models and Large Language Models (LLM), using langchain or a similar tool\n\nExperience in implementing LLMs using vector bases and Retrieval-Augmented Generation (RAG), as well as tuning models, building Knowledge Graphs\n\nCloud Platforms & Tools\n\nAzure, AWS, or Google Cloud and AI Stack\n\nData Technologies\n\nBig data technologies: Apache Spark, Hadoop, and MongoDB\n\nMathematical Foundation\n\nExperience Requirements\n\nAt least 5 years of experience putting Machine Learning models into production, 4 years of relevant experience.\n\nBrand:\n\nFull time\n\nContract Type:\n\nPermanent",
    "url": "https://in.jooble.org/rjdp/5003282700183690670?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Replacement Data Analytics AI/ML",
    "company": "confidential",
    "location": "Pune",
    "salary": "",
    "description": "Calling all innovators \u2013 find your future at Fiserv.\n\nWe're Fiserv, a global leader in Fintech and payments, and we move money and information in a way that moves the world. We connect financial institutions, corporations, merchants, and consumers to one another millions of times a day \u2013 quickly, reliably, and securely. Any time you swipe your credit card, pay through a mobile app, or withdraw money from the bank, we're involved. If you want to make an impact on a global scale, come make a difference at Fiserv.\n\nJob Title\n\nReplacement Data Analytics AI/ML\n\u2022 Bachelor's or Master's degree in Computer Science, Data Science, Statistics, Mathematics, or a related field.\n\u2022 8+ years of experience in data science, preferably in the payments or fintech industry.\n\u2022 Proficiency in Python, SQL, and data science libraries (e.g., pandas, scikit-learn, TensorFlow, PyTorch).\n\u2022 Strong understanding of payment systems, transaction flows, and fraud detection techniques.\n\u2022 Experience with big data technologies (e.g., Spark, Hadoop) and cloud platforms (e.g., AWS, GCP, Azure).\n\u2022 Excellent problem-solving skills and the ability to work in a fast-paced, collaborative environment.\n\nThank You For Considering Employment With Fiserv. Please\n\u2022 Apply using your legal name\n\u2022 Complete the step-by-step profile and attach your resume (either is acceptable, both are preferable).\n\nOur Commitment To Diversity And Inclusion\n\nFiserv is proud to be an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, gender, gender identity, sexual orientation, age, disability, protected veteran status, or any other category protected by law.\n\nNote To Agencies\n\nFiserv does not accept resume submissions from agencies outside of existing agreements. Please do not send resumes to Fiserv associates. Fiserv is not responsible for any fees associated with unsolicited resume submissions.\n\nWarning About Fake Job Posts\n\nPlease be aware of fraudulent job postings that are not affiliated with Fiserv. Fraudulent job postings may be used by cyber criminals to target your personally identifiable information and/or to steal money or financial information. Any communications from a Fiserv representative will come from a legitimate Fiserv email address.",
    "url": "https://in.jooble.org/jdp/-1459608365054407569?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Junior Data Scientist - Python - SQL",
    "company": "confidential",
    "location": "Pune",
    "salary": "",
    "description": "The ideal candidate's favorite words are learning, data, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers.\nResponsibilities\nAnalyze raw data: assessing quality, cleansing, structuring for downstream processing\nDesign accurate and scalable prediction algorithms\nCollaborate with engineering team to bring analytical prototypes to production\nGenerate actionable insights for business improvements\n\nQualifications\n\nBachelor's degree or equivalent experience in quantative field (Statistics, Mathematics, Computer Science, Engineering, etc.)\nAt least 1 - 2 years' of experience in quantitative analytics or data modeling\nDeep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithms\nFluency in a programming language (Python, C,C++, Java, SQL)\nFamiliarity with Big Data frameworks and visualization tools (Cassandra, Hadoop, Spark, Tableau)",
    "url": "https://in.jooble.org/rjdp/2779840858600349240?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-05T00:00:00.000Z"
  },
  {
    "title": "Senior Data Governance Engineer",
    "company": "Medtronic",
    "location": "Pune",
    "salary": "",
    "description": "Our Global Diabetes Capability Center in Pune is expanding to serve more people living with diabetes globally. Our state-of-the-art facility is dedicated to transforming diabetes management through innovative solutions and technologies that reduce the burden of living with diabetes.\n\nMedtronic is hiring a Senior Data Governance Engineer. As a Senior engineer, you will be a key member of our Data Governance team, defining scope, assessing current data governance capabilities, building roadmaps to mature data governance capabilities.\n\nThis role offers a dynamic opportunity to join Medtronic's Diabetes business. Medtronic has announced its intention to separate the Diabetes division to promote future growth and innovation within the business and reallocate investments and resources across Medtronic, subject to applicable information and consultation requirements. While you will start your employment with Medtronic, upon establishment of SpinCo or the transition of the Diabetes business to another company, your employment may transfer to either SpinCo or the other company, at Medtronic's discretion and subject to any applicable information and consultation requirements in your jurisdiction.\n\nResponsibilities may include the following and other duties may be assigned:\n\u2022 Data Governance Strategy Development - responsible for the strategic development, architectural definition, and enterprise wide data governance and data management initiatives supporting the delivery of data as a service.\n\u2022 Provide Data Governance and Data Management advisory expertise\n\u2022 Responsible for the identification and evaluation of metadata platform alternatives, the development of the logical metadata framework architecture, and the definition and implementation of metadata maintenance processes.\n\u2022 Defining Data Governance operating models, roles, and responsibilities in collaboration with Medtronic requirements.\n\u2022 Responsible for the assessment and selection of Data Management tools landscape including: data profiling, data quality, metadata, MDM, rules engines, and pattern matching\n\u2022 Refine and develop the data-centric approach and methodologies which may include areas such as: data strategy, data governance, data lineage, analytics, business intelligence, data architecture, data quality, master data management and data integration and delivery\n\u2022 Assess current state capabilities, identify gaps versus leading practices, and recommend future state data requirements.\n\u2022 Identify opportunities for new workflows, third party \u2018glossary/metadata\u2019 tools, database architectures, and third party pre-existing data models.\n\u2022 Work closely with business and technology stakeholders to assist in understanding and documenting data requirements, lineage, and partnering with IT data integration and data warehouse teams to ensure requirements are effectively executed.\n\u2022 Help define data modeling naming standards, abbreviations, guidelines, and best practices\n\u2022 Enhance or design data model review processes based on business requirements.\n\nRequired Knowledge and Experience:\n\u2022 At least 6 years of experience developing / structuring an enterprise-wide data governance organization and business process (operating models, roles, partner organizations, responsibilities).\n\u2022 Hands-on experience with both the business side and IT side implementing or supporting an MDM and/or Data Warehouse and Reporting IT solutions.\n\u2022 Utilize strong business knowledge of the investment management industry and common data management operations.\n\u2022 Broad understanding of the role of data management within global markets organizations, information flow, and data governance issues.\n\u2022 Domain expertise in specific areas of Data Management such as: data strategy, data governance, data lineage, analytics, business intelligence, data architecture, data quality, master data management and data integration and delivery.",
    "url": "https://in.linkedin.com/jobs/view/senior-data-governance-engineer-at-medtronic-4320539177?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "IT ServiceMax Lead Data Developer",
    "company": "Johnson Controls",
    "location": "Pimpri-Chinchwad",
    "salary": "",
    "description": "ServiceMax Lead Data Developer\n\nJohnson Controls is searching for a ServiceMax Lead Data Developer to design, develop, and manage data integration and development processes between ServiceMax, Salesforce, and other enterprise systems. In this role, you will lead the development of data pipelines, integrate field service data, and ensure that the data infrastructure supports the needs of business stakeholders. You will work closely with cross-functional teams, including data analysts, engineers, and business users, to ensure seamless and effective data workflows for field service management.\n\nWhat You Do\n\u2022 Lead the design of data flows between ServiceMax, Salesforce, ERP, and other enterprise applications.\n\u2022 Build data pipelines to support real-time and batch data processing for reporting and analytics.\n\u2022 Optimize and scale data workflows to handle large volumes of field service data while ensuring performance and data accuracy.\n\u2022 Design and implement the data architecture for ServiceMax, ensuring data consistency, accuracy, and quality across systems.\n\u2022 Work with cross-functional teams to define data models, sources, and transformations that support field service operations and reporting needs.\n\u2022 Manage and oversee the data integration process, ensuring that data from various sources is cleansed, transformed, and loaded correctly into the system.\n\u2022 Ensure compliance with data governance, privacy, and security standards.\n\nHow Will You Do It\n\u2022 Develop DB scripts to support specific Salesforce/ServiceMax data migration activities to meet business requirements.\n\u2022 Collaborate with business stakeholders to understand data needs and provide technical solutions to enhance data quality in the ServiceMax platform.\n\u2022 Implement data validation processes and ensure data integrity throughout the lifecycle of ServiceMax deployments.\n\u2022 Work closely with ServiceMax administrators, developers, and data analysts to align data systems with business objectives.\n\u2022 Coordinate with IT and business teams to troubleshoot data-related issues and implement fixes in a timely manner.\n\u2022 Monitor the performance of data workflows and integrations, proactively identifying bottlenecks or issues.\n\u2022 Continuously optimize data processes to ensure fast, reliable access to field service data for reporting and analytics purposes.\n\nRequired\n\nWhat we look for\n\u2022 Bachelor\u2019s degree in computer science, Information Systems, Engineering, or a related field.\n\u2022 5+ years of experience in data activities, with a focus on Salesforce and/or ServiceMax platform.\n\u2022 Strong experience with data integration tools (e.g., Informatica, DM Amp, Snowflake. BI tools) and APIs for connecting different systems.\n\u2022 Strong Experience with SQL and working with relational databases (e.g., MySQL, SQL Server).\n\u2022 Strong knowledge of data transformation, cleansing, and validation processes\n\u2022 Understanding of ServiceMax modules and how they integrate with Salesforce and other enterprise systems is a plus.\n\nPreferred\n\u2022 Proficiency in programming languages like SQL along with data modelling, ETL processes\n\u2022 Familiarity with field service management KPIs and operational reporting needs.\n\u2022 Experience with advanced data processing technologies (e.g., Hadoop, Spark) or machine learning integration is a plus.\n\u2022 Knowledge of Agile/Scrum methodologies and tools (e.g., Jira, Confluence).\n\u2022 Any certification related to MySQL/Oracle\n\u2022 Salesforce/ServiceMax Certified Administrator is an added advantage\n\nWho We Are\n\nAt Johnson Controls, we\u2019re shaping the future to create a world that\u2019s safe, comfortable and sustainable. Our global team creates innovative, integrated solutions to make cities more connected, buildings more intelligent and vehicles more efficient. We are passionate about improving the way the world lives, works and plays. The future requires bold ideas, an entrepreneurial mind-set and collaboration across boundaries. You need a career focused on tomorrow. Tomorrow needs you.",
    "url": "https://in.linkedin.com/jobs/view/it-servicemax-lead-data-developer-at-johnson-controls-4337454561?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-04T00:00:00.000Z"
  },
  {
    "title": "Senior Salesforce Data Analyst",
    "company": "Magma Digital Ventures",
    "location": "Pune",
    "salary": "",
    "description": "About the Role\n\nWe are hiring an accomplished Senior Salesforce Data Analyst to drive advanced analytics, reporting, and data-led decision-making across the organisation. This role is designed for a high-ownership problem-solver who can transform Salesforce data into business insights, performance acceleration, and executive-level intelligence.\n\nThe ideal candidate combines deep Salesforce platform expertise, strong analytical skills, and business acumen to help stakeholders optimise revenue, sales operations, forecasting accuracy, customer retention, and product adoption.\n\nThis role directly influences C-suite strategy, GTM execution, sales performance, customer lifecycle insights, and operational scalability.\n\nKey Responsibilities\n\n\ud83d\udd39 Own end-to-end Salesforce analytics, including data architecture, dashboards, insights, forecasting & reporting\n\n\ud83d\udd39 Build and optimise Sales, Revenue, Customer Success, Marketing & Product dashboards in Salesforce (CRM Analytics/Einstein Analytics/Tableau strongly preferred)\n\n\ud83d\udd39 Analyse and model pipeline health, revenue performance, churn patterns, user adoption & customer behaviour\n\n\ud83d\udd39 Partner with leadership to shape data-driven decision-making across the organisation\n\n\ud83d\udd39 Convert raw Salesforce datasets into actionable insights for CRO, CMO, CPO, CFO and CEO level stakeholders\n\n\ud83d\udd39 Develop datasets, reports and automation frameworks to reduce manual analytics effort\n\n\ud83d\udd39 Proactively identify process gaps, automation opportunities and performance levers\n\n\ud83d\udd39 Maintain high data accuracy, hygiene, governance and compliance\n\nRequired Skills & Experience\n\n\u2714 6+ years of analytics experience, with working hands-on with Salesforce datasets\n\n\u2714 Strong command over Salesforce CRM data model, objects, relationships & reporting\n\n\u2714 Expertise in CRM Analytics / Einstein Analytics / Tableau / Power BI / SQL / Python (any combination acceptable)\n\n\u2714 Proven experience building executive dashboards & business intelligence frameworks\n\n\u2714 Ability to communicate insights clearly to CXOs, VPs, and global leadership stakeholders\n\n\u2714 Experience working closely with Sales Ops, RevOps, Customer Success, Product, and Finance\n\n\u2714 Strong understanding of SaaS metrics such as ACV, ARR, churn, expansion, win-rates, pipeline velocity, CAC, LTV, and cohort modelling\n\nGood to Have\n\n\ud83d\udca0 Salesforce certifications (Salesforce Admin, Tableau CRM & Einstein Analytics, etc.)\n\n\ud83d\udca0 Experience with Salesforce CPQ, Marketing Cloud, Service Cloud, Commerce Cloud or Revenue Cloud\n\n\ud83d\udca0 Experience in RevOps, FP&A, Management Consulting or Analyst roles in SaaS organisations\n\nWhat Success Looks Like in This Role\n\n\ud83d\udd38 Data transparency across the organisation improves meaningfully\n\n\ud83d\udd38 Executives get metrics & insights before they ask for them\n\n\ud83d\udd38 Forecast accuracy increases & revenue predictability strengthens\n\n\ud83d\udd38 Data becomes the single source of truth for strategy and decisions\n\n\ud83d\udd38 Time spent on manual reporting dramatically reduces\n\nWhy This is a High-Impact & High-Growth Opportunity\n\n\ud83c\udf1f Strategic role with direct visibility to senior leadership & board\n\n\ud83c\udf1f Ownership of the entire Salesforce analytics landscape\n\n\ud83c\udf1f Autonomy to implement modern BI solutions and automation frameworks\n\n\ud83c\udf1f Work in a high-performance, outcome-driven organisation",
    "url": "https://in.linkedin.com/jobs/view/senior-salesforce-data-analyst-at-magma-digital-ventures-4322890723?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-15T00:00:00.000Z"
  },
  {
    "title": "Sr. Associate - Data Analyst",
    "company": "185 Northern Operating Sols Pvt Ltd",
    "location": "Pune",
    "salary": "",
    "description": "About Northern Trust: Northern Trust, a Fortune 500 company, is a globally recognized, award-winning financial institution that has been in continuous operation since 1889. Northern Trust is proud to provide innovative financial services and guidance to the world\u2019s most successful individuals, families, and institutions by remaining true to our enduring principles of service, expertise, and integrity. With more than 130 years of financial experience and over 22,000 partners, we serve the world\u2019s most sophisticated clients using leading technology and exceptional service. Role Overview We are seeking an experienced Senior Associate - Data Analyst to join our team. The ideal candidate will have a strong background in data analysis, modern data architectures, and cloud-based solutions. This role requires expertise in Azure Cloud Services, Data Mesh principles, and proficiency in programming languages such as Java and Python. You will collaborate with cross-functional teams to design, implement, and optimize data solutions that enable actionable insights and support business decisions. Key Responsibilities Analyze large and complex datasets to identify trends, patterns, and actionable insights. Design and implement data models aligned with Data Mesh architecture principles. Build and manage data solutions using Azure Cloud Services (Azure Data Lake, Azure Synapse, Azure Databricks, etc.). Develop and maintain ETL pipelines and data workflows for efficient data processing. Create dashboards, reports, and visualizations to communicate findings to stakeholders. Ensure data quality, governance, and compliance with organizational standards. Stay updated on emerging technologies and best practices in data analytics and distributed data systems. Mandatory Skills & Qualifications Azure Cloud Services: Hands-on experience with Azure Data Lake, Azure Synapse Analytics, Azure Databricks, and related services. Data Mesh: Strong understanding of Data Mesh principles, domain-oriented data ownership, and decentralized architecture. Programming Languages: Proficiency in Java, Python, and familiarity with other languages such as Scala or R. Data Analysis Tools: Expertise in SQL, data visualization tools (Power BI, Tableau), and statistical analysis. Data Engineering Concepts: Knowledge of ETL processes, data pipelines, and data governance. Communication Skills: Ability to present complex data insights to technical and non-technical stakeholders. Preferred Skills Experience with Big Data technologies (Spark, Hadoop). Familiarity with CI/CD pipelines and DevOps practices. Knowledge of API development and integration. Understanding of machine learning workflows for advanced analytics. Education Bachelor\u2019s or Master\u2019s degree in Computer Science, Data Science, Information Technology, or related field. Working with Us: As a Northern Trust partner, greater achievements await. You will be part of a flexible and collaborative work culture in an organization where financial strength and stability is an asset that emboldens us to explore new ideas. Movement within the organization is encouraged, senior leaders are accessible, and you can take pride in working for a company committed to assisting the communities we serve! Join a workplace with a greater purpose. We\u2019d love to learn more about how your interests and experience could be a fit with one of the world\u2019s most admired and sustainable companies! Build your career with us and apply today. #MadeForGreater Reasonable accommodation Northern Trust is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation for any part of the employment process, please email our HR Service Center at MyHRHelp@ntrs.com. We hope you\u2019re excited about the role and the opportunity to work with us. We value an inclusive workplace and understand flexibility means different things to different people. Apply today and talk to us about your flexible working requirements and together we can achieve greater. About Our Pune Office The Northern Trust Pune office, established in 2016, is now home to over 3,000 employees. The office handles various functions, including Operations for Asset Servicing and Wealth Management, as well as delivering critical technology solutions that support business operations across the globe. Our Pune team takes our commitment to service to heart. In 2024, they volunteered more than 10,000+ hours into the communities where they live and work. Learn more. Looking for greater? You found it. A global financial leader with more than 22,000 employees in 23 locations worldwide, Northern Trust empowers our employees to achieve more than just business goals. Our focus on work-life balance, career mobility and unique opportunities are just a few of the reasons we\u2019ve been named one of the world\u2019s most admired companies. Terms and Conditions Candidate Privacy Notice California Applicant Privacy Notice Pay Transparency Nondiscrimination Provision (U.S) Transparency in Coverage Disclosure \u2013 North America Northern Trust is committed to working with and providing reasonable accommodations to individuals with disabilities. If, because of a medical condition or disability, you need a reasonable accommodation for any part of the employment process, please email our HR Service Center or call 1-800-807-0302 (North America), +630-276-5353 (Asia Pacific), 1800-425-0333 (India), +44(0)207 982 4357 (Europe, Middle East and Africa) and let us know the nature of your request and your contact information. APAC/INDIA EEO STATEMENT It is the policy and practice of Northern Trust to provide equal employment opportunities to all employees and applicants. Northern Trust does not discriminate on the basis of race, colour, religion or belief, nationality, ethnic or national origin, sex, marital status, sexual orientation, disability or age. All employment decisions will be made in a non-discriminatory manner in accordance with our obligations under the law and codes of practice. This includes human resources\u2019 decisions relating to recruitment, terms and conditions of employment, transfers, promotions and access to learning and development. Canada EEO STATEMENT Northern Trust is an Equal Opportunity Employer. Hiring and other employment decisions at Northern Trust are made without regard to race, colour, religion, sex, ancestry, national origin, ethnic origin, age, disability, citizenship, veteran status, sexual orientation, record of offences, marital status, family status, or any other characteristic protected by federal, provincial, or local law, regulation, or ordinance. EMEA EEO STATEMENT It is the policy and practice of Northern Trust to provide equal employment opportunities to all employees and applicants. Northern Trust does not discriminate on the basis of race, colour, religion or belief, nationality, ethnic or national origin, sex, marital status, sexual orientation, disability or age. All employment decisions will be made in a non-discriminatory manner in accordance with our obligations under the law and codes of practice. This includes human resources\u2019 decisions relating to recruitment, terms and conditions of employment, transfers, promotions and access to learning and development. USA EEO STATEMENT It is the policy of The Northern Trust Company to afford equal opportunity in all phases of employment without regard to an individual's age, race, color, religion, creed, gender, national origin, citizenship status, marital status, pregnancy, sexual orientation, gender identity, gender expression, genetic tests and information, physical or mental disability, protected veteran status or any other legally protected status. EEO Know Your Rights (U.S.)",
    "url": "https://ntrs.wd1.myworkdayjobs.com/en-US/northerntrust/job/Sr-Associate---Data-Analyst_R146423?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-14T00:00:00.000Z"
  },
  {
    "title": "Sr. IT Data Analyst",
    "company": "Persistent Systems",
    "location": "Pune",
    "salary": "",
    "description": "About Position:\n\nWe are currently seeking a Sr IT Data Analyst to perform data analysis for a data warehouse/operational data store, data marts, and other data stores in support of the business. The new hire will define and maintain business intelligence/data warehouse methodologies, standards, and industry\u2019s best practices.\n\u2022 Role: Sr. IT Data Analyst\n\u2022 Location: All Persistent Locations\n\u2022 Experience: 8 to 12 Years\n\u2022 Job Type: Full Time Employment\n\nWhat You'll Do:\n\u2022 Gather business requirements for analytical applications in iterative/agile development model partnering with Business and IT stakeholders.\n\u2022 Create source-to-target mapping based on requirements.\n\u2022 Create rules definitions, data profiling and transformation logic.\n\u2022 Gather and prepare analysis based on requirements from internal and external sources to evaluate and demonstrate program effectiveness and efficiency, and problem solving.\n\u2022 Support Data Governance activities and be responsible for data integrity.\n\u2022 Developing scalable reporting processes and querying data sources to conduct ad hoc analyses/detailed data profiling.\n\u2022 Research complex functional data/analytical issues.\n\u2022 Assume responsibility for data integrity, data quality among various internal groups and/or between internal and external sources.\n\nExpertise You'll Bring:\n\u2022 Healthcare business and data analysis experience\n\u2022 Proficient in SQL, understands data modeling and storage concepts like Snowflake\n\u2022 Must have an aptitude for learning new data flows quickly and participate in data quality and automation discussions.\n\u2022 Be comfortable in working as SME educating data consumers on data profiles and issues.\n\u2022 Must be able to take end to end responsibility to quickly solve data issues in production setting.\n\u2022 Knowledge of Data Platforms, Data as a Service model and Data Ops practices\n\u2022 Highly preferred working knowledge of Kafka, Databricks, GitHub, Airflow, Azure\n\nBenefits:\n\u2022 Competitive salary and benefits package\n\u2022 Culture focused on talent development with quarterly growth opportunities and company-sponsored higher education and certifications\n\u2022 Opportunity to work with cutting-edge technologies\n\u2022 Employee engagement initiatives such as project parties, flexible work hours, and Long Service awards\n\u2022 Annual health check-ups\n\u2022 Insurance coverage: group term life, personal accident, and Mediclaim hospitalization for self, spouse, two children, and parents\n\nValues-Driven, People-Centric & Inclusive Work Environment:\n\nPersistent Ltd. is dedicated to fostering diversity and inclusion in the workplace. We invite applications from all qualified individuals, including those with disabilities, and regardless of gender or gender preference. We welcome diverse candidates from all backgrounds.\n\u2022 We support hybrid work and flexible hours to fit diverse lifestyles.\n\u2022 Our office is accessibility-friendly, with ergonomic setups and assistive technologies to support employees with physical disabilities.\n\u2022 If you are a person with disabilities and have specific requirements, please inform us during the application process or at any time during your employment\n\nLet\u2019s unleash your full potential at Persistent - persistent.com/careers\n\n\u201cPersistent is an Equal Opportunity Employer and prohibits discrimination and harassment of any kind.\u201d",
    "url": "https://in.linkedin.com/jobs/view/sr-it-data-analyst-at-persistent-systems-4340560384?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-14T00:00:00.000Z"
  },
  {
    "title": "Senior Data Analyst - Business Intelligence",
    "company": "beBeeDataIntegration",
    "location": "Pune",
    "salary": "",
    "description": "Job Description\n\nWe are seeking a skilled Data Integration Specialist to join our team. As an ETL Developer, you will play a key role in designing, building, and integrating data from various sources into our Enterprise Data Warehouse environment.\n\nThe ideal candidate will have advanced knowledge of relational databases, dimensional data modeling concepts, and experience with modern SaaS/PaaS data solutions.\nResponsibilities:\n\u2022 Design, develop, and implement ETL processes using industry-recognized standards and best practices.\n\u2022 Work closely with the Development Lead to plan, implement, and deliver ETL strategies.\n\u2022 Collaborate with business analysts to understand requirements and create technical design specifications.\n\u2022 Develop and deploy data-oriented solutions in the cloud (Azure/Synapse Analytics/Fabric).\n\u2022 Ensure data transformation and ETL layers are designed and implemented efficiently.\nRequired Skills and Qualifications:\n\u2022 Proven work experience as an ETL Developer.\n\u2022 Advanced knowledge of relational databases and dimensional data modeling concepts.\n\u2022 Expert-level knowledge of Microsoft Data stack.\n\u2022 Experience in developing and deploying data-oriented solutions in Cloud (Azure/Synapse Analytics/Fabric).\n\u2022 Strong SQL knowledge and ability to create complex queries.\n\u2022 Good working knowledge of at least one scripting language (Python is an advantage).\n\u2022 Experience with GIT repositories and working with branches.\n\u2022 Ability to troubleshoot and solve complex technical problems.\n\u2022 Good understanding of software development best practices and Agile principles.\nBenefits:\n\u2022 Opportunity to work on high-priority projects and contribute to the success of our organization.\n\u2022 Chance to collaborate with experienced professionals and learn from their expertise.\n\u2022 Professional growth and development opportunities.\nOthers:\n\nBackground in SSIS/SSAS/SSRS is a plus. Experience with Azure DevTest Labs, ARM templates, and Azure PurView is also advantageous. Banking/finance experience is preferred but not required.",
    "url": "https://in.bebee.com/job/229fefa9e838e9985cb6c40cad1e25d4?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-16T06:00:00.000Z"
  },
  {
    "title": "Senior Big Data Analyst",
    "company": "beBeeData",
    "location": "Pune",
    "salary": "",
    "description": "Big Data Developer Role\n\nWe are seeking a skilled Big Data Developer to join our team. The ideal candidate will have 5+ years of experience in developing Spark Scala applications, designing and implementing solutions for large-scale data processing using Hadoop ecosystem technologies such as HDFS, Spark, Hive, Parquet File format, YARN, MapReduce, Sqoop, and Autosys.\n\u2022 Responsibilities:\n\u2022 Design and develop scalable Spark Scala applications for efficient big data processing.\n\u2022 Develop complex Hive and SQL queries to process huge datasets.\n\u2022 Utilize UNIX commands and shell scripting to optimize data processing pipelines.\n\u2022 Implement User-Defined Functions (UDFs), tables, joins, views, and debug Spark code to deliver high-quality results.\n\u2022 Requirements:\n\u2022 Minimum 5+ years of experience in developing big data processing applications.\n\u2022 Excellent analytical and problem-solving skills.\n\u2022 Able to collaborate with Subject Matter Experts (SMEs) and stakeholders.\n\u2022 Familiarity with UNIX commands and shell scripting.",
    "url": "https://in.bebee.com/job/448e5d568ac34f5698c020fe85bf2c82?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-14T00:00:00.000Z"
  },
  {
    "title": "Senior Data Scientist",
    "company": "Mastercard",
    "location": "Pune",
    "salary": "",
    "description": "Our Purpose\n\nMastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we\u2019re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.\n\nTitle and Summary\n\nSenior Data Scientist\n\nLead, Data Scientist\n\u2022 Our Purpose\nWe work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team \u2013 one that makes better decisions, drives innovation and delivers better business results.\nJob Title: Data Scientist (Data, Analytics & AI), Advanced Analytics\n\nJob Description Summary Overview\nAdvanced Analytics drives AI-based solutions and products at a globally scalable level across the different customer lifecycle stages, across both financial institutions and retail & commerce.\n\nThis role is for a Lead Data Scientist that will work across Product, Client Services & Delivery, Data & Engineering and the broader teams, to deliver truly differentiated products driven by analytics & AI, leveraging rich data resources, AI platform capabilities and near real-time execution.\n\nThe Global Data Analytics & AI Product team is developing multiple new products and capabilities using analytics & AI, and this role is central in that vision, from concept, technical design to market release and optimization. This role is positioned to drive new ideas forward by combining creative thought leadership with innovation and industry best practices. By entering in the early phase of a truly transformative and impactful strategic initiative, the experience is certain to be rewarding. This role will report into the Vice President of Data Science & AI within Advanced Analytics.\n\nThe successful candidate\u2019s primary responsibilities will be to:\n- Drive the evolution of Advanced Analytics products with an impact focused on data science and engineering\n- Participate in the exploration, application and development of data science for product development\n- Participate in identification and evaluation of AI/ML techniques and tools to deliver models and analytics for product development\n- Continuously innovate and determine new data science approaches & technologies to solve business problems and generate business insights & recommendations\n- Partner with roles across the organization including product, engineering, and sales to determine the highest priority data science problems to solve in a customer-centric framework\n- Evaluate trade-offs between many possible analytics solutions to a problem, taking into account performance, usability, technical feasibility, timelines, and differing stakeholder opinions to make a decision\n- Break large solutions into smaller, releasable milestones to collect data and feedback from product managers, clients and other stakeholders\n- Evangelize releases to users, incorporating feedback, and tracking usage to inform future development\n- Work with small, cross-functional teams to define vision, establish team culture and processes\n- Consistently focus on key drivers of organization value and prioritize operational activities accordingly\n- Identify and act upon product improvement opportunities\n- Provide technical leadership of junior colleagues as a senior member of the data science team, through technical and non-technical mentoring\n\nThis role requires the successful candidate to have the following:\n- Prior experience in working in a data science product development role\n- Strong hands-on experience in Advanced Analytics, Machine Learning, Deep Learning, Advanced Statistics etc.\n- High proficiency in Python, Spark, SQL, R and be able to navigate across multiple languages\n- Preferably with hands-on experience with Hadoop big data tools (Hive, Impala, Spark) or Databricks\n- Demonstrated quantitative and problem-solving abilities including application to real business problems\n- Strong project management skills and ability to meet business deadlines and execution\n- Motivated, flexible, self-directed, and desire to lead small project teams as applicable\n- Curiosity, creativity, and excitement for technology and innovation and outside-in perspectives\n- Ability to multi-task and strong attention to detail including data utilized, methodology, results and validation\n- Outstanding communication and organizational skills\n- Masters preferred in Quantitative discipline like Physical Sciences, Mathematics, Statistics, Economics, Engineering etc.\n- 7-10 years of experience in Data Science function supporting Products\n\nCorporate Security Responsibility\n\nAll activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:\n\u2022 Abide by Mastercard\u2019s security policies and practices;\n\u2022 Ensure the confidentiality and integrity of the information being accessed;\n\u2022 Report any suspected information security violation or breach, and\n\u2022 Complete all periodic mandatory security trainings in accordance with Mastercard\u2019s guidelines.",
    "url": "https://careers.mastercard.com/us/en/job/R-245505/Senior-Data-Scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-13T00:00:00.000Z"
  },
  {
    "title": "Senior Data Analyst (SQL, Power BI)",
    "company": "Ranger Technical Resources",
    "location": "Pune",
    "salary": "",
    "description": "Data Analyst \u2013 Finance #2525\nOur partner is a global manufacturing and services company modernizing its finance analytics foundation replacing Excel with Power BI, integrating SAP ECC/S4 data, and building a scalable reporting layer across Finance. They\u2019re looking for a finance-savvy Data Analyst to own core reporting and forecasting models automating month-end close, building DAX-driven dashboards, and analyzing margin, spend, and cost structures at scale. You\u2019ll partner closely with FP&A and work inside a BI team that\u2019s moving fast on Databricks, Power Platform, and governed data modeling. If you\u2019ve worked in ERP-heavy environments, understand financial reporting structures (CO-PA, cost centers), and build with both speed and structure in mind this is a high-impact seat with strong visibility.\n\nExperience and Education:\n\u2022 Bachelor\u2019s degree in Finance, Accounting, Economics, or a related field\n\u2022 5+ years of experience in FP&A, financial analysis, or data-driven Finance roles\n\u2022 Experience working with ERP-based financial data (SAP ECC or S/4HANA preferred)\n\u2022 Prior experience transitioning teams from Excel-based reporting to BI platforms\n\nPower BI\nSQL\n\nFinancial Modeling\nCost Analysis\nVariance Analysis\nMargin Analysis\nSAP ECC\n\nSAP S/4HANA\n\nData Visualization\nETL\n\nAd Hoc Reporting\nAdvanced Excel\n\nAutomate and maintain Finance reporting workflows using Power BI\nAnalyze gross margin and cost drivers (labor, freight, materials, overhead)\nSupport the shift from Excel-based to governed, scalable BI tools\nPartner with cross-functional stakeholders to translate financial needs into usable data outputs\nConduct ad hoc analysis to answer time-sensitive finance questions\nEnsure consistency and quality of SAP-derived financial data used in reporting",
    "url": "https://in.jooble.org/rjdp/-8500824595756247058?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-13T00:00:00.000Z"
  },
  {
    "title": "Senior Analyst Knowledge Services",
    "company": "Infosys BPM Limited",
    "location": "Pune",
    "salary": "",
    "description": "Job Description:\n\u2022 Purpose of the role\n\u2022 Digital Transformation Services is one of the fastest growing businesses in the company\n\u2022 This role works towards Practice development incorporating new technologies and generating new revenue streams for the Practice\n\u2022 Support Digital Transformation Programs by designing and developing new digital solutions in Sourcing Procurement\n\u2022 Work alongside clients Sourcing Procurement function including outsourced operations and internal external technical teams to create and manage new age digital solutions in Sourcing Procurement\n\nKey Responsibilities:\n\u2022 Responsibilities\n\u2022 As a domain SME develop enhance improve digital solutions for the practice including but not limited to cognitive procurement suites category management tools predictive analytics internal procurement intelligence platforms\n\u2022 Business case creation and designing solutions on digital S P solutions based including value proposition business benefits commercial models etc\n\u2022 Benchmark and incorporate industry best practices in developing digital solutions\n\u2022 Support Digital Transformation Programs in Sourcing and Procurement including utilizing various technological interventions\n\u2022 Demonstrate digital solutions to clients and explain relevant value propositions\n\u2022 Conduct quick assessment on client s existing landscape\n\u2022 Interact manage internal and external stakeholders and seek feedback in order to ensure strong customer satisfaction\n\u2022 Develop analysis to understand performance Performs quantitative and qualitative analysis like raw data analysis statistical modelling data deep dives etc\n\u2022 to acquire insights from data\n\u2022 Project collaboration Work effectively both independently and as a member of cross functional teams\n\nTechnical Requirements:\n\u2022 Knowledge Skills\n\u2022 Excellent knowledge of Sourcing and Procurement processes\n\u2022 Exposure to Analytics autonomous Procurement Category management tools and platforms\n\nAdditional Responsibilities:\n\u2022 Experience\n\u2022 4 8 years experience in the Sourcing Procurement domain\n\u2022 At least 2 4 years experience in front line business consulting crafting solutions and delivering presentations to management teams\n\u2022 Needs to have exposure to various digital solutions in Sourcing and Procurement\n\u2022 Analyzing data interpreting results\n\nPreferred Skills:\n\nSourcing & Procurement->Procurement",
    "url": "https://www.glassdoor.co.in/job-listing/senior-analyst-knowledge-services-infosys-JV_IC2856202_KO0,33_KE34,41.htm?jl=1009938601038&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-13T00:00:00.000Z"
  },
  {
    "title": "Sr. Business Analyst (AI/ML Domain) | Immediate Joiner |",
    "company": "Zimetrics",
    "location": "Pune",
    "salary": "",
    "description": "We are looking for a highly skilled Senior Business Analyst with a strong background in AI/ML-based products. The ideal candidate will bridge business objectives and technical solutions, working closely with product, engineering, and data science teams to deliver high-impact AI-driven solutions.\n\nKey Responsibilities:\n\u2022 Collaborate with stakeholders to understand business needs and translate them into detailed product and functional requirements.\n\u2022 Work with data scientists and engineering teams to conceptualize and validate AI/ML models and product features.\n\u2022 Define KPIs and success metrics for AI-driven product performance and adoption.\n\u2022 Conduct data-driven analysis and generate actionable insights to support product decisions.\n\u2022 Create user stories, process flows, and documentation for development and testing teams.\n\u2022 Support product lifecycle activities \u2014 from ideation to deployment and continuous improvement.\n\u2022 Partner with cross-functional teams (Product, Engineering, QA, and UI/UX) to ensure alignment and timely delivery.\n\nRequired Skills & Experience:\n\u2022 5+ years of experience as a Business Analyst, ideally in AI/ML or data-driven product environments.\n\u2022 Strong understanding of ML concepts, data workflows, and analytics platforms.\n\u2022 Proven experience in product-based organizations or tech-driven startups.\n\u2022 Proficiency in writing BRDs, FRDs, user stories, and acceptance criteria.\n\u2022 Strong analytical mindset with experience using tools like JIRA, Confluence, Excel, SQL, or Tableau/Power BI.\n\u2022 Excellent communication and stakeholder management skills.",
    "url": "https://in.linkedin.com/jobs/view/sr-business-analyst-ai-ml-domain-immediate-joiner-at-zimetrics-4336020731?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-13T00:00:00.000Z"
  },
  {
    "title": "Senior Specialist- Data Analyst Lead",
    "company": "RiverForest Connections Private Limited",
    "location": "Pune",
    "salary": "",
    "description": "Job description\n\nJob Requirements for LEAD DA role\n\n1 Banking Domain Experience\n\n2 Experience in DA related project not Data Engineering Development\n\n3 Tech Skills PySpark Hadoop SQL Excel all are MUST\n\n4 Experience in Agile framework Jira Confluence\n\n5 Experience in Stakeholder Management\n\n6 Experience in Project Management\n\n7 Experience in Leading Team\n\n8 Experience Min 7 years\n\n9 Location Pune candidate must relocate to Pune if based in other location\n\n10 Availability Immediate\n\nSkills\n\nMandatory Skills : MS Excel, PowerBI, Python, QlikView, Tableau\n\nGood to Have Skills : ANSI-SQL, Cognos Analytics, Microstrategy, SAP Business Objects",
    "url": "https://www.glassdoor.co.in/job-listing/senior-specialist-data-analyst-lead-riverforest-connections-private-limited-JV_IC2856202_KO0,35_KE36,75.htm?jl=1009711442792&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-16T00:00:00.000Z"
  },
  {
    "title": "Data Operations Analyst",
    "company": "DigiTaiken Tech LLP",
    "location": "Pune",
    "salary": "",
    "description": "Data Operations - Analyst\n\n---\n\nJob Summary\n\nAs a Senior Data Operations Analyst, you will play a crucial role in ensuring the accuracy, integrity, and efficiency of our data processes. You will leverage your analytical and communication skills to drive data-driven insights and support critical business decisions within a dynamic and evolving environment.\n\nJob Responsibilities\n\u2022 Lead the analysis and interpretation of complex datasets, identifying trends, anomalies, and opportunities for improvement.\n\u2022 Collaborate with cross-functional teams to define data requirements, design data solutions, and implement best practices.\n\u2022 Develop and maintain data visualization dashboards and reports to effectively communicate key performance indicators and insights to stakeholders.\n\u2022 Apply commercial acumen to understand business needs and translate them into actionable data strategies.\n\u2022 Contribute to the continuous improvement of data operations processes, fostering agility and efficiency.\n\u2022 Support financial reporting activities by ensuring data accuracy and providing insightful analysis.\n\u2022 Proactively identify and assess data-related risks, implementing mitigation strategies as necessary.\n\u2022 Champion customer-centric thinking in all data initiatives, ensuring solutions meet user needs.\n\u2022 Influence and educate colleagues on data best practices, promoting a data-driven culture.\n\u2022 Drive and manage change initiatives related to data operations, ensuring smooth transitions and adoption.\n\u2022 Present findings and recommendations to various audiences, including senior management, with clarity and confidence.\n\u2022 Stay abreast of industry trends, particularly in sustainability, and incorporate relevant data considerations into operations.\n\nJob Qualifications\n\u2022 Proven experience in a Customer Master Data or in Master Data, demonstrating strong analytical thinking. (~5-6 years of experience in Master Data especially in Customer)\n\u2022 Proficiency in SAP, and interpretation tools, techniques and system like MDG, Genplus (Oracle) (~5-6 years of experience in SAP, Salesforce, MDG)\n\u2022 Excellent collaboration and communication skills, both written and verbal.\n\u2022 Demonstrated commercial acumen and an understanding of business drivers.\n\u2022 Ability to apply agility core practices to adapt to evolving business needs.\n\u2022 A strong customer-centric approach to problem-solving.\n\u2022 Proven ability to influence stakeholders and manage change effectively.\n\u2022 Skilled in presenting complex information clearly and concisely.\n\u2022 Familiarity with risk management principles and practices.\n\u2022 Awareness of sustainability considerations in data management is a plus.\n\u2022 Creativity and innovation in approaching data challenges.\n\nJob Type: Contractual / Temporary\nContract length: 12 months\n\nPay: \u20b92,000,000.00 - \u20b92,200,000.00 per year\n\nApplication Question(s):\n\u2022 Do you have Proficiency in SAP, and interpretation tools, techniques and system like MDG, Genplus (Oracle) (~5-6 years of experience in SAP, Salesforce, MDG)\n\nExperience:\n\u2022 Master data management: 5 years (Required)\n\u2022 SAP: 5 years (Required)\n\nLocation:\n\u2022 Pune, Maharashtra (Required)\n\nWork Location: In person",
    "url": "https://www.simplyhired.co.in/job/SjVuBRoYChEmWVSQLK5ff5Cf4pJ2ZT6woUXQQ2C3BB01977219ZiQw?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-12T00:00:00.000Z"
  },
  {
    "title": "Lead Data Analyst L1",
    "company": "Wipro Limited",
    "location": "Pune",
    "salary": "",
    "description": "Job Description\n\u2022 Job Title: Lead Data Analyst L1\n\nReq Id: 111195\n\nCity: Pune\n\nState/Province: Maharashtra\n\nPosting Start Date: 11/13/25\n\nWipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients\u2019 most complex digital transformation needs. Leveraging our holistic portfolio of capabilities in consulting, design, engineering, and operations, we help clients realize their boldest ambitions and build future-ready, sustainable businesses. With over 230,000 employees and business partners across 65 countries, we deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world. For additional information, visit us at www.wipro.com.\n\nJob Description:\nJob Description\n\nRole Purpose\n\nThe purpose of this role is to interpret data and turn into information (reports, dashboards, interactive visualizations etc) which can offer ways to improve a business, thus affecting business decisions\n\n\u034f\n\nDos\n\n1. Managing the technical scope of the project in line with the requirements at all stages\n\na. Gather information from various sources (data warehouses, database, data integration and modelling) and interpret patterns and trends\n\nb. Develop record management process and policies\n\nc. Build and maintain relationships at all levels within the client base and understand their requirements.\n\nd. Providing sales data, proposals, data insights and account reviews to the client base\n\ne. Identify areas to increase efficiency and automation of processes\n\nf. Set up and maintain automated data processes\n\ng. Identify, evaluate and implement external services and tools to support data validation and cleansing.\n\nh. Produce and track key performance indicators\n\n2. Analyze the data sets and provide adequate information\n\na. Liaise with internal and external clients to fully understand data content\n\nb. Design and carry out surveys and analyze survey data as per the customer requirement\n\nc. Analyze and interpret complex data sets relating to customer\u2019s business and prepare reports for internal and external audiences using business analytics reporting tools\n\nd. Create data dashboards, graphs and visualization to showcase business performance and also provide sector and competitor benchmarking\n\ne. Mine and analyze large datasets, draw valid inferences and present them successfully to management using a reporting tool\n\nf. Develop predictive models and share insights with the clients as per their requirement\n\n\u034f\n\nDeilver\n\nNo.\nPerformance Parameter\nMeasure\n\n1.\nAnalyses data sets and provide relevant information to the client\nNo. Of automation done, On-Time Delivery, CSAT score, Zero customer escalation, data accuracy\n\n\u034f\n\n\u034f\n\nMandatory Skills: Epic .\n\nExperience: 8-10 Years .\n\nReinvent your world. We are building a modern Wipro. We are an end-to-end digital transformation partner with the boldest ambitions. To realize them, we need people inspired by reinvention. Of yourself, your career, and your skills. We want to see the constant evolution of our business and our industry. It has always been in our DNA - as the world around us changes, so do we. Join a business powered by purpose and a place that empowers you to design your own reinvention.",
    "url": "https://www.glassdoor.co.in/job-listing/lead-data-analyst-l1-wipro-limited-JV_IC2856202_KO0,20_KE21,34.htm?jl=1009938326628&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-13T00:00:00.000Z"
  },
  {
    "title": "TTT - Data Analytics - Tax Senior",
    "company": "EY",
    "location": "Pune",
    "salary": "",
    "description": "At EY, you\u2019ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we\u2019re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.\n\nPosition\n\nEY\u2019s GDS Tax Technology team\u2019s mission is to develop, implement and integrate technology solutions that better serve our clients and engagement teams. As a member of EY\u2019s core Tax practice, you\u2019ll develop a deep tax technical knowledge and outstanding database, data analytics and programming skills.\n\nEver-increasing regulations require tax departments to gather, organize and analyse more data than ever before. Often the data necessary to satisfy these ever-increasing and complex regulations must be collected from a variety of systems and departments throughout an organization. Effectively and efficiently handling the variety and volume of data is often extremely challenging and time consuming for a company.\n\nEY's GDS Tax Technology team members work side-by-side with the firm's partners, clients and tax technical subject matter experts to develop and incorporate technology solutions that enhance value-add, improve efficiencies and enable our clients with disruptive and market leading tools supporting Tax.\n\nGDS Tax Technology works closely with clients and professionals in the following areas: Federal Business Tax Services, Partnership Compliance, Corporate Compliance, Indirect Tax Services, Human Capital, and Internal Tax Services. GDS Tax Technology provides solution architecture, application development, testing and maintenance support to the global TAX service line both on a pro-active basis and in response to specific requests.\n\nEY is currently seeking one ETL Data Engineering- Senior to join our Tax Technology practice in Bangalore, India.\n\nThe opportunity\n\nWe\u2019re looking for a Tax Senior with expertise in ETL Data Engineering- Senior to join the TTT team in Tax SL. This is a fantastic opportunity to be part of a pioneer firm whilst being instrumental in the growth of a new service offering.\n\nYour key responsibilities\n\u2022 Responsible for maintenance of SQL Server, database design, and create schema objects like tables, views and indexes\n\u2022 Backend database development in MS SQL Server, writing complex queries, stored procedures, views, triggers, cursors, UDFs.\n\u2022 Experience working with reporting/visualization tools like Power BI, Reporting services\n\u2022 Must have sound knowledge on Azure Data Factory V2\n\u2022 Exposure to NOSQL datastores like MongoDB, Cosmos DB\n\u2022 Good to have knowledge on BIG Data platform like Hadoop, MapReduce, Hive though not mandatory\n\u2022 Assist seniors in database architecture design effort and also develop/ review architecture designs.\n\u2022 Responsible for effectively communicating with other team members and clients on project related information\n\u2022 Experience on IaaS/PaaS based Azure offerings.\n\nSkills and attributes for success\n\u2022 Bachelors / Master\u2019s degree in Computer Engineering / Information Technology / MCA.\n\u2022 4+ years of hands on work experience building SQL Database, understanding of database design and data modelling, SQL server experience with SSIS, ETL experience working with SSIS.\n\u2022 Backend database development in MS SQL Server, writing complex queries, stored procedures, views, triggers, cursors, UDFs.\n\u2022 Experience working with reporting/visualization tools like Power BI, Reporting services\n\u2022 Strong verbal and written communications skills\n\nTo qualify for the role, you must have\n\u2022 Bachelor\u2019s / Master\u2019s degree in Science/ Engineering / MCA/ MBA\n\u2022 Master\u2019s degree preferred.\n\u2022 4-8 years of relevant experience.\n\u2022 Management experience a plus\n\nIdeally, you\u2019ll also have\n\u2022 Thorough knowledge Tax or Finance Domain.\n\u2022 Strong statistical, skills and attention to detail.\n\u2022 The ability to adapt your work style to work with both internal and client team members\n\nWhat we look for\n\u2022 SQL Server, database design.\n\u2022 Working collaboratively in a team environment\n\u2022 Excellent oral and written communication skills\n\u2022 Strong analytical and problem-solving skills\n\u2022 BE, BTech, MCA degree required.\n\nWhat we offer\n\nEY Global Delivery Services (GDS) is a dynamic and truly global delivery network. We work across six locations \u2013 Argentina, China, India, the Philippines, Poland and the UK \u2013 and with teams from all EY service lines, geographies and sectors, playing a vital role in the delivery of the EY growth strategy. From accountants to coders to advisory consultants, we offer a wide variety of fulfilling career opportunities that span all business disciplines. In GDS, you will collaborate with EY teams on exciting projects and work with well-known brands from across the globe. We\u2019ll introduce you to an ever-expanding ecosystem of people, learning, skills and insights that will stay with you throughout your career.\n\u2022 Continuous learning: You\u2019ll develop the mindset and skills to navigate whatever comes next.\n\u2022 Success, as defined by you: We\u2019ll provide the tools and flexibility, so you can make a meaningful impact, your way.\n\u2022 Transformative leadership: We\u2019ll give you the insights, coaching and confidence to be the leader the world needs.\n\u2022 Diverse and inclusive culture: You\u2019ll be embraced for who you are and empowered to use your voice to help others find theirs.\n\nEY | Building a better working world\n\nEY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.\n\nEnabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.\n\nWorking across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.",
    "url": "https://careers.ey.com/ey/job/Pune-TTT-Data-Analytics-Tax-Senior-MH-411014/1113443801/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-13T00:00:00.000Z"
  },
  {
    "title": "System Data Analyst",
    "company": "beBeeAnalysis",
    "location": "Pune",
    "salary": "",
    "description": "Business Intelligence Analyst\n\nWe are seeking an experienced Business Intelligence Analyst to join our team. As a key member of our organization, you will be responsible for developing and maintaining business intelligence solutions to drive strategic decision-making.\nKey Responsibilities:\n\u2022 Create and edit Web Intelligence and Desktop Intelligence documents based on business requirements.\n\u2022 Develop VB Macros and Microsoft Excel or PowerPoint reports using various data types and expected result sets.\n\u2022 Automate data analysis processes by creating Excel-based macros to improve efficiency.\n\u2022 Create or modify SQL queries as per data gathering and analytical needs.\n\u2022 Generate reports in HTML, PDF, or RTF formats as specified by business teams.\nRequirements:\n\u2022 Strong Analytical Skills: Ability to analyze complex data sets and develop actionable insights.\n\u2022 Excellent Communication Skills: Effective communication with stakeholders to present findings and recommendations.\n\u2022 Technical Expertise: Proficiency in Microsoft Office, particularly Excel, and experience with SQL queries.\nBenefits:\n\nWe offer a competitive salary, comprehensive benefits package, and opportunities for professional growth and development.",
    "url": "https://in.bebee.com/job/87150f9625589952b13d515ec61ec91c?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-16T06:00:00.000Z"
  },
  {
    "title": "Data Security Analyst",
    "company": "NMS Consultant",
    "location": "Pune",
    "salary": "",
    "description": "As a Data Security Analyst, you will champion the security and integrity of our ever-evolving data landscape, focusing on modern domains like DLP and DSPM, empowering classification, protection, and monitoring across cloud and on-prem environments.\n\nKey Responsibilities:\n\nData Leak Prevention (DLP): Implement and extend DLP solutions to secure sensitive information across data at rest, in motion and in use.\n\nData Security Posture Management (DSPM): Continuously assess and enhance the security posture of our data estates, using DSPM techniques to discover inventory and remediate exposures.\n\nMonitoring Shared Folder Activities: Monitor and analyze activities on shared drives and folders for anomalous behavior and unauthorized access.\n\nSensitive Information Types (SITs) & Data Types: Identify and define SITs and data types to drive accurate classification and automated policy enforcement.\n\nSensitivity Labels & Microsoft Information Protection (MIP): Apply and manage sensitivity labels via MIP to enforce encryption, rights management and access restrictions.\n\nData Access Monitoring (DAM): Utilize DAM capabilities to track database access, detect threats, and respond to compromised credentials.\n\nFile Activity Logs Monitoring: Maintain visibility into user activity across SaaS/On-Prem applications (e.g. O365, SharePoint, ServiceNow, Salesforce, Servers, Endpoints).\n\nIntegration of Security Tools: Leverage cutting-edge platforms such as Microsoft Purview, Varonis DSP, Harmony Browse and Zscaler and more to enforce policies and glean actionable insights.\n\nSecurity Frameworks & Compliance: Apply knowledge of security and privacy frameworks (e.g. NIST, CIS, PCI-DSS, GDPR) to maintain compliance and best practices.\n\nScripting & Automation: Develop and maintain scripts in PowerShell/Python to automate classification, remediation and reporting.\n\nExperience: Proven track record in data security encompassing DLP, DSPM, data types of classification, SIT definition, sensitivity labels and MIP.\n\nTechnical Skills: Hands-on expertise with Microsoft Purview, Varonis, Harmony Browse, Zscaler or any other DLP/DSPM platforms.\n\nScripting: Strong scripting skills in PowerShell and Python to build tools, automations and alerts.\n\nData Security Frameworks & Regulation: Deep understanding of frameworks and regulations (GDPR, ISO 27001, NIST CSF/SP800, PCI DSS, SOC 2).\n\nInvestigation & Response: Ability to investigate anomalies, respond to incidents and escalate appropriately.\n\nTeamwork: Collaboration, transparency and knowledge share is the key for successful teamwork.\n\nCommunication: Excellent written and verbal communication skills to collaborate across functions and convey complex technical concepts clearly.",
    "url": "https://in.linkedin.com/jobs/view/data-security-analyst-at-nms-consultant-4322216371?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-13T00:00:00.000Z"
  },
  {
    "title": "Data and  Analytics",
    "company": "Kone",
    "location": "IN",
    "salary": "",
    "description": "A Data and Machine Learning Specialist is responsible for managing, analyzing, and leveraging data to drive business insights and develop predictive models. This role combines elements of data science, data engineering, data management, and machine learning to ensure data-driven decision-making and innovation.\n\nResponsibilities:\n\u2022 Data Collection & Management: Gather, clean, and organize data from various sources to ensure its accuracy and accessibility.\n\u2022 Data Analysis: Utilize statistical methods and machine learning tools to analyze data and uncover trends and patterns.\n\u2022 Pipeline Development: Design and maintain efficient data pipelines and architectures to facilitate seamless data flow.\n\u2022 Model Development: Create, test, and optimize machine learning models and algorithms to solve complex problems.\n\u2022 Reporting & Visualization: Present findings through detailed reports and visualizations to communicate insights effectively.\n\u2022 Collaboration: Work closely with cross-functional teams, including software engineers, data scientists, and business analysts, to implement data-driven solutions.\n\u2022 Performance Optimization: Continuously improve data delivery, scalability, and model performance.\n\u2022 Documentation: Maintain thorough documentation of processes, models, and results.\n\nRequirements:\n\u2022 Bachelors or equivalent degree with over 5+ years of experience and proficiency in programming languages such as Python, SQL.\n\u2022 Strong knowledge of cloud platforms like AWS, Google Cloud, or Microsoft Azure.\n\u2022 Experience with data visualization tools and techniques.\n\u2022 Solid understanding of machine learning algorithms and statistical analysis.\n\u2022 Excellent problem-solving skills and attention to detail.\n\u2022 Ability to collaborate effectively with diverse teams.\n\nAt KONE, we are focused on creating an innovative and collaborative working culture where we value the contribution of each individual. Employee engagement is a key focus area for us and we encourage participation and the sharing of information and ideas. Sustainability is an integral part of our culture and the daily practice. We follow ethical business practices and we seek to develop a culture of working together where co-workers trust and respect each other and good performance is recognized. In being a great place to work, we are proud to offer a range of experiences and opportunities that will help you to achieve your career and personal goals and enable you to live a healthy and balanced life.\n\nRead more on www.kone.com/careers",
    "url": "https://careers.kone.com/fi-fi/avoimet-tyopaikat/r0648559/data-and-analytics/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-15T00:00:00.000Z"
  },
  {
    "title": "Product & Growth Data Analyst(SQL,Python,Power BI) with Service based  Company Pune",
    "company": "Rajiv Padmanabhan Padmanabhan( Proprietor of Seventh Contact Hiring Solutions)",
    "location": "Pune",
    "salary": "",
    "description": "Key Responsibilities\n\nBusiness Intelligence & Reporting\n\n? Design executive dashboards: revenue, ride metrics, cohort analysis, churn/retention, subscription\n\nfunnels, ROAS, CAC/LTV\n\n? Deliver weekly/monthly insight reports with clear recommendations\n\n? Establish automated reporting systems.\n\nProduct Analytics\n\n? Define and instrument KPIs with Product/Engineering teams\n\n? Analyze feature performance (T+7, T+30, T+60 post-launch)\n\n? Monitor guardrail metrics, anomaly detection, funnel analysis\n\n? Maintain self-service analytics dashboards.\n\nGrowth & Marketing Analytics\n\n? Own marketing channel ROAS measurement with attribution methodology\n\n? Perform segmentation analysis across geographies, partners, user cohorts\n\n? Implement advanced attribution models (MMM/MTA).\n\nML Data Enablement\n\n? Publish documented training datasets and labels regularly\n\n? Implement data quality checks: leakage prevention, train/serve parity\n\n? Establish data contracts for ML applications.\n\nData Quality & Automation\n\n? Build monitoring systems for data freshness, completeness, reconciliation\n\n? Implement alerting with defined SLAs.\n\nDaily Operations\n\n? Morning business health checks and anomaly detection\n\n? Rapid response to stakeholder data inquiries\n\nTechnical Skills\n\n? SQL (MySQL): Advanced joins, window functions, CTEs, cohort analysis, optimization\n\n? Python: Strong pandas, NumPy, Jupyter experience\n\n? BI Tools: Retool, Metabase, Looker, or Power BI\n\n? Statistics: Attribution modeling, experiment design, lift analysis, holdout testing\n\n? Data Exploration: EDA, outlier detection, distribution analysis, sensitivity testing.\n\nProfessional Skills\n\n? Exceptional communication: distill complex analyses into clear narratives\n\n? Strong problem-solving with attention to detail and accuracy\n\n? Independent worker with cross-team collaboration ability\n\n? Experience with AI-assisted coding tools\n\n? Preferred - MongoDB Git Consumer apps/marketplace/subscription business experience",
    "url": "https://www.foundit.in/job/product-growth-data-analyst-sql-python-power-bi-with-service-based-company-pune-rajiv-padmanabhan-padmanabhan-proprietor-of-seventh-contact-hiring-solutions-pune-38065141?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-11T00:00:00.000Z"
  },
  {
    "title": "Looking for immediate joiners - Lab Data Analyst-Python Programming",
    "company": "IQVIA India",
    "location": "Pune",
    "salary": "",
    "description": "Job Title : Lab Data Analyst-Python Programming\n\nSkill : Python programming, data analysis, review and processing\n\nExperience : 2 to 4 years\n\nLocation : Across PAN India\n\nJob Overview\n\u2022 Provide comprehensive clinical lab data expertise as part of a team to develop and maintain Laboratory Data Management (LDM) tasks for the studies awarded to IQVIA Laboratories and meets the external client data reporting needs. May be required to support the development of new systems and processes related to the electronic data transfer process, or the configuration of business rules and master data in study and laboratory information systems. Understand and comply with core standard operating procedures and working instructions.\n\nEssential Functions\n\n\u2022 2-3 years of experience in Data Management and Python Programming. Requires basic knowledge of Python Programming and Data Management procedures obtained through prior work experience or education. Equivalent combination of education, training, computing qualification and experience.\n\u2022 \u2022 Capable of taking up, independently or providing inputs for, Python programming activities pertaining to ongoing study requirements or any other adhoc projects in the department\n\u2022 \u2022 Create and/or review all appropriate data management documents\n\u2022 \u2022 Understand and comply with core standard operating procedures and working instructions\n\u2022 \u2022 Develop and maintain good communications and working relationships with LDM team. Serve as back-up for other Data Team Leads\n\u2022 \u2022 Interact with internal and external team members to negotiate timelines and responsibilities\n\u2022 \u2022 Train and mentor junior staff in DM expertise\n\u2022 \u2022 Ensure service and quality meet agreed upon timelines and deliverables in data transmission agreements. Ensure quality checks performed on data files before transmission and obtain peer-review where required. Review own work for accuracy and completeness\n\u2022 \u2022 Record all evidence of the data transmission process from data file definition to closure of study\n\u2022 \u2022 Ensure that all specification and design documentation are filed and stored according to company policy\n\u2022 \u2022 Ensure the internal and external customer queries are timely addressed and resolved effectively\n\u2022 \u2022 Multiple communication styles and skill to effectively broker, audience specific (peers, senior team members, internal/external customers) business and interpersonal relationships that lead to positive outcomes and successful business results\n\u2022 \u2022 Perform other duties as directed by the functional manager\n\u2022 \u2022 Manages the delivery of projects through full data management study life-cycle, from setup to lock\n\u2022 \u2022 Supports the identification and resolution of service level issues, as well as the proactive development of contingency plans to mitigate laboratory risk\n\u2022 \u2022 Works with customers, scientific team, data managers and internal team members to manage issue escalation, workload projections, and provide technical expertise\n\u2022 \u2022 Interacts and communicates with internal and external customers to ensure that timelines are met and that data is delivered following company guidelines and regulatory compliance\n\u2022 \u2022 With guidance, manages project timelines and quality issues, and identifies and justifies out-of-scope client requests\n\u2022 \u2022 Assists internal team with data entry, review and validation of laboratory reports, and serves as back-up contact when needed\n\u2022 \u2022 Performs comprehensive quality control and edit check procedures\n\u2022 \u2022 Supports service delivery with comprehensive process and technical expertise in executing projects which includes identifying and resolving issues. Effectively works on corrective and develop preventive action plans\n\nQualifications\n\u2022 Bachelor's Degree (B. E, B. Tech, B. Pharm):\n\u2022 Computer Science with Software Configuration and Validation experience Req",
    "url": "https://in.jobrapido.com/jobpreview/627469108908130304?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-13T00:00:00.000Z"
  },
  {
    "title": "General Manager Product Innovation West East Zone",
    "company": "Godrej Properties",
    "location": "Pune",
    "salary": "",
    "description": "Key responsibilitiesThe General Manager\nProduct Innovation will lead product\nrelated activities across projects at various lifecycle stages\npre\nlaunch\nlaunch\nand sustenance\nThis role involves assisting the Product Head and senior management in making strategic product decisions to position as the most customer\ncentric real estate brand with innovative and differentiated offerings\nThe incumbent will define the right product mix for upcoming launches\nestablish unique selling propositions\nUSPs\n\nanalyze competition\nassist the marketing team in campaigns\nand train the sales team to ensure project success\nKey Responsibilities\nProduct Strategy\nDevelopment\nDefine and recommend the right product mix for upcoming projects\nDevelop USPs for each project by identifying consumer needs and market trends\nResearch and recommend innovative features addressing customer pain points and aspirations\nMarket Research\nBenchmarking\nConduct competition benchmarking and consumer research in collaboration with HO teams\nProvide critical inputs for land acquisition based on desirability\nsales velocities\nand pricing\nInnovation\nStandardization\nSet up and update product innovation processes\ntemplates\nand standards\nMonitor and ensure the implementation of standardized processes across regions\nStakeholder Collaboration\nCollaborate with internal teams\nMarketing\nDesign\nand Sales\nand external vendors to ensure seamless project execution\nConduct value proposition testing with stakeholders\nincluding channel partners and consumers\nTraining\nSupport\nDeliver product training to the sales team during launches and sustenance phases\nProvide guidance to regions on market positioning and pricing strategies\nKey Performance Indicators\nKPIs\n\nSuccessful product launches with defined USPs and optimal product mix\nEffective training sessions and support for the sales team\nHigh accuracy in market research and competition analysis\nTimely delivery of innovative recommendations and standardized processes\nImproved customer satisfaction and market positioning for all projects\nWho are we looking for\n\nQualifications\nExperience\n\nMBA or Master\ns in Construction Management from a leading institution\n\nBachelor\ns degree in Civil Engineering\n710 years of experience in product innovation\nmarketing strategy\nor related roles in the real estate or construction industry\n\nSkills\nCompetencies\n\nComprehensive understanding of the real estate or related industries and technical aspects\n\nStrong analytical\nproblem\nsolving\nand decision\nmaking abilities\n\nExcellent communication\npresentation\nand interpersonal skills",
    "url": "https://www.jobaaj.com/job/godrej-properties-general-manager-product-innovation-west-east-zone-pune-8-to-13-years-1149906?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-30T00:00:00.000Z"
  },
  {
    "title": "Lead Product Manager - Technical",
    "company": "Mastercard",
    "location": "Pune",
    "salary": "",
    "description": "Job Title:\n\nLead Product Manager - Technical\n\nOverview:\n\nRole Overview\nAs a Product Manager \u2013 Technical (PM-T), you will help shape the platform product roadmap by translating business needs, customer experiences, and technology trends into actionable features. You will work closely with engineering, UX, and business stakeholders to deliver scalable, high-impact platform capabilities that drive value across the organization.\n\nKey Responsibilities\nProduct Strategy & Planning\n\u2022 Translate business needs, market opportunities, and technology trends into platform initiatives.\n\u2022 Use the Working Backwards method to decompose customer experiences into features and functions.\n\u2022 Own the vision and documentation for feature releases, including the Working Backwards document and the product requirement document.\n\u2022 Identify gaps and charter new platform capabilities as needed.\n\u2022 Use runtime metrics as feedback into the backlog and balance them against new feature requests.\nCustomer & Market Insights\n\u2022 Participate in customer research with business teams to understand platform feature needs.\n\u2022 Use runtime metrics and customer feedback to inform backlog prioritization.\n\u2022 Conduct competitive analysis to support prioritization and roadmap planning.\n\u2022 Develop and implement new metrics; collaborate with development teams to monitor them.\nExecution & Delivery\n\u2022 Define release goals and prioritize features based on business and platform value.\n\u2022 Continuously monitor feature development and ensure alignment with goals.\n\u2022 Review product demos with development teams against acceptance criteria.\n\u2022 Prepare for launches and monitor platform performance, adoption, and operational health.\n\u2022 Independently and proactively monitor product performance to detect unusual patterns or issues, investigate potential causes, and escalate to the appropriate teams when necessary..\n\u2022 Ensure testability is embedded in product design and development, enabling robust validation and faster deployment cycles.\nCollaboration & Communication\n\u2022 Work with Technical Program Managers, developers, UX designers, and internal customers to define business requirements.\n\u2022 Act as the voice of the business customer and advocate for customer needs.\n\u2022 Coordinate in internal forums to gather feedback and identify development opportunities.\n\u2022 Build, get reviewed and follow go-to-market (GTM) plans for the features to be released.\nOperational Support\n\u2022 Identify and communicate risks that may impact timely or quality delivery of features.\n\u2022 Support post-launch reviews and ensure feedback is incorporated into future iterations.\n\u2022 Collaborate with internal teams and customer service to classify and prioritize customer issues.\n\u2022 Own and manage product documentation to support self-service and reduce overhead.\nGrowth & Mentorship\n\u2022 Exhibit expertise in your platform feature area and coordinate with interdependent teams.\n\u2022 Mentor junior team members and contribute to a culture of continuous learning.\n\u2022 Build internal and external networks to support product success.\nQualifications\n\u2022 Experience in product management, preferably in a technical or platform-focused role.\n\u2022 Solid understanding of software development processes, APIs, and platform services.\n\u2022 Experience writing user stories, acceptance criteria, and working closely with engineering and UX teams.\n\u2022 Strong analytical skills with experience using metrics and customer feedback to inform decisions.\n\u2022 Ability to manage feature-level trade-offs and prioritize based on business and technical value.\n\u2022 Excellent collaboration and communication skills across technical and non-technical stakeholders.\n\u2022 Familiarity with Agile/Scrum methodologies and product documentation practices.\n\u2022 Bachelor\u2019s degree in Computer Science, Engineering, or a related field; product certifications (e.g., CSPO, Pragmatic) are a plus.\nReady to Join Us?\nIf you're looking to grow your career with a technology leader in the payments space, apply now and help build the next generation of platform products.\n\nTo find US Salary Ranges, visit People Place. Under the Compensation tab, select \"Salary Structures.\" Within the text of \"Salary Structures,\" click on the link \"salary structures 2025,\" through which you will be able to access the salary ranges for each Mastercard job family. For more information regarding US benefits, visit People Place and review the Benefits tab and the Time Off & Leave tab.",
    "url": "https://careers.mastercard.com/us/en/job/R-261359/Lead-Product-Manager-Technical?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-03T00:00:00.000Z"
  },
  {
    "title": "Senio Product Manager-Crm10-12 Years (Pune)",
    "company": "Recognized",
    "location": "Pune",
    "salary": "",
    "description": "We\u2019re Hiring: Senior Product Manager\n\nWe\u2019re looking for a Senior Product Manager who can own and drive end-to-end product strategy, especially across modern enterprise and AI-driven ecosystems. If you thrive in ambiguity, think strategically, and execute with precision, we want to talk to you.\n\nWhat We're Looking For\n\nExtensive Product Leadership (10\u201312 Years)\n\nYou\u2019ve led 0\u21921 product development, defined MVPs, and built strategic roadmaps across complex enterprise environments. You can quickly grasp business problems, craft a compelling vision, and drive execution with an experimentation mindset. Familiarity with OKRs is essential.\n\n\ufe0f Deep Domain Expertise: Sales Lifecycle + CRM\n\nSolid experience across the Sales Lifecycle (Quoting \u2192 Billing \u2192 Invoicing) and deep knowledge of CRM systems\u2014Salesforce preferred . You\u2019ve built scalable products for GTM/sales users within Salesforce or similar ecosystems.",
    "url": "https://in.jobrapido.com/jobpreview/429965243960000512?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-30T00:00:00.000Z"
  },
  {
    "title": "Product Manager (Technical) - Insurance Background",
    "company": "Zinnia (zinnia.com)",
    "location": "Pune",
    "salary": "",
    "description": "WHO WE ARE:\n\nZinnia is the leading technology platform for accelerating life and annuities growth. With innovative enterprise solutions and data insights, Zinnia simplifies the experience of buying, selling, and administering insurance products. All of which enables more people to protect their financial futures. Our success is driven by a commitment to three core values: be bold, team up, deliver value \u2013 and that we do. Zinnia has over $180 billion in assets under administration, serves 100+ carrier clients, 2500 distributors and partners, and over 2 million policyholders.\n\nWHO YOU ARE:\n\nYou will be a liaison between Technology and other Business Functions to ensure sound business solutions are formed and implemented with quality. You\u2019ll join our System of Record (SoR) team. The SoR is a critical component of our platform, managing ownership, compliance, and transitions of insurance policies across agents and brokers. You\u2019ll lead initiatives to strengthen our SoR capabilities, ensure regulatory alignment, and build scalable, API-first products that serve both internal and external users.\n\nWHAT YOU\u2019LL DO:\n\u2022 Contribute into the execution of all product lifecycle processes for products, including product research, market research, competitive analysis, planning, positioning, roadmap development, requirements development, and product launch\n\u2022 Own the SoR product roadmap \u2013 define strategy, prioritize features, and align with business goals.\n\u2022 Partner with engineering, design, compliance, and customer success teams to deliver high-quality features on time.\n\u2022 Define product requirements and user stories with clarity and manage the backlog effectively.\n\u2022 Works with a cross-functional team to ensure fulfilment of product requirements, evaluates product performance and transition products from development to commercialization\n\u2022 Assist in drive automation and data accuracy in SoR transitions, audits, and reporting.\n\u2022 Influence the evolution of APIs and data models that underpin SoR logic.\n\u2022 Communicate product plans and updates clearly across technical and non-technical audiences.\n\u2022 Assist in Developing and executing proposed business and technical solutions\n\u2022 Assist in the research and investigation of escalated production issues and engage teams for resolution\n\u2022 Document business impact, research and resolution steps and long-term preventative measures via incident reports\n\nWHAT YOU\u2019LL NEED:\n\u2022 A Bachelor\u2019s/Master\u2019s Degree with Technology focused role & experience in Product Management or Business Analysis\n\u2022 5+ years of Product Management experience, ideally in B2B SaaS or FinTech/InsurTech domains\n\u2022 Must have experience across Insurance Industry - Life Insurance, Annuity, financial services etc.\n\u2022 Strong understanding of insurance distribution, agency/broker relationships, and regulatory concepts (SoR, commissions, appointments, licensing).\n\u2022 Experience working with API-based products and backend platforms.\n\u2022 Comfortable writing SQL queries or collaborating closely with data/engineering teams.\n\u2022 Proven success delivering complex products involving compliance and external integrations.\n\u2022 Excellent communication, problem-solving, and stakeholder management skills.\n\u2022 Detail-oriented with a bias for action and ownership mindset.\n\nWHAT\u2019S IN IT FOR YOU?\n\nZinnia offers excellent career progression and competitive compensation. We offer great benefits, including health/dental insurance, parental leave, profit sharing, PF, incentive/bonus opportunity, tuition reimbursement, and so much more. We\u2019re looking for the best and brightest innovators in the industry to join our team. At Zinnia, you collaborate with smart, creative professionals who are dedicated to delivering cutting-edge technologies, deeper data insights, and enhanced services to transform how insurance is done. Visit our website at www.zinnia.com for more information. Apply by completing the online application on the careers section of our website. We are an Equal Opportunity employer committed to a diverse workforce. We do not discriminate based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability.\n\n#LI-RS1",
    "url": "https://builtin.com/job/product-manager-technical-insurance-background/7367917?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-30T00:00:00.000Z"
  },
  {
    "title": "Senior Product Manager / Head of Product Management",
    "company": "confidential",
    "location": "Pune",
    "salary": "",
    "description": "Are you looking for an opportunity to build and grow products used by some of the biggest and most influential organizations around the world \u2014 right from Pune\n\nIcertis is seeking a Senior Manager, Product Management to play a key role in shaping the next generation of our industry-leading CLM (Contract Lifecycle Management) platform. The ideal candidate is a hands-on Product Management professional with experience delivering enterprise-grade SaaS products. Own the definition, planning, and execution of product roadmap for one or more key areas of the Icertis Contract Intelligence (ICI) platform.\n\nDirector of Product Management, CTO, and Engineering teams to define product capabilities that deliver sustainable differentiation.\n\nPartner with Professional Services, Customer Success, and Support teams to identify and prioritize capabilities that improve product implementation, deployment, and usability.\n\nChampion product capabilities that enhance user experience, ease of use, and administration.\n\nManage the end-to-end product lifecycle \u2014 from ideation and requirements to release management and adoption tracking.\n\n12\u201317 years of overall experience, with at least 6\u20138 years in Product Management for enterprise SaaS or platform products.\n\u2022 Strong understanding of B2B SaaS, preferably in enterprise software, CLM, or related domains.\n\u2022 Excellent analytical and problem-solving skills, with a data-driven approach to decision making.\n\u2022 Experience with AI/ML-driven product capabilities or enterprise platform architecture is a plus.\n\nIcertis is the global leader in AI-powered contract intelligence. The Icertis platform revolutionizes contract management, equipping customers with powerful insights and automation to grow revenue, control costs, mitigate risk, and ensure compliance - the pillars of business success. Today, more than one third of the Fortune 100 trust Icertis to realize the full intent of millions of commercial agreements in 90+ countries.\n\nWho we a re: Icertis is the only contract intelligence platform companies trust to keep them out in front, now and in the future. Our unwavering commitment to contract intelligence is grounded in our FORTE values\u2014Fairness, Openness, Respect, Teamwork and Execution\u2014which guide all our interactions with employees, customers, partners, and stakeholders. Because in our mission to be the contract intelligence platform of the world, we believe how we get there is as important as the destination.\n\nIcertis, Inc. provides Equal Employment Opportunity to all employees and applicants for employment without regard to race, color, religion, gender identity or expression, sex, sexual orientation, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Icertis, Inc. complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. If you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to [HIDDEN TEXT] or get in touch with your recruiter.",
    "url": "https://in.jooble.org/rjdp/-8232345394481567171?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-01T00:00:00.000Z"
  },
  {
    "title": "Product Manager/Business Developement",
    "company": "Avnet",
    "location": "Pune",
    "salary": "",
    "description": "Job Summary:\n\nSupplier professional focused on the strategic leadership and relationship of company suppliers to achieve the best financial performance and relationship with assigned product lines\n\nPrincipal Responsibilities:\n\u2022 Directs and manages the supplier business plan and implementation process throughout the organization leveraging supplier strengths and resources on behalf of the supplier and communicating supplier benefits to the company.\n\u2022 Aligns goals and objectives of supplier with the company to ensure mutual goals and objectives are achieved.\n\u2022 Determines, monitors and recommends plans for the supplier, company business relationship on a tactical and strategic level.\n\u2022 Participates in supplier business reviews providing appropriate data and engaging in resolving issues.\n\u2022 Identifies and drives new supplier opportunities with particular emphasis on the development of new services that blend unique supplier resource/capability along with service/capability to create a unique value proposition.\n\u2022 Supports cross functional communication with the company's product groups in price negotiations and market knowledge.\n\u2022 Responsible for the management of activities and programs that will drive the supplier\u2019s pro-forma performance in an effort to achieve Avnet's financial goals.\n\u2022 Performs analysis and reports of various program impact for the supplier.\n\u2022 Manages forecasting pipeline requirements and rebate projections.\n\u2022 Other duties as assigned.\n\nJob Level Specifications:\n\u2022 Mastery knowledge of industry best practices and disciplines. Considered a subject matter expert within the organization and contributes to the development of new concepts, techniques and standards.\n\u2022 Develops solutions to highly complex and uniquely challenging situations. Assignments require extensive evaluation of alternatives and variables. Expected to make improvements to policies and procedures.\n\u2022 Works independently toward long-range goals and objectives. Assignments are often self-initiated using independent judgment and discretion. May act as informal team lead and/or coach less experienced team members.\n\u2022 Serves as consultant to management and/or internal/external spokesperson for the organization on major initiatives related to policies, plans and long-range objectives.\n\u2022 Actions may impact the organization and its reputation. Effects of erroneous decisions may be long-lasting, influence the future course of the organization and/or require the expenditure of extensive additional resources.\n\nWork Experience:\n\u2022 Typically 8+ years with bachelor's or equivalent.\n\nEducation and Certification(s):\n\u2022 Bachelor's degree or equivalent experience from which comparable knowledge and job skills can be obtained.\n\nDistinguishing Characteristics:\n\nThe above statements are intended to describe the general nature and level of work being performed. They are not intended to be construed as an exhaustive list of all responsibilities, duties, and skills.",
    "url": "https://www.glassdoor.co.in/job-listing/product-manager-business-developement-avnet-JV_IC2856202_KO0,37_KE38,43.htm?jl=1009519084627&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-01T00:00:00.000Z"
  },
  {
    "title": "Analyst, Technical Product Management [T500-21651]",
    "company": "McDonald's Global Office in India",
    "location": "Pune",
    "salary": "",
    "description": "About McDonald\u2019s:\n\nOne of the world\u2019s largest employers with locations in more than 100 countries, McDonald\u2019s Corporation has corporate opportunities in Hyderabad. Our global offices serve as dynamic innovation and operations hubs, designed to expand McDonald's global talent base and in-house expertise. Our new office in Hyderabad will bring together knowledge across business, technology, analytics, and AI, accelerating our ability to deliver impactful solutions for the business and our customers across the globe.\n\nWe are excited to announce an opening for a Technology Testing Analyst at MCC India.\n\nPlease find below the details of the role and its responsibilities.\n\nJob Description:\n\nThis role will be a part of Operations Excellence function and Tech Excellence team and will report to (QA Manager \u2013 Operations Excellence). This role will be responsible for QA testing, QA automation, creating test strategies, leading a team of testers, reporting, maintaining traceability, risks and issues control with regards to QA delivery.\n\nSkills Required:\n\u2022 TOSCA (preferable) or any other automation tool (UFT / Selenium etc), Oracle E Business Suite, JIRA, Zephyr, Automation Testing, Test Automation\n\nExperience Range:\n\u2022 6 - 10 years\n\nResponsibilities & Accountabilities:\n\u2022 Technology \u2013 QA Automation using TOSCA (preferable) or any other automation tool (UFT / Selenium etc), CI/CD - FlexDeploy, Web, API, Mobile automation - Technology support & Guidelines on industry best practices, Test Management using Jira / Zephyr, QA Test Lab Servers and Infrastructure Administration, QA Tools License Management\n\u2022 Strong Interface/Integration Testing experience.\n\u2022 Hands on with Product Integration with Scripting.\n\u2022 Process \u2013 Test Strategy, Test Metrics, Reporting, Traceability management, Risk and Issues\n\u2022 Performance testing strategy and load test planning using Neoload\n\u2022 QA Delivery and Testing for Oracle Ebusiness Suite, Cloud ERP, HR-Payroll applications, Patch testing\n\u2022 Leading a team of testers in the team\n\nQualifications:\n\nBasic Qualifications:\n\u2022 Minimum of 5 years of experience in relevant role\n\u2022 Strong knowledge of QA processes and technology\n\u2022 Excellent communication and presentation skills\n\u2022 Experience in leading a team\n\nPreferred Qualifications:\n\u2022 Professional certifications such as CSTE / CSQA / Tosca Certification\n\u2022 MCP Playwright automation, Load testing, CI/CD as nice to have skills.",
    "url": "https://in.jobrapido.com/jobpreview/7399853290193682432?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-02T00:00:00.000Z"
  },
  {
    "title": "Product Owner - Intermediate",
    "company": "Equifax",
    "location": "Pune",
    "salary": "",
    "description": "Whether you started from the product side and developed technical skills or started as a technical resource, you have a knack for the product side of the business. You possess the necessary technical product knowledge to drive strategic conversations about the product and enhance value to Equifax and its customers.\n\nEquifax is seeking a technical product owner who is a master at bridging the desires of the customer and the capabilities of the technology, removing barriers to software development. You will be responsible for grooming the product backlog and have insight into technical requirements of individual stories thus creating a more efficient user experience.\n\nWhat you will do\n\u2022 Connects with the Customer in partnership with Product Management including: Know the customer & stakeholders: Can identify who the customers and stakeholders are and their role in their organization. Regularly partners with key engineering and QA counterparts; Understands the Problem(s) to be solved: May participate in interviews with users, customers and stakeholders to understand requirements. Understands the customer pain points and gets to know the concept of jobs to be done - what the customer needs to accomplish; Develops whole product solutions: Begins to understand the context for a given solution within the existing capabilities in the ecosystem\n\u2022 Contributes to the Plan and Roadmap including: Solutioning and Estimation: Weighs in the solutioning and epic decomposition process to groom the backlog of stories as well as initial t-shirt sizing sessions; Dependency management: Helps identifying, capturing and documenting dependencies required to deliver the plan; Backlog Prioritization and planning: Is consulted regarding value/effort dynamics in weighing conversations for quarterly planning\n\u2022 Manages & Prioritizes Team Backlog(s) - User Story creation: Understands how to write stories and creates initial drafts; Prioritization and sprint planning: Applies prioritization criteria aligned to Product Management and Product Owner best practices. Understands and helps document sprint, sprint goal, ensures sprint plans are in place for the current sprint and the subsequent two sprints. Helps ensure alignment with upstream dependencies to deliver; Testing and Acceptance Criteria: Documents story acceptance criteria and ensures development and QE team have a clear understanding; Demos: Contributes ideas for how to best demonstrate the value delivered and draft initial demo script\n\u2022 Getting and Applying Feedback & Lessons Learned - Captures feedback from Demos: Help document customer and stakeholder feedback to incorporate into enhancements, and new story development; Delivery Retrospectives: Velocity, quality (incidents/bugs), reasons for delays: Understands drivers of team velocity; Understands testing gaps that drove incidents and bugs; Understands drivers for delays in committed deliverables. Proposes ideas to address the drivers for these challengers; Monitors adoption KPIs: Understands metrics driving the adoption success of the released value and connects the dots with the previous and upcoming deliverables; Adopts feedback in future iterations: Can articulate the scope and/or changes to new release increments to feedback collected.\n\nWhat experience you need\n\u2022 Bachelor's degree in a related discipline strongly preferred; equivalent experience may be considered\n\u2022 2-5 years of product management experience or related coursework and project based experience\n\u2022 Has a general understanding of Agile methodologies\n\u2022 Has a general understanding of data structure &, data analytics, relevant experience in financial services is a plus\n\u2022 Cloud certification or ability to attain\n\nWhat could set you apart\n\u2022 You have the ability build strong relationships with partners across the business; ensure that you understand their role, the needs of their area, and their requirements throughout the project\n\u2022 You are a self-starter who is organized, detail oriented, takes initiative with minimal direction, and understands concepts quickly\n\u2022 You understand the value of product ownership and can effectively communicate the value proposition\n\u2022 You have experience working with multiple partners in a global setting with varying level of needs\n\u2022 You bring a consultative, creative and process driven approach to your work\n\u2022 You have an aptitude for handling multiple concurrent demands and prioritizing responsibilities in a dynamic, high energy environment\n\u2022 Your problem-solving skills enable you to effectively and creatively find solutions for hard problems while maintaining a high level of professionalism and integrity\n\u2022 Engage and collaborate with all stakeholders, make people feel heard and understood, are able to say no and stand up for tough calls needed to better serve the business and our clients",
    "url": "https://careers.equifax.com/fr/trouver-un-emploi/j00172110/product-owner-intermediate/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-11-30T00:00:00.000Z"
  },
  {
    "title": "Manager, Product Development (Payments Domain Exp)",
    "company": "Mastercard",
    "location": "Pune",
    "salary": "",
    "description": "Our Purpose\n\nMastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we\u2019re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.\n\nTitle and Summary\n\nManager, Product Development (Payments Domain Exp)\n\nWho is Mastercard?\nMastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.\nOur decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.\n\nOverview:\nThe Connectivity and Switching team is dedicated to growing MasterCard revenue from transaction switching and proprietary value added services associated with switching and as standalone offerings. The Connectivity and Switching Solutions team partners with other Mastercard Product Groups, Operations & Technology and Regional Partners to enhance the strategic fit, quality, efficiency and applicability of Mastercard\u2019s network and services assets to customer needs. The team creates and packages Product and Solutions offerings to drive new transaction flows, VAS product distribution and competitive advantage with merchants, processors, financial institutions, fin-techs, and other industry participants.\nAs part of the larger team and reporting to the Technical Product Architect the Product Director is responsible for identifying and creating technical designs for the Mastercard Network Exchange structures and features to improve and solve business and client needs. This position will use deep knowledge of the current functionality of the architecture, leverage licensed, but unused components available through our partner vendor and Mastercard or other networks to help drive competitive advantage and product evolution. The Product Director will focus on the capabilities, and detailed information from Mastercard and non-Mastercard networks to design solutions using (as often as possible) standard Mastercard tools. This position will seek to maximize the release of new technical capabilities used by our partner vendor to rationalize and improve the client experience. The goal is to design solutions that make Networks Exchange easy to implement and simple to use for clients. Maximize automation of manual tasks and integrate solutions to streamline the processes and procedures that are supported today by clients, internal operations, and technical resources. This position will deliver the technology features roadmap to ensure the coordination of product initiatives (e.g. automating exception processing) and corporate projects (e.g. future technology evolution) to drive the realization of our Network or Networks strategy across the business.\n\nRole:\n\u2022 Perform technical design, support development of existing and new products.\nUnderstand product vision and business needs to define product requirements and inform product architectural solutions.\n\u2022 Develop architectural and design principles to improve performance, capacity, efficacy and scalability of product.\nWork with Product Manager in planning and executing technical and new product releases.\n\u2022 Consult business management team to clarify objectives and functional requirements for new or modified products.\n\u2022 Work with domain, product management and product engineering teams in the solution engineering efforts.\n\u2022 Work with sales and product management teams in solution demonstrations.\n\u2022 Deliver technical product roadmap and architectural standards that assure product development projects optimally align with business objectives.\n\u2022 Drive product validation policies so as to deliver products that meet system and project expectations.\n\u2022 Facilitate the creation, review, and approval of project deliverables.\n\u2022 Provide support for production escalations and problem resolution for customers.\n\u2022 Assist technical team with issues needing technical expertise or complex systems knowledge.\n\u2022 Develop broad knowledge about current and future product features.\n\u2022 Define technical response to business requirements that address market opportunities.\n\u2022 Manage small team of Product Managers.\n\nAll about you:\n\u2022 Significant experience in payment switching technologies, turning customer use cases into technical solutions, and using technology to reinforce strong client value propositions.\n\u2022 Product management experience highly desired.\n\u2022 Bachelor\u2019s or Master\u2019s degree in a related technical field.\n\u2022 Significant experience designing payment solutions for use in different geographies, considering regulatory, business and processing characteristics present in different markets.\n\u2022 Creative design thinking skills that seek to create value driven technical solutions with the end user in mind.\n\u2022 Vendor management experience.\n\u2022 Ability to manage across a global and decentralized organization.\n\u2022 Creativity and problem solving.\n\u2022 Proven ability to build and maintain strong, productive working relationships with internal stakeholders and external customers.\n\nCorporate Security Responsibility\n\nAll activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:\n\u2022 Abide by Mastercard\u2019s security policies and practices;\n\u2022 Ensure the confidentiality and integrity of the information being accessed;\n\u2022 Report any suspected information security violation or breach, and\n\u2022 Complete all periodic mandatory security trainings in accordance with Mastercard\u2019s guidelines.",
    "url": "https://careers.mastercard.com/us/en/job/R-265683/Manager-Product-Development-Payments-Domain-Exp?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-03T00:00:00.000Z"
  },
  {
    "title": "Product Management Lead (Functional)-Oracle Projects (Costing/Billing)- | US Product Company - Pune (Baner)",
    "company": "Seventh Contact Hiring Solutions",
    "location": "Pune",
    "salary": "",
    "description": "Job Title: Product Management Lead / Functional\n\nLocation: Pune (Baner)\n\nExperience: 8+ Years\n\nRole Type: Individual Contributor \u2013 Functional Architect\n\nNotice Period: Immediate joiners preferred\n\nQualification: MBA/CA or any other relevant qualification\n\nJob Description:\n\nWe are seeking an experienced Functional Architect / Product Management Lead with strong expertise in Oracle Projects (Costing/Billing) and hands-on experience across multiple enterprise project management systems.\n\nKey Responsibilities:\n\nLead implementation and support projects for Oracle Projects modules (Costing/Billing).\n\nWork across Oracle EBS, Oracle Fusion, SAP PS, Monday.com, Zoho Projects, and EcoSys; experience in any of these is acceptable.\n\nOwn the complete configuration and creation of functional designs for complex RICEF components.\n\nDemonstrate a deep understanding of project management processes across various domains, supported by real implementation experience.\n\nEffectively manage stakeholders, ensuring clarity in requirement gathering, communication, and delivery of project solutions.\n\nDevelop test scripts aligned with client-provided requirements.\n\nCollaborate with the product development team to contribute to domain enhancements, feature development, and testing.\n\nProvide recommendations for improving processes related to procurement, payables, and receivables.\n\nDrive product enhancements using AI by proposing, analyzing, and implementing AI-driven improvements.\n\nConduct competitive analysis of similar products and suggest enhancements to ensure the product stays competitive.\n\nQualifications:\n\nPreferred: CA / MBA\n\nStrong candidates with other relevant qualifications will also be considered.\n\nAdditional Skills:\n\nStrong analytical and problem-solving abilities.\n\nAbility to understand customer needs and translate them into functional requirements.\n\nExposure to product lifecycle, feature planning, and solutioning is a plus.\n\nInterested candidates may send their CV to View email address on click.appcast.io",
    "url": "https://in.jooble.org/jdp/6194574287435648943?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-01T00:00:00.000Z"
  },
  {
    "title": "Senior Software Engineer \u2013 Python, AWS",
    "company": "EPAM Systems",
    "location": "Pune",
    "salary": "",
    "description": "EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.\n\nWe are currently seeking a Senior Python Developer to join our team for an exciting project that involves designing and building RESTful APIs for seamless communication between different components.\n\nIn this role, you will be responsible for developing and maintaining microservices architecture using containerization tools such as Docker, AWS ECS, and ECR. Additionally, you will be required to demonstrate solutions to cross-functional teams and take ownership of the scope of work for successful project delivery.\n\nRESPONSIBILITIES\n\u2022 Develop and maintain microservices architecture using containerization tools such as Docker, AWS ECS, and ECR\n\u2022 Design and build RESTful APIs for seamless communication between different components\n\u2022 Present and organize demo sessions to demonstrate solutions to cross-functional teams\n\u2022 Collaborate with cross-functional teams for successful project delivery\n\u2022 Take ownership of the scope of work for successful project delivery\n\u2022 Ensure consistency and scalability of applications and dependencies into containers\n\nREQUIREMENTS\n\u2022 5-8 years of experience in software development using Python\n\u2022 Proficient in AWS services such as Lambda, DynamoDB, CloudFormation, and IAM\n\u2022 Strong experience in designing and building RESTful APIs\n\u2022 Expertise in microservices architecture and containerization using Docker, AWS ECS, and ECR\n\u2022 Ability to present and organize demo sessions to demonstrate solutions\n\u2022 Excellent communication skills and ability to collaborate with cross-functional teams\n\u2022 Strong sense of responsibility and ownership over the scope of work\n\nNICE TO HAVE\n\u2022 Experience in DevOps tools such as Jenkins and GitLab for continuous integration and deployment\n\u2022 Familiarity with NoSQL databases such as MongoDB and Cassandra\n\u2022 Experience in data analysis and visualization using Python libraries such as Pandas and Matplotlib\n\nWE OFFER\n\u2022 Opportunity to work on technical challenges that may impact across geographies\n\u2022 Vast opportunities for self-development: online university, knowledge sharing opportunities globally, learning opportunities through external certifications\n\u2022 Opportunity to share your ideas on international platforms\n\u2022 Sponsored Tech Talks & Hackathons\n\u2022 Unlimited access to LinkedIn learning solutions\n\u2022 Possibility to relocate to any EPAM office for short and long-term projects\n\u2022 Focused individual development\n\u2022 Benefit package\n\u2022 Health benefits\n\u2022 Retirement benefits\n\u2022 Paid time off\n\u2022 Flexible benefits\n\u2022 Forums to explore beyond work passion (CSR, photography, painting, sports, etc.)",
    "url": "https://www.epam.com/careers/job-listings/job.epamgdo_blt8203c732d3e6c75d_en-us_Pune_India.senior-software-engineer-python-aws_pune_india?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-10T00:00:00.000Z"
  },
  {
    "title": "Embedded Python Developer",
    "company": "Avatron Industries Private Limited",
    "location": "Pune",
    "salary": "",
    "description": "Urgent requirement for the post of Embedded Python developer at Kharadi, Pune.\n\nMale candidates preferred\n\nTechnical skills-\nPython\nFlask\nStreamlit\nDatabase, SQlite\nPython based web and desktop app development\nFlutter\nArduino and Raspberry pi\nComputer Vision\nElectronics hardware interfacing basics\n\nEducation-\nB.E./B.Tech- Electronics & Telecommunication, Computer, Biomedical Engineer, with above skill sets\n\nIf selected, expected Joining within 7-25 days\n\nJob Type: Full-time\n\nSalary: \u20b920,000.00 - \u20b940,000.00 per month\n\nMore about this Embedded Python Developer job\n\nAvatron Industries Private Limited is aggressively hiring for the job profile of Embedded Python Developer at Pune in Radison Hotel locality. Kindly go through the FAQs below to get all answers related to the given job.\n\n1. How much salary can I expect as a Embedded Python Developer in Avatron Industries Private Limited in Pune?\n\nAns. You can expect a minimum salary of 20,000 INR and can go up to 40,000 INR. The salary offered will depend on your skills, experience and performance in the interview.\n\n2. What is the eligibility criteria to apply for Embedded Python Developer in Avatron Industries Private Limited in Pune?\n\nAns. The candidate should have completed Graduate degree and people who have 0.5 to 31 years are eligible to apply for this job. You can apply for more jobs in Pune to get hired quickly.\n\n3. Is there any specific skill required for this job?\n\nAns. The candidate should have Basic English skills and sound communication skills for this job.\n\n4. Who can apply for this job?\n\nAns. Only Male candidates can apply for this job.\n\n5. Is it a work from home job?\n\nAns. No, it\u2019s not a work from home job and can\u2019t be done online. You can explore and apply for other work from home jobs in Pune at apna.\n\n6. Are there any charges or deposits required while applying for the role or while joining?\n\nAns. No work-related deposit needs to be made during your employment with the company.\n\n7. How can I apply for this job?\n\nAns. Go to the apna app and apply for this job. Click on the apply button and call HR directly to schedule your interview.\n\n8. What is the last date to apply?\n\nAns. The last date to apply for this job is 24-Dec-2025.\n\nFor more details, download apna app and find Full Time jobs in Pune. Through apna, you can find jobs in 74 cities across India. Join NOW!",
    "url": "https://apna.co/job/pune/embedded-python-developer-246329272?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-09T00:00:00.000Z"
  },
  {
    "title": "Python Specialist",
    "company": "Amdocs",
    "location": "Pune",
    "salary": "",
    "description": "Job ID: 206338\nRequired Travel :Minimal\n\nLocation: :[[reqLocation]]\nWho are we?\n\nAmdocs helps those who build the future to make it amazing. With our market-leading portfolio of software products and services, we unlock our customers\u2019 innovative potential, empowering them to provide next-generation communication and media experiences for both the individual end user and enterprise customers. Our employees around the globe are here to accelerate service providers\u2019 migration to the cloud, enable them to differentiate in the 5G era, and digitalize and automate their operations. Listed on the NASDAQ Global Select Market, Amdocs had revenue of $5.00 billion in fiscal 2024. For more information, visit www.amdocs.com\n\nAt Amdocs, our mission is to empower our employees to 'Live Amazing, Do Amazing' every day. We believe in creating a workplace where you not only excel professionally but also thrive personally. Through our culture of making a real impact, fostering growth, embracing flexibility, and building connections, we enable them to live meaningful lives while making a difference in the world.\n\nIn one sentence\n\nResponsible for the design, development, modification, debugging and/or maintenance of software systems. Works on specific modules, applications or technologies, and deals with sophisticated assignments during the software development process.\n\nWhat will your job look like?\n\u2022 Be accountable for and own specific modules within an application and provide technical support and guidance during solution design for new requirements, problem resolution for critical / complex issues while ensuring code is maintainable, scalable and supportable.\n\u2022 Present demos of the software products to partners and internal/external customers, using technical knowledge to influence the direction and evolution of the product/solution.\n\u2022 Investigate issues by reviewing/debugging code and providing fixes (analyzes and fixes bugs) and workarounds, will review changes for operability to maintain existing software solutions, will highlight risks and will help mitigate risks from technical aspects.\n\u2022 Bring continuous improvements/efficiencies to the software or business processes by utilizing software engineering tools and various innovative techniques, and reusing existing solutions. By means of automation, reduces design complexity, reduces time to response, and simplifies the client/end-user experience.\n\u2022 Represent/lead discussions related to product/application/modules/team (for example, leads technical design reviews). Establishes relationships with internal customers/partners\n\nAll you need is...\n\u2022 Bachelor's degree in Science/IT/Computing or equivalent and 7-8 years' experience as a software engineer or a software support engineer.\n\u2022 Awareness of programming concepts and ability to write software code in at least one programming language.\n\nWhy you will love this job:\n\u2022 The chance to serve as a specialist in software and technology.\n\u2022 You will take an active role in technical mentoring within the team.\n\u2022 We provide stellar benefits from health to dental to paid time off and parental leave!\n\nAmdocs is an equal opportunity employer. We welcome applicants from all backgrounds and are committed to fostering a diverse and inclusive workforce",
    "url": "https://jobs.amdocs.com/careers/job/563431010940440-python-specialist-pune-india?domain=amdocs.com&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-09T00:00:00.000Z"
  },
  {
    "title": "Python Development - Internship",
    "company": "Maxgen Technologies Private Limited",
    "location": "Pune",
    "salary": "",
    "description": "About the internship:\nWe are thrilled to announce an exciting opportunity for a Python Development intern at Maxgen Technologies Private Limited! As a talented individual with expertise in CSS, HTML, Django, Machine Learning, REST API, and Python, you will have the chance to work on cutting-edge projects and gain valuable hands-on experience in the tech industry.\n\nKey Responsibilities:\n\n1. Collaborate with the development team to design and implement web applications using Django framework.\n\n2. Utilize your knowledge of CSS and HTML to create visually appealing and user-friendly interfaces.\n\n3. Assist in the integration of Machine Learning algorithms into our software solutions.\n\n4. Develop and maintain RESTful APIs for seamless data communication between different systems.\n\n5. Write clean, efficient, and well-documented Python code to meet project requirements.\n\n6. Participate in code reviews and contribute to the continuous improvement of our development processes.\n\n7. Stay updated on industry trends and technologies to bring fresh ideas and innovation to our team.\n\nIf you are passionate about Python development and eager to learn and grow in a dynamic environment, we want to hear from you! Join us at Maxgen Technologies Private Limited and take your career to new heights. Apply now and unleash your full potential!\n\nWho can apply:\n\nOnly those candidates can apply who:\n\u2022 are available for the part time job/internship\n\u2022 can start the part time job/internship between 13th Dec'25 and 17th Jan'26\n\u2022 are available for duration of 3 months\n\u2022 have relevant skills and interests\n\u2022 are Computer Science Engineering students\n\nStipend:\nINR\u20b9 5,000 - 12,000 /month\n\nDeadline:\n2026-01-12 23:59:59\n\nOther perks:\nCertificate, Letter of recommendation, Flexible work hours, 5 days a week\n\nSkills required:\nHTML, CSS, Python, Django, Machine Learning and REST API\n\nAbout Company:\nMaxgen Technologies Private Limited (MNC) conducts web design & development, SAP professional (FICO, MM, ABAP, and SD), and corporate training in PHP/MySQL, WordPress, ASP.NET, Java framework technology, and Android mobile application. Maxgen Technologies (MNC) also provides web development, e-commerce & SEO (search engine optimization) & maintenance services for existing sites.",
    "url": "https://internshala.com/internship/detail/python-development-internship-in-pune-at-maxgen-technologies-private-limited1765594730?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-13T00:00:00.000Z"
  },
  {
    "title": "Lead Software Engineer (Python, GenAI, LLM)",
    "company": "EPAM Systems",
    "location": "Pune",
    "salary": "",
    "description": "EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.\n\nWe are seeking a skilled Lead Software Engineer to join our team and lead a project focused on developing GenAI applications using Large Language Models (LLMs) and Python programming.\n\nIn this role, you will be responsible for designing and optimizing Al-generated text prompts to maximize effectiveness for various applications. You will also collaborate with cross-functional teams to ensure seamless integration of optimized prompts into the overall product or system. Your expertise in prompt engineering principles and techniques will allow you to guide models to desired outcomes and evaluate prompt performance to identify areas for optimization and iteration.\n\nRESPONSIBILITIES\n\u2022 Design, develop, test and refine AI-generated text prompts to maximize effectiveness for various applications\n\u2022 Ensure seamless integration of optimized prompts into the overall product or system\n\u2022 Rigorously evaluate prompt performance using metrics and user feedback\n\u2022 Collaborate with cross-functional teams to understand requirements and ensure prompts align with business goals and user needs\n\u2022 Document prompt engineering processes and outcomes, educate teams on prompt best practices and keep updated on the latest AI advancements to bring innovative solutions to the project\n\nREQUIREMENTS\n\u2022 7 to 12 years of relevant professional experience\n\u2022 Expertise in Python programming including experience with Al/machine learning frameworks like TensorFlow, PyTorch, Keras, Langchain, MLflow, Promtflow\n\u2022 2-5 years of working knowledge of NLP and LLMs like BERT, GPT-3/4, T5, etc. Knowledge of how these models work and how to fine-tune them\n\u2022 Expertise in prompt engineering principles and techniques like chain of thought, in-context learning, tree of thought, etc\n\u2022 Knowledge of retrieval augmented generation (RAG)\n\u2022 Strong analytical and problem-solving skills with the ability to think critically and troubleshoot issues\n\u2022 Excellent communication skills, both verbal and written in English at a B2+ level for collaborating across teams, explaining technical concepts, and documenting work outcomes\n\nWE OFFER\n\u2022 Opportunity to work on technical challenges that may impact across geographies\n\u2022 Vast opportunities for self-development: online university, knowledge sharing opportunities globally, learning opportunities through external certifications\n\u2022 Opportunity to share your ideas on international platforms\n\u2022 Sponsored Tech Talks & Hackathons\n\u2022 Unlimited access to LinkedIn learning solutions\n\u2022 Possibility to relocate to any EPAM office for short and long-term projects\n\u2022 Focused individual development\n\u2022 Benefit package\n\u2022 Health benefits\n\u2022 Retirement benefits\n\u2022 Paid time off\n\u2022 Flexible benefits\n\u2022 Forums to explore beyond work passion (CSR, photography, painting, sports, etc.)",
    "url": "https://www.epam.com/careers/job-listings/job.epamgdo_blt3c95b5bb35a02a25_en-us_Pune_India.lead-software-engineer-python-genai-llm_pune_india?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-10T00:00:00.000Z"
  },
  {
    "title": "Scientific Coding Physics and Python",
    "company": "People Prime Worldwide",
    "location": "Pune",
    "salary": "",
    "description": "About Company :\n\nOur client is a Palo Alto\u2013based AI infrastructure and talent platform founded in 2018. It helps companies connect with remote software developers using AI-powered vetting and matching technology. Originally branded as the \u201cIntelligent Talent Cloud,\u201denabled companies to \u201cspin up their engineering dream team in the cloud\u201d by sourcing and managing vetted global talent.\n\nIn recent years, they have evolved to support AI infrastructure and AGI workflows, offering services in model training, fine-tuning, and deployment\u2014powered by their internal AI platform, ALAN, and backed by a vast talent network. They reported $300 million in revenue and reached profitability. Their growth is driven by demand for annotated training data from AI labs, including major clients like OpenAI, Google, Anthropic, and Meta.\n\nJob Description :\n\nJob Title : Scientific Coding\n\nLocation : Pan India\n\nExperience : 6+ yrs.\n\nEmployment Type : Contract to hire\n\nWork Mode : Hybrid\n\nNotice Period : - Immediate joiners\n\nRequired Qualifications :\n\u2022 PhD or PhD Candidates in Computational Physics\n\u2022 Has published at least 1 peer-reviewed paper\n\u2022 Advanced proficiency in Python programming for scientific coding is preferred\n\u2022 Excellent analytical, logical thinking, and problem-solving skills\n\u2022 Strong written and verbal communication skills for clear documentation and collaboration",
    "url": "https://in.talent.com/view?id=086ee506a0f1&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-14T00:00:00.000Z"
  },
  {
    "title": "Python Coder",
    "company": "Aceolution",
    "location": "Pune",
    "salary": "",
    "description": "Job Title : Data Engineer \u2013 Python Expert(Freelance Role)\n\nLocation : Remote / Hybrid\n\nEmployment Type : Contract / Freelance\n\nRole Summary\n\nWe are looking for a seasoned Senior Data Engineer to architect, build, and own the data pipelines that power our large language model (LLM) development. As a senior Individual Contributor (IC), you will be the team's expert on data ingestion, processing, and quality for all AI training.\n\nYour primary mission is to build scalable, automated systems that transform massive, raw datasets into pristine, model-ready formats. While your focus will be on data engineering, your expertise will be valued in collaborating on model training runs and experiments. You're the perfect fit if you are a Python expert who thrives on solving large-scale data challenges and enjoys working at the intersection of data engineering and machine learning.\n\nKey Responsibilities\n\nArchitect & Build : Design, develop, and own robust, scalable, and automated ETL / ELT pipelines in Python for ingesting and processing terabyte-scale text datasets.\n\nData Quality : Implement rigorous data cleaning, deduplication, filtering, and normalization strategies. Define and enforce data quality standards to ensure the highest integrity for model training.\n\nData Transformation : Efficiently structure and format diverse datasets (JSON, Parquet, etc.) for consumption by LLM training frameworks.\n\nCollaboration : Work closely with our team of AI researchers and ML engineers to understand data requirements, define metrics, and support the model training lifecycle.\n\nOptimization : Continuously optimize data processing workflows for speed, cost, and reliability.\n\nML Support (Secondary) : Occasionally assist in launching, monitoring, and debugging data-related issues during model training runs.\n\nRequired Qualifications\n\n8+ years of professional experience in data engineering, data processing, or backend software engineering.\n\nExpert-level proficiency in Python and its data ecosystem (e.g., Pandas, NumPy, Dask, Polars).\n\nProven experience building and maintaining large-scale data pipelines.\n\nDeep understanding of data structures, data modeling, and software engineering best practices (Git, CI / CD, testing).\n\nExperience handling and parsing diverse data formats (JSON, CSV, XML, Parquet) at scale.\n\nExcellent problem-solving skills and a meticulous attention to detail.\n\nStrong communication and collaboration skills, with experience working in a team environment.\n\nPreferred Qualifications (Nice-to-Haves)\n\nHands-on experience with the data preprocessing pipeline for an LLM (e.g., LLaMA, BERT, GPT-family).\n\nStrong experience with big data frameworks like Apache Spark or Ray.\n\nExperience with Hugging Face libraries (Transformers, Datasets, Tokenizers).\n\nFamiliarity with ML frameworks like PyTorch or TensorFlow.\n\nProficiency with cloud platforms (AWS, GCP, Azure) and their data / storage services.\n\nWhy Join Us\n\u2022 Opportunity to lead cutting-edge AI and ML projects.\n\u2022 Collaborative and innovative team culture.\n\u2022 Competitive compensation with continuous learning opportunities.\n\n\ud83d\udce9 If you are interested, please share your updated CV to sharmila@aceolution.com along with your expected rate per hour.",
    "url": "https://in.talent.com/view?id=17b941acc622&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-11T00:00:00.000Z"
  },
  {
    "title": "Python Developer with AI and Web Application Integration",
    "company": "Jade Global Software Pvt Ltd",
    "location": "Pune",
    "salary": "",
    "description": "Python AI Integration Developer\nPython AI Integration Developer3\n\nWe are looking for a talented Developer with strong expertise in Python, modern web frameworks, and AI model integration. The ideal candidate will build and integrate scalable web applications with AI/ML components, ensuring seamless interaction between frontend, backend, and intelligent systems.\n\nKey Responsibilities:\n\u2022 Design, develop, and maintain end-to-end web applications using Python (Django/FastAPI/Flask).\n\u2022 Integrate AI and ML models (e.g., OpenAI, LangChain, Hugging Face, TensorFlow, PyTorch) into web applications and APIs.\n\u2022 Build and optimize RESTful APIs for scalable data processing.\n\u2022 Work closely with data scientists and ML engineers to deploy and serve AI models in production.\n\u2022 Implement secure authentication, authorization, and data handling mechanisms.\n\u2022 Optimize applications for performance, scalability, and reliability.\n\u2022 Collaborate with DevOps teams to automate deployment and CI/CD workflows (Docker, Kubernetes, etc.).\n\u2022 Write clean, maintainable, and well-documented code following best practices.\n\nRequired Skills & Experience:\n\u2022 Bachelor's degree or higher in Computer Science or Engineering\n\u2022 5 to 7 years of Strong experience in Python and one or more web frameworks (FastAPI, Django, or Flask).\n\u2022 Hands-on experience with AI/ML model integration and working with APIs from platforms like OpenAI, Anthropic, or Hugging Face.\n\u2022 Proficient in JavaScript/TypeScript.\n\u2022 Solid understanding of database technologies (PostgreSQL, MongoDB, or MySQL).\n\u2022 Experience with API design, testing, and documentation.\n\u2022 Familiarity with containerization and deployment tools (Docker, AWS, Azure, GCP, Kubernetes).\n\u2022 Strong problem-solving skills and ability to work in an agile, collaborative environment.\n\nExperience Level\nSenior Level",
    "url": "https://in.bebee.com/job/ea9cc5e0683537554959923a63b734bf?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-13T00:00:00.000Z"
  },
  {
    "title": "Software Engineer - Java / Python",
    "company": "Global Payments Inc.",
    "location": "Pune",
    "salary": "",
    "description": "Description :\n\nSummary of This Role :\n\nWorks throughout the software development life cycle and performs in a utility capacity to create, design, code, debug, maintain, test, implement and validate applications with a broad understanding of a variety of languages and architectures.\n\nAnalyzes existing applications or formulate logic for new applications, procedures, flowcharting, coding and debugging programs.\n\nMaintains and utilizes application and programming documents in the development of code.\n\nRecommends changes in development, maintenance and system standards.\n\nCreates appropriate deliverables and develops application implementation plans throughout the life cycle in a flexible development environment.\n\nWhat Part Will You Play ?\n\u2022 Develops basic to moderately complex code using a front or back end programming language within a platform as needed in collaboration with business and technology teams for internal and external client software solutions.\n\u2022 Creates, and delivers routine program specifications for code development and support on a project / issue with a moderate understanding of the application / database to better align interactions and technologies.\n\u2022 Analyzes, modifies, and develops basic to moderately complex code / unit testing in order to develop application documentation.\n\u2022 Performs testing and validation requirements for basic to moderately complex code changes.\n\u2022 Performs corrective measures for basic to moderately complex code deficiencies and escalates alternative proposals.\n\u2022 Applies a moderate understanding of procedures, methodology and application standards to include Payment Card Industry (PCI) security compliance.\n\nWhat Are We Looking For in This Qualifications :\n\u2022 BS in Computer Science, Information Technology, Business / Management Information Systems or related field.\n\u2022 Typically minimum of 2 years Professional Experience In Coding, Designing, Developing And Analyzing Data.\n\u2022 Typically has a basic knowledge and use of one or more languages / technologies from the following but not limited to; two or more modern programming languages used in the enterprise, experience working with various APIs, external Services, experience with both relational and NoSQL Databases.\n\nPreferred Qualifications :\n\u2022 BS in Computer Science, Information Technology, Business / Management Information Systems or related field.\n\u2022 4+ years professional Experience In Coding, Designing, Developing And Analyzing Data and experience with IBM Rational Tools.\n\nWhat Are Our Desired Skills and Capabilities? :\n\u2022 Skills / Knowledge Developing professional expertise, applies company policies and procedures to resolve a variety of issues.\n\u2022 Job Complexity Works on problems of moderate scope where analysis of situations or data requires a review of a variety of factors.\n\u2022 Exercises judgment within defined procedures and practices to determine appropriate action.\n\u2022 Builds productive internal / external working relationships.\n\u2022 Supervision Normally receives general instructions on routine work, detailed instructions on new projects or assignments.\n\nOperating Systems :\n\u2022 Linux distributions including one or more for the following : Ubuntu, CentOS / RHEL, Amazon Linux.\n\u2022 Microsoft Windows.\n\u2022 z / OS.\n\u2022 Tandem / HP-Nonstop.\n\u2022 Database Design, familiarity with DDL and DML for one or more of the following databases : Oracle, MySQL, MS SQL Server, IMS, DB2, Hadoop.\n\u2022 Back-end technologies : Java, Python, .NET, Ruby, Mainframe COBOL, Mainframe Assembler.\n\u2022 Front-end technologies : HTML, JavaScript, jQuery, CICS.\n\u2022 Web Frameworks Web technologies like : Node.js, React.js, Angular, Redux.\n\u2022 Development Tools : Eclipse, Visual Studio, Webpack, Babel, Gulp.\n\u2022 Mobile Development : iOS, Android.\n\u2022 Machine Learning : Python, R, Matlab, Tensorflow, DMTK.\n\n(ref : hirist.tech)",
    "url": "https://in.talent.com/view?id=a2ba4717d0ef&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-12T00:00:00.000Z"
  },
  {
    "title": "Python Developer with Snowflake",
    "company": "Gravity Infosolutions, Inc.",
    "location": "Pune",
    "salary": "",
    "description": "As a Python Developer with Snowflake, you will be responsible for designing and developing scalable data pipelines using Python and Snowflake.\n\nYou will work on creating efficient data storage solutions, implementing data visualizations, and ensuring seamless integration with Azure services. Strong proficiency in SQL and Python is required, along with experience in backend development using Fast API and UI development using React.\n\nCandidates with CI/CD experience, familiarity with Agile delivery methodologies, and excellent analytical and problem-solving skills will be preferred. Exposure to data automation and Tableau, as well as experience working in regulated or customer service environments, is also desirable.",
    "url": "https://in.bebee.com/job/2639e317f962d8dba6d12e10c7dfde28?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-11T00:00:00.000Z"
  },
  {
    "title": "Leicester, Le1",
    "company": "Opusclean",
    "location": "Pune",
    "salary": "",
    "description": "Job Ref: IHH-0403\n\n\u00a3529pcm\n\u2022 *Evening Cleaner required. Hill Street, Leicester, LE1 3PT.**\n\u2022 *Monday to Friday for 2.00hrs each day, starting anytime after 3:30pm.**\n\nDuties include vacuuming, mopping, dusting, polishing, emptying bins, cleaning toilets and kitchen areas and any other associated tasks as required.\n\nImmediate start available. Previous cleaning experience required. Locking up if starting later than 3:30pm.\n- Must live locally or have own transport and you must be reliable and able to get to site for the required start time._\n\nCall our Recruitment Line on 0116 239 1803",
    "url": "https://in.trabajo.org/job-3396-2f43fe235bccc6c51785b734f9186bb2?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-10T00:00:00.000Z"
  },
  {
    "title": "Production Executive",
    "company": "Hengyu Cleaning products pvt ltd (Raylong)",
    "location": "Sanaswadi",
    "salary": "",
    "description": "Production Executive:\nAs a Production Executive, you will oversee the planning, coordination, and execution of production processes to ensure timely delivery of high-quality products. You will be responsible for managing production schedules, optimizing workflow efficiency, and maintaining quality standards while adhering to safety protocols. Your role will involve liaising with various departments, including manufacturing, engineering, and quality assurance, to streamline operations and resolve any issues that may arise during production.\n\u2022 *Responsibilities**:\n\n- **Production Planning**: Develop and maintain production schedules to meet customer demands and operational goals. Coordinate with sales and marketing teams to forecast production requirements and ensure adequate inventory levels.\n- **Resource Allocation**: Allocate resources, including manpower, equipment, and materials, efficiently to optimize production output while minimizing costs. Monitor resource utilization and make adjustments as necessary to meet production targets.\n- **Quality Assurance**: Implement and enforce quality control measures to ensure products meet specifications and regulatory standards. Conduct regular inspections and audits of production processes to identify areas for improvement and prevent defects.\n- **Process Optimization**: Identify opportunities to streamline production processes and improve workflow efficiency. Collaborate with engineering and manufacturing teams to implement process improvements and technological advancements.\n\nPay: \u20b912,000.00 - \u20b920,000.00 per month\n\u2022 *Experience**:\n\n- total work: 1 year (preferred)\n\nWork Location: In person",
    "url": "https://in.trabajo.org/job-3396-4ee80f1f9e73b8db547cdd4d34e07bd7?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-10T00:00:00.000Z"
  },
  {
    "title": "Immediately Want Online Python Trainer    in Mumbai  (Job Id: 18826751)",
    "company": "UrbanPro.com",
    "location": "Mumbai",
    "salary": "",
    "description": "I am searching for a tutor who can improve my skills in Python Training. I want to take classes on the internet. The Python Trainer must have a clear and in-depth knowledge of Python Training. I prefer classes to be taken during the day. 100% Remote Job.\n\nJob Location\nOnline\n\nPython Applications interested to learn\nData Extraction with Python , Web Scraping with Python , Web Development with Python , Regular Expressions with Python , Data Science with Python, Automation with Python , Data Analysis with Python\n\nPlan to start Python Training classes\nImmediately\n\nAvailability\nWeekdays",
    "url": "https://jobs.urbanpro.com/mumbai/immediately-want-online-python-trainer-in-ghatkopar-west/60193438?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-13T00:00:00.000Z"
  },
  {
    "title": "Backend Developer with Python",
    "company": "Phygital Insights",
    "location": "Mumbai",
    "salary": "",
    "description": "Full time\n\n|\n\nWork from Office\n\nThis Position is Currently Open\n\nDepartment / Category:\n\nDEVELOPER\n\nListed on Nov 13, 2025\n\nWork Location:\n\nMUMBAI\n\nJob Descritpion of Backend Developer with Python\n\n4-6 Years of Relevant Experience\n\nWe\u2019re looking for an experienced Backend Developer with strong Python expertise to design, develop, and maintain high-performance backend systems and APIs. The ideal candidate will have hands-on experience with Flask, Django, or FastAPI, and the ability to build scalable microservices deployed on Azure Cloud.\n\nThis role is perfect for someone passionate about building efficient, secure, and maintainable backend architectures in a fast-paced, collaborative environment.\n\nKey Responsibilities\n\u2022 Develop, optimize, and maintain RESTful APIs and microservices using Python frameworks like Flask, Django, or FastAPI.\n\u2022 Design and implement robust, scalable backend solutions aligned with business and technical requirements.\n\u2022 Work closely with cross-functional teams to ensure smooth integration with front-end components and data systems.\n\u2022 Deploy, monitor, and maintain applications on Microsoft Azure.\n\u2022 Leverage Azure Data Factory for data integration and orchestration workflows.\n\u2022 Manage and maintain code repositories using Git and follow version control best practices.\n\u2022 Design and integrate SQL and NoSQL databases for backend services.\n\u2022 Write clean, maintainable, and efficient code while adhering to coding standards and best practices.\n\nRequired Skills & Qualifications\n\u2022 4\u20136 years of hands-on experience in backend development using Python.\n\u2022 Strong expertise in Python frameworks: Flask, Django, and FastAPI.\n\u2022 Proven experience in designing and developing RESTful APIs and microservices.\n\u2022 Solid understanding of Azure Cloud, including Azure Data Factory.\n\u2022 Experience with database design and integration (SQL and NoSQL).\n\u2022 Proficiency in Git or other version control tools.\n\u2022 Strong problem-solving, debugging, and optimization skills.\n\u2022 Excellent communication and collaboration abilities.\n\nGood to Have\n\u2022 Familiarity with CI/CD pipelines and containerization (Docker, Kubernetes).\n\u2022 Knowledge of API security and authentication protocols (OAuth, JWT).\n\u2022 Exposure to data processing or ETL workflows.\n\nWhy Join Us\n\u2022 Opportunity to work with cutting-edge technologies and modern cloud infrastructure.\n\u2022 Collaborative and innovative work environment.\n\u2022 Continuous learning and professional growth opportunities.\n\u2022 Competitive compensation and benefits package.\n\nRequired Skills for Backend Developer with Python Job\n\nMicrosoft Azure\n\nPython Web Frameworks\n\nOur Hiring Process\n\u2022 Screening (HR Round)\n\u2022 Technical Round 1\n\u2022 Technical Round 2\n\u2022 Final HR Round",
    "url": "https://www.glassdoor.co.in/job-listing/backend-developer-with-python-phygital-insights-JV_IC2851180_KO0,29_KE30,47.htm?jl=1009938587159&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-13T00:00:00.000Z"
  },
  {
    "title": "Python Developer - Computer Vision & YOLO Specialist",
    "company": "Right Hire Consulting Services",
    "location": "Mumbai",
    "salary": "",
    "description": "About the Role\n\nWe are looking for a skilled Python AI Developer with hands-on experience in Computer Vision, YOLO, and Face Recognition . The candidate will work on developing real-time video analytics solutions, optimizing AI models, and integrating intelligent surveillance features.\n\nKey Responsibilities\n\u2022 Develop, train, and optimize computer vision models using YOLO (v5/v8) for object detection and tracking.\n\u2022 Implement and integrate Face Recognition systems into real-time applications.\n\u2022 Build, fine-tune, and deploy AI/ML models for video analytics and automation workflows.\n\u2022 Work with large video datasets to improve accuracy, speed, and performance.\n\nRequired Skills\n\u2022 Strong proficiency in Python and OpenCV .\n\u2022 Experience with TensorFlow or PyTorch for model training and development.\n\u2022 Practical knowledge of YOLOv5 / YOLOv8 and face recognition libraries.\n\u2022 Understanding of real-time processing pipelines and GPU optimization.\n\nGood to Have\n\u2022 Experience with CCTV, video surveillance, or security analytics .\n\u2022 Familiarity with deployment on edge devices (Jetson, Raspberry Pi) .\n\u2022 Basic knowledge of MLOps or model deployment frameworks.",
    "url": "https://in.jooble.org/jdp/2543963868978755379?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-12T00:00:00.000Z"
  },
  {
    "title": "Senior Python Developer(QA/Deveops)",
    "company": "Uplers",
    "location": "Thane",
    "salary": "",
    "description": "Experience: 4.00 + years\n\nSalary: Confidential (based on experience)\n\nExpected Notice Period: 30 Days\n\nShift: (GMT+05:30) Asia/Kolkata (IST)\n\nOpportunity Type: Remote\n\nPlacement Type: Full Time Contract for 12 Months(40 hrs a week/160 hrs a month)\n\n(*Note: This is a requirement for one of Uplers' client - Global leader in data integrity)\n\nWhat do you need for this opportunity?\n\nMust have skills required:\n\nAI/ML-related Python libraries, cloud platforms, Data Engineering, CI/CD, QA, Test automation, testing frameworks, Git, Python, RESTAPI\n\nGlobal leader in data integrity is Looking for:\n\nSenior Python Developer (QA/DEVOPS)\n\nAbout The Role\n\nWe are seeking an experienced Senior Python Developer to support our engineering team with critical, time-sensitive development work. The ideal candidate will bring deep expertise in the Python ecosystem and hands-on experience building scalable, maintainable systems. They should also have previous experience in DevOps tools and test automation. This is a high-impact, individual contributor role requiring both technical excellence and the ability to work independently in a fast-paced environment.\n\nKey Responsibilities\n\u2022 Design, develop, and maintain robust, scalable applications using Python.\n\u2022 Collaborate with internal teams to understand requirements, develop solutions, and deliver high-quality code.\n\u2022 Utilize the Pydantic ecosystem\u2014particularly Pydantic AI\u2014to define and validate data models and ensure data integrity across applications.\n\u2022 Optimize code for performance, scalability, and maintainability.\n\u2022 Conduct code reviews, troubleshoot complex issues, and mentor junior team members when required.\n\u2022 Contribute to architecture discussions and recommend best practices for Python-based systems.\n\u2022 Contribute to building robust CI/CD pipelines in a distributed architecture\n\u2022 Experience in test automation and continuous improvement tooling.\n\nRequired Skills & Qualifications\n\u2022 4-5 years of hands-on experience in Python development.\n\u2022 2-3 years of hands-on experience in QA and Test Automation\n\u2022 Strong understanding of the Python ecosystem, frameworks, and libraries.\n\u2022 Solid understanding of object-oriented programming, REST APIs, and data validation principles.\n\u2022 Experience with modern development practices including CI/CD, testing frameworks, and version control (Git).\n\u2022 Excellent problem-solving, analytical, and communication skills.\n\u2022 Ability to work independently with minimal supervision.\n\nNice to Have\n\u2022 Experience with AI/ML-related Python libraries or frameworks.\n\u2022 Exposure to data engineering or backend system architecture.\n\u2022 Familiarity with cloud platforms (AWS, GCP, or Azure).\n\nWhy Join Us\n\u2022 Work on impactful projects in a fast-moving environment.\n\u2022 Opportunity to collaborate with a skilled, globally distributed team.\n\u2022 Flexible remote working arrangement.\n\nHow to apply for this opportunity?\n\u2022 Step 1: Click On Apply! And Register or Login on our portal.\n\u2022 Step 2: Complete the Screening Form & Upload updated Resume\n\u2022 Step 3: Increase your chances to get shortlisted & meet the client for the Interview!\n\nAbout Uplers:\n\nOur goal is to make hiring reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant contractual onsite opportunities and progress in their career. We will support any grievances or challenges you may face during the engagement.\n\n(Note: There are many more opportunities apart from this on the portal. Depending on the assessments you clear, you can apply for them as well).\n\nSo, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you!",
    "url": "https://in.linkedin.com/jobs/view/senior-python-developer-qa-deveops-at-uplers-4343273569?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-11T00:00:00.000Z"
  },
  {
    "title": "In Senior Associate Java/python Developer Risk Analytics - Grc Advisory  Mumbai (India)",
    "company": "PwC",
    "location": "Mumbai",
    "salary": "",
    "description": "Line of Service Advisory Industry Sector Not Applicable Specialism Risk Management Level Senior Associate Summary At PwC our people in audit and assurance focus on providing independent and objective assessments of financial statements internal controls and other assurable information enhancing the credibility and reliability of this information with a variety of stakeholders They evaluate compliance with regulations including assessing governance and risk management processes and related controls Those in internal audit at PwC help build optimise and deliver end-to-end internal audit services to clients in all industries This includes IA function setup and transformation co-sourcing outsourcing and managed services using AI and other risk technology and delivery models IA capabilities are combined with other industry and technical expertise in areas like cyber forensics and compliance to address the full spectrum of risks This helps organisations to harness the power of IA to help the organisation protect value and navigate disruption and obtain confidence to take risks to power growth Why PWC At PwC you will be part of a vibrant community of solvers that leads with trust and creates distinctive outcomes for our clients and communities This purpose-led and values-driven work powered by technology in an environment that drives innovation will enable you to make a tangible impact in the real world We reward your contributions support your wellbeing and offer inclusive benefits flexibility programmes and mentorship that will help you thrive in work and life Together we grow learn care collaborate and create a future of infinite experiences for each other Learn more At PwC we believe in providing equal employment opportunities without any discrimination on the grounds of gender ethnic background age disability marital status sexual orientation pregnancy gender identity or expression religion or other beliefs perceived differences and status protected by law We strive to create an environment where each one of our people can bring their true selves and contribute to their personal growth and the firm s growth To enable this we have zero tolerance for any discrimination and harassment based on the above considerations Summary Are you looking for a technically challenging role then we ve one for you We are looking for a seasoned software engineer to design and execute our platform migration from monolithic to microservice based architecture In this role you ll Your main responsibilities You ll be responsible for redesigning the application from present monolithic architecture to microservices based architecture in the most efficient and scalable way You ll be owning the application migration from current platform to data driven streaming platform Responsibilities Autonomous motivated and self-driven A very good team player who can synergize among all relevant stakeholders in the division effectively Passionate to strive for Customer experience and on-time delivery An excellent communicator who can have critical conversations with Peers and other relevant stakeholders articulate and impart knowledge to stakeholders effectively Accountability commitment to deliver quality work ready to embrace challenges Plans Prioritize owns individual group activities effectively Mandatory skill sets Hands on experience in Java 8 Python Hands on experience in designing and developing applications using Spring Guice Hands on experience in Sprint Boot Web service Rest Service Microservice based Architecture Positive understanding of design patterns and should be able to design solutions and algorithms Experience in migrating monolithic application to microservice will be a plus Experience with NoSQL DBs Couchbase MongoDB will be a plus Experience in any Message Queue Kafka knowledge will be a plus Exposure to OpenShift Docker Kubernetes will be a plus Good understanding of NFRs Good understanding of CICD Preferred skill sets Experience in Airline domain is a plus Years of experience required 4 to 9 years of experience in analysis design development of software systems in Java Education Qualification Any Education if blank degree and or field of study not specified Degrees Field of Study required Bachelor Degree Degrees Field of Study preferred Certifications if blank certifications not specified Required Skills Java Optional Skills Accepting Feedback Accepting Feedback Accounting and Financial Reporting Standards Active Listening Analytical Thinking Artificial Intelligence AI Platform Auditing Auditing Methodologies Business Process Improvement Communication Compliance Auditing Corporate Governance Creativity Data Analysis and Interpretation Data Ingestion Data Modeling Data Quality Data Security Data Transformation Data Visualization Embracing Change Emotional Regulation Empathy Financial Accounting Financial Audit 24 more Desired Languages If blank desired languages not specified Travel Requirements Not Specified Available for Work Visa Sponsorship No Government Clearance Required No Job Posting End Date",
    "url": "https://in.jobrapido.com/jobpreview/1334003933613391872?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-13T00:00:00.000Z"
  },
  {
    "title": "Remote Python Engineer",
    "company": "Turing",
    "location": "Navi Mumbai",
    "salary": "",
    "description": "Role Overview:\n\nWe\u2019re looking for experienced Python engineers to collaborate with one of the world\u2019s top Large Language Model (LLM) companies. Your work will directly help improve how AI models think, reason, and code.\n\nIn this role, you\u2019ll generate and evaluate high-quality data used to fine-tune and benchmark LLMs. You\u2019ll design prompts, analyze model outputs, write Python solutions, and provide detailed feedback that guides model improvements. This is a unique opportunity to contribute to the next generation of AI systems\u2014without needing to train or build the models yourself.\n\nWhat You\u2019ll Do:\n\u2022 Write and maintain clean, efficient Python code for AI training and evaluation.\n\u2022 Evaluate and compare model responses as part of RLHF (Reinforcement Learning with Human Feedback).\n\u2022 Create and refine datasets for SFT (Supervised Fine-Tuning).\n\u2022 Develop reasoning-based feedback to enhance model accuracy and alignment.\n\u2022 Collaborate with cross-functional teams to ensure high-quality data and evaluations.\n\nRequirements:\n\u2022 3+ years of strong Python development experience.\n\u2022 Solid understanding of testing, debugging, async programming, and software best practices.\n\u2022 Excellent written and verbal communication in English.\n\nOffer Details:\n\u2022 Commitment: Minimum 20 hrs/week (options for 20, 30, or 40 hrs).\n\u2022 Time Zone: 4-hour overlap with PST.\n\u2022 Contract: 1-month contractor role (no paid leave).\n\nPerks:\n\u2022 Remote & Flexible \u2192 Work from anywhere, on your schedule.\n\u2022 Collaborate with leading LLM and AI research teams.\n\u2022 Work on real-world AI challenges shaping the future of intelligent systems.\n\nAbout Turing:\n\nBased in San Francisco, California, Turing is the world\u2019s leading research accelerator for frontier AI labs and a trusted partner for global enterprises deploying advanced AI systems. Turing supports customers in two ways: first, by accelerating frontier research with high-quality data, advanced training pipelines, plus top AI researchers who specialize in software engineering, logical reasoning, STEM, multilinguality, multimodality, and agents; and second, by applying that expertise to help enterprises transform AI from proof of concept into proprietary intelligence with systems that perform reliably, deliver measurable impact, and drive lasting results on the P&L.\n\nAfter applying, you will receive an email with a login link. Please use that link to access the portal and complete your profile.\n\nKnow amazing talent? Refer them at turing.com/referrals, and earn money from your network.",
    "url": "https://navimumbai.in.expertini.com/job/remote-python-engineer-navi-mumbai-turing-1963-49406659/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-09T00:00:00.000Z"
  },
  {
    "title": "Sr. Python Developer",
    "company": "Wisdom Square Technologies",
    "location": "Thane",
    "salary": "",
    "description": "Sr. Python Developer\n\nWe're looking for an experienced Python Developer to work with our US-based client.\n\u2022 Develop and maintain backend systems using Python frameworks.\n\u2022 Build and optimize REST APIs and microservices.\n\u2022 Collaborate with global teams to deliver high-quality solutions.\n\u2022 Debug, test, and improve application performance.\n\nRequirements:\n\u2022 4+ years of Python development experience.\n\u2022 Strong expertise in Django, Flask, FastAPI.\n\u2022 Good knowledge of databases (PostgreSQL/MySQL), REST APIs, and Git.\n\u2022 Familiar with CI/CD, cloud platforms (AWS/Azure/GCP) is a plus.\n\u2022 Strong communication skills.\n\nWhat We Offer\n\u2022 Competitive salary and performance-based incentives.\n\u2022 Collaborative, growth-focused work culture.\n\u2022 Opportunities for continuous learning and professional development.\n\nThe role involves developing scalable APIs and backend systems. A strong understanding of Python frameworks, databases, and cloud platforms is essential. Good communication skills are also required.",
    "url": "https://in.bebee.com/job/db1a4e67c7a02f9686ac97667fd0452e?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-14T00:00:00.000Z"
  },
  {
    "title": "SQL or Python Developer",
    "company": "HRM Counsel",
    "location": "Dombivli",
    "salary": "",
    "description": "We are looking for an experienced SQL or Python Developer to join our engineering team and help us create dynamic software applications for our clients. In this role, you will be responsible for writing and testing scalable code, developing back-end components, and integrating user-facing elements in collaboration with front-end developers. To be successful as a SQL or Python Developer, you should possess in-depth knowledge of object-relational mapping, experience with server-side logic, and above-average knowledge of Python programming. Ultimately, a top-class SQL or Python Developer is able to design highly responsive web-applications that perfectly meet the needs of the client.\n\nResponsibilities:\n\u2022 Coordinating with development teams to determine application requirements.\n\u2022 Writing scalable code using Python programming language.\n\u2022 Testing and debugging applications.\n\u2022 Developing back-end components.\n\u2022 Integrating user-facing elements using server-side logic.\n\u2022 Assessing and prioritizing client feature requests.\n\u2022 Integrating data storage solutions.\n\u2022 Coordinating with front-end developers.\n\u2022 Reprogramming existing databases to improve functionality.\n\u2022 Developing digital tools to monitor online traffic.\n\nRequirements:\n\u2022 Bachelor's degree in computer science, computer engineering, or related field.\n\u2022 Expert knowledge of Python and related frameworks including Django and Flask.\n\u2022 A deep understanding and multi-process architecture and the threading limitations of Python.\n\u2022 Familiarity with server-side templating languages including Jinja 2 and Mako.\n\u2022 Ability to integrate multiple data sources into a single system.\n\u2022 Familiarity with testing tools.\n\u2022 Ability to collaborate on projects and work independently when required.",
    "url": "https://www.recruit.net/job/sql-python-developer-jobs/0A325D5249589FD9?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-13T00:00:00.000Z"
  },
  {
    "title": "Vice President - Architecture, Data and Python Engineering | Mumbai, IN",
    "company": "JPMorgan Chase & Co.",
    "location": "Mumbai",
    "salary": "",
    "description": "Vice President - Architecture, Data and Python Engineering\n\nJob Description\n\n55ip, a leading fintech firm and part of JPMorgan Chase, empowers financial advisors and enterprise partners to break down barriers to financial progress, improve client outcomes, and grow their business through intelligence, technology, and client experience. Our mission is to set the industry standard by delivering innovative, automated solutions for tax-smart investing, supported by a culture of hustle, collaboration, and a relentless drive for excellence. At 55ip, we are united in delivering better outcomes for our clients, their clients, and the industry.\n\n55ip is seeking a hands-on Senior Vice President for our IT Architecture Group. You will play a key leadership role in designing and scaling our automated tax-smart investing platform, leveraging public cloud (AWS) infrastructure, and driving architectural excellence across domains. This role requires advanced technical expertise, strategic vision, and strong stakeholder management and communication skills. You will be responsible for engaging with cross-functional stakeholders to align technology solutions with business objectives and ensure successful delivery, while maintaining comprehensive architecture documentation and standards.\n\nAs 55ip continues its rapid growth trajectory, we are on the path to managing over $1 trillion in assets under supervision (AUS) by 2030. This scale brings significant challenges and opportunities, including supporting exponential increases in accounts, net flows, revenue, and pre-tax income. Our technology platform must evolve to handle this growth, ensuring robust performance, reliability, and automation for tax-smart investing portfolios across diverse product mixes and client segments.\n\nJob responsibilities:\n\n\u2022 Lead architecture reviews to improve scalability, reliability, and performance on AWS.\n\u2022 Design and optimize domain architectures for business growth and evolving product needs.\n\u2022 Architect and implement distributed, event-driven microservices for investment workflows.\n\u2022 Oversee and enforce architectural standards, documentation, and decision records (ADR).\n\u2022 Develop and optimize high-performance data pipelines and database solutions.\n\u2022 Integrate and evaluate AWS services, Python upgrades, and distributed messaging (Kafka, RabbitMQ, Redis).\n\u2022 Implement and enhance observability solutions for monitoring, logging, and alerting.\n\u2022 Collaborate horizontally with wide feature teams to drive architectural alignment and influence outcomes.\n\u2022 Lead PoC and pilot projects for new platform features, including AI and machine learning initiatives.\n\u2022 Mentor and guide junior engineers, promoting best practices in security, compliance, and cloud-native development.\n\u2022 Identify and remediate technical debt, ensuring robust, scalable, and efficient solutions.\nRequired qualifications, capabilities, and skills:\n\n\u2022 12+ years of hands-on experience in software engineering and architecture.\n\u2022 Advanced proficiency in Python, including performance tuning and automation.\n\u2022 Strong experience with database design, modeling, and optimization (SQL, NoSQL).\n\u2022 Deep expertise in AWS infrastructure and services (EC2, S3, Lambda, RDS, ECS).\n\u2022 Proven track record in designing distributed, event-driven microservices architectures.\n\u2022 Experience with Kafka, RabbitMQ, and Redis for messaging and real-time data processing.\n\u2022 Hands-on experience with data warehouse technologies (Redshift, Snowflake).\n\u2022 Experience with containerization and orchestration (ECS, Fargate, Kubernetes).\n\u2022 Skilled in implementing observability tools and practices (Prometheus, Grafana, Datadog).\n\u2022 Excellent communication skills and ability to create horizontal influence across feature teams.\n\u2022 Experience creating and maintaining architecture documentation and models.\nPreferred qualifications, capabilities, and skills:\n\n\u2022 Python, Database Performance Tuning, AWS, Distributed Event-Driven Microservices Architecture, Collaboration & Influence Across Feature Teams",
    "url": "https://www.efinancialcareers.com/jobs-India-Mumbai-Vice_President_-_Architecture_Data_and_Python_Engineering.id23500920?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-09T00:00:00.000Z"
  },
  {
    "title": "Python developer_Jessica",
    "company": "Coders Brain Technology",
    "location": "Mumbai",
    "salary": "",
    "description": "\u2022 Python Developer Coordinating with development teams to determine application requirements Writing scalable code using Python programming language\n\u2022 Expertise in at least one popular Python framework(like Django or Flask)\n\u2022 The developer must have sound knowledge in Apache Spark and Python programming\n\u2022 Experience in developing data processing/data pipelines tasks using pySpark such as reading data from external sources, merge data, perform data enrichment and load in to target data destinations.\n\u2022 Experience in deployment and operationalizing the code is added advantage\n\u2022 Strong communication skills Advanced oral and written English",
    "url": "https://in.bebee.com/job/7cdd6c4d2f1829c63813888380bb1d30?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-10T00:00:00.000Z"
  },
  {
    "title": "Opportunity for Full Stack Development \u2013 Python (Pune)",
    "company": "Hinduja Tech",
    "location": "Pune",
    "salary": "",
    "description": "Qualifications\n\n- 5-10 years of technical experience in software development, with a significant focus on full stack roles.\n- Proven experience in a leadership or management position, leading a team of 5 or more engineers.\n- Expertise in Python and GoLang for backend development.\n- Solid proficiency in React.js and its ecosystem for front-end development.\n- Extensive experience with relational databases, specifically PostgreSQL.\n- Deep knowledge of AWS cloud services and architecture.\n- Hands-on experience with big data technologies like Apache Hadoop, Apache Spark, and Apache Kafka.\n- Experience with machine learning frameworks, particularly TensorFlow.\n- Familiarity with the Elastic Stack for data logging and analysis.\n- Excellent problem-solving, communication, and interpersonal skills.\n- A bachelor\u2019s or master\u2019s degree in computer science or a related field.\n\nResponsibilities\n\n- Lead and mentor a team of full stack engineers, fostering a culture of technical excellence and collaboration.\n- Architect, design, and develop scalable and robust full stack applications using Python and GoLang for backend services and React.js for front-end development.\n- Manage the entire software development lifecycle, including planning, coding, testing, deployment, and maintenance.\n- Design and manage databases using PostgreSQL, ensuring data integrity and performance.\n- Utilize and manage services on AWS (Amazon Web Services), including EC2, S3, RDS, and others, to deploy and scale applications.\n- Implement and manage data processing pipelines using technologies like Apache Hadoop, Apache Spark, and Apache Kafka.\n- Develop and integrate machine learning models using TensorFlow to enhance application functionality.\n- Build and maintain logging and monitoring systems using the Elastic Stack (Elasticsearch, Logstash, Kibana).\n- Collaborate with product managers, designers, and other stakeholders to translate business requirements into technical solutions.\n- Conduct code reviews and ensure adherence to coding standards, best practices, and security protocols.",
    "url": "https://in.jobrapido.com/jobpreview/8210771591311654912?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-14T00:00:00.000Z"
  },
  {
    "title": "Senior Python Developer \u2013 Vice President \u2013 C13 - Pune",
    "company": "Professional",
    "location": "Pune",
    "salary": "",
    "description": "The Applications Development Technology Lead Analyst is a senior level position responsible for establishing and implementing new or revised application systems and programs in coordination with the Technology team. The overall objective of this role is to lead applications systems analysis and programming activities.\n\nResponsibilities:\n\u2022 Partner with multiple management teams to ensure appropriate integration of functions to meet goals as well as identify and define necessary system enhancements to deploy new products and process improvements\n\u2022 Resolve variety of high impact problems/projects through in-depth evaluation of complex business processes, system processes, and industry standards\n\u2022 Provide expertise in area and advanced knowledge of applications programming and ensure application design adheres to the overall architecture blueprint\n\u2022 Utilize advanced knowledge of system flow and develop standards for coding, testing, debugging, and implementation\n\u2022 Develop comprehensive knowledge of how areas of business, such as architecture and infrastructure, integrate to accomplish business goals\n\u2022 Provide in-depth analysis with interpretive thinking to define issues and develop innovative solutions\n\u2022 Serve as advisor or coach to mid-level developers and analysts, allocating work as necessary\n\u2022 Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency.\n\nQualifications:\n\u2022 9-15 years of relevant experience in Apps Development or systems analysis role\n\u2022 Highly experienced and skilled senior core python developer with 9+ years of experience with software building and platform engineering.\n\u2022 Extensive development expertise in building the high scaled and performant software platforms for data computation and processing.\n\u2022 Expert level knowledge of core python concepts and libraries such as pandas, numpy and scipy and well versed with OOPs concepts and design patterns.\n\u2022 Strong computer science fundamentals in data structures, algorithms, databases and operating systems.\n\u2022 Highly experienced with Unix based operating systems\n\u2022 Strong analytical and logical skills.\n\u2022 Hands-on experience in writing SQL queries.\n\u2022 Experience with source code management tools such as Bitbucket, Git etc\n\u2022 Experience working with banking domain like pricing, risk etc is plus\n\u2022 CFA/FRM certification is plus.\n\u2022 Extensive experience system analysis and in programming of software applications\n\u2022 Experience in managing and implementing successful projects\n\u2022 Subject Matter Expert (SME) in at least one area of Applications Development\n\u2022 Ability to adjust priorities quickly as circumstances dictate\n\u2022 Demonstrated leadership and project management skills\n\u2022 Consistently demonstrates clear and concise written and verbal communication\n\nEducation:\n\u2022 Bachelor\u2019s degree/University degree or equivalent experience\n\u2022 Master\u2019s degree preferred\n\nThis job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.\n\nPython developer with experience in developing python applications with good skills in python libraries for development of Risk and Finance analytical applications that provide sensitive data to senior management. Application involves large volume data computation, analysis and data loads. The candidate must have 8-12 years software development experience in core python with expert level skill set. Should be able to design, review and suggest improvements, guide junior team members and deliver in an agile environment.\n\u2022 Expert level knowledge of core python libraries such as pandas, numpy and scipy and databases\n\u2022 Experience working with high data volumes, computation and processing\n\u2022 Strong computer science fundamentals in data structures, algorithms, databases and operating systems\n\u2022 Experience developing high-performance applications.\n\u2022 Good analytical and logical skills.\n\u2022 Hands experience in writing SQL queries.\n\u2022 Experience with source code management tools such as github, SVN.\n\n------------------------------------------------------\n\nJob Family Group:\nTechnology\n\n------------------------------------------------------\n\nJob Family:\nApplications Development\n\n------------------------------------------------------\n\nTime Type:\nFull time\n\n------------------------------------------------------\n\nMost Relevant Skills\nPlease see the requirements listed above.\n\n------------------------------------------------------\n\nOther Relevant Skills\nFor complementary skills, please see above and/or contact the recruiter.\n\n------------------------------------------------------\n\nCiti is an equal opportunity employer, and qualified candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other characteristic protected by law.\n\nIf you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.\n\nView Citi\u2019s EEO Policy Statement and the Know Your Rights poster.",
    "url": "https://jobs.citi.com/job/pune/senior-python-developer-vice-president-c13-pune/287/88303748768?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-09T00:00:00.000Z"
  },
  {
    "title": "Lead Software Engineer (Combination of strong Java + strong Python Developer) | Pune, IN",
    "company": "Mastercard",
    "location": "Pune",
    "salary": "",
    "description": "Lead Software Engineer (Combination of strong Java + strong Python Developer)\n\nOur Purpose\n\nMastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we're helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.\n\nTitle and Summary\n\nLead Software Engineer (Combination of strong Java + strong Python Developer)\n\nWho is Mastercard\nMastercard is a global technology company in the payments industry. We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible.\nOur mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.\nOur decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.\n\nOrganizational Overview\nMastercard's Reactive Systems Architecture (RSA) team is looking to onboard a lead software engineering to its growing team. RSA allows Application Teams to focus on the functional business requirements, leaving the task of addressing various non-functional requirements to the underlying framework, platform components and infrastructure. The functional business logic layer deals in messages, the delivery of which is an event that invokes some processing on that message. Specific to Mastercard / payment systems these are typically financial messages. The non-functional requirements include, but are not limited to, security, traffic management, infrastructure-independent deployment, scalability, resiliency, high availability, consistent message delivery, delivery auditing, message delivery for failed/absent consumers, application lifecycle management, live/silent mode testing, stateful stream processing, strong consistency, observability, root cause detection and recovery.\nFor developers we aim to provide a single manifest deployment and provisioning experience. This allows our developers to declaratively provision the shared services they need, wherever they need them (on-prem, cloud, edge) in a self-service manner so they can focus on solving real business problems and delivering exceptional value to our customers. Our customers can consume our services with as frictionless of an experience as possible to enable them to get up and running as fast as possible with the security and performance they need.\nAll About You\nAs a Lead Software Engineer, you will be responsible for designing, implementing, and maintaining Messaging systems, Stateful Event Processing systems and to contribute to observability, autonomics and scalability.\nAs a Lead Observability Engineer, you will be responsible for designing, implementing, and maintaining our observability platform. You'll work closely with cross-functional teams to ensure our systems are transparent, measurable, and reliable. By leveraging your expertise in observability tools and techniques, you will help us gain deep insights into our applications, infrastructure, and user experiences.\n\nResponsibilities:\n\u2022 Design and develop robust observability solutions to monitor, analyze, and troubleshoot highly distributed systems, especially message streaming systems, stateful even processing systems\n\u2022 Familiar with OTEL standards and tools.\n\u2022 Previous experience working with application teams to implement \"self-healing\" i.e. alerting that triggers automated remediation.\n\u2022 Implement and configure monitoring, logging, tracing, and alerting systems to ensure comprehensive coverage of our infrastructure and applications.\n\u2022 Collaborate with software engineers to instrument code for telemetry data collection and analysis.\n\u2022 Optimize observability tooling and processes to improve system reliability, performance, and scalability.\n\u2022 Create dashboards, reports, and visualizations to provide actionable insights into system health and performance.\n\u2022 Investigate and resolve incidents by analyzing telemetry data and identifying root causes.\n\u2022 Stay current with industry trends and best practices in observability and recommend improvements to our observability strategy and infrastructure.\n\nQualifications:\n\u2022 Bachelor's degree in computer science, Engineering, or a related field (or equivalent experience).\n\u2022 5-10 years experience as an Observability Engineer or a similar role in a production environment.\n\u2022 Deep understanding of observability principles, methodologies, and tools such as Prometheus, Grafana, Jaeger, ELK stack, etc.\n\u2022 Proficiency in programming/scripting languages like Java, Python, Go, or similar for automation and tooling development.\n\u2022 Strong practical knowledge on messaging systems like Kafka, Flink, MQ\n\u2022 Strong knowledge of cloud computing platforms (AWS preferred) and container orchestration systems (e.g., Kubernetes).\n\u2022 Excellent problem-solving skills and the ability to troubleshoot complex issues in distributed systems.\n\u2022 Strong communication skills and the ability to collaborate effectively with cross-functional teams.\n\nAs a Lead Software Engineer, you will be responsible for designing, implementing, and maintaining Messaging systems, Stateful Event Processing systems and to contribute to observability, autonomics and scalability.\n\nCorporate Security Responsibility\n\nAll activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:\n\n\u2022 Abide by Mastercard's security policies and practices;\n\u2022 Ensure the confidentiality and integrity of the information being accessed;\n\u2022 Report any suspected information security violation or breach, and\n\u2022 Complete all periodic mandatory security trainings in accordance with Mastercard's guidelines.",
    "url": "https://www.efinancialcareers.com/jobs-India-Pune-Lead_Software_Engineer_Combination_of_strong_Java__strong_Python_Developer.id23557434?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-12T00:00:00.000Z"
  },
  {
    "title": "SQL or Python Developer",
    "company": "HRM Counsel",
    "location": "Pune",
    "salary": "",
    "description": "We are looking for an experienced SQL or Python Developer to join our engineering team and help us create dynamic software applications for our clients. In this role, you will be responsible for writing and testing scalable code, developing back-end components, and integrating user-facing elements in collaboration with front-end developers. To be successful as a SQL or Python Developer, you should possess in-depth knowledge of object-relational mapping, experience with server-side logic, and above-average knowledge of Python programming. Ultimately, a top-class SQL or Python Developer is able to design highly responsive web-applications that perfectly meet the needs of the client.\n\nResponsibilities :\n\u2022 Coordinating with development teams to determine application requirements.\n\u2022 Writing scalable code using Python programming language.\n\u2022 Testing and debugging applications.\n\u2022 Developing back-end components.\n\u2022 Integrating user-facing elements using server-side logic.\n\u2022 Assessing and prioritizing client feature requests.\n\u2022 Integrating data storage solutions.\n\u2022 Coordinating with front-end developers.\n\u2022 Reprogramming existing databases to improve functionality.\n\u2022 Developing digital tools to monitor online traffic.\n\nRequirements :\n\u2022 Bachelor's degree in computer science, computer engineering, or related field.\n\u2022 Expert knowledge of Python and related frameworks including Django and Flask.\n\u2022 A deep understanding and multi-process architecture and the threading limitations of Python.\n\u2022 Familiarity with server-side templating languages including Jinja 2 and Mako.\n\u2022 Ability to integrate multiple data sources into a single system.\n\u2022 Familiarity with testing tools.\n\u2022 Ability to collaborate on projects and work independently when required.",
    "url": "https://in.talent.com/view?id=b9a2b65703b3&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-13T00:00:00.000Z"
  },
  {
    "title": "Staff Software Engineer (Java, Python)",
    "company": "Rapid7",
    "location": "Pune",
    "salary": "",
    "description": "Staff Software Engineer (Java, Python)\nAbout the Role\n\nThe Staff Engineer is a recognized leader in the organization, responsible for driving the technical strategy and execution of critical, high-scale systems. This role operates with high technical autonomy, focusing on solving problems that cross team and organizational boundaries and ensuring the platform can scale to meet the company's long-term needs.\n\nIn this role, you will:\n\u2022 Define and drive the multi-year technical roadmap and architecture for a major platform component or domain, anticipating future scaling, performance, and security requirements.\n\u2022 Act as the expert technical consultant and decision-maker for complex architecture choices, balancing trade-offs between performance, cost, and development speed.\n\u2022 Lead the design and implementation of large-scale distributed systems, leveraging expert-level knowledge of Core Java to build robust, high-throughput, and low-latency services.\n\u2022 Identify opportunities for significant architectural simplification or refactoring that materially improves product reliability, developer velocity, or system performance.\n\u2022 Mentor and coach engineers at all levels (SE I through SSE), raising the overall technical bar and promoting best practices across the organization.\n\u2022 Collaborate closely with Product Management and Engineering leadership to translate business objectives into clear, executable technical strategies.\n\nThe skills you\u2019ll bring include:\n\u2022 A minimum of 8+ years experience in software development, with demonstrated mastery of Core Java and its ecosystem, including deep knowledge of distributed systems in a Core Java environment.\n\u2022 Expert-level understanding of the JVM, including advanced garbage collection tuning, memory management, and performance diagnostics.\n\u2022 Proven Ability to work in Python to solve complex problems, or a strong track record of quickly adopting and leveraging new languages/technologies like Python for strategic initiatives, tooling, or data processing.\n\u2022 Extensive experience designing and operating mission-critical services on Cloud Infrastructure such as AWS / GCP / Azure, including experience with infrastructure-as-code (Terraform, CloudFormation).\n\u2022 Deep expertise in architectural patterns for large-scale distributed systems (e.g., event-driven architecture, microservices, consensus protocols, large-scale data storage/processing).\n\u2022 Demonstrated experience leading technical strategy and large, complex projects that span multiple engineering teams.\n\u2022 Exceptional communication and influencing skills, capable of driving consensus on technical decisions across organizational boundaries.\n\u2022 Defines the technical direction for how the organization uses GenAI, ensuring it aligns with long-term product and engineering strategy.\n\u2022 Architects scalable, reusable GenAI integration patterns, frameworks, or platforms that multiple teams can adopt.\n\u2022 A track record of identifying technical debt, proposing solutions, and successfully driving major engineering initiatives to completion.\n\nAbout Rapid7\n\nAt Rapid7, our vision is to create a secure digital world for our customers, our industry, and our communities. We do this by harnessing our collective expertise and passion to challenge what\u2019s possible and drive extraordinary impact. We\u2019re building a dynamic and collaborative workplace where new ideas are welcome.\n\nProtecting 11,000+ customers against bad actors and threats means we\u2019re continuing to push the envelope just like we\u2019 ve been doing for the past 20 years. If you \u2019re ready to solve some of the toughest challenges in cybersecurity, we\u2019re ready to help you take command of your career. Join us.",
    "url": "https://careers.rapid7.com/jobs/staff-software-engineer-java-python-pune-india?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-11T00:00:00.000Z"
  },
  {
    "title": "Python Developer-AI",
    "company": "Quest Global",
    "location": "Pune",
    "salary": "",
    "description": "Job Requirements\n\nAt Quest Global, it\u2019s not just what we do but how and why we do it that makes us different. With over 25 years as an engineering services provider, we believe in the power of doing things differently to make the impossible possible. Our people are driven by the desire to make the world a better place\u2014to make a positive difference that contributes to a brighter future. We bring together technologies and industries, alongside the contributions of diverse individuals who are empowered by an intentional workplace culture, to solve problems better and faster.\n\nWe are seeking an experienced Python Developer to design and develop Windows-based desktop applications involving data processing, visualization, and database interaction. The ideal candidate should have strong Python programming skills, solid knowledge of PostgreSQL, and a good understanding of thermodynamics or applied physics. Experience with engineering, calculation, or simulation tools, and OPC DA communication, will be considered a strong advantage.\n\nRequired Skills and Qualifications:\n\nPython Engineer-\n\u2022 Education: Bachelor\u2019s degree in Computer Science, Engineering, or a related technical field.\n\u2022 Python Experience: 5+ years of professional experience in Python development, focused on application front-ends (GUIs/Web) and API development.\n\u2022 Front-End Expertise: Strong experience in building user interfaces using frameworks like PyQt6 for desktop applications or modern web frameworks (e.g., Django, Flask, FastAPI with templating).\n\u2022 API Development: Proven experience designing, building, and maintaining robust and scalable APIs using Python frameworks such as FastAPI, Flask, or Django Rest Framework (DRF).\n\u2022 Database Knowledge: Strong knowledge of database systems (SQL/NoSQL). Experience with object-relational mappers (ORMs) like SQLAlchemy or Django ORM, and database interaction libraries such as psycopg2.\n\u2022 Core Libraries: Hands-on experience with general-purpose Python libraries for data validation, file handling, and security (e.g., Pydantic, openpyxl, cryptography).\n\u2022 Software Design: Solid understanding of software design patterns, clean architecture principles, and best practices for testing and documentation.\n\nDesired Qualifications (Knowledge of AI):\n\u2022 AI/ML Familiarity: Foundational knowledge of AI/ML concepts and exposure to key frameworks such as TensorFlow, PyTorch, or scikit-learn.\n\u2022 ML Integration: Understanding of how to integrate pre-built machine learning models into production applications via API endpoints.\n\u2022 Version Control & CI/CD: Knowledge of version control systems (e.g., Git) and familiarity with modern CI/CD pipelines for deployment.\n\u2022 Cloud Experience: Familiarity with deploying applications and APIs on cloud platforms like AWS, Azure, or Google Cloud.\n\u2022 Problem Solving: Excellent analytical, debugging, and problem-solving skills.\n\u2022 We are known for our extraordinary people who make the impossible possible every day. Questians are driven by hunger, humility, and aspiration. We believe that our company culture is the key to our ability to make a true difference in every industry we reach. Our teams regularly invest time and dedicated effort into internal culture work, ensuring that all voices are heard.\n\nWe wholeheartedly believe in the diversity of thought that comes with fostering a culture rooted in respect, where everyone belongs, is valued, and feels inspired to share their ideas. We know embracing our unique differences makes us better, and that solving the worlds hardest engineering problems requires diverse ideas, perspectives, and backgrounds. We shine the brightest when we tap into the many dimensions that thrive across over 21,000 difference-makers in our workplace.\n\nWork Experience\n\nPython Engineer-\n\u2022 Education: Bachelor\u2019s degree in Computer Science, Engineering, or a related technical field.\n\u2022 Python Experience: 5+ years of professional experience in Python development, focused on application front-ends (GUIs/Web) and API development.\n\u2022 Front-End Expertise: Strong experience in building user interfaces using frameworks like PyQt6 for desktop applications or modern web frameworks (e.g., Django, Flask, FastAPI with templating).\n\u2022 API Development: Proven experience designing, building, and maintaining robust and scalable APIs using Python frameworks such as FastAPI, Flask, or Django Rest Framework (DRF).\n\u2022 Database Knowledge: Strong knowledge of database systems (SQL/NoSQL). Experience with object-relational mappers (ORMs) like SQLAlchemy or Django ORM, and database interaction libraries such as psycopg2.\n\u2022 Core Libraries: Hands-on experience with general-purpose Python libraries for data validation, file handling, and security (e.g., Pydantic, openpyxl, cryptography).\n\u2022 Software Design: Solid understanding of software design patterns, clean architecture principles, and best practices for testing and documentation.\n\nDesired Qualifications (Knowledge of AI):\n\u2022 AI/ML Familiarity: Foundational knowledge of AI/ML concepts and exposure to key frameworks such as TensorFlow, PyTorch, or scikit-learn.\n\u2022 ML Integration: Understanding of how to integrate pre-built machine learning models into production applications via API endpoints.\n\u2022 Version Control & CI/CD: Knowledge of version control systems (e.g., Git) and familiarity with modern CI/CD pipelines for deployment.\n\u2022 Cloud Experience: Familiarity with deploying applications and APIs on cloud platforms like AWS, Azure, or Google Cloud.\n\u2022 Problem Solving: Excellent analytical, debugging, and problem-solving skills.",
    "url": "https://careers.quest-global.com/global/en/job/P-113457/Python-Developer-AI?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-11T00:00:00.000Z"
  },
  {
    "title": "Senior Python Developers (Machine Learning)",
    "company": "MillionLogics",
    "location": "Pune",
    "salary": "",
    "description": "Company Description\n\nMillionLogics is a trusted Oracle Partner with a global presence, combining innovation, expertise, and strategic vision. Based in London, UK, with a development hub in Hyderabad, India, MillionLogics leverages exceptional technical talent and business foresight to deliver transformative IT solutions. The company specializes in areas such as Data & AI, Cloud Solutions, IT Consulting, and Enterprise Application Optimization. MillionLogics is supported by a team of expert professionals dedicated to delivering tailored, results-driven solutions that empower organizations to adapt and lead in the digital age.\n\nRole Description\n\nWe\u2019re looking for a world-class Python Developer \u2014 someone who lives and breathes code, optimizes for performance, and has proven mastery on competitive programming or data challenge platforms like LeetCode, Codeforces, HackerRank, or Kaggle. This is a pure coding role - where you\u2019ll tackle challenging engineering problems, design scalable systems, and collaborate with leading AI research teams..\n\nWhat You will do\n\u2022 Build, test, and optimize high-performance Python systems used in large-scale AI and data pipelines.\n\u2022 Design and maintain modular, clean, and production-ready Python codebases.\n\u2022 Collaborate with cross-functional teams (data, infra, and research engineers) to deliver reliable backend components.\n\u2022 Write efficient, maintainable, and testable code with strong focus on algorithms and data structures.\n\u2022 Stay current with modern Python tools, frameworks, and best practices.\n\nQualifications\n\u2022 Bachelor\u2019s or Master\u2019s in Computer Science, Software Engineering, or a related field.\n\u2022 4+ years of professional experience writing Python in production environments.\n\u2022 Expert-level proficiency in Python and core libraries (Pandas, NumPy, AsyncIO, FastAPI, or similar).\n\u2022 Proven track record on coding platforms \u2014 e.g., top percentile or strong rating on LeetCode, Codeforces, HackerRank, or Kaggle competitions.\n\u2022 Deep understanding of data structures, algorithms, and problem-solving at scale.\n\u2022 Experience with system design, clean architecture, and performance optimization.\n\u2022 Working level Proficiency in ML / DS\n\nPreferred Qualifications\n\u2022 Strong experience with distributed systems, APIs, or data processing pipelines.\n\u2022 Familiarity with cloud environments (AWS, GCP, or Azure) and CI / CD workflows.\n\u2022 Experience in open-source contributions or building developer tools.\n\u2022 Comfort working in fast-paced, research-driven environments.\n\nNumber of Positions : 20\n\nBonus\n\u2022 Recognized performance in Kaggle, Codeforces, or ICPC / TopCoder contests.\n\u2022 Deep curiosity for performance tuning, scalability, and elegant code design.\n\nPerks of Contracting with MillionLogics\n\u2022 Work fully remotely, from anywhere.\n\u2022 Collaborate with world-class AI labs and frontier research companies.\n\u2022 Tackle real engineering challenges with high autonomy and ownership.\n\nOffer Details\n\u2022 Salary : Competitive\n\u2022 Commitment : Minimum 20 hours / week with 4-hour PST overlap (options : 20, 30, or 40 hrs / week).\n\u2022 Type : Contractor (no medical / paid leave).\n\u2022 Duration : 18 months (start date : immediately).\n\nEvaluation Process (\u224875 mins)\n\u2022 Technical Interview (60 mins) : Deep discussion of Python problem-solving, architecture, and system design.\n\u2022 Onboarding & Culture Fit (15 mins)\n\nHow to Apply\n\u2022 Send your updated CV to careers@millionlogics.com with JOB ID : 5378 or Apply on or visit our careers section www.millionlogics.com / careers.",
    "url": "https://in.talent.com/view?id=d8090416fc8a&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-11T00:00:00.000Z"
  },
  {
    "title": "Python Software Developer (Pune)",
    "company": "Tata Technologies",
    "location": "Pune",
    "salary": "",
    "description": "Position Overview:\nWe are looking for Python Developers with 3+ years of core development experience to build and optimize the Python applications that form the backbone of our AI solution. The ideal candidate will be responsible for writing clean, efficient code, conducting thorough testing, and resolving issues throughout the development lifecycle.\n\nKey Responsibilities:\n\n- Develop, optimize, and maintain Python-based applications supporting our AI solution.\n- Write clean, efficient, and well-documented code following best practices.\n- Build and enhance backend components, APIs, and data processing modules.\n- Conduct unit testing, integration testing, and debugging to ensure high-quality deliverables.\n- Troubleshoot and resolve technical issues that arise during development.\n- Collaborate with AI/ML teams, frontend engineers, and product teams to integrate features seamlessly.\n- Participate in code reviews and contribute to improving development standards and practices.\n- Support performance tuning, scalability improvements, and system optimization efforts.\n\nRequired Skills & Experience:\n\n- 3+ years of hands-on experience in Python development.\n- Strong understanding of core Python concepts (OOP, data structures, multithreading/async programming).\n- Experience with frameworks like Django, Flask, or FastAPI.\n- Solid experience building and consuming RESTful APIs.\n- Knowledge of database systems (SQL or NoSQL) and ORM tools.\n- Familiarity with unit testing frameworks (pytest, unittest).\n- Experience with Git and cooperative development workflows.\n- Understanding of microservices, Docker, or cloud platforms (AWS/Azure/GCP) is a plus.\n- Strong analytical and troubleshooting skills.\n\nEducation:\n\n- Bachelors degree in Computer Science, Engineering, or related field (preferred).",
    "url": "https://in.jobrapido.com/jobpreview/6420984639472533504?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
    "posted_date": "2025-12-09T00:00:00.000Z"
  }
]